<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>10年IT老兵给职场新人的一些建议</title>
    <url>/posts/7b3f0619.html</url>
    <content><![CDATA[<div id="vip-container"><p>2020年04年01，对我来说一个非常值得纪念的日子，因为10年前的今天我从一个<strong>普通二类本科</strong>的大学毕业生正式步入职场，开启了我人生的新篇章。</p>
<p>经过10年的成长，我从一个青涩少年依然蜕变为一个“中年大叔”了，也取得了一定的成绩，为了突破“中年危机”，将持续努力。</p>
<p>首先先来一个自我介绍：丁威，《RocketMQ技术内幕》作者、『中间件兴趣圈』公众号维护者、2019年RocketMQ社区优秀布道师评选斩获第一名、2019年度CSDN博客之星TOP10获得者，目前就任中通科技技术平台部担任资深架构师，负责消息中间件与全链路压测在科技中心的落地与实施工作。</p>
<a id="more"></a>

<p>回想这10年的工作经历，我个人觉得有很多点可以和大家一起来分享分享。</p>
<p>首先我职业生涯的前面四年，是呆在一家国企控股公司，主要从事的业务是电子政务方面的业务，是一个传统行业，虽然我很努力，解决工作中的问题显得得心应手，在公司所在的部门也能得到领导的赏识、同事们的认可，但受限于所在平台的局限性以及公司的规模，薪资无法得到较大幅度的提升，萌生了离开的想法。但让我所料不及的是我满怀信心去找工作的时候让我备受打击，阿里系企业直接将我秒杀，诸如HashMap的内存结构是什么？HashMap为什么不是线程安全的，什么大数据、高并发这些场景更是连想都没有相关，后面就选择一家外部公司，开始了探究互联网相关的技能。</p>
<p><strong>回想这段经验，我有如下感悟与建议</strong><br><strong>1、第一份工作真的很重要，如果有好的学历背景，找工作时不能将就。</strong><br><strong>2、如果没有好的学历背景，也无需气馁，要一开始就为自己树立一个远大的目标：一定要凭着自己的努力，励志要进入一线互联网企业。</strong><br><strong>3、有了目标，在工作的第一年主要还是要扩大知识面，点到为止，以便功能好的完成工作，进入工作第二年后，就要开始打牢基础，探究原理，快速成长。</strong></p>
<p>那如何打牢基础，探究原理，快速成长呢？</p>
<p>在经过阿里系面试打击后，我决定先离开工作了4年的环境，寻找了一家有机会接触互联网相关技术的公司，开始打拼，这个时候，在完成工作的情况下，我会利用业余时间进行学习，越努力越幸运，我的运气还不错，认识了MyCat社区的负责人，为我指明了方向，融入开源社区，但那个时候的我发现我无看懂MyCat的源码，也就无法深层次参与其开源建设，那如何破解。</p>
<p>后面痛定思痛，既然没有能力看懂MyCat源码，那就从JAVA的基础开始，故与2016年9月正式开通CSDN博客，从源码分析Java集合、JUC(Java并发包)、Java NIO、Netty，经过了半年源码研究分析，基础终于打牢，一鼓作气在CSDNS上发表了源码分析MyCat专栏，并且还对MyCat开源社区贡献过代码，在MyCat形成了一定的社区影响力。</p>
<p>正式由于在MyCat社区活跃的表现，终于迎来职业生涯一个非常重要的转折点：一家公司在生产环境大规模使用MyCat，但缺乏专业人士对其进行维护，故通过MyCat社区的介绍，我正式入职该公司，从此正式进入亿级数据规模，我所学的知识终于有了用武之地，而且能应付自如，在一家拥有300号人的科技公司崭露头角。</p>
<p><strong>回顾这段经验，有如下感悟我觉得可以分享一下。<br>如果当我们没有一个好的平台，无法接触高并发，大数据这样的场景时，我们该如何破解，无需气馁，努力学习高并发、大数据相关的基础知识，例如Java并发、Netty网络，各主流中间件的原理、以及JVM诊断的理论基础，相信总会有伯乐找到你，让你的能力得到施展。</strong></p>
<p>在成功进入好的平台后，不能松懈，继续在工作之余学习了互联网架构中中主流的中间件，陆续发表了源码研究RocketMQ、Dubbo、ElasticJob等专栏。越努力越幸运，由于源码分析RocketMQ专栏总共发表了40余篇，成体系的剖析了RocketMQ的实现原理，被出版社相中，邀请我出书，最终成功出版了《RocketMQ技术内幕》一书，并且获得了广大读者朋友一致好评，并受我其中一个读者的邀请，最终入职了中通科技，进入更加广阔的平台，继续努力打拼。</p>
<p><strong>这段建议给我的感悟就是：越努力越幸运，唯有坚持不懈。</strong></p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>程序人生</category>
      </categories>
      <tags>
        <tag>程序人生</tag>
        <tag>职场感悟</tag>
      </tags>
  </entry>
  <entry>
    <title>10年IT老兵给职场新人的一些建议</title>
    <url>/posts/7b3f0619.html</url>
    <content><![CDATA[<div id="vip-container"><p>2020年04年01，对我来说一个非常值得纪念的日子，因为10年前的今天我从一个<strong>普通二类本科</strong>的大学毕业生正式步入职场，开启了我人生的新篇章。</p>
<p>经过10年的成长，我从一个青涩少年依然蜕变为一个“中年大叔”了，也取得了一定的成绩，为了突破“中年危机”，将持续努力。</p>
<p>首先先来一个自我介绍：丁威，《RocketMQ技术内幕》作者、『中间件兴趣圈』公众号维护者、2019年RocketMQ社区优秀布道师评选斩获第一名、2019年度CSDN博客之星TOP10获得者，目前就任中通科技技术平台部担任资深架构师，负责消息中间件与全链路压测在科技中心的落地与实施工作。</p>
<a id="more"></a>

<p>回想这10年的工作经历，我个人觉得有很多点可以和大家一起来分享分享。</p>
<p>首先我职业生涯的前面四年，是呆在一家国企控股公司，主要从事的业务是电子政务方面的业务，是一个传统行业，虽然我很努力，解决工作中的问题显得得心应手，在公司所在的部门也能得到领导的赏识、同事们的认可，但受限于所在平台的局限性以及公司的规模，薪资无法得到较大幅度的提升，萌生了离开的想法。但让我所料不及的是我满怀信心去找工作的时候让我备受打击，阿里系企业直接将我秒杀，诸如HashMap的内存结构是什么？HashMap为什么不是线程安全的，什么大数据、高并发这些场景更是连想都没有相关，后面就选择一家外部公司，开始了探究互联网相关的技能。</p>
<p><strong>回想这段经验，我有如下感悟与建议</strong><br><strong>1、第一份工作真的很重要，如果有好的学历背景，找工作时不能将就。</strong><br><strong>2、如果没有好的学历背景，也无需气馁，要一开始就为自己树立一个远大的目标：一定要凭着自己的努力，励志要进入一线互联网企业。</strong><br><strong>3、有了目标，在工作的第一年主要还是要扩大知识面，点到为止，以便功能好的完成工作，进入工作第二年后，就要开始打牢基础，探究原理，快速成长。</strong></p>
<p>那如何打牢基础，探究原理，快速成长呢？</p>
<p>在经过阿里系面试打击后，我决定先离开工作了4年的环境，寻找了一家有机会接触互联网相关技术的公司，开始打拼，这个时候，在完成工作的情况下，我会利用业余时间进行学习，越努力越幸运，我的运气还不错，认识了MyCat社区的负责人，为我指明了方向，融入开源社区，但那个时候的我发现我无看懂MyCat的源码，也就无法深层次参与其开源建设，那如何破解。</p>
<p>后面痛定思痛，既然没有能力看懂MyCat源码，那就从JAVA的基础开始，故与2016年9月正式开通CSDN博客，从源码分析Java集合、JUC(Java并发包)、Java NIO、Netty，经过了半年源码研究分析，基础终于打牢，一鼓作气在CSDNS上发表了源码分析MyCat专栏，并且还对MyCat开源社区贡献过代码，在MyCat形成了一定的社区影响力。</p>
<p>正式由于在MyCat社区活跃的表现，终于迎来职业生涯一个非常重要的转折点：一家公司在生产环境大规模使用MyCat，但缺乏专业人士对其进行维护，故通过MyCat社区的介绍，我正式入职该公司，从此正式进入亿级数据规模，我所学的知识终于有了用武之地，而且能应付自如，在一家拥有300号人的科技公司崭露头角。</p>
<p><strong>回顾这段经验，有如下感悟我觉得可以分享一下。<br>如果当我们没有一个好的平台，无法接触高并发，大数据这样的场景时，我们该如何破解，无需气馁，努力学习高并发、大数据相关的基础知识，例如Java并发、Netty网络，各主流中间件的原理、以及JVM诊断的理论基础，相信总会有伯乐找到你，让你的能力得到施展。</strong></p>
<p>在成功进入好的平台后，不能松懈，继续在工作之余学习了互联网架构中中主流的中间件，陆续发表了源码研究RocketMQ、Dubbo、ElasticJob等专栏。越努力越幸运，由于源码分析RocketMQ专栏总共发表了40余篇，成体系的剖析了RocketMQ的实现原理，被出版社相中，邀请我出书，最终成功出版了《RocketMQ技术内幕》一书，并且获得了广大读者朋友一致好评，并受我其中一个读者的邀请，最终入职了中通科技，进入更加广阔的平台，继续努力打拼。</p>
<p><strong>这段建议给我的感悟就是：越努力越幸运，唯有坚持不懈。</strong></p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>程序人生</category>
      </categories>
      <tags>
        <tag>程序人生</tag>
        <tag>职场感悟</tag>
      </tags>
  </entry>
  <entry>
    <title>Alibaba Sentinel 限流与熔断初探(技巧篇)</title>
    <url>/posts/84defd78.html</url>
    <content><![CDATA[<div id="vip-container"><blockquote>
<p>温馨提示：源码分析 Alibaba Sentinel 专栏开始连载，本文展示如何学习一个全新的技术的方法。该专栏基于 1.7.0 版本。</p>
</blockquote>
<p>在学习一个新技术或新框架时，建议先查看其官方文档， Sentinel 官方文档链接如下：<a href="https://github.com/alibaba/Sentinel/wiki/%E4%BB%8B%E7%BB%8D">官方文档</a>，以获得对其形成一个整体的认识。</p>
<h2 id="1、Sentinel-是什么-？主要能解决什么问题？"><a href="#1、Sentinel-是什么-？主要能解决什么问题？" class="headerlink" title="1、Sentinel 是什么 ？主要能解决什么问题？"></a>1、Sentinel 是什么 ？主要能解决什么问题？</h2><p>按照官方的定义，Sentinel 意为分布式系统的流量防卫兵，主要提供限流、熔断等服务治理相关的功能。</p>
<p>服务的动态注册、服务发现是 SOA、微服务架构体系中首先需要解决的基本问题，服务治理是 SOA 领域又一重要课题，而 dubbo 框架只提供了一些基本的服务治理能力，例如限制服务并发调用数、配置合适的业务线程数量等，但熔断相关的功能就涉及的较少。</p>
<p>Sentinel 将作为 Dubbo 生态的重要一员，将集中解决服务治理相关的课题，服务限流与熔断又是服务治理首先要解决的课题。</p>
<p>那什么是限流与熔断呢？</p>
<p>限流：我们通常使用TPS对流量来进行描述，限流就是现在服务被调用的并发TPS，从而对系统进行自我保护。</p>
<p>熔断：就是当系统中某一个服务出现性能瓶颈是，对这个服务的调用进行快速失败，避免造成连锁反应，从而影响整个链路的调用。</p>
<h2 id="2、限流与熔断的使用场景"><a href="#2、限流与熔断的使用场景" class="headerlink" title="2、限流与熔断的使用场景"></a>2、限流与熔断的使用场景</h2><p>限流还是比较好理解，例如一个项目在上线之前经过性能测试评估，例如服务在 TPS 达到 1w/s 时系统资源利用率飙升，与此同时响应时间急剧增大，那我们就要控制该服务的调用TPS，超过该 TPS 的流量就需要进行干预，可以采取拒绝、排队等策略，实现流量的削峰填谷。</p>
<p>还有一个场景，例如一下开放平台，对接口进行收费，免费用户要控制调用TPS，账户的等级不同，允许调用的TPS也不同，这种情况就非常适合限流。</p>
<p>那熔断的使用场景呢？我们首先来看一下如下的分布式架构。<br><img src="https://img-blog.csdnimg.cn/20191214230343989.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>例如应用A 部署了3台机器，如果由于某种原因，例如线程池 hold 住，导致发送到它上面的请求会出现超时而报错，由于该进程并未宕机，请求还是会通过负载算法请求出现故障的机器，出现整个1/3的请求出现超时报错，影响整个系统的可用性？也就是其中一台故障会对整个服务质量产生严重的影响，虽然是集群部署，但无法达到高可用性。那如何解决该问题？如果在调用方(API-Center) 对异常进行统计，发现发往某一台机器的错误数或错误率达到设定的值，就在一定的世界间隔内不继续发往该机器，转而发送给集群内正常的节点，这样就实现了高可用，这就是所谓的熔断机制。</p>
<p>有了上面的基本认识，接下来会进行一些阅读源码的准备，为后面的源码分析 Sentinel 打下坚实的基础。</p>
<a id="more"></a>

<h2 id="3、Sentinel-源码结构"><a href="#3、Sentinel-源码结构" class="headerlink" title="3、Sentinel 源码结构"></a>3、Sentinel 源码结构</h2><p><img src="https://img-blog.csdnimg.cn/20191214230725995.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>Sentinel 的核心模块说明如下：</p>
<ul>
<li><p>sentinel-core<br>Sentinel 核心模块，实现限流、熔断等基本能力。</p>
</li>
<li><p>sentinel-dashboard<br>Sentinel 可视化控制台，提供基本的管理界面，配置限流、熔断规则等，展示监控数据等。</p>
</li>
<li><p>sentinel-adapter<br>Sentinel 适配，Sentinel-core 模块提供的是限流等基本API，主要是提供给应用自己去显示调用，对代码有侵入性，故该模块对主流框架进行了适配，目前已适配的模块如下：</p>
<ul>
<li>sentinel-apache-dubbo-adapter<br>对 Apache Dubbo 版本进行适配，这样应用只需引入 sentinel-apache-dubbo-adapter 包即可对 dubbo 服务进行流控与熔断，大家可以思考会利用 Dubbo 的哪个功能特性。</li>
<li>sentinel-dubbo-adapter<br>对 Alibaba Dubbo 版本进行适配。</li>
<li>sentinel-grpc-adapter<br>对 GRPC 进行适配。</li>
<li>sentinel-spring-webflux-adapter<br>对响应式编程框架 webflux 进行适配。</li>
<li>sentinel-web-servlet<br>对 servlet 进行适配，例如 Spring MVC。</li>
<li>sentinel-zuul-adapter<br>对 zuul 网关进行适配。</li>
</ul>
</li>
<li><p>sentinel-cluster<br>提供集群模式的限流与熔断支持，因为通常一个应用会部署在多台机器上组成应用集群。</p>
</li>
<li><p>sentinel-transport<br>网络通讯模块，提供 Sentinel 节点与 sentinel-dashboard 的通讯支持，主要有如下两种实现。</p>
<ul>
<li>sentinel-transport-netty-http<br>基于 Netty 实现的 http 通讯模式。</li>
<li>sentinel-transport-simple-http<br>简单的 http 实现方式。</li>
</ul>
</li>
<li><p>sentinel-extension<br>Sentinel 扩展模式。主要提供了如下扩展(高级)功能：</p>
<ul>
<li>sentinel-annotation-aspectj<br>提供基于注解的方式来定义资源等。</li>
<li>sentinel-parameter-flow-control<br>提供基于参数的限流（热点限流）。</li>
<li>sentinel-datasource-extension<br>限流规则、熔断规则的存储实现，默认是存储在内存中。</li>
<li>sentinel-datasource-apollo<br>基于 apollo 配置中心实现限流规则、熔断规则的存储，动态推送生效机制。</li>
<li>sentinel-datasource-consul<br>基于 consul 实现限流规则、熔断规则的存储，动态推送生效机制。</li>
<li>sentinel-datasource-etcd<br>基于 etcd 实现限流规则、熔断规则的存储，动态推送生效机制。</li>
<li>sentinel-datasource-nacos<br>基于 nacos 实现限流规则、熔断规则的存储，动态推送生效机制。</li>
<li>sentinel-datasource-redis<br>基于 redis 实现限流规则、熔断规则的存储，动态推送生效机制。</li>
<li>sentinel-datasource-spring-cloud-config<br>基于 spring-cloud-config 实现限流规则、熔断规则的存储，动态推送生效机制。</li>
<li>sentinel-datasource-zookeeper<br>基于 zookeeper 实现限流规则、熔断规则的存储，动态推送生效机制。</li>
</ul>
</li>
</ul>
<h2 id="4、在-IntelliJ-IDEA-中运行-Sentine-Demo"><a href="#4、在-IntelliJ-IDEA-中运行-Sentine-Demo" class="headerlink" title="4、在 IntelliJ IDEA 中运行 Sentine Demo"></a>4、在 IntelliJ IDEA 中运行 Sentine Demo</h2><p>在 sentinel-demo 模块下提供了很多示例，Seninel 一开始是为 Dubbo 而生的，故我们选取一下 sentinel-demo-apache-dubbo 为本次演示的示例。</p>
<p>注意：该版本需要引入的 apache dubbo 版本需要修改为 2.7.2。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.dubbo<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>dubbo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>Step1：先启动 sentinel-dashboard，启动参数配置如下：<br><img src="https://img-blog.csdnimg.cn/20191214230758222.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>sentinel-demo-apache-dubbo 模块如下所示：<br><img src="https://img-blog.csdnimg.cn/20191214230836334.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>先启动服务提供者，其配置参数如下：<br><img src="https://img-blog.csdnimg.cn/20191214230902547.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>然后启动服务消费者，其配置参数如下：<br><img src="https://img-blog.csdnimg.cn/20191214230924603.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>启动后，我们能看到消费者会出现报错，因为触发了限流，我们可以通过控制台查看接入应用的信息，例如输入：<a href="http://localhost:8080/">http://localhost:8080</a></p>
<p>部分截图如下：<br><img src="https://img-blog.csdnimg.cn/20191214231003110.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191214231019623.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>可以在控制台动态添加限流、熔断等规则配置，然后接入的客户端将能在不启动应用的情况下生效。</p>
<p>默认情况下，sentinel-dashboard 中的规则是存储在内存中，重启后就会丢失，因此 Sentinel 提供了很多种数据源的实现，例如 sentinel-datasource-zookeeper，这部分内容随着该专栏的陆续更新，将会对该机制进行介绍。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>限流</tag>
        <tag>熔断</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka与RocketMQ性能对比大揭秘</title>
    <url>/posts/b9e3e3ee.html</url>
    <content><![CDATA[<div id="vip-container"><p>在双十一过程中投入同样的硬件资源，Kafka 搭建的日志集群单个Topic可以达到几百万的TPS，而使用RocketMQ组件的核心业务集群，集群TPS只能达到几十万TPS，这样的现象激发了我对两者性能方面的思考。</p>
<blockquote>
<p>温馨提示：TPS只是众多性能指标中的一个，我们在做技术选型方面要从多方面考虑，本文并不打算就消息中间件选型方面投入太多笔墨，重点想尝试剖析两者在性能方面的设计思想。</p>
</blockquote>
<a id="more"></a>

<h2 id="1、文件布局"><a href="#1、文件布局" class="headerlink" title="1、文件布局"></a>1、文件布局</h2><h3 id="1-1-Kafka-文件布局"><a href="#1-1-Kafka-文件布局" class="headerlink" title="1.1 Kafka 文件布局"></a>1.1 Kafka 文件布局</h3><p>Kafka 文件在宏观上的布局如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201130220311325.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>正如上图所示，Kafka 文件布局的主要特征如下：</p>
<p>文件的组织以 topic + 分区进行组织，每一个 topic 可以创建多个分区，每一个分区包含单独的文件夹，并且是多副本机制，即 topic 的每一个分区会有 Leader 与 Follow，<strong>并且 Kafka 内部有机制保证 topic 的某一个分区的 Leader 与 follow 不会存在在同一台机器，并且每一台 broker 会尽量均衡的承担各个分区的 Leader</strong>，当然在运行过程中如果不均衡，可以执行命令进行手动重平衡。Leader 节点承担一个分区的读写，follow 节点只负责数据备份。</p>
<p>Kafka 的负载均衡主要依靠分区 Leader 节点的分布情况。</p>
<p>分区的 Leader 节点负责读写，而从节点负责数据同步，如果Leader分区所在的Broker节点发生宕机，会触发主从节点的切换，会在剩下的 follow 节点中选举一个新的 Leader 节点，其数据的流入流程如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201130220357452.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>分区 Leader 收到客户端的消息发送请求时，是写入到 Leader 节点后就返回还是要等到它的从节点全部写入后再返回，这里非常关键，会直接影响消息发送端的时延，故 Kafka 提供了 ack 这个参数来进行策略选择：</p>
<ul>
<li><p>ack = 0</p>
<p>不等broker端确认就直接返回，即客户端将消息发送到网络中就返回发送成功。</p>
</li>
<li><p>ack = 1</p>
<p>Leader 节点接受并存储后向客户端返回成功。</p>
</li>
<li><p>ack = -1<br>Leader节点和所有的Follow节点接受并成功存储再向客户端返回成功。</p>
</li>
</ul>
<h3 id="1-2-RocketMQ-文件布局"><a href="#1-2-RocketMQ-文件布局" class="headerlink" title="1.2 RocketMQ 文件布局"></a>1.2 RocketMQ 文件布局</h3><p>RocketMQ 的文件布局如下图所示：<br><img src="https://img-blog.csdnimg.cn/2020113022041578.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>RocketMQ 所有主题的消息都会写入到 commitlog 文件中，然后基于 commitlog 文件构建消息消费队列文件(Consumequeue)，消息消费队列的组织结构按照 /topic/{queue} 进行组织。从集群的视角来看如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201130220429439.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>RocketMQ 默认采取的是主从同步，当然从RocketMQ4.5引入了多副本机制，但其<strong>副本的粒度为 Commitlog 文件</strong>，上图中不同 master 节点之间的数据完成不一样（数据分片），而主从节点节点数据一致。</p>
<h3 id="1-3-文件布局对比"><a href="#1-3-文件布局对比" class="headerlink" title="1.3 文件布局对比"></a>1.3 文件布局对比</h3><p>Kafka 中文件的布局是以 Topic/partition ，每一个分区一个物理文件夹，在<strong>分区文件级别实现文件顺序写</strong>，如果一个Kafka集群中拥有成百上千个主题，每一个主题拥有上百个分区，消息在高并发写入时，其IO操作就会显得零散，其操作相当于随机IO，<strong>即 Kafka 在消息写入时的IO性能会随着 topic 、分区数量的增长，其写入性能会先上升，然后下降</strong>。</p>
<p>而 RocketMQ在消息写入时追求极致的顺序写，所有的消息不分主题一律顺序写入 commitlog 文件，并不会随着 topic 和 分区数量的增加而影响其顺序性。但通过笔者的实践来看一台物理机并使用SSD盘，但一个文件无法充分利用磁盘IO的性能。</p>
<p>两者文件组织方式，除了在磁盘的顺序写方面有所区别后，由于其粒度的问题，Kafka 的 topic 扩容分区会涉及分区在各个 Broker 的移动，其扩容操作比较重，而 RocketMQ 数据存储是基于 commitlog 文件的，扩容时不会产生数据移动，只会对新的数据产生影响，RocketMQ 的运维成本对 Kafka 更低。</p>
<p>最后 Kafka 的 ack 参数可以类比 RocketMQ 的同步复制、异步复制。</p>
<p>Kafka 的 ack 参数为 1 时，对比 RocketMQ 的异步复制； -1 对标 RocketMQ 的 同步复制，而 -1 则对标 RocketMQ 消息发送方式的 oneway 模式。</p>
<h2 id="2、数据写入方式"><a href="#2、数据写入方式" class="headerlink" title="2、数据写入方式"></a>2、数据写入方式</h2><h3 id="2-1-Kafka-消息写入方式"><a href="#2-1-Kafka-消息写入方式" class="headerlink" title="2.1 Kafka 消息写入方式"></a>2.1 Kafka 消息写入方式</h3><p>Kafka 的消息写入使用的是 FileChannel，其代码截图如下：<br><img src="https://img-blog.csdnimg.cn/20201130220453340.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>并且在消息写入时使用了 transferTo 方法</strong>，根据网上的资料说 NIO 中网络读写真正是零拷贝的就是需要调用 FileChannel 的 transferTo或者 transferFrom 方法，其内部机制是利用了 sendfile 系统调用。</p>
<h3 id="2-2-RocketMQ-消息写入方式"><a href="#2-2-RocketMQ-消息写入方式" class="headerlink" title="2.2 RocketMQ 消息写入方式"></a>2.2 RocketMQ 消息写入方式</h3><p>RocketMQ 的消息写入支持 内存映射 与 FileChannel 写入两种方式， 示例如下图所示：<br><img src="https://img-blog.csdnimg.cn/2020113022052734.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="2-3-消息写入方式对比"><a href="#2-3-消息写入方式对比" class="headerlink" title="2.3 消息写入方式对比"></a>2.3 消息写入方式对比</h3><p>尽管 RocketMQ 与 Kafka 都支持 FileChannel 方式写入，但 RocketMQ 基于 FileChannel 写入时调用的 API 却并不是 transferTo，而是先调用 writer，然后定时 flush 刷写到磁盘，其代码截图如下：<br><img src="https://img-blog.csdnimg.cn/20201130220540388.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>为什么 RocketMQ 不调用 transerTo 方法呢，个人觉得和 RocketMQ 需要在 Broker 组装 MQ 消息格式有关，需要从网络中解码请求，传输到堆内存，然后对消息进行加工，最终持久化到磁盘相关。</p>
<p>从网上查询资料中大概倾向于这样一个 观点：sendfile 系统调用相比内存映射多了一次从用户缓存区拷贝到内核缓存区，但对于超过64K的内存写入时往往 sendfile 的性能更高，可能是由于 sendfile 是基于块内存的。</p>
<h2 id="3、消息发送方式"><a href="#3、消息发送方式" class="headerlink" title="3、消息发送方式"></a>3、消息发送方式</h2><h3 id="3-1-Kafka-消息发送机制"><a href="#3-1-Kafka-消息发送机制" class="headerlink" title="3.1 Kafka 消息发送机制"></a>3.1 Kafka 消息发送机制</h3><p>Kafka 在消息发送客户端采用了一个双端队列，引入了批处理思想，其消息发送机制如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201130220558530.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>客户端通过调用 kafka 的消息发送者发送消息时，消息会首先存入到一个双端队列中，双端队列中单个元素为 ProducerBatch，表示一个发送批次，其最大大小受参数 batch.size 控制，默认为 16K。然后会单独开一个 Send 线程，从双端队列中获取一个发送批次，将消息按批发送到 Kafka集群中，这里引入了 linger.ms 参数来控制 Send 线程的发送行为。</p>
<p>为了提高 kafka 消息发送的高吞吐量，即控制在缓存区中未积满 batch.size 时来控制消息发送线程的行为，是立即发送还是等待一定时间，如果linger.ms 设置为 0表示立即发送，如果设置为大于0，则消息发送线程会等待这个值后才会向broker发送。 <strong>linger.ms 参数者会增加响应时间，但有利于增加吞吐量。有点类似于 TCP 领域的 Nagle 算法</strong>。</p>
<p>Kafka 的消息发送，在写入 ProducerBatch 时会按照消息存储协议组织好数据，在服务端可以直接写入到文件中。</p>
<h3 id="3-2-RocketMQ-消息发送机制"><a href="#3-2-RocketMQ-消息发送机制" class="headerlink" title="3.2 RocketMQ 消息发送机制"></a>3.2 RocketMQ 消息发送机制</h3><p>RocketMQ 消息发送在客户端主要是根据路由选择算法选择一个队列，然后将消息发送到服务端，消息会在服务端按照消息的存储格式进行组织，然后进行持久化等操作。</p>
<h3 id="3-3-消息发送对比"><a href="#3-3-消息发送对比" class="headerlink" title="3.3 消息发送对比"></a>3.3 消息发送对比</h3><p>Kafka 在消息发送方面比 RokcetMQ 有一个显著的优势就是消息格式的组织是发生在客户端，这样会有一个大的优势节约了 Broker 端的CPU压力，客户端“分布式”的承接了其优势，其架构方式有点类似 shardingjdbc 与 MyCat 的区别。</p>
<p>Kafka 在消息发送端另外一个特点是引入了双端缓存队列，Kafka 无处不在追求批处理，这样显著的特点是能提高消息发送的吞吐量，但与之带来的是增大消息的响应时间，并且带来了消息丢失的可能性，因为 Kafka 追加到消息缓存后会返回成功，如果消息发送方异常退出，会带来消息丢失。</p>
<p>Kafka 中的 linger.ms = 0 可类比 RocketMQ 消息发送的效果。</p>
<p>但 Kafka 通过提供 batch.size 与 linger.ms 两个参数按照场景进行定制化，比 RocketMQ 灵活。</p>
<p>例如日志集群，通常会调大 batch.size 与 linger.ms 参数，重复发挥消息批量发送机制，提高其吞吐量；但如果对一些响应时间比较敏感的话，可以适当减少 linger.ms 的值。</p>
<h2 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h2><p>从上面的对比来看，Kafka 在性能上综合表现确实要比 RocketMQ 更加的优秀，但在消息选型过程中，我们不仅仅要参考其性能，还有从功能性上来考虑，例如 RocketMQ 提供了丰富的消息检索功能、事务消息、消息消费重试、定时消息等。</p>
<p>笔者个人认为通常在大数据、流式处理场景基本选用 Kafka，业务处理相关选择 RocketMQ。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>rocketmq</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title>Mybatis执行SQL的4大基础组件详解</title>
    <url>/posts/7c04b5f0.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、Executor"><a href="#1、Executor" class="headerlink" title="1、Executor"></a>1、Executor</h2><p>sql执行器，其对应的类全路径：org.apache.ibatis.executor.Executor。</p>
<h3 id="1-1-Executor类图"><a href="#1-1-Executor类图" class="headerlink" title="1.1 Executor类图"></a>1.1 Executor类图</h3><p><img src="https://img-blog.csdnimg.cn/20190526170433414.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li><p>Executor<br>执行器根据接口，定义update(更新或插入)、query(查询)、commit(提交事务)、rollback(回滚事务)。接下来简单介绍几个重要方法：</p>
<ul>
<li>int update(MappedStatement ms, Object parameter) throws SQLException<br>更新或插入方法，其参数含义如下：、<br>1）MappedStatement ms：SQL映射语句（Mapper.xml文件每一个方法对应一个MappedStatement对象）<br>2）Object parameter：参数，通常是List集合。</li>
<li>&lt; E&gt; List&lt; E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler)<br>查询方法，其参数含义如下：<br>1）RowBounds：行边界，主要值分页参数limit、offset。<br>2）ResultHandler resultHandler：结果处理器。</li>
<li>CacheKey createCacheKey(MappedStatement ms, Object parameterObj, RowBounds bounds, BoundSql bSql)<br>创建缓存Key，Mybatis一二级缓存的缓存Key，可以看出Key由上述4个参数来决定。<br>1）BoundSql boundSql：可以通过该对象获取SQL语句。</li>
</ul>
</li>
<li><p>CachingExecutor<br>支持结果缓存的SQL执行器，注意其设计模式的应用，该类中，会持有Executor的一个委托对象，CachingExecutor关注与缓存特定的逻辑，其最终的SQL执行由其委托对象来实现，即其内部的委托对象为BaseExecutor的实现类。</p>
</li>
<li><p>BaseExecutor<br>Executor的基础实现类，该类为抽象类，关于查询、更新具体的实现由其子类来实现，下面4个都是其子类。</p>
</li>
<li><p>SimpleExecutor<br>简单的Executor执行器。</p>
</li>
<li><p>BatchExecutor<br>支持批量执行的Executor执行器。</p>
</li>
<li><p>ClosedExecutor<br>表示一个已关闭的Executor。</p>
</li>
<li><p>ReuseExecutor<br>支持重复使用Statement,以SQL为键，缓存Statement对象。</p>
</li>
</ul>
<h3 id="1-2-创建Executor"><a href="#1-2-创建Executor" class="headerlink" title="1.2 创建Executor"></a>1.2 创建Executor</h3><p>在Mybatis中，Executor的创建由Configuration对象来创建，具体的代码如下：</p>
<h4 id="Configuration-newExecitor"><a href="#Configuration-newExecitor" class="headerlink" title="Configuration#newExecitor"></a>Configuration#newExecitor</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Executor <span class="title">newExecutor</span><span class="params">(Transaction transaction)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> newExecutor(transaction, defaultExecutorType);   <span class="comment">// @1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Executor <span class="title">newExecutor</span><span class="params">(Transaction transaction, ExecutorType executorType)</span> </span>&#123;</span><br><span class="line">  executorType = executorType == <span class="keyword">null</span> ? defaultExecutorType : executorType;</span><br><span class="line">  executorType = executorType == <span class="keyword">null</span> ? ExecutorType.SIMPLE : executorType;</span><br><span class="line">  Executor executor;</span><br><span class="line">  <span class="keyword">if</span> (ExecutorType.BATCH == executorType) &#123;   <span class="comment">// @2</span></span><br><span class="line">    executor = <span class="keyword">new</span> BatchExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ExecutorType.REUSE == executorType) &#123;</span><br><span class="line">    executor = <span class="keyword">new</span> ReuseExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    executor = <span class="keyword">new</span> SimpleExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (cacheEnabled) &#123; <span class="comment">// @3</span></span><br><span class="line">    executor = <span class="keyword">new</span> CachingExecutor(executor);</span><br><span class="line">  &#125;</span><br><span class="line">  executor = (Executor) interceptorChain.pluginAll(executor);  <span class="comment">// @4</span></span><br><span class="line">  <span class="keyword">return</span> executor;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上面的代码可以看出，Executor的创建由如下三个关键点：<br>代码@1：默认的ExecutorType为ExecutorType.SIMPLE，即默认创建的Executory为SimpleExecutor。<br>代码@2：根据executorType的值创建对应的Executory。<br>代码@3：如果cacheEnabled为true，则创建CachingExecutory，然后在其内部持有上面创建的Executor,cacheEnabled默认为true，则默认创建的Executor为CachingExecutor，并且其内部包裹着SimpleExecutor。<br>代码@4：使用InterceptorChain.pluginAll为executor创建代理对象，即Mybatis的拆件机制，将在该系列文章中详细介绍。</p>
<a id="more"></a>

<h2 id="2、StatementHandler"><a href="#2、StatementHandler" class="headerlink" title="2、StatementHandler"></a>2、StatementHandler</h2><p>在学习StatementHandler之前，我们先来回顾一下JDBC相关的知识。JDBC与语句执行的两大主流对象：java.sql.Statement、java.sql.PrepareStatement对象大家应该不会陌生，该对象的execute方法就是执行SQL语句的入口，通过java.sql.Connection对象创建Statement对象。Mybatis的StatementHandler，是Mybatis创建Statement对象的处理器，即StatementHandler会接管Statement对象的创建。</p>
<h3 id="2-1-StatementHandler类图"><a href="#2-1-StatementHandler类图" class="headerlink" title="2.1 StatementHandler类图"></a>2.1 StatementHandler类图</h3><p><img src="https://img-blog.csdnimg.cn/20190526171050653.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li><p>StatementHandler<br>根接口，我们重点关注一下其定义的方法：</p>
<ul>
<li>Statement prepare(Connection connection)<br>创建Statement对象，即该方法会通过Connection对象创建Statement对象。</li>
<li>void parameterize(Statement statement)<br>对Statement对象参数化，特别是PreapreStatement对象。</li>
<li>void batch(Statement statement)<br>批量执行SQL。</li>
<li>int update(Statement statement)<br>更新操作。</li>
<li>&lt; E&gt; List&lt; E&gt; query(Statement statement, ResultHandler resultHandler)<br>查询操作。</li>
<li>BoundSql getBoundSql()<br>获取SQL语句。</li>
<li>ParameterHandler getParameterHandler()<br>获取对应的参数处理器。</li>
</ul>
</li>
<li><p>BaseStatementHandler<br>StatementHandler的抽象实现类，SimpleStatementHandler、PrepareStatementHandler、CallableStatementHandler是其子类。<br>我们来一一看一下其示例变量：</p>
<ul>
<li>Configuration configuration<br>Mybatis全局配置对象。</li>
<li>ObjectFactory objectFactory<br>对象工厂。</li>
<li>TypeHandlerRegistry typeHandlerRegistry<br>类型注册器。</li>
<li>ResultSetHandler resultSetHandler<br>结果集Handler。</li>
<li>ParameterHandler parameterHandler<br>参数处理器Handler。</li>
<li>Executor executor<br>SQL执行器。</li>
<li>MappedStatement mappedStatement<br>SQL映射语句（Mapper.xml文件每一个方法对应一个MappedStatement对象）</li>
<li>RowBounds rowBounds<br>行边界，主要值分页参数limit、offset。</li>
<li>BoundSql boundSql<br>可以通过该对象获取SQL语句。</li>
</ul>
</li>
<li><p>SimpleStatementHandler<br>具体的StatementHandler实现器，java.sql.Statement对象创建处理器。</p>
</li>
<li><p>PrepareStatementHandler<br>java.sql.PrepareStatement对象的创建处理器。</p>
</li>
<li><p>CallableStatementHandler<br>java.sql.CallableStatement对象的创建处理器，可用来执行存储过程调用的Statement。</p>
</li>
<li><p>RoutingStatementHandler<br>StatementHandler路由器，我们看一下其构造方法后，就会对该类了然于胸。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">RoutingStatementHandler</span><span class="params">(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">switch</span> (ms.getStatementType()) &#123; <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">case</span> STATEMENT:</span><br><span class="line">      delegate = <span class="keyword">new</span> SimpleStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> PREPARED:</span><br><span class="line">      delegate = <span class="keyword">new</span> PreparedStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> CALLABLE:</span><br><span class="line">      delegate = <span class="keyword">new</span> CallableStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> ExecutorException(<span class="string">&quot;Unknown statement type: &quot;</span> + ms.getStatementType());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>原来是会根据MappedStatement对象的statementType创建对应的StatementHandler。</p>
</li>
</ul>
<h3 id="2-2-创建StatementHandler"><a href="#2-2-创建StatementHandler" class="headerlink" title="2.2 创建StatementHandler"></a>2.2 创建StatementHandler</h3><h4 id="Configuration-newStatementHandler"><a href="#Configuration-newStatementHandler" class="headerlink" title="Configuration#newStatementHandler"></a>Configuration#newStatementHandler</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> StatementHandler <span class="title">newStatementHandler</span><span class="params">(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql)</span> </span>&#123;</span><br><span class="line">  StatementHandler statementHandler = <span class="keyword">new</span> RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); <span class="comment">// @1</span></span><br><span class="line">  statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); <span class="comment">// @2</span></span><br><span class="line">  <span class="keyword">return</span> statementHandler;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法的两个关键点如下：<br>代码@1：创建RoutingStatementHandler对象，在其内部再根据SQL语句的类型，创建对应的StatementHandler对象。<br>代码@2：对StatementHandler引入拆件机制，该部分将在该专题的后续文章中会详细介绍，这里暂时跳过。</p>
<h2 id="3、ParameterHandler"><a href="#3、ParameterHandler" class="headerlink" title="3、ParameterHandler"></a>3、ParameterHandler</h2><p>参数处理器。同样我们先来看一下其类图。</p>
<h3 id="3-1-ParameterHandler类图"><a href="#3-1-ParameterHandler类图" class="headerlink" title="3.1 ParameterHandler类图"></a>3.1 ParameterHandler类图</h3><p><img src="https://img-blog.csdnimg.cn/20190526171502281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>这个比较简单，就是处理PreparedStatemet接口的参数化处理，也可以顺便看一下其调用链(该部分会在下一篇中详细介绍)。<br><img src="https://img-blog.csdnimg.cn/20190526171635381.png" alt="在这里插入图片描述"></p>
<h3 id="3-2-创建ParameterHandler"><a href="#3-2-创建ParameterHandler" class="headerlink" title="3.2 创建ParameterHandler"></a>3.2 创建ParameterHandler</h3><h4 id="Configuration-newParameterHandler"><a href="#Configuration-newParameterHandler" class="headerlink" title="Configuration#newParameterHandler"></a>Configuration#newParameterHandler</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ParameterHandler <span class="title">newParameterHandler</span><span class="params">(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql)</span> </span>&#123;</span><br><span class="line">  ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql);</span><br><span class="line">  parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler);  <span class="comment">// @1</span></span><br><span class="line">  <span class="keyword">return</span> parameterHandler;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同样该接口也支持插件化机制。</p>
<h2 id="4、ResultSetHandler"><a href="#4、ResultSetHandler" class="headerlink" title="4、ResultSetHandler"></a>4、ResultSetHandler</h2><p>处理结果的Handler。我们同样看一下其类图。</p>
<h3 id="4-1-ResultSetHandler类图"><a href="#4-1-ResultSetHandler类图" class="headerlink" title="4.1 ResultSetHandler类图"></a>4.1 ResultSetHandler类图</h3><p><img src="https://img-blog.csdnimg.cn/20190526171756530.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>处理Jdbc ResultSet的处理器。</p>
<h3 id="4-2-ResultSetHandler创建"><a href="#4-2-ResultSetHandler创建" class="headerlink" title="4.2 ResultSetHandler创建"></a>4.2 ResultSetHandler创建</h3><h4 id="Configuration-newResultSetHandler"><a href="#Configuration-newResultSetHandler" class="headerlink" title="Configuration#newResultSetHandler"></a>Configuration#newResultSetHandler</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ResultSetHandler <span class="title">newResultSetHandler</span><span class="params">(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler,</span></span></span><br><span class="line"><span class="function"><span class="params">    ResultHandler resultHandler, BoundSql boundSql)</span> </span>&#123;</span><br><span class="line">  ResultSetHandler resultSetHandler = <span class="keyword">new</span> DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds);</span><br><span class="line">  resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler);</span><br><span class="line">  <span class="keyword">return</span> resultSetHandler;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同样支持插件化机制，我们也稍微再看一下其调用链：<br><img src="https://img-blog.csdnimg.cn/20190526171844420.png" alt="在这里插入图片描述"><br>可以看出其调用的入口为SQL执行时。</p>
<p>本文作为下一篇《源码分析Mybatis整合ShardingJdbc SQL执行流程》的前置篇，重点介绍Executor、StatementHandler、ParameterHandler、ResultSetHandler的具体职责，以类图为基础并详细介绍其核心方法的作用，然后详细介绍了这些对象是如何创建，并引出Mybatis拆件机制。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
        <tag>Executor</tag>
        <tag>StatementHandler</tag>
        <tag>ParameterHandler</tag>
        <tag>ResultSetHandler</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty4 Channel 概述</title>
    <url>/posts/a79560fc.html</url>
    <content><![CDATA[<div id="vip-container"><blockquote>
<p>专栏介绍：《让天下没有难学的Netty》系列，基于 Netty，以源码分析为主要手段，关键流程给出流程图，从 通道篇、内存篇、性能篇三个维度深度剖析 Netty 的实现原理。 </p>
</blockquote>
<h2 id="1、通道概述"><a href="#1、通道概述" class="headerlink" title="1、通道概述"></a>1、通道概述</h2><p>我们从如下几个方面来简单了解一下 Channel。</p>
<ul>
<li>通道的当前状态，open(端口打开)、connect(连接)。</li>
<li>通道的配置，包含通道的配置属性与网络通信选项(ChannelOption)。</li>
<li>IO 通道方法诸如 read、write、connect、bind 与管道(ChannelPipeline)。</li>
<li>所有 IO 操作在 Netty 中都是异步的，调用 IO 方法例如 write 方法后，并不是等 IO 操作实际完成后再返回，而是会立即返回一个凭证，IO 操作完成后会将结果写入凭证中，典型的 Future设计模式。</li>
<li>Channel 具有父子关系，由于所有的 SocketChannel（客户端发起TCP连接）都是由 ServerSocketChannel（服务端接收连接）接收客户端连接而创建的，故 SocketChannel 的 parent() 方法会返回对应的 ServerSocketChannel。</li>
<li>所有通道对象在使用完后，请务必调用通道的colse方法来释放资源。</li>
</ul>
<p>本节将从如下3个方面来重点介绍Channel。</p>
<ul>
<li>Channel 常用API</li>
<li>Channel 配置与选项</li>
<li>NIO相关的Channel继承图</li>
</ul>
<a id="more"></a>

<h2 id="2、Channel常用API"><a href="#2、Channel常用API" class="headerlink" title="2、Channel常用API"></a>2、Channel常用API</h2><p>Channel 类图结构如下：<br><img src="https://img-blog.csdnimg.cn/20201129210717360.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>核心API一览：</p>
<ul>
<li>EventLoop eventLoop()<br>返回该通道注册的事件轮询器。</li>
<li>Channel parent()<br>返回该通道的父通道，如果是ServerSocketChannel实例则返回null，SocketChannel实例则返回对应的ServerSocketChannel。</li>
<li>ChannelConfig config()<br>返回该通道的配置参数。</li>
<li>boolean isOpen()<br>端口是否处于open，通道默认一创建isOpen方法就会返回true，close方法被调用后该方法返回false。</li>
<li>boolean isRegistered()<br>是否已注册到EventLoop。</li>
<li>public boolean isActive()<br>通道是否处于激活。NioSocketChannel的实现是java.nio.channels.SocketChannel实例的isOpen()与isConnected()都返回true。NioServerSocketChannel的实现是ServerSocketChannel.socket().isBound()，如果绑定到端口中，意味着处于激活状态。</li>
<li>ChannelFuture closeFuture()<br>Future模式的应用，调用该方法的目的并不是关闭通道，而是预先创建一个凭证(Future)，等通道关闭时，会通知该Future，用户可以通过该Future注册事件。</li>
<li>ChannelFuture bind(SocketAddress localAddress)<br>Netty服务端绑定到本地端口，开始监听客户端的连接请求。该过程会触发事件链(ChannelPipeline)。该部分将在后续讲解服务端启动流程时再详细分析。</li>
<li>ChannelFuture connect(SocketAddress remoteAddress)<br>Netty客户端连接到服务端，该过程同样会触发一系列事件(ChannelPipeline)。该部分将在后续讲解客户端启动流程时再详细分析。</li>
<li>ChannelFuture disconnect()<br>断开连接，但不会释放资源，该通道还可以再通过connect重新与服务器建立连接。</li>
<li>ChannelFuture close()<br>关闭通道，回收资源，该通道的生命周期完全结束。</li>
<li>ChannelFuture deregister()<br>取消注册。</li>
<li>Channel read()<br>通道读，该方法并不是直接从读写缓存区读取文件，而是向NIO Selecor注册读事件（目前主要基于NIO）。当通道收到对端的数后，事件选择器会处理读事件，从而触发ChannelInboundHandler#channelRead 事件，然后继续触发ChannelInboundHandler#channelReadComplete(ChannelHandlerContext)事件。</li>
<li>ChannelFuture write(Object msg)<br>向通道写字节流，会触发响应的写事件链，该方法只是会将字节流写入到通道缓存区，并不会调用flush方法写入通道中。</li>
<li>Channel flush()<br>刷写所有挂起的消息（刷写到流中）。</li>
<li>ChannelFuture writeAndFlush(Object msg)<br>相当于调用write与flush方法。</li>
</ul>
<h2 id="3、Channel配置与选项"><a href="#3、Channel配置与选项" class="headerlink" title="3、Channel配置与选项"></a>3、Channel配置与选项</h2><h4 id="3-1-Channel配置"><a href="#3-1-Channel配置" class="headerlink" title="3.1 Channel配置"></a>3.1 Channel配置</h4><p>ChannelConfig 的类图如下：<br><img src="https://img-blog.csdnimg.cn/20201129210953154.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>核心配置如下：</p>
<ul>
<li>Map&lt;ChannelOption&lt;?&gt;, Object&gt; options：选项，在下文会重点介绍。</li>
<li>int connectTimeoutMillis：连接超时时间。</li>
<li>int maxMessagesPerRead：每次读事件中调用读方法的最大次数(AbstractNioByteChannel)或读事件循环中最多处理的消息条数(AbstractNioMessageChannel)。</li>
<li>int writeSpinCount：一次写事件处理期间最多调用write方法的次数，引入该机制主要是为了避免一个网络通道写入大量数据，对其他网络通道的读写处理带来延迟，默认值为16。</li>
<li>ByteBufAllocator getAllocator()：返回该通道的内存分配器(ByteBuf)。<br>RecvByteBufAllocator getRecvByteBufAllocator()：读事件读缓冲区的分配策略。</li>
<li>boolean autoRead：是否自动触发read方法调用，默认为true，读事件触发后自动调用read方法 ，而无需应用程序显示调用。</li>
<li>int writeBufferHighWaterMark：设置写缓存区的高水位线。如果写缓存区中的数据超过该值，Channel#isWritable()方法将返回false。</li>
<li>int writeBufferLowWaterMark：设置写缓存区的低水位线。如果写缓存区的数据超过高水位线后，通道将变得不可写，等写缓存数据降低到低水位线后通道恢复可写状态(Channel#isWritable()将再次返回true)。<h4 id="3-2-ChannelOption"><a href="#3-2-ChannelOption" class="headerlink" title="3.2 ChannelOption"></a>3.2 ChannelOption</h4><img src="https://img-blog.csdnimg.cn/20201129211116360.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>网络通道(Channel)选项值，下面介绍一下与TCP协议相关的核心参数：</li>
<li>SO_BROADCAST<br>选择值类型:boolean。表值该数据包是否是广播包，true表示广播包，false表示非广播，如果包的IP地址为广播地址，但该选型为false，则在内核层会抛出错误。</li>
<li>SO_KEEPALIVE<br>对于面向连接的TCP socket,在实际应用中通常都要检测对端是否处于连接中,连接端口分两种情况:<ul>
<li><pre><code>连接正常关闭,调用close() shutdown()连接优雅关闭,send与recv立马返回错误,select返回SOCK_ERR</code></pre>
</li>
<li><pre><code>连接的对端异常关闭,比如网络断掉,突然断电.</code></pre>
</li>
</ul>
</li>
<li>SO_SNDBUF的大小<br>为了达到最大网络吞吐，socket send buffer size(SO_SNDBUF)不应该小于带宽和延迟的乘积。</li>
<li>SO_REUSEADDR<br>该参数如果设置为true的一个常用应用场景是端口复用(直接复用TIME_WAIT状态的socket)。</li>
<li>SO_LINGER<br>该参数是控制TCP关闭行为的。</li>
<li>SO_BACKLOG<br>服务端接受客户端连接的处理队列，在TCP三次握手协议中，服务端接收到客户端的SYN包后，会向客户端发送SYN+ACK包，同时会将连接放入到 backlog 队列中，等待客户端ACK包。在服务端没有接收到客户端的ACK包之前，连接会暂存 backlog 队列。</li>
<li>SO_TIMEOUT<br>以毫秒为单位定义套接字超时(SO_TIMEOUT)，它是等待数据的超时，或者换句话说，是两个连续数据包之间的最大活动周期。超时值为0将被解释为无限超时。如果没有设置该参数，读取操作将不会超时(无穷小超时)。个人思考：在NIO编程开发中应该不要设置该值，但为了保证每个连接的读平等，Netty会控制一次事件选择周期，最多可调用read方法的次数。</li>
<li>TCP_NODELAY<br>在TCP数据包发送的时候，有一种算法（Nagle算法）。该算法的核心是如果发生数据包比较小，为了提高带宽的利用率，会等待更多的数据到达后再发送或等待超时后将小包发送，也就是TCP发送延迟，TCP_NODELAY=true表示不使用tcp delay延迟，故禁用Nagle算法。通常接受端的ACK包也会使用延迟（默认40ms)，旨在合并多个ACK确认包。<br>Nagle 算法的改进在于：如果发送端欲多次发送包含少量字符的数据包(一般情况下,后面统一称长度小于MSS的数据包为小包,与此相对,称长度等于MSS的数据包为大包,为了某些对比说明,还有中包,即长度比小包长,但又不足一个MSS的包;MSS,TCP最大分段大小,以太网下一般就是1460字节。),则发送端会先将第一个小包发送出去,而将后面到达的少量字符数据都缓存起来而不立即发送,直到收到接收端对前一个数据包报文段的ACK确认、或当前字符属于紧急数据,或者积攒到了一定数量的数据(比如缓存的字符数据已经达到数据包报文段的最大长度)等多种情况才将其组成一个较大的数据包发送出去。</li>
</ul>
<h2 id="4、Channel-NIO-继承图"><a href="#4、Channel-NIO-继承图" class="headerlink" title="4、Channel NIO 继承图"></a>4、Channel NIO 继承图</h2><p>Channel 类继承图主要是想展示一下与 NIO 相关的 NioSocketChannel (客户端通道)与NioServerSocketChannel (服务端通道)在 Channel 中的位置。<br><img src="https://img-blog.csdnimg.cn/20201129212730624.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Channel 通道统一抽象接口。</p>
<ul>
<li>AbstractChannel 通道默认抽象实现类</li>
<li>AbstractEpollChannel unix Epoll通道实现</li>
<li>AbstractOioChannel 阻塞IO通道抽象类</li>
<li>AbstractNioChannel NIO通道抽象类</li>
<li>AbstractNioByteChannel NIO客户端通道抽象类</li>
<li>AbstractNIoMessageChannel NIO服务端通道抽象类</li>
<li>NioSocketChannel  NIO客户端通道实现类</li>
<li>NioServerSocketChannel NIO服务端通道实现类</li>
</ul>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>netty4</category>
      </categories>
      <tags>
        <tag>netty4</tag>
        <tag>Channel</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ ACL 使用指南</title>
    <url>/posts/7b95946e.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、什么是ACL"><a href="#1、什么是ACL" class="headerlink" title="1、什么是ACL?"></a>1、什么是ACL?</h2><p>ACL是access control list的简称，俗称访问控制列表。访问控制，基本上会涉及到用户、资源、权限、角色等概念，那在RocketMQ中上述会对应哪些对象呢？</p>
<ul>
<li>用户<br>用户是访问控制的基础要素，也不难理解，RocketMQ ACL必然也会引入用户的概念，即支持用户名、密码。</li>
<li>资源<br>资源，需要保护的对象，在RocketMQ中，消息发送涉及的Topic、消息消费涉及的消费组，应该进行保护，故可以抽象成资源。</li>
<li>权限<br>针对资源，能进行的操作，</li>
<li>角色<br>RocketMQ中，只定义两种角色：是否是管理员。</li>
</ul>
<p>另外，RocketMQ还支持按照客户端IP进行白名单设置。</p>
<h2 id="2、ACL基本流程图"><a href="#2、ACL基本流程图" class="headerlink" title="2、ACL基本流程图"></a>2、ACL基本流程图</h2><p>在讲解如何使用ACL之前，我们先简单看一下RocketMQ ACL的请求流程：<br><img src="https://img-blog.csdnimg.cn/2019063014185470.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>对于上述具体的实现，将在后续文章中重点讲解，本文的目的只是希望给读者一个大概的了解。</p>
<h2 id="3、如何配置ACL"><a href="#3、如何配置ACL" class="headerlink" title="3、如何配置ACL"></a>3、如何配置ACL</h2><h3 id="3-1-acl配置文件"><a href="#3-1-acl配置文件" class="headerlink" title="3.1 acl配置文件"></a>3.1 acl配置文件</h3><p>acl默认的配置文件名：plain_acl.yml,需要放在${ROCKETMQ_HOME}/store/config目录下。下面对其配置项一一介绍。</p>
<a id="more"></a>

<h4 id="3-1-1-globalWhiteRemoteAddresses"><a href="#3-1-1-globalWhiteRemoteAddresses" class="headerlink" title="3.1.1 globalWhiteRemoteAddresses"></a>3.1.1 globalWhiteRemoteAddresses</h4><p>全局白名单，其类型为数组，即支持多个配置。其支持的配置格式如下：</p>
<ul>
<li>空<br>表示不设置白名单，该条规则默认返回false。</li>
<li>“*”<br>表示全部匹配，该条规则直接返回true，将会阻断其他规则的判断，请慎重使用。</li>
<li>192.168.0.{100,101}<br>多地址配置模式，ip地址的最后一组，使用{}，大括号中多个ip地址，用英文逗号(,)隔开。</li>
<li>192.168.1.100,192.168.2.100<br>直接使用,分隔，配置多个ip地址。</li>
<li>192.168.*.<em>或192.168.100-200.10-20<br>每个IP段使用 “</em>“ 或”-“表示范围。</li>
</ul>
<h4 id="3-1-2-accounts"><a href="#3-1-2-accounts" class="headerlink" title="3.1.2 accounts"></a>3.1.2 accounts</h4><p>配置用户信息，该类型为数组类型。拥有accessKey、secretKey、whiteRemoteAddress、admin、defaultTopicPerm、defaultGroupPerm、topicPerms、groupPerms子元素。</p>
<h5 id="3-1-2-1-accessKey"><a href="#3-1-2-1-accessKey" class="headerlink" title="3.1.2.1 accessKey"></a>3.1.2.1 accessKey</h5><p>登录用户名，长度必须大于6个字符。</p>
<h5 id="3-1-2-2-secretKey"><a href="#3-1-2-2-secretKey" class="headerlink" title="3.1.2.2 secretKey"></a>3.1.2.2 secretKey</h5><p>登录密码。长度必须大于6个字符。</p>
<h5 id="3-1-2-3-whiteRemoteAddress"><a href="#3-1-2-3-whiteRemoteAddress" class="headerlink" title="3.1.2.3 whiteRemoteAddress"></a>3.1.2.3 whiteRemoteAddress</h5><p>用户级别的IP地址白名单。其类型为一个字符串，其配置规则与globalWhiteRemoteAddresses，但只能配置一条规则。</p>
<h5 id="3-1-2-4-admin"><a href="#3-1-2-4-admin" class="headerlink" title="3.1.2.4 admin"></a>3.1.2.4 admin</h5><p>boolean类型，设置是否是admin。如下权限只有admin=true时才有权限执行。</p>
<ul>
<li>UPDATE_AND_CREATE_TOPIC<br>更新或创建主题。</li>
<li>UPDATE_BROKER_CONFIG<br>更新Broker配置。</li>
<li>DELETE_TOPIC_IN_BROKER<br>删除主题。</li>
<li>UPDATE_AND_CREATE_SUBSCRIPTIONGROUP<br>更新或创建订阅组信息。</li>
<li>DELETE_SUBSCRIPTIONGROUP<br>删除订阅组信息。</li>
</ul>
<h5 id="3-1-2-5-defaultTopicPerm"><a href="#3-1-2-5-defaultTopicPerm" class="headerlink" title="3.1.2.5 defaultTopicPerm"></a>3.1.2.5 defaultTopicPerm</h5><p>默认topic权限。该值默认为DENY(拒绝)。</p>
<h5 id="3-1-2-6-defaultGroupPerm"><a href="#3-1-2-6-defaultGroupPerm" class="headerlink" title="3.1.2.6 defaultGroupPerm"></a>3.1.2.6 defaultGroupPerm</h5><p>默认消费组权限，该值默认为DENY(拒绝)，建议值为SUB。</p>
<h5 id="3-1-2-7-topicPerms"><a href="#3-1-2-7-topicPerms" class="headerlink" title="3.1.2.7 topicPerms"></a>3.1.2.7 topicPerms</h5><p>设置topic的权限。其类型为数组，其可选择值在下节介绍。</p>
<h5 id="3-1-2-8-groupPerms"><a href="#3-1-2-8-groupPerms" class="headerlink" title="3.1.2.8 groupPerms"></a>3.1.2.8 groupPerms</h5><p>设置消费组的权限。其类型为数组，其可选择值在下节介绍。可以为每一消费组配置不一样的权限。</p>
<h3 id="3-2-RocketMQ-ACL权限可选值"><a href="#3-2-RocketMQ-ACL权限可选值" class="headerlink" title="3.2 RocketMQ ACL权限可选值"></a>3.2 RocketMQ ACL权限可选值</h3><ul>
<li>DENY<br>拒绝。</li>
<li>PUB<br>拥有发送权限。</li>
<li>SUB<br>拥有订阅权限。</li>
</ul>
<h3 id="3-3、权限验证流程"><a href="#3-3、权限验证流程" class="headerlink" title="3.3、权限验证流程"></a>3.3、权限验证流程</h3><p>上面定义了全局白名单、用户级别的白名单，用户级别的权限，为了更好的配置ACL权限规则，下面给出权限匹配逻辑。<br><img src="https://img-blog.csdnimg.cn/20190630142301617.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="4、使用示例"><a href="#4、使用示例" class="headerlink" title="4、使用示例"></a>4、使用示例</h2><h3 id="4-1-Broker端安装"><a href="#4-1-Broker端安装" class="headerlink" title="4.1 Broker端安装"></a>4.1 Broker端安装</h3><p>首先，需要在broker.conf文件中，增加参数aclEnable=true。并拷贝distribution/conf/plain_acl.yml文件到${ROCKETMQ_HOME}/conf目录。</p>
<p>broker.conf的配置文件如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brokerClusterName &#x3D; DefaultCluster</span><br><span class="line">brokerName &#x3D; broker-b</span><br><span class="line">brokerId &#x3D; 0</span><br><span class="line">deleteWhen &#x3D; 04</span><br><span class="line">fileReservedTime &#x3D; 48</span><br><span class="line">brokerRole &#x3D; ASYNC_MASTER</span><br><span class="line">flushDiskType &#x3D; ASYNC_FLUSH</span><br><span class="line">listenPort&#x3D;10915</span><br><span class="line">storePathRootDir&#x3D;E:&#x2F;SH2019&#x2F;tmp&#x2F;rocketmq_home&#x2F;rocketmq4.5MB&#x2F;store</span><br><span class="line">storePathCommitLog&#x3D;E:&#x2F;SH2019&#x2F;tmp&#x2F;rocketmq_home&#x2F;rocketmq4.5MB&#x2F;store&#x2F;commitlog</span><br><span class="line">namesrvAddr&#x3D;127.0.0.1:9876</span><br><span class="line">autoCreateTopicEnable&#x3D;false</span><br><span class="line">aclEnable&#x3D;true</span><br></pre></td></tr></table></figure>
<p>plain_acl.yml文件内容如下：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">globalWhiteRemoteAddresses:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">accounts:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">accessKey:</span> <span class="string">RocketMQ</span></span><br><span class="line">  <span class="attr">secretKey:</span> <span class="number">12345678</span></span><br><span class="line">  <span class="attr">whiteRemoteAddress:</span></span><br><span class="line">  <span class="attr">admin:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">defaultTopicPerm:</span> <span class="string">DENY</span></span><br><span class="line">  <span class="attr">defaultGroupPerm:</span> <span class="string">SUB</span></span><br><span class="line">  <span class="attr">topicPerms:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">TopicTest=PUB</span></span><br><span class="line">  <span class="attr">groupPerms:</span></span><br><span class="line">  <span class="comment"># the group should convert to retry topic</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">oms_consumer_group=DENY</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">accessKey:</span> <span class="string">admin</span></span><br><span class="line">  <span class="attr">secretKey:</span> <span class="number">12345678</span></span><br><span class="line">  <span class="attr">whiteRemoteAddress:</span></span><br><span class="line">  <span class="comment"># if it is admin, it could access all resources</span></span><br><span class="line">  <span class="attr">admin:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>从上面的配置可知，用户RocketMQ只能发送TopicTest的消息，其他topic无权限发送；拒绝oms_consumer_group消费组的消息消费，其他消费组默认可消费。</p>
<h3 id="4-2-消息发送端示例"><a href="#4-2-消息发送端示例" class="headerlink" title="4.2 消息发送端示例"></a>4.2 消息发送端示例</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AclProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, InterruptedException </span>&#123;</span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;please_rename_unique_group_name&quot;</span>, getAclRPCHook());</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;127.0.0.1:9876&quot;</span>);</span><br><span class="line">        producer.start();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;TopicTest3&quot;</span> ,<span class="string">&quot;TagA&quot;</span> , (<span class="string">&quot;Hello RocketMQ &quot;</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">                SendResult sendResult = producer.send(msg);</span><br><span class="line">                System.out.printf(<span class="string">&quot;%s%n&quot;</span>, sendResult);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">                Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> RPCHook <span class="title">getAclRPCHook</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> AclClientRPCHook(<span class="keyword">new</span> SessionCredentials(<span class="string">&quot;rocketmq&quot;</span>,<span class="string">&quot;12345678&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行效果如图所示：<br><img src="https://img-blog.csdnimg.cn/20190630142551897.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="4-3-消息消费端示例"><a href="#4-3-消息消费端示例" class="headerlink" title="4.3 消息消费端示例"></a>4.3 消息消费端示例</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AclConsumer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, MQClientException </span>&#123;</span><br><span class="line">        DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">&quot;please_rename_unique_group_name_4&quot;</span>, getAclRPCHook(),<span class="keyword">new</span> AllocateMessageQueueAveragely());</span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class="line">        consumer.subscribe(<span class="string">&quot;TopicTest&quot;</span>, <span class="string">&quot;*&quot;</span>);</span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">&quot;127.0.0.1:9876&quot;</span>);</span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs,</span></span></span><br><span class="line"><span class="function"><span class="params">                ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">                System.out.printf(<span class="string">&quot;%s Receive New Messages: %s %n&quot;</span>, Thread.currentThread().getName(), msgs);</span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.printf(<span class="string">&quot;Consumer Started.%n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> RPCHook <span class="title">getAclRPCHook</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> AclClientRPCHook(<span class="keyword">new</span> SessionCredentials(<span class="string">&quot;rocketmq&quot;</span>,<span class="string">&quot;12345678&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>发现并不没有消费消息，符合预期。</p>
<p>关于RocketMQ ACL的使用就介绍到这里了，下一篇将介绍RocketMQ ACL实现原理。，下一篇，我们将进入到多副本的学习中。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>acl</tag>
        <tag>访问控制</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty4 ChannelHandler 概述</title>
    <url>/posts/eab70bff.html</url>
    <content><![CDATA[<div id="vip-container"><blockquote>
<p>专栏介绍：《让天下没有难学的Netty》系列，基于 Netty，以源码分析为主要手段，关键流程给出流程图，从 通道篇、内存篇、性能篇三个维度深度剖析 Netty 的实现原理。 </p>
</blockquote>
<h2 id="1、通道概述"><a href="#1、通道概述" class="headerlink" title="1、通道概述"></a>1、通道概述</h2><p>我们从如下几个方面来简单了解一下 Channel。</p>
<ul>
<li>通道的当前状态，open(端口打开)、connect(连接)。</li>
<li>通道的配置，包含通道的配置属性与网络通信选项(ChannelOption)。</li>
<li>IO 通道方法诸如 read、write、connect、bind 与管道(ChannelPipeline)。</li>
<li>所有 IO 操作在 Netty 中都是异步的，调用 IO 方法例如 write 方法后，并不是等 IO 操作实际完成后再返回，而是会立即返回一个凭证，IO 操作完成后会将结果写入凭证中，典型的 Future设计模式。</li>
<li>Channel 具有父子关系，由于所有的 SocketChannel（客户端发起TCP连接）都是由 ServerSocketChannel（服务端接收连接）接收客户端连接而创建的，故 SocketChannel 的 parent() 方法会返回对应的 ServerSocketChannel。</li>
<li>所有通道对象在使用完后，请务必调用通道的colse方法来释放资源。</li>
</ul>
<p>本节将从如下3个方面来重点介绍Channel。</p>
<ul>
<li>Channel 常用API</li>
<li>Channel 配置与选项</li>
<li>NIO相关的Channel继承图</li>
</ul>
<a id="more"></a>

<h2 id="2、Channel常用API"><a href="#2、Channel常用API" class="headerlink" title="2、Channel常用API"></a>2、Channel常用API</h2><p>Channel 类图结构如下：<br><img src="https://img-blog.csdnimg.cn/20201129210717360.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>核心API一览：</p>
<ul>
<li>EventLoop eventLoop()<br>返回该通道注册的事件轮询器。</li>
<li>Channel parent()<br>返回该通道的父通道，如果是ServerSocketChannel实例则返回null，SocketChannel实例则返回对应的ServerSocketChannel。</li>
<li>ChannelConfig config()<br>返回该通道的配置参数。</li>
<li>boolean isOpen()<br>端口是否处于open，通道默认一创建isOpen方法就会返回true，close方法被调用后该方法返回false。</li>
<li>boolean isRegistered()<br>是否已注册到EventLoop。</li>
<li>public boolean isActive()<br>通道是否处于激活。NioSocketChannel的实现是java.nio.channels.SocketChannel实例的isOpen()与isConnected()都返回true。NioServerSocketChannel的实现是ServerSocketChannel.socket().isBound()，如果绑定到端口中，意味着处于激活状态。</li>
<li>ChannelFuture closeFuture()<br>Future模式的应用，调用该方法的目的并不是关闭通道，而是预先创建一个凭证(Future)，等通道关闭时，会通知该Future，用户可以通过该Future注册事件。</li>
<li>ChannelFuture bind(SocketAddress localAddress)<br>Netty服务端绑定到本地端口，开始监听客户端的连接请求。该过程会触发事件链(ChannelPipeline)。该部分将在后续讲解服务端启动流程时再详细分析。</li>
<li>ChannelFuture connect(SocketAddress remoteAddress)<br>Netty客户端连接到服务端，该过程同样会触发一系列事件(ChannelPipeline)。该部分将在后续讲解客户端启动流程时再详细分析。</li>
<li>ChannelFuture disconnect()<br>断开连接，但不会释放资源，该通道还可以再通过connect重新与服务器建立连接。</li>
<li>ChannelFuture close()<br>关闭通道，回收资源，该通道的生命周期完全结束。</li>
<li>ChannelFuture deregister()<br>取消注册。</li>
<li>Channel read()<br>通道读，该方法并不是直接从读写缓存区读取文件，而是向NIO Selecor注册读事件（目前主要基于NIO）。当通道收到对端的数后，事件选择器会处理读事件，从而触发ChannelInboundHandler#channelRead 事件，然后继续触发ChannelInboundHandler#channelReadComplete(ChannelHandlerContext)事件。</li>
<li>ChannelFuture write(Object msg)<br>向通道写字节流，会触发响应的写事件链，该方法只是会将字节流写入到通道缓存区，并不会调用flush方法写入通道中。</li>
<li>Channel flush()<br>刷写所有挂起的消息（刷写到流中）。</li>
<li>ChannelFuture writeAndFlush(Object msg)<br>相当于调用write与flush方法。</li>
</ul>
<h2 id="3、Channel配置与选项"><a href="#3、Channel配置与选项" class="headerlink" title="3、Channel配置与选项"></a>3、Channel配置与选项</h2><h4 id="3-1-Channel配置"><a href="#3-1-Channel配置" class="headerlink" title="3.1 Channel配置"></a>3.1 Channel配置</h4><p>ChannelConfig 的类图如下：<br><img src="https://img-blog.csdnimg.cn/20201129210953154.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>核心配置如下：</p>
<ul>
<li>Map&lt;ChannelOption&lt;?&gt;, Object&gt; options：选项，在下文会重点介绍。</li>
<li>int connectTimeoutMillis：连接超时时间。</li>
<li>int maxMessagesPerRead：每次读事件中调用读方法的最大次数(AbstractNioByteChannel)或读事件循环中最多处理的消息条数(AbstractNioMessageChannel)。</li>
<li>int writeSpinCount：一次写事件处理期间最多调用write方法的次数，引入该机制主要是为了避免一个网络通道写入大量数据，对其他网络通道的读写处理带来延迟，默认值为16。</li>
<li>ByteBufAllocator getAllocator()：返回该通道的内存分配器(ByteBuf)。<br>RecvByteBufAllocator getRecvByteBufAllocator()：读事件读缓冲区的分配策略。</li>
<li>boolean autoRead：是否自动触发read方法调用，默认为true，读事件触发后自动调用read方法 ，而无需应用程序显示调用。</li>
<li>int writeBufferHighWaterMark：设置写缓存区的高水位线。如果写缓存区中的数据超过该值，Channel#isWritable()方法将返回false。</li>
<li>int writeBufferLowWaterMark：设置写缓存区的低水位线。如果写缓存区的数据超过高水位线后，通道将变得不可写，等写缓存数据降低到低水位线后通道恢复可写状态(Channel#isWritable()将再次返回true)。<h4 id="3-2-ChannelOption"><a href="#3-2-ChannelOption" class="headerlink" title="3.2 ChannelOption"></a>3.2 ChannelOption</h4><img src="https://img-blog.csdnimg.cn/20201129211116360.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>网络通道(Channel)选项值，下面介绍一下与TCP协议相关的核心参数：</li>
<li>SO_BROADCAST<br>选择值类型:boolean。表值该数据包是否是广播包，true表示广播包，false表示非广播，如果包的IP地址为广播地址，但该选型为false，则在内核层会抛出错误。</li>
<li>SO_KEEPALIVE<br>对于面向连接的TCP socket,在实际应用中通常都要检测对端是否处于连接中,连接端口分两种情况:<ul>
<li><pre><code>连接正常关闭,调用close() shutdown()连接优雅关闭,send与recv立马返回错误,select返回SOCK_ERR</code></pre>
</li>
<li><pre><code>连接的对端异常关闭,比如网络断掉,突然断电.</code></pre>
</li>
</ul>
</li>
<li>SO_SNDBUF的大小<br>为了达到最大网络吞吐，socket send buffer size(SO_SNDBUF)不应该小于带宽和延迟的乘积。</li>
<li>SO_REUSEADDR<br>该参数如果设置为true的一个常用应用场景是端口复用(直接复用TIME_WAIT状态的socket)。</li>
<li>SO_LINGER<br>该参数是控制TCP关闭行为的。</li>
<li>SO_BACKLOG<br>服务端接受客户端连接的处理队列，在TCP三次握手协议中，服务端接收到客户端的SYN包后，会向客户端发送SYN+ACK包，同时会将连接放入到 backlog 队列中，等待客户端ACK包。在服务端没有接收到客户端的ACK包之前，连接会暂存 backlog 队列。</li>
<li>SO_TIMEOUT<br>以毫秒为单位定义套接字超时(SO_TIMEOUT)，它是等待数据的超时，或者换句话说，是两个连续数据包之间的最大活动周期。超时值为0将被解释为无限超时。如果没有设置该参数，读取操作将不会超时(无穷小超时)。个人思考：在NIO编程开发中应该不要设置该值，但为了保证每个连接的读平等，Netty会控制一次事件选择周期，最多可调用read方法的次数。</li>
<li>TCP_NODELAY<br>在TCP数据包发送的时候，有一种算法（Nagle算法）。该算法的核心是如果发生数据包比较小，为了提高带宽的利用率，会等待更多的数据到达后再发送或等待超时后将小包发送，也就是TCP发送延迟，TCP_NODELAY=true表示不使用tcp delay延迟，故禁用Nagle算法。通常接受端的ACK包也会使用延迟（默认40ms)，旨在合并多个ACK确认包。<br>Nagle 算法的改进在于：如果发送端欲多次发送包含少量字符的数据包(一般情况下,后面统一称长度小于MSS的数据包为小包,与此相对,称长度等于MSS的数据包为大包,为了某些对比说明,还有中包,即长度比小包长,但又不足一个MSS的包;MSS,TCP最大分段大小,以太网下一般就是1460字节。),则发送端会先将第一个小包发送出去,而将后面到达的少量字符数据都缓存起来而不立即发送,直到收到接收端对前一个数据包报文段的ACK确认、或当前字符属于紧急数据,或者积攒到了一定数量的数据(比如缓存的字符数据已经达到数据包报文段的最大长度)等多种情况才将其组成一个较大的数据包发送出去。</li>
</ul>
<h2 id="4、Channel-NIO-继承图"><a href="#4、Channel-NIO-继承图" class="headerlink" title="4、Channel NIO 继承图"></a>4、Channel NIO 继承图</h2><p>Channel 类继承图主要是想展示一下与 NIO 相关的 NioSocketChannel (客户端通道)与NioServerSocketChannel (服务端通道)在 Channel 中的位置。<br><img src="https://img-blog.csdnimg.cn/20201129212730624.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Channel 通道统一抽象接口。</p>
<ul>
<li>AbstractChannel 通道默认抽象实现类</li>
<li>AbstractEpollChannel unix Epoll通道实现</li>
<li>AbstractOioChannel 阻塞IO通道抽象类</li>
<li>AbstractNioChannel NIO通道抽象类</li>
<li>AbstractNioByteChannel NIO客户端通道抽象类</li>
<li>AbstractNIoMessageChannel NIO服务端通道抽象类</li>
<li>NioSocketChannel  NIO客户端通道实现类</li>
<li>NioServerSocketChannel NIO服务端通道实现类</li>
</ul>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>netty4</category>
      </categories>
      <tags>
        <tag>netty4</tag>
        <tag>源码</tag>
        <tag>ChannelHandler</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ HA机制(主从同步)</title>
    <url>/posts/12eccc4e.html</url>
    <content><![CDATA[<div id="vip-container"><blockquote>
<p>温馨提示：建议参考代码RocketMQ4.4版本，4.5版本引入了多副本机制，实现了主从自动切换，本文并不关心主从切换功能。</p>
</blockquote>
<h2 id="1、初识主从同步"><a href="#1、初识主从同步" class="headerlink" title="1、初识主从同步"></a>1、初识主从同步</h2><p>主从同步基本实现过程如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190625233757881.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>RocketMQ 的主从同步机制如下：<br>A. 首先启动Master并在指定端口监听；<br>B. 客户端启动，主动连接Master，建立TCP连接；<br>C. 客户端以每隔5s的间隔时间向服务端拉取消息，如果是第一次拉取的话，先获取本地commitlog文件中最大的偏移量，以该偏移量向服务端拉取消息；<br>D. 服务端解析请求，并返回一批数据给客户端；<br>E. 客户端收到一批消息后，将消息写入本地commitlog文件中，然后向Master汇报拉取进度，并更新下一次待拉取偏移量；<br>F. 然后重复第3步；</p>
<p>RocketMQ主从同步一个重要的特征：主从同步不具备主从切换功能，即当主节点宕机后，从不会接管消息发送，但可以提供消息读取。</p>
<blockquote>
<p>温馨提示：本文并不会详细分析RocketMQ主从同步的实现细节，如大家对其感兴趣，可以查阅笔者所著的《RocketMQ技术内幕》或查看笔者博文：<a href="https://blog.csdn.net/prestigeding/article/details/79600792">https://blog.csdn.net/prestigeding/article/details/79600792</a></p>
</blockquote>
<h2 id="2、提出问题"><a href="#2、提出问题" class="headerlink" title="2、提出问题"></a>2、提出问题</h2><ul>
<li>主，从服务器都在运行过程中，消息消费者是从主拉取消息还是从从拉取？</li>
<li>RocketMQ主从同步架构中，如果主服务器宕机，从服务器会接管消息消费，此时消息消费进度如何保持，当主服务器恢复后，消息消费者是从主拉取消息还是从从服务器拉取，主从服务器之间的消息消费进度如何同步？</li>
</ul>
<p>接下来带着上述问题，一起来探究其实现原理。</p>
<h2 id="3、原理探究"><a href="#3、原理探究" class="headerlink" title="3、原理探究"></a>3、原理探究</h2><h3 id="3-1-RocketMQ主从读写分离机制"><a href="#3-1-RocketMQ主从读写分离机制" class="headerlink" title="3.1 RocketMQ主从读写分离机制"></a>3.1 RocketMQ主从读写分离机制</h3><p>RocketMQ的主从同步，在默认情况下RocketMQ会优先选择从主服务器进行拉取消息，并不是通常意义的上的读写分离，那什么时候会从拉取呢？</p>
<blockquote>
<p>温馨提示：本节同样不会详细整个流程，只会点出其关键点，如果想详细了解消息拉取、消息消费等核心流程，建议大家查阅笔者所著的《RocketMQ技术内幕》。</p>
</blockquote>
<p>在RocketMQ中判断是从主拉取，还是从从拉取的核心代码如下：<br>DefaultMessageStore#getMessage</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> diff = maxOffsetPy - maxPhyOffsetPulling;  <span class="comment">// @1</span></span><br><span class="line"><span class="keyword">long</span> memory = (<span class="keyword">long</span>) (StoreUtil.TOTAL_PHYSICAL_MEMORY_SIZE</span><br><span class="line">                            * (<span class="keyword">this</span>.messageStoreConfig.getAccessMessageInMemoryMaxRatio() / <span class="number">100.0</span>));  <span class="comment">// @2</span></span><br><span class="line">getResult.setSuggestPullingFromSlave(diff &gt; memory);   <span class="comment">// @3</span></span><br></pre></td></tr></table></figure>
<p>代码@1：首先介绍一下几个局部变量的含义：</p>
<ul>
<li>maxOffsetPy<br>当前最大的物理偏移量。返回的偏移量为已存入到操作系统的PageCache中的内容。</li>
<li>maxPhyOffsetPulling<br>本次消息拉取最大物理偏移量，按照消息顺序拉取的基本原则，可以基本预测下次开始拉取的物理偏移量将大于该值，并且就在其附近。</li>
<li>diff<br>maxOffsetPy与maxPhyOffsetPulling之间的间隔，getMessage通常用于消息消费时，即这个间隔可以理解为目前未处理的消息总大小。</li>
</ul>
<p>代码@2：获取RocketMQ消息存储在PageCache中的总大小，如果当RocketMQ容量超过该阔值，将会将被置换出内存，如果要访问不在PageCache中的消息，则需要从磁盘读取。</p>
<ul>
<li>StoreUtil.TOTAL_PHYSICAL_MEMORY_SIZE<br>返回当前系统的总物理内存。参数</li>
<li>accessMessageInMemoryMaxRatio<br>设置消息存储在内存中的阀值，默认为40。<br>结合代码@2这两个参数的含义，算出RocketMQ消息能映射到内存中最大值为40% * (机器物理内存)。</li>
</ul>
<p>代码@3：设置下次拉起是否从从拉取标记，触发下次从从服务器拉取的条件为：当前所有可用消息数据(所有commitlog)文件的大小已经超过了其阔值，默认为物理内存的40%。</p>
<a id="more"></a>

<p>那GetResult的suggestPullingFromSlave属性在哪里使用呢？</p>
<p>PullMessageProcessor#processRequest</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (getMessageResult.isSuggestPullingFromSlave()) &#123;      <span class="comment">// @1</span></span><br><span class="line">responseHeader.setSuggestWhichBrokerId(subscriptionGroupConfig.getWhichBrokerWhenConsumeSlowly());</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       responseHeader.setSuggestWhichBrokerId(MixAll.MASTER_ID);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">switch</span> (<span class="keyword">this</span>.brokerController.getMessageStoreConfig().getBrokerRole()) &#123;      <span class="comment">// @2</span></span><br><span class="line">       <span class="keyword">case</span> ASYNC_MASTER:</span><br><span class="line">       <span class="keyword">case</span> SYNC_MASTER:</span><br><span class="line">               <span class="keyword">break</span>;</span><br><span class="line">       <span class="keyword">case</span> SLAVE:</span><br><span class="line">               <span class="keyword">if</span> (!<span class="keyword">this</span>.brokerController.getBrokerConfig().isSlaveReadEnable()) &#123;</span><br><span class="line">                        response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY);</span><br><span class="line">                        responseHeader.setSuggestWhichBrokerId(MixAll.MASTER_ID);</span><br><span class="line">               &#125;</span><br><span class="line">              <span class="keyword">break</span>;</span><br><span class="line"> &#125; </span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">this</span>.brokerController.getBrokerConfig().isSlaveReadEnable()) &#123; <span class="comment">// @3</span></span><br><span class="line">            <span class="comment">// consume too slow ,redirect to another machine</span></span><br><span class="line">            <span class="keyword">if</span> (getMessageResult.isSuggestPullingFromSlave()) &#123;</span><br><span class="line">                 responseHeader.setSuggestWhichBrokerId(subscriptionGroupConfig.getWhichBrokerWhenConsumeSlowly());</span><br><span class="line">            &#125;</span><br><span class="line">           <span class="comment">// consume ok</span></span><br><span class="line">           <span class="keyword">else</span> &#123;</span><br><span class="line">                responseHeader.setSuggestWhichBrokerId(subscriptionGroupConfig.getBrokerId());</span><br><span class="line">           &#125;</span><br><span class="line">     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           responseHeader.setSuggestWhichBrokerId(MixAll.MASTER_ID);</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果从commitlog文件查找消息时，发现消息堆积太多，默认超过物理内存的40%后，会建议从从服务器读取。</p>
<p>代码@2：如果当前服务器的角色为从服务器:并且slaveReadEnable=true，则忽略代码@1设置的值，下次拉取切换为从主拉取。</p>
<p>代码@3：如果slaveReadEnable=true(从允许读)，并且建议从从服务器读取，则从消息消费组建议当消息消费缓慢时建议的拉取brokerId，由订阅组配置属性whichBrokerWhenConsumeSlowly决定；如果消息消费速度正常，则使用订阅组建议的brokerId拉取消息进行消费，默认为主服务器。如果不允许从可读，则固定使用从主拉取。</p>
<blockquote>
<p>温馨提示：请注意broker服务参数slaveReadEnable，与订阅组配置信息：whichBrokerWhenConsumeSlowly、brokerId的值，在生产环境中，可以通过updateSubGroup命令动态改变订阅组的配置信息。</p>
</blockquote>
<p>如果订阅组的配置保持默认值的话，拉取消息请求发送到从服务器后，下一次消息拉取，无论是否开启slaveReadEnable，下一次拉取，还是会发往主服务器。</p>
<p>上面的步骤，在消息拉取命令的返回字段中，会将下次建议拉取Broker返回给客户端，根据其值从指定的broker拉取。</p>
<p>消息拉取实现PullAPIWrapper在处理拉取结果时会将服务端建议的brokerId更新到broker拉取缓存表中。<br><img src="https://img-blog.csdnimg.cn/20190625234245349.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在发起拉取请求之前，首先根据如下代码，选择待拉取消息的Broker。<br><img src="https://img-blog.csdnimg.cn/20190625234309172.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="3-2-消息消费进度同步机制"><a href="#3-2-消息消费进度同步机制" class="headerlink" title="3.2 消息消费进度同步机制"></a>3.2 消息消费进度同步机制</h3><p>从上面内容可知，主从同步引入的主要目的就是消息堆积的内容默认超过物理内存的40%，则消息读取则由从服务器来接管，实现消息的读写分离，避免主服务IO抖动严重。那问题来了，主服务器宕机后，从服务器接管消息消费后，那消息消费进度存储在哪里？当主服务器恢复正常后，消息是从主服务器拉取还是从从服务器拉取？主服务器如何得知最新的消息消费进度呢？</p>
<p>RocketMQ消息消费进度管理（集群模式）：<br>集群模式下消息消费进度存储文件位于服务端${ROCKETMQ_HOME}/store/config/consumerOffset.json。消息消费者从服务器拉取一批消息后提交到消费组特定的线程池中处理消息，当消息消费成功后会向Broker发送ACK消息，告知消费端已成功消费到哪条消息，Broker收到消息消费进度反馈后，首先存储在内存中，然后定时持久化到consumeOffset.json文件中。备注：关于消息消费进度管理更多的实现细节，建议查阅笔者所著的《RocketMQ技术内幕》。</p>
<p>我们先看一下客户端向服务端反馈消息消费进度时如何选择Broker。<br>因为主服务的brokerId为0，默认情况下当主服务器存活的时候，优先会选择主服务器，只有当主服务器宕机的情况下，才会选择从服务器。</p>
<p>既然集群模式下消息消费进度存储在Broker端，当主服务器正常时，消息消费进度文件存储在主服务器，那提出如下两个问题：<br>1）消息消费端在主服务器存活的情况下，会优先向主服务器反馈消息消费进度，那从服务器是如何同步消息消费进度的。<br>2）当主服务器宕机后则消息消费端会向从服务器反馈消息消费进度，此时消息消费进度如何存储，当主服务器恢复正常后，主服务器如何得知最新的消息消费进度。</p>
<p>为了解开上述两个疑问，我们优先来看一下Broker服务器在收到提交消息消费进度反馈命令后的处理逻辑：</p>
<p>客户端定时向Broker端发送更新消息消费进度的请求，其入口为：RemoteBrokerOffsetStore#updateConsumeOffsetToBroker，该方法中一个非常关键的点是：选择broker的逻辑，如下所示：<br><img src="https://img-blog.csdnimg.cn/20190625234502316.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>如果主服务器存活，则选择主服务器，如果主服务器宕机，则选择从服务器。也就是说，不管消息是从主服务器拉取的还是从从服务器拉取的，提交消息消费进度请求，优先选择主服务器。服务端就是接收其偏移量，更新到服务端的内存中，然后定时持久化到${ROCKETMQ_HOME}/store/config/consumerOffset.json。</p>
<p>经过上面的分析，我们来讨论一下这个场景：<br>消息消费者首先从主服务器拉取消息，并向其提交消息消费进度，如果当主服务器宕机后，从服务器会接管消息拉取服务，此时消息消费进度存储在从服务器，主从服务器的消息消费进度会出现不一致？那当主服务器恢复正常后，两者之间的消息消费进度如何同步？</p>
<h5 id="3-2-1-从服务定时同步主服务器进度"><a href="#3-2-1-从服务定时同步主服务器进度" class="headerlink" title="3.2.1 从服务定时同步主服务器进度"></a>3.2.1 从服务定时同步主服务器进度</h5><p><img src="https://img-blog.csdnimg.cn/20190625234556971.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>如果Broker角色为从服务器，会通过定时任务调用syncAll，从主服务器定时同步topic路由信息、消息消费进度、延迟队列处理进度、消费组订阅信息。</p>
<p>那问题来了，如果主服务器启动后，从服务器马上从主服务器同步消息消息进度，那岂不是又要重新消费？</p>
<p>其实在绝大部分情况下，就算从服务从主服务器同步了很久之前的消费进度，只要消息者没有重新启动，就不需要重新消费，在这种情况下，RocketMQ提供了两种机制来确保不丢失消息消费进度。</p>
<p>第一种，消息消费者在内存中存在最新的消息消费进度，继续以该进度去服务器拉取消息后，消息处理完后，会定时向Broker服务器反馈消息消费进度，在上面也提到过，在反馈消息消费进度时，会优先选择主服务器，此时主服务器的消息消费进度就立马更新了，从服务器此时只需定时同步主服务器的消息消费进度即可。</p>
<p>第二种是，消息消费者在向主服务器拉取消息时，如果是是主服务器，在处理消息拉取时，也会更新消息消费进度。</p>
<h5 id="3-2-2-主服务器消息拉取时更新消息消费进度"><a href="#3-2-2-主服务器消息拉取时更新消息消费进度" class="headerlink" title="3.2.2 主服务器消息拉取时更新消息消费进度"></a>3.2.2 主服务器消息拉取时更新消息消费进度</h5><p>主服务器在处理消息拉取命令时，会触发消息消费进度的更新，其代码入口为：PullMessageProcessor#processRequest</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">boolean</span> storeOffsetEnable = brokerAllowSuspend;  <span class="comment">// @1</span></span><br><span class="line">storeOffsetEnable = storeOffsetEnable &amp;&amp; hasCommitOffsetFlag; </span><br><span class="line">storeOffsetEnable = storeOffsetEnable</span><br><span class="line">            &amp;&amp; <span class="keyword">this</span>.brokerController.getMessageStoreConfig().getBrokerRole() != BrokerRole.SLAVE;  <span class="comment">// @2</span></span><br><span class="line"><span class="keyword">if</span> (storeOffsetEnable) &#123;</span><br><span class="line">            <span class="keyword">this</span>.brokerController.getConsumerOffsetManager().commitOffset(RemotingHelper.parseChannelRemoteAddr(channel),</span><br><span class="line">                requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getCommitOffset());</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先介绍几个局部变量的含义：</p>
<ul>
<li>brokerAllowSuspend：broker是否允许挂起，在消息拉取时，该值默认为true。</li>
<li>hasCommitOffsetFlag：消息消费者在内存中是否缓存了消息消费进度，如果缓存了，该标记设置为true。<br>如果Broker的角色为主服务器，并且上面两个变量都为true，则首先使用commitOffset更新消息消费进度。</li>
</ul>
<p>看到这里，主从同步消息消费进度的相关问题，应该就有了答案了。</p>
<h2 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h2><p>上述实现原理的讲解有点枯燥无味，我们先来回答如下几个问题：</p>
<p>1、主，从服务器都在运行过程中，消息消费者是从主拉取消息还是从从拉取？<br>答：默认情况下，RocketMQ消息消费者从主服务器拉取，当主服务器积压的消息超过了物理内存的40%，则建议从从服务器拉取。但如果slaveReadEnable为false，表示从服务器不可读，从服务器也不会接管消息拉取。</p>
<p>2、当消息消费者向从服务器拉取消息后，会一直从从服务器拉取？<br>答：不是的。分如下情况：<br>1）如果从服务器的slaveReadEnable设置为false，则下次拉取，从主服务器拉取。<br>2）如果从服务器允许读取并且从服务器积压的消息未超过其物理内存的40%，下次拉取使用的Broker为订阅组的brokerId指定的Broker服务器，该值默认为0，代表主服务器。<br>3）如果从服务器允许读取并且从服务器积压的消息超过了其物理内存的40%，下次拉取使用的Broker为订阅组的whichBrokerWhenConsumeSlowly指定的Broker服务器，该值默认为1，代表从服务器。</p>
<p>3、主从服务消息消费进是如何同步的？<br>答：消息消费进度的同步时单向的，从服务器开启一个定时任务，定时从主服务器同步消息消费进度；无论消息消费者是从主服务器拉的消息还是从从服务器拉取的消息，在向Broker反馈消息消费进度时，优先向主服务器汇报；消息消费者向主服务器拉取消息时，如果消息消费者内存中存在消息消费进度时，主会尝试跟新消息消费进度。</p>
<p>读写分离的正确使用姿势：<br>1、主从Broker服务器的slaveReadEnable设置为true。<br>2、通过updateSubGroup命令更新消息组whichBrokerWhenConsumeSlowly、brokerId，特别是其brokerId不要设置为0，不然从从服务器拉取一次后，下一次拉取就会从主去拉取。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>ha</tag>
        <tag>主从同步</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ msgId与offsetMsgId释疑(实战篇)</title>
    <url>/posts/e0111576.html</url>
    <content><![CDATA[<div id="vip-container"><p>本篇详细介绍消息发送、消息消费、RocketMQ queryMsgById 命令以及 rocketmq-console 等使用场景中究竟是用的哪一个ID。</p>
<p>@<a href="%E6%9C%AC%E8%8A%82%E7%9B%AE%E5%BD%95">TOC</a></p>
<h2 id="1、抛出问题"><a href="#1、抛出问题" class="headerlink" title="1、抛出问题"></a>1、抛出问题</h2><h4 id="1-1-从消息发送看消息ID"><a href="#1-1-从消息发送看消息ID" class="headerlink" title="1.1 从消息发送看消息ID"></a>1.1 从消息发送看消息ID</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.rocketmq.example.quickstart;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.DefaultMQProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.SendResult;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.Message;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.remoting.common.RemotingHelper;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span>  </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;please_rename_unique_group_name&quot;</span>);</span><br><span class="line">            producer.setNamesrvAddr(<span class="string">&quot;127.0.0.1:9876&quot;</span>);</span><br><span class="line">            producer.start();</span><br><span class="line">            Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;TestTopic&quot;</span> <span class="comment">/* Topic */</span>,<span class="keyword">null</span> <span class="comment">/* Tag */</span>, (<span class="string">&quot;Hello RocketMQ test1&quot;</span> ).getBytes(RemotingHelper.DEFAULT_CHARSET) <span class="comment">/* Message body */</span>);</span><br><span class="line">            SendResult sendResult = producer.send(msg);</span><br><span class="line">            System.out.printf(<span class="string">&quot;%s%n&quot;</span>, sendResult);</span><br><span class="line">            producer.shutdown();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行效果如图所示：<br><img src="https://img-blog.csdnimg.cn/20200308201940382.png" alt="在这里插入图片描述">即消息发送会返回 msgId 与 offsetMsgId。</p>
<h4 id="1-2-从消息消费看消息ID"><a href="#1-2-从消息消费看消息ID" class="headerlink" title="1.2 从消息消费看消息ID"></a>1.2 从消息消费看消息ID</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.rocketmq.example.quickstart;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.exception.MQClientException;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.consumer.ConsumeFromWhere;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.MessageExt;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, MQClientException </span>&#123;</span><br><span class="line">        DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">&quot;please_rename_unique_group_name_1&quot;</span>);</span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">&quot;127.0.0.1:9876&quot;</span>);</span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class="line">        consumer.subscribe(<span class="string">&quot;TestTopic&quot;</span>, <span class="string">&quot;*&quot;</span>);</span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs,</span></span></span><br><span class="line"><span class="function"><span class="params">                ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;MessageExt msg.getMsgId():&quot;</span> +  msgs.get(<span class="number">0</span>).getMsgId());</span><br><span class="line">                System.out.println(<span class="string">&quot;-------------------分割线-----------------&quot;</span>);</span><br><span class="line">                System.out.printf(<span class="string">&quot;%s Receive New Messages: %s %n&quot;</span>, Thread.currentThread().getName(), msgs);</span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.printf(<span class="string">&quot;Consumer Started.%n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行效果如图所示：<br><img src="https://img-blog.csdnimg.cn/20200308202103968.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>不知道大家是否有注意到，调用 msgs.get(0).getMsgId()返回的msgId 与直接输出msgs中的 msgId 不一样，那这又是为什么呢？答案在本文的第二部分有详细分析。</strong></p>
<h2 id="2、消息ID释疑"><a href="#2、消息ID释疑" class="headerlink" title="2、消息ID释疑"></a>2、消息ID释疑</h2><p>从消息发送的结果可以得知，RocketMQ 发送的返回结果会返回msgId 与 offsetMsgId，那这两个 msgId 分别是代表什么呢？</p>
<ul>
<li>msgId：该ID 是消息发送者在消息发送时会首先在客户端生成，全局唯一，在 RocketMQ 中该 ID 还有另外的一个叫法：uniqId，无不体现其全局唯一性。</li>
<li>offsetMsgId：消息偏移ID，该 ID 记录了消息所在集群的物理地址，主要包含所存储 Broker 服务器的地址( IP 与端口号)以及所在commitlog 文件的物理偏移量。</li>
</ul>
<h4 id="2-1-msgId-即全局唯一-ID-构建规则"><a href="#2-1-msgId-即全局唯一-ID-构建规则" class="headerlink" title="2.1 msgId 即全局唯一 ID 构建规则"></a>2.1 msgId 即全局唯一 ID 构建规则</h4><p><img src="https://img-blog.csdnimg.cn/20200308202402908.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>从这张图可以看出，msgId确实是客户端生成的，接下来我们详细分析一下其生成算法。</p>
<p>MessageClientIDSetter#createUniqID</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">createUniqID</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    StringBuilder sb = <span class="keyword">new</span> StringBuilder(LEN * <span class="number">2</span>);</span><br><span class="line">    sb.append(FIX_STRING);    <span class="comment">// @1</span></span><br><span class="line">    sb.append(UtilAll.bytes2string(createUniqIDBuffer()));  <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">return</span> sb.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一个 uniqID 的构建主要分成两个部分：FIX_STRING 与唯一 ID 生成算法，顾名思义，FIX_STRING 就是一个客户端固定一个前缀，那接下来先看一下固定字符串的生成规则。</p>
<h5 id="2-1-1-FIX-STRING"><a href="#2-1-1-FIX-STRING" class="headerlink" title="2.1.1 FIX_STRING"></a>2.1.1 FIX_STRING</h5><p>MessageClientIDSetter静态代码块</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    <span class="keyword">byte</span>[] ip;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        ip = UtilAll.getIP();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        ip = createFakeIP();</span><br><span class="line">    &#125;</span><br><span class="line">    LEN = ip.length + <span class="number">2</span> + <span class="number">4</span> + <span class="number">4</span> + <span class="number">2</span>;</span><br><span class="line">    ByteBuffer tempBuffer = ByteBuffer.allocate(ip.length + <span class="number">2</span> + <span class="number">4</span>);</span><br><span class="line">    tempBuffer.position(<span class="number">0</span>);</span><br><span class="line">    tempBuffer.put(ip);</span><br><span class="line">    tempBuffer.position(ip.length);</span><br><span class="line">    tempBuffer.putInt(UtilAll.getPid());</span><br><span class="line">    tempBuffer.position(ip.length + <span class="number">2</span>);</span><br><span class="line">    tempBuffer.putInt(MessageClientIDSetter.class.getClassLoader().hashCode());</span><br><span class="line">    FIX_STRING = UtilAll.bytes2string(tempBuffer.array());</span><br><span class="line">    setStartTime(System.currentTimeMillis());</span><br><span class="line">    COUNTER = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从这里可以看出 FIX_STRING 的主要由：客户端的IP、进程ID、加载 MessageClientIDSetter 的类加载器的 hashcode。</p>
<h5 id="2-1-2-唯一性算法"><a href="#2-1-2-唯一性算法" class="headerlink" title="2.1.2 唯一性算法"></a>2.1.2 唯一性算法</h5><p>msgId 的唯一性算法由 MessageClientIDSetter 的createUniqIDBuffer 方法实现。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] createUniqIDBuffer() &#123;</span><br><span class="line">    ByteBuffer buffer = ByteBuffer.allocate(<span class="number">4</span> + <span class="number">2</span>);</span><br><span class="line">    <span class="keyword">long</span> current = System.currentTimeMillis();</span><br><span class="line">    <span class="keyword">if</span> (current &gt;= nextStartTime) &#123;</span><br><span class="line">        setStartTime(current);</span><br><span class="line">    &#125;</span><br><span class="line">    buffer.position(<span class="number">0</span>);</span><br><span class="line">    buffer.putInt((<span class="keyword">int</span>) (System.currentTimeMillis() - startTime));</span><br><span class="line">    buffer.putShort((<span class="keyword">short</span>) COUNTER.getAndIncrement());</span><br><span class="line">    <span class="keyword">return</span> buffer.array();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以得出 msgId 的后半段主要由：当前时间与系统启动时间的差值，以及自增序号。</p>
<h4 id="2-2-offsetMsgId构建规则"><a href="#2-2-offsetMsgId构建规则" class="headerlink" title="2.2 offsetMsgId构建规则"></a>2.2 offsetMsgId构建规则</h4><p><img src="https://img-blog.csdnimg.cn/20200308202705728.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在消息 Broker 服务端将消息追加到内存后会返回其物理偏移量，即在 commitlog 文件中的文件，然后会再次生成一个id，代码中虽然也叫 msgId，其实这里就是我们常说的 offsetMsgId，即记录了消息的物理偏移量，故我们重点来看一下其具体生成规则：<br>MessageDecoder#createMessageId</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">createMessageId</span><span class="params">(<span class="keyword">final</span> ByteBuffer input ,</span></span></span><br><span class="line"><span class="function"><span class="params">            <span class="keyword">final</span> ByteBuffer addr, <span class="keyword">final</span> <span class="keyword">long</span> offset)</span> </span>&#123;</span><br><span class="line">	input.flip();</span><br><span class="line">    <span class="keyword">int</span> msgIDLength = addr.limit() == <span class="number">8</span> ? <span class="number">16</span> : <span class="number">28</span>;</span><br><span class="line">    input.limit(msgIDLength);</span><br><span class="line">    input.put(addr);</span><br><span class="line">    input.putLong(offset);</span><br><span class="line">    <span class="keyword">return</span> UtilAll.bytes2string(input.array());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先结合该方法的调用上下文，先解释一下该方法三个入参的含义：</p>
<ul>
<li>ByteBuffer input<br>用来存放 offsetMsgId 的字节缓存区( NIO 相关的基础知识)</li>
<li>ByteBuffer addr<br>当前 Broker 服务器的 IP 地址与端口号，即通过解析 offsetMsgId 从而得到消息服务器的地址信息。</li>
<li>long offset<br>消息的物理偏移量。<br>即构成 offsetMsgId 的组成部分：Broker 服务器的 IP 与端口号、消息的物理偏移量。</li>
</ul>
<blockquote>
<p>温馨提示：即在 RocketMQ中，只需要提供 offsetMsgId，可用不必知道该消息所属的topic信息即可查询该条消息的内容。</p>
</blockquote>
<h4 id="2-3-消息发送与消息消费返回的消息ID信息"><a href="#2-3-消息发送与消息消费返回的消息ID信息" class="headerlink" title="2.3 消息发送与消息消费返回的消息ID信息"></a>2.3 消息发送与消息消费返回的消息ID信息</h4><p>消息发送时会在 SendSesult中返回 msgId、offsetMsgId，在了解了这个两个 ID 的含义时则问题不大，接下来重点介绍一下消息消费时返回的 msgId 到底是哪一个。</p>
<p>在消息消费时，我们更加希望因为 msgId (即客户端生成的全局唯一性ID)，因为该全局性 ID 非常方便实现消费端的幂等。</p>
<p>在本文的1.2节我们也提到一个现象，为什么如下图代码中输出的 msgId 会不一样呢？<br><img src="https://img-blog.csdnimg.cn/20200308203117923.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在客户端返回的 msg 信息，其最终返回的对象是  MessageClientExt ，继承自 MessageExt。<br>那我们接下来分别看一下其 getMsgId() 方法与 toString 方法即可。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getMsgId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    String uniqID = MessageClientIDSetter.getUniqID(<span class="keyword">this</span>);</span><br><span class="line">    <span class="keyword">if</span> (uniqID == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.getOffsetMsgId();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> uniqID;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>原来在调用 MessageClientExt 中的 getMsgId 方法时，如果消息的属性中存在其唯一ID，则返回消息的全局唯一ID，否则返回消息的 offsetMsgId。</p>
<p>而 MessageClientExt 方法并没有重写 MessageExt 的 toString 方法，其实现如图所示：<br><img src="https://img-blog.csdnimg.cn/20200308203311967.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>故返回的是 MessageExt中 的 msgId，该 msgId 存放的是offsetMsgId，所以才造成了困扰。</p>
<blockquote>
<p>温馨提示：如果消息消费失败需要重试，RocketMQ 的做法是将消息重新发送到 Broker 服务器，此时全局 msgId 是不会发送变化的，但该消息的 offsetMsgId 会发送变化，因为其存储在服务器中的位置发生了变化。</p>
</blockquote>
<h2 id="3、实践经验"><a href="#3、实践经验" class="headerlink" title="3、实践经验"></a>3、实践经验</h2><p>在回答了消息发送与消息消费关于msgId与offsetMsgId的困扰后，再来介绍一下如果根据msgId去查询消息。</p>
<p>想必大家对 rocketmq-console ，那在消息查找界面，展示的消息列表中返回的 msgId 又是哪一个呢？<br><img src="https://img-blog.csdnimg.cn/20200308203400221.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>这里的 Message ID 返回的是消息的全局唯一ID。</p>
<p>其实 RokcetMQ 也提供了 queryMsgById 命令来查看消息的内容，不过这里的 msgId 是 offsetMsgId，我们首先将全局唯一ID传入命令，其执行效果如下：<br><img src="https://img-blog.csdnimg.cn/20200308203431178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>发现报错，那我们将 offsetMsgId 传入其执行效果如图所示：<br><img src="https://img-blog.csdnimg.cn/20200308203452188.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>但在 rocketmq-console 的根据消息ID去查找消息，无论传入哪个msgId，下图该功能都能返回正确的结果：<br><img src="https://img-blog.csdnimg.cn/20200308203540222.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>这是因为 rocketmq-console 做了兼容，首先将传入的 msgId 用 queryMsgById 该命令去查，如果报错，则当成 uniqID(全局ID)去查，首先全局ID会存储在消息的属性中，并会创建 Hash 索引，即可用通过 indexfile 快速定位到该条消息。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>msgId</tag>
        <tag>offsetMsgId</tag>
        <tag>queryMsgById</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ 主题扩分片后遇到的坑</title>
    <url>/posts/c4065704.html</url>
    <content><![CDATA[<div id="vip-container"><p>消息组接到某项目组反馈，topic 在扩容后出现部分队列无法被消费者，导致消息积压，影响线上业务？</p>
<p>考虑到该问题是发送在真实的线上环境，为了避免泄密，本文先在笔者的虚拟机中来重现问题。</p>
<h2 id="1、案情回顾"><a href="#1、案情回顾" class="headerlink" title="1、案情回顾"></a>1、案情回顾</h2><h3 id="1-1-集群现状"><a href="#1-1-集群现状" class="headerlink" title="1.1 集群现状"></a>1.1 集群现状</h3><p>集群信息如下：<br><img src="https://img-blog.csdnimg.cn/20190906232935331.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>例如业务主体名 topic_dw_test_by_order_01 的路由信息如图所示：<br><img src="https://img-blog.csdnimg.cn/20190906233008367.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>当前的消费者信息：<br><img src="https://img-blog.csdnimg.cn/20190906233034814.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>broker 的配置信息如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brokerClusterName &#x3D; DefaultCluster</span><br><span class="line">brokerName &#x3D; broker-a</span><br><span class="line">brokerId &#x3D; 0</span><br><span class="line">deleteWhen &#x3D; 04</span><br><span class="line">fileReservedTime &#x3D; 48</span><br><span class="line">brokerRole &#x3D; ASYNC_MASTER</span><br><span class="line">flushDiskType &#x3D; ASYNC_FLUSH</span><br><span class="line">brokerIP1&#x3D;192.168.0.220</span><br><span class="line">brokerIP2-192.168.0.220</span><br><span class="line">namesrvAddr&#x3D;192.168.0.221:9876;192.168.0.220:9876</span><br><span class="line">storePathRootDir&#x3D;&#x2F;opt&#x2F;application&#x2F;rocketmq-all-4.5.2-bin-release&#x2F;store</span><br><span class="line">storePathCommitLog&#x3D;&#x2F;opt&#x2F;application&#x2F;rocketmq-all-4.5.2-bin-release&#x2F;store&#x2F;commitlog</span><br><span class="line">autoCreateTopicEnable&#x3D;false</span><br><span class="line">autoCreateSubscriptionGroup&#x3D;false</span><br></pre></td></tr></table></figure>
<blockquote>
<p>备注：公司对 topic、消费组进行了严格的管控，项目组需要使用时需要向运维人员申请，故 broker 集群不允许自动创建主题与自动创建消费组。</p>
</blockquote>
<p>由于该业务量稳步提升，项目组觉得该主题的队列数太少，不利于增加消费者来提高其消费能力，故向运维人员提出增加队列的需求。</p>
<h3 id="1-2、RocketMQ-在线扩容队列"><a href="#1-2、RocketMQ-在线扩容队列" class="headerlink" title="1.2、RocketMQ 在线扩容队列"></a>1.2、RocketMQ 在线扩容队列</h3><p>运维通过公司自研的消息运维平台，直接以指定集群的方式为 topic 扩容，该运维平台底层其实使用了RocketMQ 提供的 updateTopic 命令，其命令说明如下：</p>
<a id="more"></a>

<p><img src="https://img-blog.csdnimg.cn/20190906233121258.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="图片来源于《》RocketMQ技术内幕》"><br>从上图可以得知可以通过 -c 命令来指定在集群中所有的 broker 上创建队列，在本例中，将队列数从 4 设置为 8，具体命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sh .&#x2F;mqadmin upateTopic -n 192.168.0.220:9876 -c DefaultCluster -t topic_dw_test_by_order_01 -r 8 -w 8</span><br></pre></td></tr></table></figure>
<p>执行效果如图所示，表示更新成功。<br><img src="https://img-blog.csdnimg.cn/20190906233249376.png" alt="在这里插入图片描述"><br>我们再来从 rocketmq-console 中来看命令执行后的效果：<br><img src="https://img-blog.csdnimg.cn/20190906233418121.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>从上图可以得知，主题的队列数已经扩容到了8个，并且在集群的两台broker上都创建了队列。</p>
<h3 id="1-3-消息发送"><a href="#1-3-消息发送" class="headerlink" title="1.3 消息发送"></a>1.3 消息发送</h3><p>从 RocketMQ 系列可知，RocketMQ 是支持在线 topic 在线扩容机制的，故无需重启 消息发送者、消息消费者，随着时间的推移，我们可以查看topic的所有队列都参与到了消息的负载中，如图所示：<br><img src="https://img-blog.csdnimg.cn/20190906233500250.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们可以清晰的看到，所有的16个队列(每个 broker 8个队列)都参与到了消息发送的，运维小哥愉快的完成了topic的扩容。</p>
<h2 id="2、问题暴露"><a href="#2、问题暴露" class="headerlink" title="2、问题暴露"></a>2、问题暴露</h2><p>该 topic 被 5个消费组所订阅，突然接到通知，其中有两个消费组反馈，部分队列的消息没有被消费，导致下游系统并没有及时处理。</p>
<h2 id="3、问题分析"><a href="#3、问题分析" class="headerlink" title="3、问题分析"></a>3、问题分析</h2><p>当时到项目组提交到消息组时，我第一反应是先看消费者的队列，打开该主题的消费情况，如图所示：<br><img src="https://img-blog.csdnimg.cn/20190906233538617.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>发现队列数并没有积压，备注（由于生产是4主4从，每一个 broker上8个队列，故总共32个队列），当时由于比较急，并没有第一时间发现这个界面，竟然只包含一个消费者，觉得并没有消息积压，又由于同一个集群，其他消费组没有问题，只有两个消费组有问题，怀疑是应用的问题，就采取了重启，打印线程栈等方法。</p>
<p>事后诸葛亮：其实这完成是错误的，为什么这样说呢？因为项目组（业务方）已经告知一部分业务未处理，说明肯定有队列的消息积压，当根据自己的知识，结合看到的监控页面做出的判断与业务方反馈的出现冲突时，一定是自己的判断出了问题。</p>
<p>正在我们“如火如荼”的认定是项目有问题时，团队的另一成员提出了自己的观点，原来在得到业务方反馈时，他得知同一个主题，被5个消费组订阅，只有其中两个有问题，那他通过rocketmq-console来找两者的区别，找到区别，找到规律，就离解决问题的路近了。</p>
<p>他通过对比发现，出问题的消费组只有两个客户端在消费（通常生产环境是4节点消费），而没有出现问题的发现有4个进程都在处理，即发现现象：出错的消费组，并没有全员参与到消费。正如上面的图所示：只有其中一个进程在处理8个队列，另外8个队列并没有在消费。</p>
<p>那现在就是要分析为啥topic共有16个队列，但这里只有1个消费者队列在消费，另外一个消费者不作为？</p>
<p>首先根据RocketMQ 消息队列负载机制，2个消费者，只有1个消费者在消费，并且一个有一个明显的特点是，只有broker-a上的队列在消费，broker-b上的队列一个也没消费。</p>
<p>正在思考为啥会出现这种现象时，他又在思考是不是集群是不是broker-b(对应我们生产环境是broker-c、broker-d上的队列都未消费)是新扩容的机器？扩容的时候是不是没有把订阅关系在新的集群上创建？提出了疑问，接下来肖工就开始验证猜想，通过查阅broker-c、broker-d在我们系统中创建的时间是2018-4月的时候，就基本得出结论，扩容时并没有在新集群上创建订阅消息，故无法消费消息。</p>
<p>于是运维小哥使用运维工具创建订阅组，创建方法如图所示：<br><img src="https://img-blog.csdnimg.cn/20190906233645848.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>创建好消费组后，再去查看topic的消费情况时，另外一个消费组也开始处理消息了，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190906233708415.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="4、问题复盘"><a href="#4、问题复盘" class="headerlink" title="4、问题复盘"></a>4、问题复盘</h2><p>潜在原因：DefaultCluster 集群进行过一次集群扩容，从原来的一台消息服务器( broker-a )额外增加一台broker服务器( broker-b )，但扩容的时候并没有把原先的存在于 broker-a 上的主题、消费组扩容到 broker-b 服务器。</p>
<p>触发原因：接到项目组的扩容需求，将集群队列数从4个扩容到8个，这样该topic就在集群的a、b都会存在8个队列，但Broker不允许自动创建消费组（订阅关系），消费者无法从broker-b上队列上拉取消息，导致在broker-b队列上的消息堆积，无法被消费。</p>
<p>解决办法：运维通过命令，在broker-b上创建对应的订阅消息，问题解决。 </p>
<p>经验教训：集群扩容时，需要同步在集群上的topic.json、subscriptionGroup.json文件。</p>
<p>RocketMQ 理论基础，消费者向 Broker 发起消息拉取请求时，如果broker上并没有存在该消费组的订阅消息时，如果不允许自动创建(autoCreateSubscriptionGroup 设置为 false)，默认为true，则不会返回消息给客户端，其代码如下：<br><img src="https://img-blog.csdnimg.cn/20190906234625364.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>问题解决后，我们团队的成员也分享了一下他在本次排查问题的处理方法：<strong>寻找出现问题的规律、推断问题、 然后验证问题。规律可以是问题本身的规律  也可以是和正常对比的差。</strong></p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>主题扩容</tag>
        <tag>实战</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ 升级到主从切换(DLedger、多副本)实战</title>
    <url>/posts/e0ec5d91.html</url>
    <content><![CDATA[<div id="vip-container"><p>本文主要介绍如何将 RocketMQ 集群从原先的主从同步升级到主从切换。</p>
<p>首先先介绍与 DLedger 多副本即 RocketMQ 主从切换相关的核心配置属性，然后尝试搭建一个主从同步集群，再从原先的 RocketMQ 集群平滑升级到 DLedger 集群的示例，并简单测试一下主从切换功能。</p>
<h2 id="1、RocketMQ-DLedger-多副本即主从切换核心配置参数详解"><a href="#1、RocketMQ-DLedger-多副本即主从切换核心配置参数详解" class="headerlink" title="1、RocketMQ DLedger 多副本即主从切换核心配置参数详解"></a>1、RocketMQ DLedger 多副本即主从切换核心配置参数详解</h2><p>其主要的配置参数如下所示：</p>
<ul>
<li>enableDLegerCommitLog<br>是否启用 DLedger，即是否启用 RocketMQ 主从切换，默认值为 false。如果需要开启主从切换，则该值需要设置为 true 。</li>
<li>dLegerGroup<br>节点所属的 raft 组，建议与 brokerName 保持一致，例如 broker-a。</li>
<li>dLegerPeers<br>集群节点信息，示例配置如下：n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913，多个节点用英文冒号隔开，单个条目遵循   legerSlefId-ip:端口，这里的端口用作 dledger 内部通信。</li>
<li>dLegerSelfId<br>当前节点id。取自 legerPeers 中条目的开头，即上述示例中的 n0，并且特别需要强调，只能第一个字符为英文，其他字符需要配置成数字。</li>
<li>storePathRootDir<br>DLedger 日志文件的存储根目录，为了能够支持平滑升级，该值与 storePathCommitLog 设置为不同的目录。</li>
</ul>
<h2 id="2、搭建主从同步环境"><a href="#2、搭建主从同步环境" class="headerlink" title="2、搭建主从同步环境"></a>2、搭建主从同步环境</h2><p>首先先搭建一个传统意义上的主从同步架构，往集群中灌一定量的数据，然后升级到 DLedger 集群。</p>
<p>在 Linux 服务器上搭建一个 rocketmq 主从同步集群我想不是一件很难的事情，故本文就不会详细介绍按照过程，只贴出相关配置。</p>
<p>实验环境的部署结构采取 一主一次，其部署图如下：<br><img src="https://img-blog.csdnimg.cn/20191013142340811.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>下面我就重点贴一下 broker 的配置文件。<br>220 上的 broker 配置文件如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">brokerClusterName = DefaultCluster</span><br><span class="line">brokerName = broker-a</span><br><span class="line">brokerId = <span class="number">0</span></span><br><span class="line">deleteWhen = <span class="number">04</span></span><br><span class="line">fileReservedTime = <span class="number">48</span></span><br><span class="line">brokerRole = ASYNC_MASTER</span><br><span class="line">flushDiskType = ASYNC_FLUSH</span><br><span class="line">brokerIP1=<span class="number">192.168</span><span class="number">.0</span><span class="number">.220</span></span><br><span class="line">brokerIP2=<span class="number">192.168</span><span class="number">.0</span><span class="number">.220</span></span><br><span class="line">namesrvAddr=<span class="number">192.168</span><span class="number">.0</span><span class="number">.221</span>:<span class="number">9876</span>;<span class="number">192.168</span><span class="number">.0</span><span class="number">.220</span>:<span class="number">9876</span></span><br><span class="line">storePathRootDir=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store</span><br><span class="line">storePathCommitLog=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store/commitlog</span><br><span class="line">autoCreateTopicEnable=<span class="literal">false</span></span><br><span class="line">autoCreateSubscriptionGroup=<span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>221 上 broker 的配置文件如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">brokerClusterName = DefaultCluster</span><br><span class="line">brokerName = broker-a</span><br><span class="line">brokerId = <span class="number">1</span></span><br><span class="line">deleteWhen = <span class="number">04</span></span><br><span class="line">fileReservedTime = <span class="number">48</span></span><br><span class="line">brokerRole = SLAVE</span><br><span class="line">flushDiskType = ASYNC_FLUSH</span><br><span class="line">brokerIP1=<span class="number">192.168</span><span class="number">.0</span><span class="number">.221</span></span><br><span class="line">brokerIP2=<span class="number">192.168</span><span class="number">.0</span><span class="number">.221</span></span><br><span class="line">namesrvAddr=<span class="number">192.168</span><span class="number">.0</span><span class="number">.221</span>:<span class="number">9876</span>;<span class="number">192.168</span><span class="number">.0</span><span class="number">.220</span>:<span class="number">9876</span></span><br><span class="line">storePathRootDir=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store</span><br><span class="line">storePathCommitLog=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store/commitlog</span><br><span class="line">autoCreateTopicEnable=<span class="literal">false</span></span><br><span class="line">autoCreateSubscriptionGroup=<span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>相关的启动命令如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">nohup bin/mqnamesrv  /dev/<span class="literal">null</span>  <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br><span class="line">nohup bin/mqbroker -c conf/broker.conf  /dev/<span class="literal">null</span>  <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br></pre></td></tr></table></figure>
<p>安装后的集群信息如图所示：<br><img src="https://img-blog.csdnimg.cn/20191013142514649.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="3、主从同步集群升级到DLedger"><a href="#3、主从同步集群升级到DLedger" class="headerlink" title="3、主从同步集群升级到DLedger"></a>3、主从同步集群升级到DLedger</h2><h3 id="3-1-部署架构"><a href="#3-1-部署架构" class="headerlink" title="3.1 部署架构"></a>3.1 部署架构</h3><p>DLedger 集群至少需要3台机器，故搭建 DLedger 还需要再引入一台机器，其部署结构图如下：</p>
<a id="more"></a>

<p><img src="https://img-blog.csdnimg.cn/20191013142635780.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>从主从同步集群升级到 DLedger 集群，用户最关心的还是升级后的集群是否能够兼容原先的数据，即原先存储在消息能否能被消息消费者消费端，甚至于能否查询到。<br>为了方便后续验证，首先我使用下述程序向 mq 集群中添加了一篇方便查询的消息（设置消息的key）。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, InterruptedException </span>&#123;</span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;producer_dw_test&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;192.168.0.220:9876;192.168.0.221:9876&quot;</span>);</span><br><span class="line">        producer.start();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">600000</span>; i &lt; <span class="number">600100</span>; i ++) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;topic_dw_test_by_order_01&quot;</span>,<span class="keyword">null</span> , <span class="string">&quot;m&quot;</span> + i,(<span class="string">&quot;Hello RocketMQ&quot;</span> + i ).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">                SendResult sendResult = producer.send(msg);</span><br><span class="line">               <span class="comment">//System.out.printf(&quot;%s%n&quot;, sendResult);</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">                Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">        System.out.println(<span class="string">&quot;end&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>消息的查询结果示例如下：<br><img src="https://img-blog.csdnimg.cn/20191013142707763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="3-2-升级步骤"><a href="#3-2-升级步骤" class="headerlink" title="3.2 升级步骤"></a>3.2 升级步骤</h3><p>Step1：将 192.168.0.220 的 rocketmq 拷贝到 192.168.0.222，可以使用如下命令进行操作。在 192.168.0.220 上敲如下命令：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">scp -r rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/ root@<span class="number">192.168</span><span class="number">.0</span><span class="number">.222</span>:<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release</span><br></pre></td></tr></table></figure>

<blockquote>
<p>温馨提示：示例中由于版本是一样，实际过程中，版本需要升级，故需先下载最新的版本，然后将老集群中的 store 目录完整的拷贝到新集群的 store 目录。</p>
</blockquote>
<p>Step2：依次在三台服务器的 broker.conf 配置文件中添加与 dledger 相关的配置属性。</p>
<p>192.168.0.220 broker配置文件如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">brokerClusterName = DefaultCluster</span><br><span class="line">brokerId = <span class="number">0</span></span><br><span class="line">deleteWhen = <span class="number">04</span></span><br><span class="line">fileReservedTime = <span class="number">48</span></span><br><span class="line">brokerRole = ASYNC_MASTER</span><br><span class="line">flushDiskType = ASYNC_FLUSH</span><br><span class="line">brokerIP1=<span class="number">192.168</span><span class="number">.0</span><span class="number">.220</span></span><br><span class="line">brokerIP2=<span class="number">192.168</span><span class="number">.0</span><span class="number">.220</span></span><br><span class="line">namesrvAddr=<span class="number">192.168</span><span class="number">.0</span><span class="number">.221</span>:<span class="number">9876</span>;<span class="number">192.168</span><span class="number">.0</span><span class="number">.220</span>:<span class="number">9876</span></span><br><span class="line">storePathRootDir=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store</span><br><span class="line">storePathCommitLog=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store/commitlog</span><br><span class="line">autoCreateTopicEnable=<span class="literal">false</span></span><br><span class="line">autoCreateSubscriptionGroup=<span class="literal">false</span></span><br><span class="line"># 与 dledger 相关的属性</span><br><span class="line">enableDLegerCommitLog=<span class="literal">true</span></span><br><span class="line">storePathRootDir=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store/dledger_store</span><br><span class="line">dLegerGroup=broker-a</span><br><span class="line">dLegerPeers=n0-<span class="number">192.168</span><span class="number">.0</span><span class="number">.220</span>:<span class="number">40911</span>;n1-<span class="number">192.168</span><span class="number">.0</span><span class="number">.221</span>:<span class="number">40911</span>;n2-<span class="number">192.168</span><span class="number">.0</span><span class="number">.222</span>:<span class="number">40911</span></span><br><span class="line">dLegerSelfId=n0</span><br></pre></td></tr></table></figure>
<p>192.168.0.221 broker配置文件如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">brokerClusterName = DefaultCluster</span><br><span class="line">brokerName = broker-a</span><br><span class="line">brokerId = <span class="number">1</span></span><br><span class="line">deleteWhen = <span class="number">04</span></span><br><span class="line">fileReservedTime = <span class="number">48</span></span><br><span class="line">brokerRole = SLAVE</span><br><span class="line">flushDiskType = ASYNC_FLUSH</span><br><span class="line">brokerIP1=<span class="number">192.168</span><span class="number">.0</span><span class="number">.221</span></span><br><span class="line">brokerIP2=<span class="number">192.168</span><span class="number">.0</span><span class="number">.221</span></span><br><span class="line">namesrvAddr=<span class="number">192.168</span><span class="number">.0</span><span class="number">.221</span>:<span class="number">9876</span>;<span class="number">192.168</span><span class="number">.0</span><span class="number">.220</span>:<span class="number">9876</span></span><br><span class="line">storePathRootDir=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store</span><br><span class="line">storePathCommitLog=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store/commitlog</span><br><span class="line">autoCreateTopicEnable=<span class="literal">false</span></span><br><span class="line">autoCreateSubscriptionGroup=<span class="literal">false</span></span><br><span class="line"># 与dledger 相关的配置属性</span><br><span class="line">enableDLegerCommitLog=<span class="literal">true</span></span><br><span class="line">storePathRootDir=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store/dledger_store</span><br><span class="line">dLegerGroup=broker-a</span><br><span class="line">dLegerPeers=n0-<span class="number">192.168</span><span class="number">.0</span><span class="number">.220</span>:<span class="number">40911</span>;n1-<span class="number">192.168</span><span class="number">.0</span><span class="number">.221</span>:<span class="number">40911</span>;n2-<span class="number">192.168</span><span class="number">.0</span><span class="number">.222</span>:<span class="number">40911</span></span><br><span class="line">dLegerSelfId=n1</span><br></pre></td></tr></table></figure>
<p>192.168.0.222 broker配置文件如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">brokerClusterName = DefaultCluster</span><br><span class="line">brokerName = broker-a</span><br><span class="line">brokerId = <span class="number">0</span></span><br><span class="line">deleteWhen = <span class="number">04</span></span><br><span class="line">fileReservedTime = <span class="number">48</span></span><br><span class="line">brokerRole = ASYNC_MASTER</span><br><span class="line">flushDiskType = ASYNC_FLUSH</span><br><span class="line">brokerIP1=<span class="number">192.168</span><span class="number">.0</span><span class="number">.222</span></span><br><span class="line">brokerIP2=<span class="number">192.168</span><span class="number">.0</span><span class="number">.222</span></span><br><span class="line">namesrvAddr=<span class="number">192.168</span><span class="number">.0</span><span class="number">.221</span>:<span class="number">9876</span>;<span class="number">192.168</span><span class="number">.0</span><span class="number">.220</span>:<span class="number">9876</span></span><br><span class="line">storePathRootDir=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store</span><br><span class="line">storePathCommitLog=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store/commitlog</span><br><span class="line">autoCreateTopicEnable=<span class="literal">false</span></span><br><span class="line">autoCreateSubscriptionGroup=<span class="literal">false</span></span><br><span class="line"># 与 dledger 相关的配置</span><br><span class="line">enableDLegerCommitLog=<span class="literal">true</span></span><br><span class="line">storePathRootDir=<span class="regexp">/opt/</span>application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store/dledger_store</span><br><span class="line">dLegerGroup=broker-a</span><br><span class="line">dLegerPeers=n0-<span class="number">192.168</span><span class="number">.0</span><span class="number">.220</span>:<span class="number">40911</span>;n1-<span class="number">192.168</span><span class="number">.0</span><span class="number">.221</span>:<span class="number">40911</span>;n2-<span class="number">192.168</span><span class="number">.0</span><span class="number">.222</span>:<span class="number">40911</span></span><br><span class="line">dLegerSelfId=n2</span><br></pre></td></tr></table></figure>
<blockquote>
<p>温馨提示：legerSelfId 分别为 n0、n1、n2。在真实的生产环境中，broker配置文件中的 storePathRootDir、storePathCommitLog 尽量使用单独的根目录，这样判断其磁盘使用率时才不会相互影响。</p>
</blockquote>
<p>Step3：将 store/config 下的 所有文件拷贝到 dledger store 的 congfig 目录下。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cd /opt/application/rocketmq-all-<span class="number">4.5</span><span class="number">.2</span>-bin-release/store/</span><br><span class="line">cp config<span class="comment">/* dledger_store/config/</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>温馨提示：该步骤按照各自按照时配置的目录进行复制即可。</p>
</blockquote>
<p>Step4：依次启动三台 broker。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">nohup bin/mqbroker -c conf/broker.conf  /dev/<span class="literal">null</span>  <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br></pre></td></tr></table></figure>
<p>如果启动成功，则在 rocketmq-console 中看到的集群信息如下：<br><img src="https://img-blog.csdnimg.cn/20191013143013142.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="3-3-验证消息发送与消息查找"><a href="#3-3-验证消息发送与消息查找" class="headerlink" title="3.3 验证消息发送与消息查找"></a>3.3 验证消息发送与消息查找</h3><p>首先我们先验证升级之前的消息是否能查询到，那我们还是查找key 为 m600000 的消息，查找结果如图所示：<br><img src="https://img-blog.csdnimg.cn/20191013143037500.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>然后我们来测试一下消息发送。测试代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, InterruptedException </span>&#123;</span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;producer_dw_test&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;192.168.0.220:9876;192.168.0.221:9876&quot;</span>);</span><br><span class="line">        producer.start();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">600200</span>; i &lt; <span class="number">600300</span>; i ++) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;topic_dw_test_by_order_01&quot;</span>,<span class="keyword">null</span> , <span class="string">&quot;m&quot;</span> + i,(<span class="string">&quot;Hello RocketMQ&quot;</span> + i ).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">                SendResult sendResult = producer.send(msg);</span><br><span class="line">                System.out.printf(<span class="string">&quot;%s%n&quot;</span>, sendResult);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">                Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">        System.out.println(<span class="string">&quot;end&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行结果如下：<br><img src="https://img-blog.csdnimg.cn/20191013143121381.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>再去控制台查询一下消息，其结果也表明新的消息也能查询到。<br><img src="https://img-blog.csdnimg.cn/20191013143149105.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>最后我们再来验证一下主节点宕机，消息发送是否会受影响。</p>
<p>在消息发送的过程中，去关闭主节点，其截图如下：<br><img src="https://img-blog.csdnimg.cn/20191013143249857.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/2019101314330055.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20191013143313982.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">再来看一下集群的状态：<br><img src="https://img-blog.csdnimg.cn/20191013143344274.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>等待该复制组重新完成主服务器选举后，即可继续处理消息发送。</p>
<blockquote>
<p>温馨提示：由于本示例是一主一从，故在选举期间，消息不可用，但在真实的生产环境上，其部署架构是多主主从，即一个复制组在 leader 选举期间，其他复制组可以接替该复制组完成消息的发送，实现消息服务的高可用。</p>
</blockquote>
<p>与 DLedger 相关的日志，默认存储在 broker_default.log 文件中。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>dledger</tag>
        <tag>多副本</tag>
        <tag>主从切换</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ 多副本前置篇：初探raft协议</title>
    <url>/posts/d198d6eb.html</url>
    <content><![CDATA[<div id="vip-container"><p>Raft协议是分布式领域解决一致性的又一著名协议，主要包含Leader选举、日志复制两个部分。</p>
<blockquote>
<p>温馨提示：<br>本文根据raft官方给出的raft动画进行学习，其动画展示地址：<a href="http://thesecretlivesofdata.com/raft/">http://thesecretlivesofdata.com/raft/</a></p>
</blockquote>
<h2 id="1、Leader选举"><a href="#1、Leader选举" class="headerlink" title="1、Leader选举"></a>1、Leader选举</h2><h3 id="1-1-一轮投票中，只有一个节点发起投票的情况"><a href="#1-1-一轮投票中，只有一个节点发起投票的情况" class="headerlink" title="1.1  一轮投票中，只有一个节点发起投票的情况"></a>1.1  一轮投票中，只有一个节点发起投票的情况</h3><p><img src="https://img-blog.csdnimg.cn/20190810192221312.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>Raft协议中节点有3种状态（角色）：</p>
<ul>
<li>Follower<br>跟随者。</li>
<li>Candidate<br>候选者。</li>
<li>Leader<br>领导者(Leader)，通常我们所说的的主节点。</li>
</ul>
<p>首先3个节点初始状态为 Follower，每个节点会有一个超时时间(计时器)，其时间设置为150ms~300ms之间的随机值。当计时器到期后，节点状态从 Follower 变成 Candidate，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190810193027410.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>通常情况下，三个节点中会有一个节点的计时器率先到期，节点状态变为 Candidate ，候选者状态下的节点会发起选举投票。我们先来考虑只有一个节点变为Candidate时是如何进行选主的。</p>
<p>当节点状态为Candidate，将发起一轮投票，由于是第一轮投票，设置本轮投票轮次为1，并首先为自己投上一票，正如上图所示的NodeA节点，Team为1，Vote Count为1.<br><img src="https://img-blog.csdnimg.cn/20190810193206869.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>当一个节点的定时器超时后，首先为自己投上一票，然后向该组内其他的节点发起投票(用拉票更加合适)，发送投票请求。<br><img src="https://img-blog.csdnimg.cn/20190810193241874.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>当集群内的节点收到投票请求外，如果本轮未进行过投票，则赞同，否则反对，然后将结果返回，并重置计时器。<br><img src="https://img-blog.csdnimg.cn/2019081019345071.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>当节点A收到的赞同票大于一半时，则升级为该集群的 Leader，然后定时向集群内的其他节点发送心跳，以便确定自己的领导地位，正如下图所示。<br><img src="https://img-blog.csdnimg.cn/20190810193534746.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>Node A，集群中的 Leader正在向其他节点发送心跳包。<br><img src="https://img-blog.csdnimg.cn/20190810193603638.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>节点在收到 Leader 的心跳包后，返回响应结果，并重置自身的计时器，如果 Flower 状态的节点在计时时间超时内没有收到Leader 的心跳包，就会从 Flower 节点变成 Candidate,该节点就会发起下一轮投票。</p>
<p>例如NodeA节点宕机，停止向它的从发送心跳，我们来看一下集群如何重新选主。</p>
<a id="more"></a>

<p><img src="https://img-blog.csdnimg.cn/20190810193731794.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>如果主节点宕机，则停止向集群内的节点发送心跳包。随着计时器的到期，节点B的先于节点C变成 Candidate，则节点B向集群内的其他节点发起投票，如下图所示。<br><img src="https://img-blog.csdnimg.cn/20190810193840481.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>节点B，首先将投票轮次设置为2，然后首先为自己投上一篇，然后向其他节点发起投票请求。<br><img src="https://img-blog.csdnimg.cn/20190810194013940.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>节点C收到请求，由于其投票轮次大于自己的投票轮次，并该轮次并未投票，投出赞成票并返回结果，然后重置计时器。节点B将顺理成章的成为新的Leader并定时发送心跳包。</p>
<p>3个节点的选主就介绍到这里了，也许有网友会说，虽然各个节点的计时器是随机的，但也有可能同一时间，或一个节点在未收到另一个节点发起的投票请求之前变成 Candidate，即在一轮投票过程中，有大于1个的节点状态都是 Candidate，那该如何选主呢？</p>
<p>下面以4个节点的集群为例，来阐述上述这种情况情况下，如何进行选主。</p>
<h3 id="1-2-一轮投票中，超过一个节点发起投票的情况"><a href="#1-2-一轮投票中，超过一个节点发起投票的情况" class="headerlink" title="1.2 一轮投票中，超过一个节点发起投票的情况"></a>1.2 一轮投票中，超过一个节点发起投票的情况</h3><p>首先同时有两个节点进入Candidate状态，并开始新的一轮投票，当前投票编号为4，首先先为自己投上一票，然后向集群中的其他节点发起投票，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190810194321440.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>然后各个节点收到投票请求，如下所示，进行投票：<br><img src="https://img-blog.csdnimg.cn/20190810194348574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>首先节点C、D在收到D、C节点的投票请求时，都会返回不同意，因为在本轮投票中，已经各自为自己投了一票，按照上图，节点A同意C节点、节点B同意D节点，那此时C、D都只获的两票，当然如果A,B都认为C或D成为主节点，则选择就可以结束了，上图显示，C、D都只获的2票，未超过半数，无法成为主节点，那接下来会发生什么呢？请看下图：<br><img src="https://img-blog.csdnimg.cn/20190810194709527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>此时A,B,C,D的定时器各自在倒计时，当节点成为Candidate时，或自身状态本身是Candidate并且定时器触发后，发起一轮新的投票，图中是节点B、节点D同时发起了新的一轮投票。<br><img src="https://img-blog.csdnimg.cn/2019081019475968.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>投票结果如下：节点A,节点C同意节点B成为leader，但由于BD都发起了第5轮投票，最终的投票轮次更新为6，如图所示：<br><img src="https://img-blog.csdnimg.cn/20190810194822483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>关于Raft协议的选主就介绍到这里了，接下来我们来思考一下，如果自己实现 Raf t协议，至少要考虑哪些问题，为下一篇源码阅读Dleger(RocketMQ多副本)模块提供一些思路。</p>
<h3 id="1-3-思考如何实现Raft选主"><a href="#1-3-思考如何实现Raft选主" class="headerlink" title="1.3 思考如何实现Raft选主"></a>1.3 思考如何实现Raft选主</h3><ol>
<li>节点状态<br> 需要引入3中节点状态：Follower(跟随者)、Candidate(候选者)，投票的触发点，Leader(主节点)。</li>
<li>进入投票状态的计时器<br> Follower、Candidate 两个状态时，需要维护一个计时器，每次定时时间从150ms-300ms之间进行随机，即每个节点的每次的计时过期不一样，Follower状态时，计时器到点后，触发一轮投票。节点在收到投票请求、Leader 的心跳请求并作出响应后需要重置定时器。</li>
<li>投票轮次Team<br> Candidate 状态的节点，每发起一轮投票，Term 加一；Term的存储。</li>
<li>投票机制<br> 每一轮一个节点只能为一个节点投赞成票，例如节点A中维护的轮次为3，并且已经为节点B投了赞成票，如果收到其他节点，投票轮次为3，则会投反对票，如果收到轮次为4的节点，是又可以投赞成票的。</li>
<li>成为Leader的条件<br> 必须得到集群中节点的大多数，即超过半数，例如如果集群中有3个节点，则必须得到两票，如果其中一台服务器宕机，剩下的两个节点，还能进行选主吗？答案是可以的，因为可以得到2票，超过初始集群中3的一半，所以通常集群中的机器各位尽量为计数，因为4台的可用性与3台的一样。</li>
</ol>
<blockquote>
<p>温馨提示：上述结论只是我的一些思考，我们可以带着上述思考，进入到Dleger的学习中，下一篇将从源码分析的角度来学习大神是如何实现Raft协议的Leader选主的，让我们一起期待吧。</p>
</blockquote>
<h2 id="2、日志复制"><a href="#2、日志复制" class="headerlink" title="2、日志复制"></a>2、日志复制</h2><p>完成集群内的选主工作后，客户端向主节点发送请求，由主节点负责数据的复制，使集群内的数据保持一致性，初始状态如下图所示：<br><img src="https://img-blog.csdnimg.cn/2019081020073042.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>客户端向主节点发起请求，例如set 5，将数据更新为5，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190810201057102.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>主节点收到客户端请求后，将数据追加到Leader的日志中(但未提交)，然后在下一个心跳包中将日志转发到集群内从节点，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190810201124742.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>从节点收到Leader的日志后，追加到从节点的日志文件中，并返回确认ACK。Leader收到从节点的确认信息后，向客户端发送确认信息。<br><img src="https://img-blog.csdnimg.cn/20190810201148743.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>上述的日志复制比较简单，是由于只考虑正常的情况，如果中间发生异常，该如何保证数据一致性呢？</p>
<ol>
<li>如果 Leader 节点向从节点广播日志时，其中某个从节点发送故障宕机，该如何处理呢？</li>
<li>日志在什么环节进行提交呢？Leader节点在收到客户端的数据变更请求后，首先追加到主节点的日志文件中，然后广播到从节点，从节点收到日志信息，是提交日志后返回ACK，还是什么时候提交呢？</li>
<li>日志如何保证唯一。</li>
<li>如何处理网络出现分区。</li>
</ol>
<p>我相信读者朋友肯定还有更多的疑问，本文不打算来回答上述疑问，而是带着这些问题进入到RocketMQ多副本的学习中，通过源码分析RocketMQ DLedger的实现后，再来重新总结raft协议。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>主从同步</tag>
        <tag>多副本</tag>
        <tag>raft</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ一行代码造成大量消息发送失败</title>
    <url>/posts/54929501.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、问题现象"><a href="#1、问题现象" class="headerlink" title="1、问题现象"></a>1、问题现象</h2><p>首先接到项目反馈使用 RocketMQ 会出现如下错误：<br><img src="https://img-blog.csdnimg.cn/2020051623272777.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>错误信息关键点：MQBrokerException：CODE:2 DESC:[TIMEOUT_CLEAN_QUEUE]broker busy,start flow control for a while,period in queue：205ms，size of queue:880。</p>
<p>由于项目组并没有对消息发送失败做任何补偿，导致丢失消息发送失败，故需要对这个问题进行深层次的探讨，并加以解决。</p>
<h2 id="2、问题分析"><a href="#2、问题分析" class="headerlink" title="2、问题分析"></a>2、问题分析</h2><p>首先我们根据关键字：TIMEOUT_CLEAN_QUEUE 去 RocketMQ 中查询，去探究在什么时候会抛出如上错误。根据全文搜索如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200517091330168.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>该方法是在 BrokerFastFailure 中定义的，通过名称即可以看成其设计目的：Broker端快速失败机制。</p>
<p><strong>Broker 端快速失败其原理图如下：</strong><br><img src="https://img-blog.csdnimg.cn/20200517091356312.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>消息发送者向 Broker 发送消息写入请求，Broker 端在接收到请求后会首先放入一个队列中(SendThreadPoolQueue)，默认容量为 10000。</li>
<li>Broker 会专门使用一个线程池(SendMessageExecutor)去从队列中获取任务并执行消息写入请求，为了保证消息的顺序处理，该线程池默认线程个数为1。</li>
</ul>
<p>如果 Broker 端受到垃圾回收等等因素造成单条写入数据发生抖动，单个 Broker 端积压的请求太多从而得不到及时处理，会极大的造成客户端消息发送的时间延长。</p>
<p>设想一下，如果由于 Broker 压力增大，写入一条消息需要500ms甚至超过1s，并且队列中积压了5000条消息，消息发送端的默认超时时间为3s，如果按照这样的速度，这些请求在轮到 Broker 执行写入请求时，客户端已经将这个请求超时了，这样不仅会造成大量的无效处理，还会导致客户端发送超时。</p>
<a id="more"></a>

<p>故 RocketMQ 为了解决该问题，引入 Broker 端快速失败机制，即开启一个定时调度线程，每隔10毫秒去检查队列中的第一个排队节点，如果该节点的排队时间已经超过了 200ms，就会取消该队列中所有已超过 200ms 的请求，立即向客户端返回失败，这样客户端能尽快进行重试，因为 Broker 都是集群部署，下次重试可以发送到其他 Broker 上，这样能最大程度保证消息发送在默认 3s 的时间内经过重试机制，能有效避免某一台 Broker 由于瞬时压力大而造成的消息发送不可用，从而实现消息发送的高可用。</p>
<p><strong>从 Broker 端快速失败机制引入的初衷来看，快速失败后会发起重试，除非同一深刻集群内所有的 Broker 都繁忙，不然消息会发送成功，用户是不会感知这个错误的，那为什么用户感知了呢？难道 TIMEOUT_ CLEAN _ QUEUE 错误，Broker 不重试？</strong></p>
<p>为了解开这个谜团，接下来会采用源码分析的手段去探究真相。接下来将以消息同步发送为例揭示其消息发送处理流程中的核心关键点。</p>
<p>MQ Client 消息发送端首先会利用网络通道将请求发送到 Broker，然后接收到请求结果后并调用 processSendResponse 方法对响应结果进行解析，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200517093407354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">在这里返回的 code 为 RemotingSysResponseCode . SYSTEM_BUSY。</p>
<p>我们从 proccessSendResponse 方法中可以得知，如果 code 为 SYSTEM_BUSY，该方法会抛出 MQBrokerException，响应 code 为 SYSTEM_BUSY，其错误描述为开头部分的错误信息。</p>
<p>那我们沿着该方法的调用链，可以找到其直接调用方为：DefaultMQProducerImpl 的 sendKernelImpl，我们重点考虑如果底层方法抛出  MQBrokerException 该方法会如何处理。</p>
<p>其关键代码如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200517093453648.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>可以看出在 sendKernelImpl 方法中首先会捕捉异常，先执行注册的钩子函数，即就算执行失败，对应的消息发送后置钩子函数也会执行，然后再原封不动的将该异常向上抛出。</p>
<p>sendKernelImpl 方法被 DefaultMQProducerImpl 的 sendDefaultImpl 方法调用，下面是其核心实现截图：<br><img src="https://img-blog.csdnimg.cn/20200517093512484.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">从这里可以看出 RocketMQ 消息发送高可用设计一个非常关键的点，重试机制，其实现是在 for 循环中 使用 try catch 将 sendKernelImpl 方法包裹，就可以保证该方法抛出异常后能继续重试。从上文可知，如果 SYSTEM_BUSY 会抛出 MQBrokerException，但发现只有上述几个错误码才会重试，因为如果不是上述错误码，会继续向外抛出异常，此时 for 循环会被中断，即不会重试。</p>
<p>这里非常令人意外的是连 SYSTEM_ERROR 都会重试，却没有包含 SYSTEM_BUSY，显然违背了快速失败的设计初衷，故笔者断定，这是 RocketMQ 的一个BUG，将 SYSTEM_BUSY 遗漏了，后面与 RocketMQ 核心成员进行过沟通，也印证了这点，后续会提一个 PR，在上面增加一行代码，将 SYSTEM_BUSY 加上即可。</p>
<p>问题分析到这里，该问题应该就非常明了。</p>
<h2 id="3、解决方案"><a href="#3、解决方案" class="headerlink" title="3、解决方案"></a>3、解决方案</h2><p>如果大家在网上搜索 TIMEOUT_CLEAN_QUEUE 的解决方法，大家不约而同提出的解决方案是增加 waitTimeMillsInSendQueue 的值，该值默认为 200ms，例如将其设置为 1000s 等等，以前我是反对的，因为我的认知里 Broker 会重试，但现在发现 Broker 不会重试，所以我现在认为该 BUG未解决的情况下适当提高该值能有效的缓解。</p>
<p><strong>但这是并不是好的解决方案，我会在近期向官方提交一个PR，将这个问题修复，建议大家在公司尽量对自己使用的版本进行修改，重新打一个包即可，因为这已经违背了 Broker 端快速失败的设计初衷。</strong></p>
<p>但在消息发送的业务方，尽量自己实现消息的重试机制，即不依懒 RocketMQ 本身提供的重试机制，因为受制与网络等因素，消息发送不可能百分之百成功，建议大家在消息发送时捕获一下异常，如果发送失败，可以将消息存入数据库，再结合定时任务对消息进行重试，尽最大程度保证消息不丢失。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>源码</tag>
        <tag>CONSUME_FROM_TIMESTAMP</tag>
        <tag>waitTimeMillsInSendQueue</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ事务消息实战</title>
    <url>/posts/56026c9f.html</url>
    <content><![CDATA[<div id="vip-container"><p>我们以一个订单流转流程来举例，例如订单子系统创建订单，需要将订单数据下发到其他子系统（与第三方系统对接）这个场景，我们通常会将两个系统进行解耦，不直接使用服务调用的方式进行交互。其业务实现步骤通常为：</p>
<ol>
<li>A系统创建订单并入库</li>
<li>发送消息到MQ</li>
<li>MQ消费者消费消息，发送远程RPC服务调用，完成订单数据的同步。</li>
</ol>
<h2 id="1、方案一"><a href="#1、方案一" class="headerlink" title="1、方案一"></a>1、方案一</h2><ol>
<li><img src="https://img-blog.csdn.net/20180731191040691?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>&ensp; &ensp;方案弊端：<br>&ensp; &ensp;1、如果消息发送成功，在提交事务的时候JVM突然挂掉，事务没有成功提交，导致两个系统之间数据不一致。<br>&ensp; &ensp;2、由于消息是在事务提交之前提交，发送的消息内容是订单实体的内容，会造成在消费端进行消费时如果需要去验证订单是否存在时可能出现订单不存在。<br>&ensp; &ensp;3、消息发送可以考虑异步发送。</li>
</ol>
<a id="more"></a>

<h2 id="2、方案二："><a href="#2、方案二：" class="headerlink" title="2、方案二："></a>2、方案二：</h2><p>&ensp; &ensp;由于存在上述问题，在MQ不支持事务消息的前提条件下，可以采用下面的方式进行优化。<br><img src="https://img-blog.csdn.net/20180802105157536?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>&ensp; &ensp;然后在控制器层，使用异步发送，将消息发送，并在消息发送成功后，更新待发送状态为已发送。<br>&ensp; &ensp;然后通过定时任务，扫描待发送，结合创建时间的记录（小于当前时间5分钟的消息待发送记录），进行消息发送。<br>&ensp; &ensp;方案弊端：<br>&ensp; &ensp;1、消息有可能重复发送，但在消费端可以通过唯一业务编号来进行去重设计。<br>&ensp; &ensp;2、实现过于复杂，为了避免 极端情况下的消息丢失，需要使用定时任务。</p>
<h2 id="3、方案三：基于RocketMQ4-3版本事务消息"><a href="#3、方案三：基于RocketMQ4-3版本事务消息" class="headerlink" title="3、方案三：基于RocketMQ4.3版本事务消息"></a>3、方案三：基于RocketMQ4.3版本事务消息</h2><p><img src="https://img-blog.csdn.net/201807311912029?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"><br>&ensp; &ensp;额外需要实现事务会查监听器：TransactionListener，其实例代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import org.apache.rocketmq.client.producer.LocalTransactionState;</span><br><span class="line">import org.apache.rocketmq.client.producer.TransactionListener;</span><br><span class="line">import org.apache.rocketmq.common.message.Message;</span><br><span class="line">import org.apache.rocketmq.common.message.MessageExt;</span><br><span class="line"></span><br><span class="line">import java.util.concurrent.ConcurrentHashMap;</span><br><span class="line"></span><br><span class="line">@SuppressWarnings(&quot;unused&quot;)</span><br><span class="line">public class OrderTransactionListenerImpl implements TransactionListener &#123;</span><br><span class="line">	</span><br><span class="line">	private ConcurrentHashMap&lt;String, Integer&gt; countHashMap &#x3D; new ConcurrentHashMap&lt;&gt;();</span><br><span class="line">	</span><br><span class="line">	private final static int MAX_COUNT &#x3D; 5;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">    public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123;</span><br><span class="line">        &#x2F;&#x2F; </span><br><span class="line">    	String bizUniNo &#x3D; msg.getUserProperty(&quot;bizUniNo&quot;); &#x2F;&#x2F; 从消息中获取业务唯一ID。</span><br><span class="line">    	&#x2F;&#x2F; 将bizUniNo入库，表名：t_message_transaction,表结构  bizUniNo(主键),业务类型。</span><br><span class="line">        return LocalTransactionState.UNKNOW;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123;</span><br><span class="line">        Integer status &#x3D; 0;</span><br><span class="line">        &#x2F;&#x2F; 从数据库查查询t_message_transaction表，如果该表中存在记录，则提交，</span><br><span class="line">        String bizUniNo &#x3D; msg.getUserProperty(&quot;bizUniNo&quot;); &#x2F;&#x2F; 从消息中获取业务唯一ID。</span><br><span class="line">        &#x2F;&#x2F; 然后t_message_transaction 表，是否存在bizUniNo，如果存在，则返回COMMIT_MESSAGE，</span><br><span class="line">        &#x2F;&#x2F; 不存在，则记录查询次数，未超过次数，返回UNKNOW，超过次数，返回ROLLBACK_MESSAGE</span><br><span class="line">        </span><br><span class="line">        if(query(bizUniNo) &gt; 0 ) &#123;</span><br><span class="line">        	return LocalTransactionState.COMMIT_MESSAGE;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        return rollBackOrUnown(bizUniNo);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public int query(String bizUniNo) &#123;</span><br><span class="line">    	return 1; &#x2F;&#x2F;select count(1) from t_message_transaction a where a.biz_uni_no&#x3D;#&#123;bizUniNo&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public LocalTransactionState rollBackOrUnown(String bizUniNo) &#123;</span><br><span class="line">    	Integer num &#x3D; countHashMap.get(bizUniNo);</span><br><span class="line">    	</span><br><span class="line">    	if(num !&#x3D; null &amp;&amp;  ++num &gt; MAX_COUNT) &#123;</span><br><span class="line">    		countHashMap.remove(bizUniNo);</span><br><span class="line">    		return LocalTransactionState.ROLLBACK_MESSAGE;</span><br><span class="line">    	&#125;</span><br><span class="line">    	</span><br><span class="line">    	if(num &#x3D;&#x3D; null) &#123;</span><br><span class="line">    		num &#x3D; new Integer(1);</span><br><span class="line">    	&#125;</span><br><span class="line">    	</span><br><span class="line">    	countHashMap.put(bizUniNo, num);</span><br><span class="line">    	return LocalTransactionState.UNKNOW;</span><br><span class="line">    	</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<p>&ensp; &ensp;TransactionListener 实现要点：<br>&ensp; &ensp;executeLocalTransaction：<br>&ensp; &ensp;该方法，主要是设置本地事务状态，该方法与业务方代码在一个事务中，例如OrderServer#createMap中，只要本地事务提交成功，该方法也会提交成功。<br>&ensp; &ensp;故在这里，主要是t_message_transaction添加一条记录，在事务会查时，如果存在记录，就认为是该消息需要提交。<br>&ensp; &ensp;checkLocalTransaction：<br>&ensp; &ensp;该方法主要是告知RocketMQ消息是否需要提交还是回滚，如果本地事务表（t_message_transaction）存在记录，则认为提交，如果不存在，可以设置会查次数，如果指定次数内还是未查到消息，则回滚，否则返回未知，rocketmq会按一定的频率回查事务，当然回查次数也有限制，默认为5次，可配置。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>实战</tag>
        <tag>事务消息</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ实战：生产环境中，autoCreateTopicEnable为什么不能设置为true</title>
    <url>/posts/e6afac5e.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、现象"><a href="#1、现象" class="headerlink" title="1、现象"></a>1、现象</h2><p>很多网友会问，为什么明明集群中有多台Broker服务器，autoCreateTopicEnable设置为true，表示开启Topic自动创建，但新创建的Topic的路由信息只包含在其中一台Broker服务器上，这是为什么呢？</p>
<p>期望值：为了消息发送的高可用，希望新创建的Topic在集群中的每台Broker上创建对应的队列，避免Broker的单节点故障。</p>
<p>现象截图如下：<br><img src="https://img-blog.csdnimg.cn/20190611220611635.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="Broker集群信息"><br><img src="https://img-blog.csdnimg.cn/20190611220736135.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>正如上图所示，自动创建的topicTest5的路由信息：</p>
<ul>
<li>topicTest5只在broker-a服务器上创建了队列，并没有在broker-b服务器创建队列，不符合期望。</li>
<li>默认读写队列的个数为4。</li>
</ul>
<p>我们再来看一下RocketMQ默认topic的路由信息截图如下：<br><img src="https://img-blog.csdnimg.cn/20190611220839184.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>从图中可以默认Topic的路由信息为broker-a、broker-b上各8个队列。</p>
<h2 id="2、思考"><a href="#2、思考" class="headerlink" title="2、思考"></a>2、思考</h2><p>默认Topic的路由信息是如何创建的？</p>
<ol>
<li>Topic的路由信息是存储在哪里？Nameserver？broker?</li>
<li>RocketMQ Topic默认队列个数是多少呢？</li>
</ol>
<h2 id="3、原理"><a href="#3、原理" class="headerlink" title="3、原理"></a>3、原理</h2><h3 id="3-1-RocketMQ基本路由规则"><a href="#3-1-RocketMQ基本路由规则" class="headerlink" title="3.1 RocketMQ基本路由规则"></a>3.1 RocketMQ基本路由规则</h3><p><img src="https://img-blog.csdnimg.cn/20190611221028332.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ol>
<li>Broker在启动时向Nameserver注册存储在该服务器上的路由信息，并每隔30s向Nameserver发送心跳包，并更新路由信息。</li>
<li>Nameserver每隔10s扫描路由表，如果检测到Broker服务宕机，则移除对应的路由信息。</li>
<li>消息生产者每隔30s会从Nameserver重新拉取Topic的路由信息并更新本地路由表；在消息发送之前，如果本地路由表中不存在对应主题的路由消息时，会主动向Nameserver拉取该主题的消息。</li>
</ol>
<p>回到本文的主题：autoCreateTopicEnable，开启自动创建主题，试想一下，如果生产者向一个不存在的主题发送消息时，上面的任何一个步骤都无法获取一个不存在的主题的路由信息，那该如何处理这种情况呢？</p>
<a id="more"></a>

<p>在RocketMQ中，如果autoCreateTopicEnable设置为true，消息发送者向NameServer查询主题的路由消息返回空时，会尝试用一个系统默认的主题名称(MixAll.AUTO_CREATE_TOPIC_KEY_TOPIC)，此时消息发送者得到的路由信息为：<br><img src="https://img-blog.csdnimg.cn/20190611221220259.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>但问题就来了，默认Topic在集群的每一台Broker上创建8个队列，那问题来了，为啥新创建的Topic只在一个Broker上创建4个队列？</p>
<h3 id="3-2-探究autoCreateTopicEnable机制"><a href="#3-2-探究autoCreateTopicEnable机制" class="headerlink" title="3.2 探究autoCreateTopicEnable机制"></a>3.2 探究autoCreateTopicEnable机制</h3><h4 id="3-2-1-默认Topic路由创建时机"><a href="#3-2-1-默认Topic路由创建时机" class="headerlink" title="3.2.1 默认Topic路由创建时机"></a>3.2.1 默认Topic路由创建时机</h4><blockquote>
<p>温馨提示：本文不会详细跟踪整个创建过程，只会点出源码的关键入口点，如想详细了解NameServer路由消息、消息发送高可用的实现原理，建议查阅笔者的书籍《RocketMQ技术内幕》第二、三章。</p>
</blockquote>
<p>Step1：在Broker启动流程中，会构建TopicConfigManager对象，其构造方法中首先会判断是否开启了允许自动创建主题，如果启用了自动创建主题，则向topicConfigTable中添加默认主题的路由信息。<br>TopicConfigManager构造方法<br><img src="https://img-blog.csdnimg.cn/20190611221400814.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<blockquote>
<p>备注：该topicConfigTable中所有的路由信息，会随着Broker向Nameserver发送心跳包中，Nameserver收到这些信息后，更新对应Topic的路由信息表。</p>
</blockquote>
<p>BrokerConfig的defaultTopicQueueNum默认为8。两台Broker服务器都会运行上面的过程，故最终Nameserver中关于默认主题的路由信息中，会包含两个Broker分别各8个队列信息。</p>
<p>Step2：生产者寻找路由信息<br>生产者首先向NameServer查询路由信息，由于是一个不存在的主题，故此时返回的路由信息为空，RocketMQ会使用默认的主题再次寻找，由于开启了自动创建路由信息，NameServer会向生产者返回默认主题的路由信息。然后从返回的路由信息中选择一个队列（默认轮询）。消息发送者从Nameserver获取到默认的Topic的队列信息后，队列的个数会改变吗？答案是会的，其代码如下：</p>
<p>MQClientInstance#updateTopicRouteInfoFromNameServer<br><img src="https://img-blog.csdnimg.cn/20190611221527317.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<blockquote>
<p>温馨提示：消息发送者在到默认路由信息时，其队列数量，会选择DefaultMQProducer#defaultTopicQueueNums与Nameserver返回的的队列数取最小值，DefaultMQProducer#defaultTopicQueueNums默认值为4，故自动创建的主题，其队列数量默认为4。</p>
</blockquote>
<p>Step3：发送消息</p>
<p>DefaultMQProducerImpl#sendKernelImpl<br><img src="https://img-blog.csdnimg.cn/20190611221914123.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在消息发送时的请求报文中，设置默认topic名称，消息发送topic名称，使用的队列数量为DefaultMQProducer#defaultTopicQueueNums，即默认为4。</p>
<p>Step4：Broker端收到消息后的处理流程<br>服务端收到消息发送的处理器为：SendMessageProcessor，在处理消息发送时，会调用super.msgCheck方法：</p>
<p>AbstractSendMessageProcessor#msgCheck<br><img src="https://img-blog.csdnimg.cn/20190611222012179.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在Broker端，首先会使用TopicConfigManager根据topic查询路由信息，如果Broker端不存在该主题的路由配置(路由信息),此时如果Broker中存在默认主题的路由配置信息，则根据消息发送请求中的队列数量，在Broker创建新Topic的路由信息。这样Broker服务端就会存在主题的路由信息。</p>
<p>在Broker端的topic配置管理器中存在的路由信息，一会向Nameserver发送心跳包，汇报到Nameserver，另一方面会有一个定时任务，定时存储在broker端，具体路径为${ROCKET_HOME}/store/config/topics.json中，这样在Broker关闭后再重启，并不会丢失路由信息。</p>
<p>广大读者朋友，跟踪到这一步的时候，大家应该对启用自动创建主题机制时，新主题是的路由信息是如何创建的，为了方便理解，给出创建主题序列图：<br><img src="https://img-blog.csdnimg.cn/20190611222056216.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h4 id="3-2-2-现象分析"><a href="#3-2-2-现象分析" class="headerlink" title="3.2.2 现象分析"></a>3.2.2 现象分析</h4><p>经过上面自动创建路由机制的创建流程，我们可以比较容易的分析得出如下结论：<br>因为开启了自动创建路由信息，消息发送者根据Topic去NameServer无法得到路由信息，但接下来根据默认Topic从NameServer是能拿到路由信息(在每个Broker中，存在8个队列)，因为两个Broker在启动时都会向NameServer汇报路由信息。此时消息发送者缓存的路由信息是2个Broker，每个Broker默认4个队列（原因见3.2.1:Step2的分析）。消息发送者然后按照轮询机制，发送第一条消息选择(broker-a的messageQueue:0)，向Broker发送消息，Broker服务器在处理消息时，首先会查看自己的路由配置管理器(TopicConfigManager)中的路由信息，此时不存在对应的路由信息，然后尝试查询是否存在默认Topic的路由信息，如果存在，说明启用了autoCreateTopicEnable，则在TopicConfigManager中创建新Topic的路由信息，此时存在与Broker服务端的内存中，然后本次消息发送结束。此时，在NameServer中还不存在新创建的Topic的路由信息。</p>
<p>这里有三个关键点：</p>
<ol>
<li>启用autoCreateTopicEnable创建主题时，在Broker端创建主题的时机为，消息生产者往Broker端发送消息时才会创建。</li>
<li>然后Broker端会在一个心跳包周期内，将新创建的路由信息发送到NameServer，于此同时，Broker端还会有一个定时任务，定时将内存中的路由信息，持久化到Broker端的磁盘上。</li>
<li>消息发送者会每隔30s向NameServer更新路由信息，如果消息发送端一段时间内未发送消息，就不会有消息发送集群内的第二台Broker，那么NameServer中新创建的Topic的路由信息只会包含Broker-a，然后消息发送者会向NameServer拉取最新的路由信息，此时就会消息发送者原本缓存了2个broker的路由信息，将会变为一个Broker的路由信息，则该Topic的消息永远不会发送到另外一个Broker，就出现了上述现象。</li>
</ol>
<p>原因就分析到这里了，现在我们还可以的大胆假设，开启autoCreateTopicEnable机制，什么情况会在两个Broker上都创建队列，其实，我们只需要连续快速的发送9条消息，就有可能在2个Broker上都创建队列，验证代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, InterruptedException </span>&#123;</span><br><span class="line">    DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;please_rename_unique_group_name&quot;</span>);</span><br><span class="line">    producer.setNamesrvAddr(<span class="string">&quot;127.0.0.1:9876&quot;</span>);</span><br><span class="line">    producer.start();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">9</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;TopicTest10&quot;</span> ,<span class="string">&quot;TagA&quot;</span> , (<span class="string">&quot;Hello RocketMQ &quot;</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">            SendResult sendResult = producer.send(msg);</span><br><span class="line">            System.out.printf(<span class="string">&quot;%s%n&quot;</span>, sendResult);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    producer.shutdown();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>验证结果如图所示：<br><img src="https://img-blog.csdnimg.cn/2019061122240920.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>本文就分析到这里了，大家如果喜欢这篇文章，麻烦大家帮忙点点赞，同时大家也可以给作者留言，告知在使用RocketMQ的过程中遇到的疑难杂症，与作者互动。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>autoCreateTopicEnable</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ学习环境搭建(RocketMQ安装与IDEA Debug环境搭建)</title>
    <url>/posts/3f6db0.html</url>
    <content><![CDATA[<div id="vip-container"><p>本文主要分如下几个部分展开：</p>
<ul>
<li>Linux服务器安装RocketMQ、RocketMQ-Console</li>
<li>IDEA中搭建可调试环境</li>
</ul>
<h2 id="1、Linux安装RocketMQ、RocketMQ-Console"><a href="#1、Linux安装RocketMQ、RocketMQ-Console" class="headerlink" title="1、Linux安装RocketMQ、RocketMQ-Console"></a>1、Linux安装RocketMQ、RocketMQ-Console</h2><h3 id="1-1安装RocketMQ"><a href="#1-1安装RocketMQ" class="headerlink" title="1.1安装RocketMQ"></a>1.1安装RocketMQ</h3><p>Step1：从如下地址下载RocketMQ安装包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/application</span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/rocketmq/4.7.1/rocketmq-all-4.7.1-bin-release.zip</span><br></pre></td></tr></table></figure>

<p>Step2：解压安装包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">unzip rocketmq-all-4.7.1-bin-release.zip</span><br><span class="line">ls -l</span><br></pre></td></tr></table></figure>

<p>解压后的文件如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201011210742646.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>其中 conf 文件夹存放的是RocketMQ的配置文件，提供了各种部署结构的示例配置。例如2m-2s-async是2主2从异步复制的配置示例；2m-noslave是2主的示例配置。由于本文主要是搭建一个学习环境，故采取的部署架构为1主的部署架构，关于生产环境下如何搭建RocketMQ集群、如何调优参数将在该专栏的后续文章中专门介绍。</p>
<p>Step3：修改Nameserver jvm参数</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd bin</span><br><span class="line">vi runserver.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 定位到如下代码</span></span><br><span class="line">JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms4g -Xmx4g -Xmn2g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改　<span class="string">&quot;-Xms -Xmx -Xmn&quot;</span>　参数</span></span><br><span class="line">JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms512M -Xmx512M -Xmn256M -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>温馨提示：这里修改JVM参数主要目的是个人学习电脑内存不够，默认NameServer 会占用4G。</p>
</blockquote>
<p>Step4：启动nameserver</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup ./mqnamesrv &amp;</span><br></pre></td></tr></table></figure>

<p>查看${user_home}/logs/rocketmqlogs/namesrv.log日志文件，如果输出结果如下图所示即表示启动成功。<br><img src="https://img-blog.csdnimg.cn/20201011210817888.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<a id="more"></a>

<p>Step5：修改broker的配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi conf/broker.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用如下配置文件</span></span><br><span class="line">brokerClusterName = DefaultCluster</span><br><span class="line">brokerName = broker-a</span><br><span class="line">brokerId = 0</span><br><span class="line">deleteWhen = 04</span><br><span class="line">fileReservedTime = 48</span><br><span class="line">brokerRole = ASYNC_MASTER</span><br><span class="line">flushDiskType = ASYNC_FLUSH</span><br><span class="line">storePathRootDir=/data/rocketmq/store</span><br><span class="line">storePathCommitLog=/data/rocketmq/store/commitlog</span><br><span class="line">namesrvAddr=127.0.0.1:9876</span><br><span class="line">brokerIP1=192.168.3.10</span><br><span class="line">brokerIP2=192.168.3.10</span><br><span class="line">autoCreateTopicEnable=false</span><br></pre></td></tr></table></figure>

<p>Step6：修改broker jvm参数。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd bin</span><br><span class="line">vi runbroker.sh </span><br><span class="line"><span class="meta">#</span><span class="bash">修改如下配置(配置前)</span></span><br><span class="line">JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash">配置后</span></span><br><span class="line">JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms1g -Xmx1g -Xmn512m&quot;</span><br></pre></td></tr></table></figure>

<p>Step7：启动broker</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd bin</span><br><span class="line">nohup ./mqbroker -c ../conf/broker.conf &amp;</span><br></pre></td></tr></table></figure>

<p>查看${user_home}/logs/rocketmqlogs/broker.log，如果输出结果如下图所示表示启动成功。<br><img src="https://img-blog.csdnimg.cn/20201011210843210.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>经过上面的步骤，就成功在Linux环境上安装了RocketMQ Nameserver服务器与Broker服务器。</p>
<blockquote>
<p>温馨提示：如果上面在安装过程中发生了错误，大家可以查看${user_home}/logs/rocketmqlogs中的日志，通过错误日志，能够较为直观的判断错误的原因。其中${user_home}为用户主目录。</p>
<p>该目录下会有众多的日志文件，如果一开始对这些文件的含义不了解也没关系，大家可以通过 ls -l 命令，逐一查看文件大小不为０的文件，从而寻找错误日志，便于快速解决问题。</p>
</blockquote>
<p>RocketMQ提供了众多的运维命令来查看RocketMQ集群的运行状态，在这里我先简单使用clusterList命令来查看集群的状态，用于验证一下集群的状态。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sh ./mqadmin clusterList -n 127.0.0.1:9876</span><br></pre></td></tr></table></figure>
<p>其运行结果如下图所示：<br><img src="https://img-blog.csdnimg.cn/2020101121091323.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="1-2-安装RocketMQ-Console"><a href="#1-2-安装RocketMQ-Console" class="headerlink" title="1.2 安装RocketMQ-Console"></a>1.2 安装RocketMQ-Console</h3><p>使用运维命令不太直观，学习成本较大，为此RocketMQ官方提供了一个运维管理界面RokcetMQ-Console，用于对RocketMQ集群提供常用的运维功能，故本节主要讲解如何在Linux环境安装rocketmq-console。</p>
<p>RocketMQ官方并未提供rocketmq-console的安装包，故需要通过源码进行编译。</p>
<p>Step1：下载源码</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/apache/rocketmq-externals/archive/rocketmq-console-1.0.0.tar.gz</span><br><span class="line">tar -xf rocketmq-console-1.0.0.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重命名，为了方便后续操作</span></span><br><span class="line">mv rocketmq-externals-rocketmq-console-1.0.0/rocketmq-console  rocketmq-console</span><br></pre></td></tr></table></figure>

<p>Step2：修改配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd rocketmq-console</span><br><span class="line">vi src/main/resources/applications.properties</span><br></pre></td></tr></table></figure>

<p>主要是修改指向的nameserver地址，修改结果如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201011210939919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step3：使用maven命令编译源代码。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mvn clean  package -DskipTests</span><br></pre></td></tr></table></figure>

<p>编译后在target目录下会生成可运行的jar包，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201011210958471.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step4：我们可以将该包复制到自己常用的软件安装目录，例如笔者喜欢将其放在/opt/application下。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp rocketmq-console-ng-1.0.0.jar /opt/application/</span><br></pre></td></tr></table></figure>
<p>Step5：启动rocketmq-conolse</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup java -jar rocketmq-console-ng-1.0.0.jar &amp;</span><br></pre></td></tr></table></figure>

<p>在浏览器中输入:<a href="http://localhost:8080查看是否安装成功，如果出现如下图则表示安装成功。">http://localhost:8080查看是否安装成功，如果出现如下图则表示安装成功。</a><br><img src="https://img-blog.csdnimg.cn/20201011211021557.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="1-3-异常分析与解决思路"><a href="#1-3-异常分析与解决思路" class="headerlink" title="1.3 异常分析与解决思路"></a>1.3 异常分析与解决思路</h3><p>如果在安装过程中出现意想不到的错误，别慌，通过查看相关的日志文件，寻找错误日志，根据错误日志进行思考或百度，相信能够轻易将其解决。</p>
<p>例如使用的baseuser 启动的rocketmq，rocketmq-console，那相关的日志路径如下：</p>
<p>rocketmq：/home/baseuser/logs/rocketmqlogs/<br>rocketmq-console：/home/baseuser/logs/consolelogs</p>
<h2 id="2、IDEA中安装RocketMQ"><a href="#2、IDEA中安装RocketMQ" class="headerlink" title="2、IDEA中安装RocketMQ"></a>2、IDEA中安装RocketMQ</h2><p>绝大数的程序员最信赖的开发调试工具基本都是DEBUG，那能在 IDEA 中 debug RocketMQ的源码吗？答案当然是可以的。本节就来演示如何在IDEA中运行RocketMQ的Nameserver、Broker组件，并进行Debug。</p>
<p>Setp1：从github上下载RocketMQ源码，并将其导入到IEDA中，其截图如下：<br><img src="https://img-blog.csdnimg.cn/20201011211103703.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step2:namesrv/src/main/java/org/apache/rocketmq/namesrv/NamesrvStartup设置环境变量ROCKETMQ_HOME，操作步骤如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201011211215333.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>设置环境变量名称：ROCKETMQ_HOME，其值用于指定RocketMQ运行的主目录，笔者设置的路径为：/home/dingwpmz/tmp/rocketmq。</p>
<p>Step3：将distribution/conf/logback_namesrv.xml文件拷贝到【Step2】中设置的主目录下,执行后的效果如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201011211228426.png#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>温馨提示：该文件为nameserver的日志路劲，可以手动修改logback_namesrv.xml文件中的日志目录，由于这是logback的基础知识，这里就不再详细介绍logback的配置方法。</p>
</blockquote>
<p>Step4：以debug方法运行NamesrvStartup，执行效果如下图所示,表示启动成功。<br><img src="https://img-blog.csdnimg.cn/20201011211248609.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step5：将distribution/conf/logback_brokerxml、broker.conf文件拷贝到【Step2】中设置的主目录下,执行后的效果如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201011211302502.png#pic_center" alt="在这里插入图片描述">Step6：修改broker.conf中的配置，主要设置nameserver的地址，broker的名称等相关属性。</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">vi</span> <span class="string">broker.conf</span></span><br><span class="line"><span class="comment"># 使用如下配置文件</span></span><br><span class="line"><span class="attr">brokerClusterName</span> = <span class="string">DefaultCluster</span></span><br><span class="line"><span class="attr">brokerName</span> = <span class="string">broker-a</span></span><br><span class="line"><span class="attr">brokerId</span> = <span class="string">0</span></span><br><span class="line"><span class="attr">deleteWhen</span> = <span class="string">04</span></span><br><span class="line"><span class="attr">fileReservedTime</span> = <span class="string">48</span></span><br><span class="line"><span class="attr">brokerRole</span> = <span class="string">ASYNC_MASTER</span></span><br><span class="line"><span class="attr">flushDiskType</span> = <span class="string">ASYNC_FLUSH</span></span><br><span class="line"><span class="attr">storePathRootDir</span>=<span class="string">/home/dingwpmz/tmp/rocketmq/store</span></span><br><span class="line"><span class="attr">storePathCommitLog</span>=<span class="string">/home/dingwpmz/tmp/rocketmq/store/commitlog</span></span><br><span class="line"><span class="attr">namesrvAddr</span>=<span class="string">127.0.0.1:9876</span></span><br><span class="line"><span class="attr">brokerIP1</span>=<span class="string">192.168.3.10</span></span><br><span class="line"><span class="attr">brokerIP2</span>=<span class="string">192.168.3.10</span></span><br><span class="line"><span class="attr">autoCreateTopicEnable</span>=<span class="string">true</span></span><br></pre></td></tr></table></figure>

<p>Step7：broker/src/main/java/org/apache/rocketmq/broker/BrokerStartup设置环境变量ROCKETMQ_HOME，操作步骤如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201011211319281.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step8：以Debug模式运行BrokerStartup，其运行结果如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201011211331486.png#pic_center" alt="在这里插入图片描述"><br>看到这样的提示就表示大功告成。</p>
<p>接下来简单来做一个验证。</p>
<p>首先先在AbstractSendMessageProcessor类的parseRequestHeader方法中打上一个断点。</p>
<p>然后运行example中org/apache/rocketmq/example/quickstart/Producer，看是否能进入到断点中，运行结果如下图所示，已进入到Debug模式。<br><img src="https://img-blog.csdnimg.cn/20201011211352570.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="3、小结"><a href="#3、小结" class="headerlink" title="3、小结"></a>3、小结</h2><p>本篇作为RocketMQ实战系列的第一篇文章，其目的就是构建一个研究RocketMQ的学习环境，故从两个方面进行展开：</p>
<p>１、在Linux环境安装RocketMQ、RocketMQ-Console。</p>
<p>２、在IDEA中运行RocketMQ，构建一个可以调试RocketMQ的环境。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>RocketMQ安装</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ核心概念扫盲篇</title>
    <url>/posts/32f79e19.html</url>
    <content><![CDATA[<div id="vip-container"><p>在正式进入RocketMQ的学习之前，我觉得有必要梳理一下RocketMQ核心概念，为大家学习RocketMQ打下牢固的基础。</p>
<h2 id="1、RocketMQ部署架构"><a href="#1、RocketMQ部署架构" class="headerlink" title="1、RocketMQ部署架构"></a>1、RocketMQ部署架构</h2><p><img src="https://img-blog.csdnimg.cn/20201018221302331.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在RocketMQ主要的组件如下：</p>
<ul>
<li><p>Nameserver</p>
<p>Nameserver集群，topic的路由注册中心，为客户端根据Topic提供路由服务，从而引导客户端向Broker发送消息。Nameserver之间的节点不通信。路由信息在Nameserver集群中数据一致性采取的最终一致性。</p>
</li>
<li><p>Broker</p>
<p>消息存储服务器，分为两种角色：Master与Slave，上图中呈现的就是2主2从的部署架构，在RocketMQ中，主服务承担读写操作，从服务器作为一个备份，当主服务器存在压力时，从服务器可以承担读服务（消息消费）。所有Broker，包含Slave服务器每隔30s会向Nameserver发送心跳包，心跳包中会包含存在在Broker上所有的topic的路由信息。</p>
</li>
<li><p>Client</p>
<p>消息客户端，包括Producer(消息发送者)和Consumer(消费消费者)．客户端在同一时间只会连接一台nameserver，只有在连接出现异常时才会向尝试连接另外一台。客户端每隔30s向Nameserver发起topic的路由信息查询。</p>
</li>
</ul>
<blockquote>
<p>温馨提示：Nameserver是在内存中存储Topic的路由信息，持久化Topic路由信息的地方是在Broker中，即${    ROCKETMQ_HOME}/store/config/topics.json。</p>
</blockquote>
<p>在RocketMQ4.5.0版本后引入了多副本机制，即一个复制组（m-s）可以演变为基于raft协议的复制组，复制组内部使用raft协议保证broker节点数据的强一致性，该部署架构在金融行业用的比较多。</p>
<a id="more"></a>

<h2 id="2、消息订阅模型"><a href="#2、消息订阅模型" class="headerlink" title="2、消息订阅模型"></a>2、消息订阅模型</h2><p>在RocketMQ的消息消费模式采用的是发布与订阅模式。</p>
<p>topic：一类消息的集合，消息发送者将一类消息发送到一个主题中，例如订单模块将订单发送到 order_topic 中，而用户登录时，将登录事件发送到 user_login_topic 中。</p>
<p>consumegroup：消息消费组，一个消费单位的“群体”，消费组首先在启动时需要订阅需要消费的topic。一个topic可以被多个消费组订阅，同样一个消费组也可以订阅多个主题。一个消费组拥有多个消费者。</p>
<p><strong>术语解释起来有点枯燥晦涩，接下来我举例来阐述。</strong></p>
<p>例如我们在开发一个订单系统，其中有一个子系统：order-service-app，在该项目中会创建一个消费组order_consumer来订阅 order_topic，并且基于分布式部署，order-service-app的部署情况如下：<br><img src="https://img-blog.csdnimg.cn/20201018221353399.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>即order-service-app部署了3台服务器，每一个jvm进程可以看做是消费组 order_consumer 消费组的其中一个消费者。</p>
<h4 id="2-1-消费模式"><a href="#2-1-消费模式" class="headerlink" title="2.1 消费模式"></a>2.1 消费模式</h4><p>那这三个消费者如何来分工来共同消费 order_topic 中的消息呢？</p>
<p>在RocketMQ中支持广播模式与集群模式。</p>
<p><strong>广播模式</strong>：一个消费组内的所有消费者每一个都会处理topic中的每一条消息，通常用于刷新内存缓存。</p>
<p><strong>集群模式</strong>：一个消费组内的所有消费者共同消费一个topic中的消息，即分工协作，一个消费者消费一部分数据，启动负载均衡，</p>
<p>集群模式是非常普遍的模式，符合分布式架构的基本理念，即横向扩容，当前消费者如果无法快速及时处理消息时，可以通过增加消费者的个数横向扩容，快速提高消费能力，及时处理挤压的消息。</p>
<h4 id="2-2-消费队列负载算法与重平衡机制"><a href="#2-2-消费队列负载算法与重平衡机制" class="headerlink" title="2.2 消费队列负载算法与重平衡机制"></a>2.2 消费队列负载算法与重平衡机制</h4><p>那集群模式下，消费者是如何来分配消息的呢？</p>
<p>例如上面实例中order_topic有16个队列，那一个拥有3个消费者的消费组如何来分配队列中。</p>
<p><strong>在MQ领域有一个不成文的约定：同一个消费者同一时间可以分配多个队列，但一个队列同一时间只会分配给一个消费者。</strong></p>
<p><strong>RocketMQ提供了众多的队列负载算法</strong>，其中最常用的两种平均分配算法。</p>
<ul>
<li><p>AllocateMessageQueueAveragely</p>
<p>平均分配</p>
</li>
<li><p>AllocateMessageQueueAveragelyByCircle</p>
<p>轮流平均分配</p>
</li>
</ul>
<p>为了说明这两种分配算法的分配规则，现在对16个队列，进行编号，用q0~q15表示，消费者用c0～c2表示。</p>
<p>AllocateMessageQueueAveragely分配算法的队列负载机制如下：</p>
<p>c0：q0 q1 q2 q3 q4 q5</p>
<p>c1:   q6 q7 q8 q9 q10</p>
<p>c2:    q11 q12 q13 q14 q15</p>
<p>其算法的特点是用总数除以消费者个数，余数按消费者顺序分配给消费者，故c0会多分配一个队列，而且队列分配是连续的。</p>
<p>AllocateMessageQueueAveragelyByCircle分配算法的队列负载机制如下：</p>
<p>c0：q0  q3 q6 q9 q12 q15</p>
<p>c1:   q1   q4 q7 q10 q13</p>
<p>c2:    q2   q5 q8 q11 q14</p>
<p>该分配算法的特点就是轮流一个一个分配。</p>
<blockquote>
<p>温馨提示：如果topic的队列个数小于消费者的个数，那有些消费者无法分配到消息。在RocketMQ中一个topic的队列数直接决定了最大消费者的个数，但topic队列个数的增加对RocketMQ的性能不会产生影响。</p>
</blockquote>
<p>在实际过程中，对主题进行扩容(增加队列个数)或者对消费者进行扩容、缩容是一件非常寻常的事情，那如果新增一个消费者，该消费者消费哪些队列呢？这就涉及到消息消费队列的重新分配，即<strong>消费队列重平衡机制</strong>。</p>
<p>在RocketMQ客户端中会每隔20s去查询当前topic的所有队列、消费者的个数，运用队列负载算法进行重新分配，然后与上一次的分配结果进行对比，如果发生了变化，则进行队列重新分配；如果没有发生变化，则忽略。</p>
<p>例如采取的分配算法如下图所示，现在增加一个消费者c3，那队列的分布情况是怎样的呢？<br><img src="https://img-blog.csdnimg.cn/20201018221426351.png#pic_center" alt="在这里插入图片描述"><br>根据新的分配算法，其队列最终的情况如下：</p>
<p>c0：q0 q1 q2 q3 </p>
<p>c1:   q4 q5 q6 q7</p>
<p>c2:    q8 q9 q10 q11</p>
<p>c3:    q12 q13 q14  q15</p>
<p>上述整个过程无需应用程序干预，由RocketMQ完成。大概的做法就是将将原先分配给自己但这次不属于的队列进行丢弃，新分配的队列则创建新的拉取任务。</p>
<h4 id="2-3-消费进度"><a href="#2-3-消费进度" class="headerlink" title="2.3 消费进度"></a>2.3 消费进度</h4><p>消费者消费一条消息后需要记录消费的位置，这样在消费端重启的时候，继续从上一次消费的位点开始进行处理新的消息。在RocketMQ中，消息消费位点的存储是以消费组为单位的。</p>
<p><strong>集群模式</strong>下，消息消费进度存储在broker端，$ { ROCKETMQ_HOME }/store/config/consumerOffset.json 是其具体的存储文件，其中内容截图如下：<br><img src="https://img-blog.csdnimg.cn/2020101822144865.png#pic_center" alt="在这里插入图片描述"><br>可见消费进度的Key为：topic@consumeGroup，然后每一个队列一个偏移量。</p>
<p><strong>广播模式</strong>的消费进度文件存储在用户的主目录，默认文件全路劲名：$ { USER_HOME }/.rocketmq_offsets。</p>
<h4 id="2-4-消费模型"><a href="#2-4-消费模型" class="headerlink" title="2.4 消费模型"></a>2.4 消费模型</h4><p>RocketMQ提供了并发消费、顺序消费两种消费模型。</p>
<p><strong>并发消费</strong>：对一个队列中消息，每一个消费者内部都会创建一个线程池，对队列中的消息多线程处理，即偏移量大的消息比偏移量小的消息有可能先消费。</p>
<p><strong>顺序消费</strong>：在某一项场景，例如MySQL binlog 场景，需要消息按顺序进行消费。在RocketMQ中提供了基于队列的顺序消费模型，即尽管一个消费组中的消费者会创建一个多线程，但针对同一个Queue，会加锁。</p>
<blockquote>
<p>温馨提示：并发消费模型中，消息消费失败默认会重试16次，每一次的间隔时间不一样；而顺序消费，如果一条消息消费失败，则会一直消费，直到消费成功。故在顺序消费的使用过程中，应用程序需要区分系统异常、业务异常，如果是不符合业务规则导致的异常，则重试多少次都无法消费成功，这个时候一定要告警机制，及时进行人为干预，否则消费会积压。</p>
</blockquote>
<h2 id="3、事务消息"><a href="#3、事务消息" class="headerlink" title="3、事务消息"></a>3、事务消息</h2><p>事务消息并不是为了解决分布式事务，而是提供消息发送与业务落库的一致性，其实现原理就是一次分布式事务的具体运用，请看如下示例：<br><img src="https://img-blog.csdnimg.cn/20201018221527456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>上述伪代码中，将订单存储关系型数据库中和将消息发送到MQ这是两个不同介质的两个操作，如果能保证消息发送、数据库存储这两个操作要么同时成功，要么同时失败，RocketMQ为了解决该问题引入了<strong>事务消息</strong>。</p>
<blockquote>
<p>温馨提示，本节主要的目的是让大家知晓各个术语的概念，由于事务消息的使用，将在该专栏的后续文章中详细介绍。</p>
</blockquote>
<h2 id="4、定时消息"><a href="#4、定时消息" class="headerlink" title="4、定时消息"></a>4、定时消息</h2><p>开源版本的RocketMQ目前并不支持任意精度的定时消息。所谓的定时消息就是将消息发送到Broker，但消费端不会立即消费，而是要到指定延迟时间后才能被消费端消费。</p>
<p>RocketMQ目前支持指定级别的延迟，其延迟级别如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h</span><br></pre></td></tr></table></figure>

<h2 id="5、消息过滤"><a href="#5、消息过滤" class="headerlink" title="5、消息过滤"></a>5、消息过滤</h2><p>消息过滤是指消费端可以根据某些条件对一个topic中的消息进行过滤，即只消费一个主题下满足过滤条件的消息。</p>
<p>RocketMQ目前主要的过滤机制是基于tag的过滤与基于消息属性的过滤，基于消息属性的过滤支持SQL92表达式，对消息进行过滤。</p>
<h2 id="6、小结"><a href="#6、小结" class="headerlink" title="6、小结"></a>6、小结</h2><p>本文的主要目的是介绍RocketMQ常见的术语，例如nameserver、broker、主题、消费组、消费者、队列负载算法、队列重平衡机制、并发消费、顺序消费、消费进度存储、定时消息、事务消息、消息过滤等基本概念，为后续的实战系列打下坚实基础。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ消息发送常见错误与解决方案</title>
    <url>/posts/6a2393aa.html</url>
    <content><![CDATA[<div id="vip-container"><p>本文将结合自己使用RocketMQ的经验，对消息发送常见的问题进行分享，基本会遵循出现问题，分析问题、解决问题。</p>
<h2 id="1、No-route-info-of-this-topic"><a href="#1、No-route-info-of-this-topic" class="headerlink" title="1、No route info of this topic"></a>1、No route info of this topic</h2><p>无法找到路由信息，其完整的错误堆栈信息如下：<br><img src="https://img-blog.csdnimg.cn/20200927212104148.png#pic_center" alt="在这里插入图片描述">而且很多读者朋友会说Broker端开启了自动创建主题也会出现上述问题。</p>
<p>RocketMQ的路由寻找流程如下图所示：<br><img src="https://img-blog.csdnimg.cn/2020092721214148.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">上面的核心关键点如下：</p>
<ul>
<li>如果Broker开启了自动创建Topic，在启动的时候会默认创建主题：TBW102，并会随着Broker发送到Nameserver的心跳包汇报给Nameserver，继而从Nameserver查询路由信息时能返回路由信息。</li>
<li>消息发送者在消息发送时首先会查本地缓存，如果本地缓存中存在，直接返回路由信息。</li>
<li>如果缓存不存在，则向Nameserver查询路由信息，如果Nameserver存在该路由信息，就直接返回。</li>
<li>如果Nameserver不存在该topic的路由信息，如果没有开启自动创建主题，则抛出 No route info of this topic。</li>
<li>如果开启了自动创建主题，则使用默认主题向Nameserver查询路由信息，并使用默认Topic的路由信息为自己的路由信息，将不会抛出 No route info of this topic。</li>
</ul>
<p>通常情况下 No route info of this topic 这个错误一般是在刚搭建RocketMQ，刚入门 RocketMQ遇到的比较多，通常的排查思路如下：</p>
<ul>
<li><p>可以通过rocketmq-console查询路由信息是否存在，或使用如下命令查询路由信息：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd $&#123;ROCKETMQ_HOME&#125;/bin</span><br><span class="line">sh ./mqadmin topicRoute -n 127.0.0.1:9876 -t dw_test_0003</span><br></pre></td></tr></table></figure>
<p>其输出结果如下所示：<br><img src="https://img-blog.csdnimg.cn/20200927212234119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</li>
<li><p>如果通过命令无法查询到路由信息，则查看Broker是否开启了自动创建topic，参数为：autoCreateTopicEnable,该参数默认为true。但在生产环境不建议开启。</p>
</li>
<li><p>如果开启了自动创建路由信息，但还是抛出这个错误，这个时候请检查客户端(Producer)连接的Nameserver地址是否与Broker中配置的nameserver地址是否一致。</p>
</li>
</ul>
<p>经过上面的步骤，基本就能解决该错误。</p>
<a id="more"></a>

<h2 id="2、消息发送超时"><a href="#2、消息发送超时" class="headerlink" title="2、消息发送超时"></a>2、消息发送超时</h2><p>消息发送超时，通常客户端的日志如下：<br><img src="https://img-blog.csdnimg.cn/20200927212258302.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>客户端报消息发送超时，通常第一怀疑的对象是RocketMQ服务器，是不是Broker性能出现了抖动，无法抗住当前的量。</p>
<p>那我们如何来排查RocketMQ当前是否有性能瓶颈呢？</p>
<p>首先我们执行如下命令查看RocketMQ 消息写入的耗时分布情况：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /$&#123;USER.HOME&#125;/logs/rocketmqlogs/</span><br><span class="line">grep -n &#x27;PAGECACHERT&#x27; store.log | more</span><br></pre></td></tr></table></figure>

<p>输出结果如下所示：<br><img src="https://img-blog.csdnimg.cn/20200927212336142.png#pic_center" alt="在这里插入图片描述"><br>RocketMQ会每一分钟打印前一分钟内消息发送的耗时情况分布，我们从这里就能窥探RocketMQ消息写入是否存在明细的性能瓶颈，其区间如下：</p>
<ul>
<li>[&lt;=0ms] 小于0ms，即微妙级别的。</li>
<li>[0~10ms] 小于10ms的个数。</li>
<li>[10~50ms]　大于10ms小</li>
<li>于50ms的个数</li>
</ul>
<p>其他区间显示，绝大多数会落在微妙级别完成，按照笔者的经验如果100-200ms及以上的区间超过20个后，说明Broker确实存在一定的瓶颈，如果只是少数几个，说明这个是内存或pagecache的抖动，问题不大。</p>
<p>通常情况下超时通常与Broker端的处理能力关系不大，还有另外一个佐证，在RocketMQ broker中还存在快速失败机制，即当Broker收到客户端的请求后会将消息先放入队列，然后顺序执行，如果一条消息队列中等待超过200ms就会启动快速失败，向客户端返回[TIMEOUT_CLEAN_QUEUE]broker busy，这个在本文的第3部分会详细介绍。</p>
<p>在RocketMQ客户端遇到网络超时，通常可以考虑一些应用本身的垃圾回收，是否由于GC的停顿时间导致的消息发送超时，这个我在测试环境进行压力测试时遇到过，但生产环境暂时没有遇到过，大家稍微留意一下。</p>
<p>在RocketMQ中通常遇到网络超时，通常与网络的抖动有关系，但由于我对网络不是特别擅长，故暂时无法找到直接证据，但能找到一些间接证据，例如在一个应用中同时连接了kafka、RocketMQ集群，发现在出现超时的同一时间发现连接到RocketMQ集群内所有Broker，连接到kafka集群都出现了超时。</p>
<p><strong>但出现网络超时，我们总得解决，那有什么解决方案吗？</strong></p>
<p>我们对消息中间件的最低期望就是高并发低延迟，从上面的消息发送耗时分布情况也可以看出RocketMQ确实符合我们的期望，绝大部分请求都是在微妙级别内，故我给出的方案时，<strong>减少消息发送的超时时间，增加重试次数，并增加快速失败的最大等待时长</strong>。具体措施如下：</p>
<ul>
<li><p>增加Broker端快速失败的时长，建议为1000，在broker的配置文件中增加如下配置：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">maxWaitTimeMillsInQueue</span>=<span class="string">1000</span></span><br></pre></td></tr></table></figure>

<p>主要原因是在当前的RocketMQ版本中，快速失败导致的错误为SYSTEM_BUSY，并不会触发重试，适当增大该值，尽可能避免触发该机制，详情可以参考本文第3部分内容，会重点介绍system_busy、broker_busy。</p>
</li>
<li><p>如果RocketMQ的客户端版本为4.3.0以下版本(不含4.3.0)<br>将超时时间设置消息发送的超时时间为500ms，并将重试次数设置为6次(这个可以适当进行调整，尽量大于3)，其背后的哲学是尽快超时，并进行重试，因为发现局域网内的网络抖动是瞬时的，下次重试的是就能恢复，并且RocketMQ有故障规避机制，重试的时候会尽量选择不同的Broker，相关的代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;dw_test_producer_group&quot;</span>);</span><br><span class="line">producer.setNamesrvAddr(<span class="string">&quot;127.0.0.1:9876&quot;</span>);</span><br><span class="line">producer.setRetryTimesWhenSendFailed(<span class="number">5</span>);<span class="comment">//　同步发送模式：重试次数</span></span><br><span class="line">producer.setRetryTimesWhenSendAsyncFailed(<span class="number">5</span>);<span class="comment">// 异步发送模式：重试次数</span></span><br><span class="line">producer.start();</span><br><span class="line">producer.send(msg,<span class="number">500</span>);<span class="comment">//消息发送超时时间</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>如果RocketMQ的客户端版本为4.3.0及以上版本</p>
<p>如果客户端版本为4.3.0及其以上版本，由于其设置的消息发送超时时间为所有重试的总的超时时间，故不能直接通过设置RocketMQ的发送API的超时时间，而是需要对其API进行包装，重试需要在外层收到进行，例如示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SendResult <span class="title">send</span><span class="params">(DefaultMQProducer producer, Message msg, <span class="keyword">int</span> </span></span></span><br><span class="line"><span class="function"><span class="params">                              retryCount)</span> </span>&#123;</span><br><span class="line">    Throwable e = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>; i &lt; retryCount; i ++ ) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> producer.send(msg,<span class="number">500</span>); <span class="comment">//设置超时时间，为500ms，内部有重试机制</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable e2) &#123;</span><br><span class="line">            e = e2;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;消息发送异常&quot;</span>,e);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<h2 id="3、System-busy、Broker-busy"><a href="#3、System-busy、Broker-busy" class="headerlink" title="3、System busy、Broker busy"></a>3、System busy、Broker busy</h2><p>在使用RocketMQ中，如果RocketMQ集群达到1W/tps的压力负载水平，System busy、Broker busy就会是大家经常会遇到的问题。例如如下图所示的异常栈。<br><img src="https://img-blog.csdnimg.cn/20200927212452995.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">纵观RocketMQ与system busy、broker busy相关的错误关键字，总共包含如下5个：</p>
</li>
<li><p>[REJECTREQUEST]system busy</p>
</li>
<li><p>too many requests and system thread pool busy</p>
</li>
<li><p>[PC_SYNCHRONIZED]broker busy</p>
</li>
<li><p>[PCBUSY_CLEAN_QUEUE]broker busy</p>
</li>
<li><p>[TIMEOUT_CLEAN_QUEUE]broker busy</p>
<h4 id="3-1-原理分析"><a href="#3-1-原理分析" class="headerlink" title="3.1 原理分析"></a>3.1 原理分析</h4><p>我们先用一张图来阐述一下在消息发送的全生命周期中分别在什么时候会抛出上述错误。<br><img src="https://img-blog.csdnimg.cn/20200927212528727.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>根据上述5类错误日志，其触发的原有可以归纳为如下3种。</p>
</li>
<li><p>pagecache压力较大</p>
<p>其中如下三类错误属于此种情况</p>
<ul>
<li>[REJECTREQUEST]system busy</li>
<li>[PC_SYNCHRONIZED]broker busy</li>
<li>[PCBUSY_CLEAN_QUEUE]broker busy</li>
</ul>
<p>判断pagecache是否忙的依据就是在写入消息时，在向内存追加消息时加锁的时间，默认的判断标准是加锁时间超过1s，就认为是pagecache压力大，向客户端抛出相关的错误日志。</p>
</li>
<li><p>发送线程池挤压的拒绝策略<br>在RocketMQ中处理消息发送的是一个只有一个线程的线程池，内部会维护一个有界队列，默认长度为1W，如果当前队列中挤压的数量超过1w，执行线程池的拒绝策略，从而抛出[too many requests and system thread pool busy]错误。</p>
</li>
<li><p>Broker端快速失败</p>
<p>默认情况下Broker端开启了快速失败机制，就是在Broker端还未发生pagecache繁忙(加锁超过1s)的情况，但存在一些请求在消息发送队列中等待200ms的情况，RocketMQ会不再继续排队，直接向客户端返回system busy，但由于rocketmq客户端目前对该错误没有进行重试处理，所以在解决这类问题的时候需要额外处理。</p>
</li>
</ul>
<h4 id="3-2-PageCache繁忙解决方案"><a href="#3-2-PageCache繁忙解决方案" class="headerlink" title="3.2 PageCache繁忙解决方案"></a>3.2 PageCache繁忙解决方案</h4><p>一旦消息服务器出现大量pagecache繁忙(在向内存追加数据加锁超过1s)的情况，这个是比较严重的问题，需要人为进行干预解决，解决的问题思路如下：</p>
<ul>
<li><p>transientStorePoolEnable</p>
<p>开启transientStorePoolEnable机制，即在broker中配置文件中增加如下配置：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">transientStorePoolEnable</span>=<span class="string">true</span></span><br></pre></td></tr></table></figure>

<p>transientStorePoolEnable的原理如下图所示：</p>
</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200927212644571.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>  引入transientStorePoolEnable能缓解pagecache的压力背后关键如下：</p>
<ul>
<li><p>消息先写入到堆外内存中，该内存由于启用了内存锁定机制，故消息的写入是接近直接操作内存，性能能得到保证。</p>
</li>
<li><p>消息进入到堆外内存后，后台会启动一个线程，一批一批将消息提交到pagecache，即写消息时对pagecache的写操作由单条写入变成了批量写入，降低了对pagecache的压力。</p>
<p>引入transientStorePoolEnable会增加数据丢失的可能性，如果Broker JVM进程异常退出，提交到PageCache中的消息是不会丢失的，但存在堆外内存(DirectByteBuffer)中但还未提交到PageCache中的这部分消息，将会丢失。但通常情况下，RocketMQ进程退出的可能性不大，通常情况下，如果启用了transientStorePoolEnable，消息发送端需要有重新推送机制(补偿思想)。</p>
</li>
<li><p>扩容</p>
<p>如果在开启了transientStorePoolEnable后，还会出现pagecache级别的繁忙，那需要集群进行扩容，或者对集群中的topic进行拆分，即将一部分topic迁移到其他集群中，降低集群的负载。</p>
<blockquote>
<p>温馨提示：在RocketMQ出现pagecache繁忙造成的broker busy，RocketMQ Client会有重试机制。</p>
</blockquote>
<h4 id="3-3-TIMEOUT-CLEAN-QUEUE-解决方案"><a href="#3-3-TIMEOUT-CLEAN-QUEUE-解决方案" class="headerlink" title="3.3 TIMEOUT_CLEAN_QUEUE 解决方案"></a>3.3 TIMEOUT_CLEAN_QUEUE 解决方案</h4><p>由于如果出现TIMEOUT_CLEAN_QUEUE的错误，客户端暂时不会对其进行重试，故现阶段的建议是适当增加快速失败的判断标准，即在broker的配置文件中增加如下配置：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">＃该值默认为200，表示200ms</span></span><br><span class="line"><span class="attr">waitTimeMillsInSendQueue</span>=<span class="string">1000</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>温馨提示，关于Broker busy，笔者发表过两篇文章，大家也可以结合着看：</p>
<p>1、<a href="https://mp.weixin.qq.com/s/N_ttVjBpqVUA0CGrOybNLA">RocketMQ 消息发送system busy、broker busy原因分析与解决方案</a> </p>
<p>2、<a href="https://mp.weixin.qq.com/s/1yFedcwtQ7mYcuHDvGCrqw">再谈RocketMQ broker busy</a> </p>
</blockquote>
</li>
</ul>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>发送超时</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ消息轨迹-设计篇</title>
    <url>/posts/98d74d79.html</url>
    <content><![CDATA[<div id="vip-container"><p>RocketMQ消息轨迹主要包含两篇文章：设计篇与源码分析篇，本节将详细介绍RocketMQ消息轨迹-设计相关。</p>
<p>RocketMQ消息轨迹，主要跟踪消息发送、消息消费的轨迹，即详细记录消息各个处理环节的日志，从设计上至少需要解决如下三个核心问题：</p>
<ul>
<li>消费轨迹数据格式</li>
<li>记录消息轨迹(消息日志)</li>
<li>消息轨迹数据存储在哪？</li>
</ul>
<h2 id="1、消息轨迹数据格式"><a href="#1、消息轨迹数据格式" class="headerlink" title="1、消息轨迹数据格式"></a>1、消息轨迹数据格式</h2><p>RocketMQ4.5版本消息轨迹主要记录如下信息：</p>
<ul>
<li>traceType<br>跟踪类型，可选值：Pub(消息发送)、SubBefore(消息拉取到客户端，执行业务定义的消费逻辑之前)、SubAfter(消费后)。</li>
<li>timeStamp<br>当前时间戳。</li>
<li>regionId<br>broker所在的区域ID，取自BrokerConfig#regionId。</li>
<li>groupName<br>组名称，traceType为Pub时为生产者组的名称；如果traceType为subBefore或subAfter时为消费组名称。</li>
<li>requestId<br>traceType为subBefore、subAfter时使用，消费端的请求Id。</li>
<li>topic<br>消息主题。</li>
<li>msgId<br>消息唯一ID。</li>
<li>tags<br>消息tag。</li>
<li>keys<br>消息索引key，根据该key可快速检索消息。</li>
<li>storeHost<br>跟踪类型为PUB时为存储该消息的Broker服务器IP；跟踪类型为subBefore、subAfter时为消费者IP。</li>
<li>bodyLength<br>消息体的长度。</li>
<li>costTime<br>耗时。</li>
<li>msgType<br>消息的类型，可选值：Normal_Msg(普通消息),Trans_Msg_Half(预提交消息),Trans_msg_Commit(提交消息),Delay_Msg(延迟消息)。</li>
<li>offsetMsgId<br>消息偏移量ID,该ID中包含了broker的ip以及偏移量。</li>
<li>success<br>是发送成功。</li>
<li>contextCode<br>消费状态码，可选值：SUCCESS,TIME_OUT,EXCEPTION,RETURNNULL,FAILED。</li>
</ul>
<a id="more"></a>

<h2 id="2、记录消息轨迹"><a href="#2、记录消息轨迹" class="headerlink" title="2、记录消息轨迹"></a>2、记录消息轨迹</h2><p>消息中间件的两大核心主题：消息发送、消息消费，其核心载体就是消息，消息轨迹（消息的流转）主要是记录消息是何时发送到哪台Broker，发送耗时多少时间，在什么是被哪个消费者消费。记录消息的轨迹主要是集中在消息发送前后、消息消费前后，可以通过RokcetMQ的Hook机制。通过如下两个接口来定义钩子函数。<br><img src="https://img-blog.csdnimg.cn/20190714204429722.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>通过实行上述两个接口，可以实现在消息发送、消息消费前后记录消息轨迹，为了不明显增加消息发送与消息消费的时延，记录消息轨迹最好使用异步发送模式。</p>
<h2 id="3、如何存储消息轨迹数据"><a href="#3、如何存储消息轨迹数据" class="headerlink" title="3、如何存储消息轨迹数据"></a>3、如何存储消息轨迹数据</h2><p>消息轨迹需要存储什么消息以及在什么时候记录消息轨迹的问题都以及解决，那接下来就得思考将消息轨迹存储在哪里？存储在数据库中或其他媒介中，都会加重消息中间件，使其依赖外部组件，最佳的选择还是存储在Broker服务器中，将消息轨迹数据也当成一条消息存储到Broker服务器。</p>
<p>既然把消息轨迹当成消息存储在Broker服务器，那存储消息轨迹的Topic如何确定呢？RocketMQ提供了两种方法来定义消息轨迹的Topic。</p>
<ul>
<li>系统默认Topic<br>如果Broker的traceTopicEnable配置设置为true，表示在该Broker上创建topic名为：RMQ_SYS_TRACE_TOPIC，队列个数为1，默认该值为false，表示该Broker不承载系统自定义用于存储消息轨迹的topic。</li>
<li>自定义Topic<br>在创建消息生产者或消息消费者时，可以通过参数自定义用于记录消息轨迹的Topic名称，不过要注意的是，rokcetmq控制台(rocketmq-console)中只支持配置一个消息轨迹Topic，故自定义Topic，在目前这个阶段或许还不是一个最佳实践，建议使用系统默认的Topic即可。</li>
</ul>
<p>通常为了避免消息轨迹的数据与正常的业务数据混合在一起，官方建议，在Broker集群中，新增加一台机器，只在这台机器上开启消息轨迹跟踪，这样该集群内的消息轨迹数据只会发送到这一台Broker服务器上，并不会增加集群内原先业务Broker的负载压力。</p>
<p>RocketMQ消息轨迹的设计细节就介绍到这里了，下一篇将从源码的角度对其实现细节进行详细的剖析；如果觉得本文对您有帮助的话，期待您的点赞，谢谢。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>消息轨迹</tag>
      </tags>
  </entry>
  <entry>
    <title>Sentienl 动态数据源架构设计理念与改造实践</title>
    <url>/posts/2a5ec050.html</url>
    <content><![CDATA[<div id="vip-container"><p>在介绍集群限流之前需要首先掌握动态数据源的配置方式，本文将根据 Sentinel 官方提供的代码提出整体架构思路，并最终给出实践指导。</p>
<blockquote>
<p>温馨提示：本文主要分为动态数据源架构设计理念、从官方示例寻找改造思路、基于SpringBoot改造方案三个部分来详细剖析 Sentienl 动态数据源的改造方案，循序渐进，不仅解决问题本身，更是反映了作者研究一个问题的思路与方法。</p>
</blockquote>
<h2 id="1、架构设计理念"><a href="#1、架构设计理念" class="headerlink" title="1、架构设计理念"></a>1、架构设计理念</h2><p>在 Sentinel 中主要有如下几个角色：管理后台、限流熔断规则数据源、应用程序。</p>
<p>1）管理后台</p>
<p>管理后台主要用于可视化配置限流规则、熔断规则，其操作界面截图如下：<br><img src="https://img-blog.csdnimg.cn/20200425210307130.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>2）限流熔断规则数据源</p>
<p>用于存储限流熔断规则的数据容器，在 Sentinel 中对应动态数据源这个概念，动态数据源包含两层含义：</p>
<ul>
<li>数据容器<br>数据容器指的就是存储熔断、限流等规则配置的数据库，例如关系型数据库、Zookeeper等等，在实际生产过程中需要选用支持持久化功能的数据库，否则程序一重启，配置规则就会丢失，显然是不能接受的。</li>
<li>动态<br>动态二字主要强调的是配置规则的更改能动态及时生效，引入 Sentinel 限流 SDK 的应用程序在不需要重启的情况下动态感知配置规则发生变化并立即生效。Sentinel 目前对 apollo、consul、etcd、nacos、redis、spring-clould-config、zookeeper 等进行了适配支持。</li>
</ul>
<p>3）应用程序</p>
<p>希望通过 Sentinel 提供的限流、熔断功能对应用程序加以保护，需要引用 Sentinel 相关的 SDK，根据采集的调用信息判断当前是否符合限流规则。</p>
<p>后台管理系统、动态数据源、应用程序的关系如图所示：<br><img src="https://img-blog.csdnimg.cn/20200425210401161.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h2 id="2、从官方示例寻找改造思路"><a href="#2、从官方示例寻找改造思路" class="headerlink" title="2、从官方示例寻找改造思路"></a>2、从官方示例寻找改造思路</h2><p>从官方的文档中可以明确获悉 sentinel-dashboard 即官方自带的后台管理系统只支持将限流、熔断等限流配置规则存储在内存中，一旦后台管理系统重启，配置的熔断规则将全部丢失，所以在生产实践过程中需要对 sentinel-dashboard 进行一定的改造，引入动态数据源，例如 Zookeeper，对限流等配置进行持久化存储。</p>
<p>有了上面的架构设计理念为我们的改造提供了方向，那如何具体改造呢？首先我们来看一下官方提供的 Demo 程序。官方提供的示例代码如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200425210450996.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>接下来我们将以 zookeeper 动态数据源来介绍基于 zookeeper 如何构建 Sentinel 动态数据源。</p>
<a id="more"></a>

<h4 id="2-1-限流熔断等规则存储"><a href="#2-1-限流熔断等规则存储" class="headerlink" title="2.1 限流熔断等规则存储"></a>2.1 限流熔断等规则存储</h4><p>首先查阅一下 ZookeeperConfigSender，该类主要的作用是将配置写入到 zookeeper 中，其关键代码截图如下：<br><img src="https://img-blog.csdnimg.cn/20200425210528331.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这个类的测试目的很简单，先将限流规则持久化到 Zookeeper 中，充当的角色与 sentinel-dashboard 的角色一致，故这个类为我们改造后台管理系统带来很大的启发，即可以通过 zookeeper 存储 sentinel 限流规则，从 demo 示例可以看出限流规则在 zookeeper 中的目录结构，路径为 /{groupId} / {dataid} ，该节点的 value 值存储 json 字符串，存储所有的限流规则。</p>
<p><strong>实践指导,通常基于 zookeeper 的开发，主要是规划好目录结构，关于 Sentinel，我对给出一个初步的目录规划。</strong></p>
<p>在 zookeeper 中创建一个根节点，例如 /sentienl 用来表示限流相关的根目录。</p>
<ul>
<li>groupId 通常为一个独立的应用名称，例如应用的 appId，例如示例中的 provider-demo。</li>
<li>dataId 通常为配置类型，例如限流规则、熔断规则、热点规则等类别，例如限流规则使用 /flowRule ，熔断规则使用 /degradeRule，其 value 值使用 json 存储，将该应用下的所有限流规则用一个 json 对象表示，其存储格式类似于 [{},{}]。</li>
</ul>
<h4 id="2-2-客户端动态感知配置"><a href="#2-2-客户端动态感知配置" class="headerlink" title="2.2 客户端动态感知配置"></a>2.2 客户端动态感知配置</h4><p>实现存储规则的配置存储后接下来是需要客户端能动态感知规则的变化，从而是配置规则实时生效。</p>
<p>我们依然先来看一下官方示例，其核心代码如图所示：<br><img src="https://img-blog.csdnimg.cn/2020042521083764.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">这里尽管引入 groupId 与 dataId 的概念是方便与 nacos 进行切换，但就算不切换，基于 zookeeper 的编程，这种目录规划是非常有必要的。上面的示例代码有两个关键点：</p>
<ul>
<li>创建 ZookeeperDataSource，每一个 ZookeeperDataSource 负责监听一个节点。</li>
<li>需要调用 FlowRuleManager 的 register2Property 方法将数据源关联的数据注册到 FlowRuleManager 中，方便 Sentinel 内核根据数据源中存储的限流熔断等规则进行工作。</li>
</ul>
<p>客户端在启动的时候会调用 FlowRuleManager 相关方法加载限流相关的配置，那如果配置规则发生变化后，客户端如何动态感知呢？其关键就在于 ZookeeperDataSource 的实现中，其实现关键点如下：<br><img src="https://img-blog.csdnimg.cn/2020042521094273.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">即在构建 ZookeeperDataSource 时会监听 /groupId/dataId 节点，即存放限流配置的节点，一旦数据发生变化，就会通知到客户端，从而调用 loadConfig 重新更新 Sentienl 客户端的限流配置，从而实现配置实时生效。</p>
<h2 id="3、Sentinel-引入Zookeeper-动态数据源实现方案"><a href="#3、Sentinel-引入Zookeeper-动态数据源实现方案" class="headerlink" title="3、Sentinel 引入Zookeeper 动态数据源实现方案"></a>3、Sentinel 引入Zookeeper 动态数据源实现方案</h2><p>从官方的示例中我们不难发现，引入 Zookeeper 数据源主要有两个步骤：将数据存储在Zookeeper中以及在客户端监听ZK从而实时生效两个步骤。</p>
<p>sentinel 官方提供了默认的后台管理系统实现：sentinel-dashboard，但其缺点非常明显：基于内存存储，无法用于实际生产过程。大家可能会向后台管理系统将配置信息存储在内存中，那接入的客户端如何从 sentinel-dashboard 的内存中获取配置信息呢，这是因为 sentinel-dashboard 里提供了简单的机器发现，并且内置了 sentinel 客户端之间、sentinel 客户端与 sentinel-dashboard 之间的通讯协议，具体由 sentinel-transport 模块实现，目前提供了基于 http 与 netty 的实现方式，故能将 sentinel-dashboard 内存中的配置信息推送到客户端，从而使客户端根据配置进行限流与熔断。</p>
<p>接下来回答本文的重点部分，基于 sentinel-dashboard 如何引入 zookeeper 等动态数据源呢？</p>
<h4 id="3-1-将配置规则存储在Zookeeper中"><a href="#3-1-将配置规则存储在Zookeeper中" class="headerlink" title="3.1 将配置规则存储在Zookeeper中"></a>3.1 将配置规则存储在Zookeeper中</h4><p>首先我们可以顺着 sentinel-dashboard 的提供的控制器，寻找其后台入口，改造目标也很明确，就是将数据持久化到 zookeeper中，例如增加流控规则的后台处理入口为：<br><img src="https://img-blog.csdnimg.cn/20200425211030452.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">Sentinel 动态数据源架构设计理念与改造实践<br>只需要从这里开始改造，将其配置持久化到数据库中和 zookeeper中即可。</p>
<p>将数据存储在 zookeeper 中，其关键是设计好各个项目如何有组织有条理的在 zookeeper 中进行组织。我给出如下设计方案：<br><img src="https://img-blog.csdnimg.cn/20200425211059470.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">这样相关管理人员可以直接在 sentinel-dashboard 中配置限流规则，即按照应用为维度进行存储，每一个应用再按照维度，例如限流、熔断、热点、集群等维度进行配置，每一分类节点的值存储的是所有的配置，使用 [{},{}] 这种JSON格式进行存储。</p>
<h4 id="3-2-Sentinel-客户端规则加载封装"><a href="#3-2-Sentinel-客户端规则加载封装" class="headerlink" title="3.2 Sentinel 客户端规则加载封装"></a>3.2 Sentinel 客户端规则加载封装</h4><p>目前大部分项目都是基于 SpringBoot，故本文给出基于 SpringBoot 进行的客户端加载实现思路。</p>
<p>Sentinel 动态数据源架构设计理念与改造实践<br>客户端改造伪代码<br><img src="https://img-blog.csdnimg.cn/202004252111428.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">其主要关键点如下：</p>
<ul>
<li>基于 Spring ApplicationReadyEvent 事件，实现限流规则的加载。</li>
<li>创建 ZookeeperDataSource 创建动态数据源。<br>并调用 Sentinel 提供的相关 API 完成限流规则的加载。</li>
</ul>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>源码</tag>
        <tag>架构设计</tag>
        <tag>动态数据源</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Sentienl 流控效果之匀速排队与预热实现原理与实战建议</title>
    <url>/posts/c534f93a.html</url>
    <content><![CDATA[<div id="vip-container"><blockquote>
<p>温馨提示，如果大家对源码不感兴趣，可以直接跳到本文的总结部分，了解一下预热实现原理的一些实战建议。</p>
<p>首先先回顾一下 Sentinel 流控效果相关的类图：<br><img src="https://img-blog.csdnimg.cn/20200406112941248.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>DefaultController 快速失败已经在上文详细介绍过，本文将详细介绍其他两种策略的实现原理。</p>
</blockquote>
<p>首先我们应该知道，一条流控规则(FlowRule)对应一个 TrafficShapingController 对象。</p>
<h2 id="1、RateLimiterController"><a href="#1、RateLimiterController" class="headerlink" title="1、RateLimiterController"></a>1、RateLimiterController</h2><p>匀速排队策略实现类，首先我们先来介绍一下该类的几个成员变量的含义：</p>
<ul>
<li>int maxQueueingTimeMs<br>排队等待的最大超时时间，如果等待超过该时间，将会抛出 FlowException。</li>
<li>double count<br>流控规则中的阔值，即令牌的总个数，以QPS为例，如果该值设置为1000，则表示1s可并发的请求数量。</li>
<li>AtomicLong latestPassedTime<br>上一次成功通过的时间戳。</li>
</ul>
<p>接下来我们详细来看一下其算法的实现：<br>RateLimiterController#canPass</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">canPass</span><span class="params">(Node node, <span class="keyword">int</span> acquireCount, <span class="keyword">boolean</span> prioritized)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (acquireCount &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (count &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">long</span> currentTime = TimeUtil.currentTimeMillis();</span><br><span class="line">    <span class="keyword">long</span> costTime = Math.round(<span class="number">1.0</span> * (acquireCount) / count * <span class="number">1000</span>);    <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">long</span> expectedTime = costTime + latestPassedTime.get();                <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">if</span> (expectedTime &lt;= currentTime) &#123;                                                    <span class="comment">// @3</span></span><br><span class="line">        latestPassedTime.set(currentTime);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">long</span> waitTime = costTime + latestPassedTime.get() - TimeUtil.currentTimeMillis();   <span class="comment">// @4</span></span><br><span class="line">        <span class="keyword">if</span> (waitTime &gt; maxQueueingTimeMs) &#123;                                                                        <span class="comment">// @5</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">long</span> oldTime = latestPassedTime.addAndGet(costTime);                                     <span class="comment">// @6</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                waitTime = oldTime - TimeUtil.currentTimeMillis();                                            </span><br><span class="line">                <span class="keyword">if</span> (waitTime &gt; maxQueueingTimeMs) &#123;</span><br><span class="line">                    latestPassedTime.addAndGet(-costTime);</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">		<span class="keyword">if</span> (waitTime &gt; <span class="number">0</span>) &#123;                                                     <span class="comment">// @7</span></span><br><span class="line">                    Thread.sleep(waitTime);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先算出每一个请求之间最小的间隔，时间单位为毫秒。例如 cout 设置为 1000,表示一秒可以通过 1000个请求，匀速排队，那每个请求的间隔为 1 / 1000(s)，乘以1000将时间单位转换为毫秒，如果一次需要2个令牌，则其间隔时间为2ms，用 costTime 表示。</p>
<p>代码@2：计算下一个请求的期望达到时间，等于上一次通过的时间戳 + costTime ，用 expectedTime 表示。</p>
<p>代码@3：如果 expectedTime 小于等于当前时间，说明在期望的时间没有请求到达，说明没有按照期望消耗令牌，故本次请求直接通过，并更新上次通过的时间为当前时间。</p>
<p>代码@4：如果 expectedTime 大于当前时间，说明还没到令牌发放时间，当前请求需要等待。首先先计算需要等待是时间，用 waitTime 表示。</p>
<p>代码@5：如果计算的需要等待的时间大于允许排队的时间，则返回 false，即本次请求将被限流，返回 FlowException。</p>
<p>代码@6：进入排队，默认是本次请求通过，故先将上一次通过流量的时间戳增加 costTime，然后直接调用 Thread 的 sleep 方法，将当前请求先阻塞一会，然后返回 true 表示请求通过。</p>
<blockquote>
<p>匀速排队模式的实现的关键：主要是记录上一次请求通过的时间戳，然后根据流控规则，判断两次请求之间最小的间隔，并加入一个排队时间。</p>
</blockquote>
<h2 id="2、WarmUpController"><a href="#2、WarmUpController" class="headerlink" title="2、WarmUpController"></a>2、WarmUpController</h2><p>预热策略的实现，首先我们先来介绍一下该类的几个成员变量的含义：</p>
<ul>
<li>double count<br>流控规则设定的阔值。</li>
<li>int coldFactor<br>冷却因子。</li>
<li>int warningToken<br>告警token，对应 Guava 中的 RateLimiter 中的 </li>
<li>int maxToken<br>double slope<br>AtomicLong storedTokens<br>AtomicLong lastFilledTime</li>
</ul>
<h4 id="2-1-WarmUpController-构造函数"><a href="#2-1-WarmUpController-构造函数" class="headerlink" title="2.1 WarmUpController 构造函数"></a>2.1 WarmUpController 构造函数</h4><p>内部的构造函数，最终将调用 construct 方法。<br>WarmUpController#construct</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">construct</span><span class="params">(<span class="keyword">double</span> count, <span class="keyword">int</span> warmUpPeriodInSec, <span class="keyword">int</span> coldFactor)</span> </span>&#123; <span class="comment">// @1</span></span><br><span class="line">	<span class="keyword">if</span> (coldFactor &lt;= <span class="number">1</span>) &#123;</span><br><span class="line">		<span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;Cold factor should be larger than 1&quot;</span>);</span><br><span class="line">         &#125;</span><br><span class="line">	<span class="keyword">this</span>.count = count;  </span><br><span class="line">	<span class="keyword">this</span>.coldFactor = coldFactor;   </span><br><span class="line">	warningToken = (<span class="keyword">int</span>)(warmUpPeriodInSec * count) / (coldFactor - <span class="number">1</span>);   <span class="comment">// @2</span></span><br><span class="line">	maxToken = warningToken + (<span class="keyword">int</span>)(<span class="number">2</span> * warmUpPeriodInSec * count / (<span class="number">1.0</span> + coldFactor));  <span class="comment">// @3</span></span><br><span class="line">	slope = (coldFactor - <span class="number">1.0</span>) / count / (maxToken - warningToken);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>要理解该方法，就需要理解 Guava 框架的 SmoothWarmingUp 相关的预热算法，其算法原理如图所示：<br><img src="https://img-blog.csdnimg.cn/20200406114151249.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>关于该图的详细介绍，请参考笔者的另外一篇博文：<a href="https://blog.csdn.net/prestigeding/article/details/105262127">源码分析RateLimiter SmoothWarmingUp 实现原理</a>，对该图进行了详细解读。</p>
<p>代码@1：首先介绍该方法的参数列表：</p>
<ul>
<li>double count<br>限流规则配置的阔值，例如是按 TPS 类型来限流，如果限制为100tps，则该值为100。</li>
<li>int warmUpPeriodInSec<br>预热时间，单位为秒，通用在限流规则页面可配置。</li>
<li>int coldFactor<br>冷却因子，这里默认为3，与 RateLimiter 中的冷却因子保持一致，表示的含义为 coldIntervalMicros 与  stableIntervalMicros 的比值。</li>
</ul>
<p>代码@2：计算 warningToken 的值，与 Guava 中的 RateLimiter 中的 thresholdPermits 的计算算法公式相同，thresholdPermits = 0.5 * warmupPeriod / stableInterval，在Sentienl 中，而 stableInteral = 1 / count，thresholdPermits  表达式中的 0.5 就是因为 codeFactor 为3，因为 warm up period与 stable   面积之比等于 (coldIntervalMicros - stableIntervalMicros ) 与 stableIntervalMicros 的比值，这个比值又等于 coldIntervalMicros / stableIntervalMicros  - stableIntervalMicros / stableIntervalMicros 等于 coldFactor - 1。</p>
<p>代码@3：同样根据 Guava 中的 RateLimiter 关于 maxToken 也能理解。</p>
<a id="more"></a>

<h4 id="2-2-canPass-方法详解"><a href="#2-2-canPass-方法详解" class="headerlink" title="2.2 canPass 方法详解"></a>2.2 canPass 方法详解</h4><p>WarmUpController#canPass </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">canPass</span><span class="params">(Node node, <span class="keyword">int</span> acquireCount, <span class="keyword">boolean</span> prioritized)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> passQps = (<span class="keyword">long</span>) node.passQps(); <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">long</span> previousQps = (<span class="keyword">long</span>) node.previousPassQps();  <span class="comment">// @2</span></span><br><span class="line">    syncToken(previousQps);  <span class="comment">// @3</span></span><br><span class="line">	<span class="comment">// 开始计算它的斜率</span></span><br><span class="line">    <span class="comment">// 如果进入了警戒线，开始调整他的qps</span></span><br><span class="line">    <span class="keyword">long</span> restToken = storedTokens.get();</span><br><span class="line">    <span class="keyword">if</span> (restToken &gt;= warningToken) &#123;    <span class="comment">// @4</span></span><br><span class="line">        <span class="keyword">long</span> aboveToken = restToken - warningToken;</span><br><span class="line">        <span class="comment">// 消耗的速度要比warning快，但是要比慢</span></span><br><span class="line">        <span class="comment">// current interval = restToken*slope+1/count</span></span><br><span class="line">        <span class="keyword">double</span> warningQps = Math.nextUp(<span class="number">1.0</span> / (aboveToken * slope + <span class="number">1.0</span> / count));</span><br><span class="line">        <span class="keyword">if</span> (passQps + acquireCount &lt;= warningQps) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;   <span class="comment">// @5</span></span><br><span class="line">        <span class="keyword">if</span> (passQps + acquireCount &lt;= count) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：先获取当前节点已通过的QPS。</p>
<p>代码@2：获取当前滑动窗口的前一个窗口收集的已通过QPS。</p>
<p>代码@3：调用 syncToken 更新 storedTokens 与 lastFilledTime 的值，即按照令牌发放速率发送指定令牌，将在下文详细介绍 syncToken 方法内部的实现细节。</p>
<p>代码@4：如果当前存储的许可大于warningToken的处理逻辑，主要是在预热阶段允许通过的速率会比限流规则设定的速率要低，判断是否通过的依据就是当前通过的TPS与申请的许可数是否小于当前的速率（这个值加入斜率，即在预热期间，速率是慢慢达到设定速率的。</p>
<p>代码@5：当前存储的许可小于warningToken，则按照规则设定的速率进行判定。</p>
<blockquote>
<p>不知大家有没有一个疑问，为什么 storedTokens 剩余许可数越大，限制其通过的速率竟然会越慢，这又怎么理解呢？大家可以思考一下这个问题，将在本文的总结部分进行解答。</p>
</blockquote>
<p>我们先来看一下 syncToken 的实现细节，即更新 storedTokens 的逻辑。<br>WarmUpController#syncToken </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">syncToken</span><span class="params">(<span class="keyword">long</span> passQps)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> currentTime = TimeUtil.currentTimeMillis();</span><br><span class="line">    currentTime = currentTime - currentTime % <span class="number">1000</span>;    <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">long</span> oldLastFillTime = lastFilledTime.get();</span><br><span class="line">    <span class="keyword">if</span> (currentTime &lt;= oldLastFillTime) &#123;                          <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> oldValue = storedTokens.get();</span><br><span class="line">    <span class="keyword">long</span> newValue = coolDownTokens(currentTime, passQps);   <span class="comment">// @3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (storedTokens.compareAndSet(oldValue, newValue)) &#123;  </span><br><span class="line">        <span class="keyword">long</span> currentValue = storedTokens.addAndGet(<span class="number">0</span> - passQps);    <span class="comment">// @4</span></span><br><span class="line">        <span class="keyword">if</span> (currentValue &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            storedTokens.set(<span class="number">0L</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        lastFilledTime.set(currentTime);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：这个是计算出当前时间秒的最开始时间。例如当前是 2020-04-06 08:29:01:056，该方法返回的时间为 2020-04-06 08:29:01:000。</p>
<p>代码@2：如果当前时间小于等于上次发放许可的时间，则跳过，无法发放令牌，即每秒发放一次令牌。</p>
<p>代码@3：具体方法令牌的逻辑，稍后详细介绍。</p>
<p>代码@4：更新剩余令牌，即生成的许可后要减去上一秒通过的令牌。</p>
<p>我们详细来看一下 coolDownTokens 方法。<br>WarmUpController#coolDownTokens </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">coolDownTokens</span><span class="params">(<span class="keyword">long</span> currentTime, <span class="keyword">long</span> passQps)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> oldValue = storedTokens.get();</span><br><span class="line">    <span class="keyword">long</span> newValue = oldValue;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 添加令牌的判断前提条件:</span></span><br><span class="line">    <span class="comment">// 当令牌的消耗程度远远低于警戒线的时候</span></span><br><span class="line">    <span class="keyword">if</span> (oldValue &lt; warningToken) &#123;    <span class="comment">// @1</span></span><br><span class="line">        newValue = (<span class="keyword">long</span>)(oldValue + (currentTime - lastFilledTime.get()) * count / <span class="number">1000</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (oldValue &gt; warningToken) &#123;   <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">if</span> (passQps &lt; (<span class="keyword">int</span>)count / coldFactor) &#123;</span><br><span class="line">            newValue = (<span class="keyword">long</span>)(oldValue + (currentTime - lastFilledTime.get()) * count / <span class="number">1000</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Math.min(newValue, maxToken);<span class="comment">// @3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果当前剩余的 token 小于警戒线，可以按照正常速率发放许可。</p>
<p>代码@2：如果当前剩余的 token 大于警戒线但前一秒的QPS小于 (count 与 冷却因子的比)，也发放许可（这里我不是太明白其用意）。</p>
<p>代码@3：这里是关键点，第一次运行，由于 lastFilledTime 等于0，这里将返回的是 maxToken，故这里一开始的许可就会超过 warningToken，启动预热机制，进行速率限制。</p>
<h2 id="3、总结"><a href="#3、总结" class="headerlink" title="3、总结"></a>3、总结</h2><p>WarmUpController 这个预热算法还是挺复杂的，接下来我们来总结一下它的特征。</p>
<p>不知大家有没有一个疑问，为什么 storedTokens 剩余许可数越大，限制其通过的速率竟然会越慢，这又怎么理解呢？</p>
<p>这里感觉有点逆向思维的味道，因为一开始就会将 storedTokens 的值设置为 maxToken，即开始就会超过 warningToken，从而一开始进入到预热阶段，此时的速率有一个爬坡的过程，类似于数学中的斜率，达到其他启动预热的效果。</p>
<p><strong>实战指南：注意 warmUpPeriodInSec 与 coldFactor 的设置，将会影响最终的限流效果。</strong></p>
<p>为了更加直观的理解，我们举例如下，warningToken 与 maxToken 的生成公式如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">warningToken = (<span class="keyword">int</span>)(warmUpPeriodInSec * count) / (coldFactor - <span class="number">1</span>);  </span><br><span class="line">maxToken = warningToken + (<span class="keyword">int</span>)(<span class="number">2</span> * warmUpPeriodInSec * count / (<span class="number">1.0</span> + coldFactor));  </span><br></pre></td></tr></table></figure>
<p>coldFactor 设定为 3，例如限流规则中配置每秒允许通过的许可数量为 10，即 count 值等于 10，我们改变 warmUpPeriodInSec 的值来看一下 warningToken 与 maxToken 的值，以此来探究 Sentinel WarmUpController 的工作机制或工作效果。</p>
<table>
<thead>
<tr>
<th>warmUpPeriodInSec</th>
<th>warningToken</th>
<th>maxToken</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>5</td>
<td>10</td>
</tr>
<tr>
<td>2</td>
<td>10</td>
<td>20</td>
</tr>
<tr>
<td>3</td>
<td>15</td>
<td>30</td>
</tr>
<tr>
<td>4</td>
<td>20</td>
<td>40</td>
</tr>
</tbody></table>
<p>根据上面的算法，如果 warningToken  的值小于 count，则限流会变的更严厉，即最终的限流TPS会小于设置的TPS。即 warmUpPeriodInSec   设置过大过小都不合适，其标准是要使得 warningToken  的值大于 count。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>源码</tag>
        <tag>RateLimiterController</tag>
        <tag>匀速排队</tag>
        <tag>预热</tag>
        <tag>WarmUpController</tag>
      </tags>
  </entry>
  <entry>
    <title>Sentinel Dubbo 适配器看限流与熔断(实战思考篇)</title>
    <url>/posts/fd3813a.html</url>
    <content><![CDATA[<div id="vip-container"><p>本文是源码分析 Sentinel 系列的第十三篇，已经非常详细的介绍了 Sentinel 的架构体系、滑动窗口、调用链上下文、限流、熔断的实现原理，相信各位读者朋友们对Sentinel有一个较为体系化的认知了，这个时候是该开始如何在生产环境进行运用了。</p>
<blockquote>
<p>本文将以 Dubbo 服务调用为案例剖析场景，尝试对官方提供的 Dubbo 适配器做一个研究学习并对此做出自己的评价，抛出我的观点，期待与大家共同探讨，交流。</p>
</blockquote>
<p>一个 Dubbo RPC 的简易调用过程如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200510202405377.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>消费者会维护一个服务提供者列表，然后再发一起一个服务调用的时候会首先根据负载均衡算法从中选择一个服务提供者，然后发起 RPC 调用，在请求真实发送之前会依次通过客户端设置的过滤器链(Filter)，然后经过网络传输到到达服务提供者，并执行完服务提供者端的 Filter，最后进入到业务逻辑执行并返回结果。</p>
<p>Sentinel 与 Dubbo 的整合就是利用了 Dubbo 的 Filter 机制，为 Dubbo 提供对应的 过滤器，无缝实现限流、熔断等功能，做到业务无感知，即业务代码无需使用 Sentinel 相关的 API。</p>
<p>接下来请大家带着在 Dubbo 中如何使用限流、熔断方面来看官方给出的解决方案。</p>
<blockquote>
<p>思考题：在看接下来的内容之前，建议大家稍作停顿，思考一下，在服务调用模型中，限流、熔断通常在哪个端做比较合适。</p>
</blockquote>
<h2 id="1、从消费端来看限流与熔断"><a href="#1、从消费端来看限流与熔断" class="headerlink" title="1、从消费端来看限流与熔断"></a>1、从消费端来看限流与熔断</h2><p><img src="https://img-blog.csdnimg.cn/20200510202451273.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">从消费端的视角，虽然提供了服务端的负载均衡，但从客户端不管是向192.168.1.3还是向192.168.1.4发送RPC调用，都会经过同一个 Sentinel Dubbo Filter。这个看似简单明了，但这是我们接下来思考的最基本最核心的点。</p>
<p>我们先来看看官方提供的 Dubbo 适配器的核心实现：<br>SentinelDubboConsumerFilter#invoke<br><img src="https://img-blog.csdnimg.cn/20200510202524603.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>消费端这边使用到了两个资源名称，一个是接口级别，例如 com.demo.service.UserService，另外一是方法级别，例如 com.demo.servcie.UserServce#findUser(Ljava.lang.String)。<br>定义了两个资源后，Sentinel 会使用滑动窗口机制，为上述两个资源收集实时的调用信息，为后续的限流、熔断提供数据依据。</p>
<a id="more"></a>

<p>限流规则是依附于具体某一个项目的，例如如下图所示：<br><img src="https://img-blog.csdnimg.cn/2020051020261021.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">限流、熔断都是根据资源级别，如果需要对消费端的调用进行限流的话，就需要为这两个资源配置对应的限流规则，如果不配置则默认通过，表示不限流。</p>
<h4 id="1-1-服务调用端-消费方-是否需要配置限流规则"><a href="#1-1-服务调用端-消费方-是否需要配置限流规则" class="headerlink" title="1.1 服务调用端(消费方)是否需要配置限流规则"></a>1.1 服务调用端(消费方)是否需要配置限流规则</h4><p>在 dubbo 的服务调用场景中，在消费端设置限流的规则的话，这个调用链是针对整个集群所有服务提供者的，例如当前集群中包含3个服务提供者，每个服务提供者用于1000tps的服务能力，那消费端的限流，应该配置的限流TPS应该为3000tps，如果设置为1000tps，则无法完整的利用服务端的能力，基于这样的情况，通常消费端无需配置限流规则。</p>
<p>那是不是说消费端就没必要配置限流规则呢？其实也不是，有如下这个场景，例如调用第三方外部的计费类服务接口，对方通常为特定的账户等级设置对应的TPS上限，如果超过该调用频率就会抛出错误，这种情况还是需要设置限流规则，确保消费端以不超过要求进行调用，避免业务异常。</p>
<h4 id="1-2-服务调用端-消费方-是否需要配置熔断"><a href="#1-2-服务调用端-消费方-是否需要配置熔断" class="headerlink" title="1.2 服务调用端(消费方)是否需要配置熔断"></a>1.2 服务调用端(消费方)是否需要配置熔断</h4><p>引入熔断的目的是避免服务端单节点响应慢而导致这个服务不稳定，例如示例中有3个服务提供者，如果192.168.1.3的服务提供者由于触发了BUG导致响应时间大大增加，导致发往该服务提供者的请求大概率超时，在这样的情况下希望在接下来某段时间内消费方发往这这个服务提供者的请求快速熔断降级，返回错误，由客户端重试其他服务提供者。其实现效果如下：<br><img src="https://img-blog.csdnimg.cn/20200510202651125.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>当前的 Sentinel 默认是否能满足上述的需求呢？</p>
<p>我们以 Sentinel 基于异常比例熔断策略来进行阐述，如果资源的调用异常比例超过一定值是会触发降级熔断，抛出 DegradeException 异常。</p>
<p>由于总共只有三个服务提供者，其中发往192.168.1.3的请求大概率会由于超时失败，则异常比例会超过设置的熔断降级规则，会触发降级，造成的效果是整个服务调用都会发送熔断降级，即调用192.168.1.4,5两个请求都不会被熔断，造成整个服务调用不可用，与期望不一致。即还是会出现一个节点的不稳定而导致整个服务不稳定的情况。</p>
<p>其造成的根本原因是因为其资源的定义并没有包含服务提供者的信息，改进的初步方案：</p>
<ol>
<li>在过滤器中再定义一个资源，加上服务提供的IP与端口号，例如 SphU.entry(“com.d.s.UserService@ip:port”)，对单个服务提供者进行单独收集调用信息，并且需要提供一可配置的项，用来标记该类型的资源在做熔断判断可使用某一个资源的配置，例如配置为 com.d.s.UserService，表示用这个配置规则来判断熔断。</li>
<li>在熔断规则判断的时候，该资源使用被引用资源的熔断规则进行判断。</li>
</ol>
<p>最后来解答一下，熔断规则通常只需要配置在调用方即可。</p>
<h2 id="2、从服务来看限流与熔断"><a href="#2、从服务来看限流与熔断" class="headerlink" title="2、从服务来看限流与熔断"></a>2、从服务来看限流与熔断</h2><p>由于服务端看限流与熔断就比较简单，因为服务端与客户端存在一个非常大的区别是客户端存在负载均衡机制，一个消费端对于同一资源来说，会调用多个服务提供者，而服务提供者对于一个资源来就是其自身，故限流规则，熔断规则都是针对个体，其复杂度降低。</p>
<p>为了知识体系的完备性，我们来看一下 Sentinel Dubbo 在服务端的适配器的实现。</p>
<p>SentinelDubboProviderFilter#invoke<br><img src="https://img-blog.csdnimg.cn/20200510202746713.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这里有二个关键点：</p>
<ol>
<li>使用了 ContextUtil 的 entry 方法，定义本次调用的上下文环境名称为：resourceName，默认为接口名与方法名、参数列表，例如 com.d.s.UserServce#findUser(Ljava.lang.String),源头为消费端的应用名称。</li>
<li>定义两个资源，这里与消费端相同，就不做重复解读。</li>
</ol>
<p>关于这个 ContextUtil 的 entry 方法非常关键，因为 Sentinel 中数据节点的统计是以 ContextName 为维度的。</p>
<p>例如想对一个应用所有的操作 redis 操作统一设置为一个资源名，redisOpsResource，即想控制该应用整体的 redis 操作 tps，其场景如下：<br><img src="https://img-blog.csdnimg.cn/20200510202841580.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>例如初衷设计为 opsReisTotal 的整个 tps 为 500，例如从UserService#findser链路的访问 redis tps 为 400，而从 Order#createOrder 链路访问 redis tps 为 400，此时 redis 的整体 tps 已经达到了 800 tps，但你会发现并不会触发限流，因为对资源 RredisOpResource 的调用信息统计是以 context name 为维度的，不同的 context name 互不影响，从而无法做到全局控制。</p>
<h2 id="3、总结"><a href="#3、总结" class="headerlink" title="3、总结"></a>3、总结</h2><p>本文结合 Sentinel 官方对于 Dubbo 提供的适配器并加以理解，提出了如下观点，欢迎大家留言探讨，相互交流，共同进步。</p>
<ol>
<li>限流规则根据不同的使用场景可以在客户端、服务端配置。</li>
<li>熔断规则通常在服务调用方配置即可。</li>
<li>Sentinel 目前的熔断还实现的比较简单，无法解决集群中因为某一个节点的访问慢而触发熔断，并使服务稳定的能力。</li>
<li>Sentienl 的实时统计是以调用上下文(Context Name)，即 ContextUtil.entry 方法定义的上下文为维度的，这点非常关键，不然容易踩坑。</li>
</ol>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>源码</tag>
        <tag>实战</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>Sentinel 系统自适应限流原理剖析与实战指导</title>
    <url>/posts/a815ae71.html</url>
    <content><![CDATA[<div id="vip-container"><p>看到标题中的几个关键字<strong>系统自适应</strong>限流是不是觉得高大上，这个自适应又是如何实现的呢？</p>
<h2 id="1、Sentinel-系统自适应概述"><a href="#1、Sentinel-系统自适应概述" class="headerlink" title="1、Sentinel 系统自适应概述"></a>1、Sentinel 系统自适应概述</h2><p>从官方了解到 Sentienl 系统自适应限流是一个全局的概念，对应用入口流量统一进行统一控制，结合应用的机器负载、CPU 使用率，总体平均响应时间、入口 QPS 和并发线程数等几个维度的监控指标从而决定是否调用进行限流操作。为了有一个直观的感受，我们可以从官方的运维平台看看其系统自适应限流的操作界面：<br><img src="https://img-blog.csdnimg.cn/2020052413411896.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>RT、线程数、入口QPS这三个指标是可以通过采集调用信息进行统计计算的，那系统LOAD、CPU使用率是如何获取的呢？大家可以带着这个问题进入本文的学习中来。</p>
<p>在详细分析系统自适应实现原理之前我们先来思考一下 Sentinel 引入该机制的目的。</p>
<p>官方文档针对这个问题有过仔细阐述，我们先来看看官方文档对其阐述。</p>
<p>引入系统自适应限流的主要的目的有如下两个：</p>
<ul>
<li>保证系统不被拖垮</li>
<li>在系统稳定的前提下保证系统的吞吐量。</li>
</ul>
<p>目前我们接触的限流的防护思路都是设定一个指标（阔值），例如系统的负载 load 超过某个阔值后就阻止或减少流量的继续进入，当系统负载降低到某一水平后则恢复流量的进入。通常都是被动的，其实际效果取决与阔值设置是否合理，但往往设置合理不是一件容易的事情。</p>
<p>那 Sentinel 提供的系统自适应是可以将设定的规则作为一个保护因子，而允许通过的流量由处理请求的能力来决定，即根据请求的响应时间、当前系统正在处理的请求速率来决定。</p>
<p>那 Sentinel 是如何实现的呢？接下来用源码的手段来揭晓其实现原理。</p>
<h2 id="2、系统自适应限流原理"><a href="#2、系统自适应限流原理" class="headerlink" title="2、系统自适应限流原理"></a>2、系统自适应限流原理</h2><p>Sentinel 执行系统限流的核心入口类为 SystemSlot，该类实现简单，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200524134158678.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="SystemRuleManager#checkSystem"><br>从这里可以看出实现的关键在于SystemRuleManager，这里是直接调用 checkSystem 进行是否触发其限流，那我们接下来重点跟踪一下该方法的实现。</p>
<h4 id="2-1-自适应限流检测流程"><a href="#2-1-自适应限流检测流程" class="headerlink" title="2.1 自适应限流检测流程"></a>2.1 自适应限流检测流程</h4><p>系统自适应限流检测具体由 SystemRuleManager 的 checkSystem 方法实现，接下来详细剖析其实现细节。<br><img src="https://img-blog.csdnimg.cn/2020052413421556.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step1：验证相关资源，主要包含三层验证：</p>
<ul>
<li>如果资源名称为空，则直接跳过，这个是容错机制。</li>
<li>如果系统自适应开关为打开，直接放行，该开关初始化时为 false，在加载到一条系统自适应配置规则时该状态会设置为 true，具体在 loadSystemConf 中。</li>
<li>如果资源的类型不是入口流量(EntryType.IN),则直接放行。<br><img src="https://img-blog.csdnimg.cn/20200524134428924.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step2：从QPS为维度验证是否需要被限流，其实现关键点如下：</li>
<li>当前的qps，如果 ENTRY_NODE 为空则返回0，否则返回该统计节点的成功 qps，那 ENTRY_NODE 统计节点是“何许人也”，原来是 Sentinel 特定定义了一个资源，其名称为__total_inbound_traffic__，用来采集所有入口调用的信息，当资源进入类型为 ENTRY_TYPE_IN 时，会自动采集信息，其具体统计信息在 StatisticSlot 的 entry 方法中被调用，其截图如下：<br><img src="https://img-blog.csdnimg.cn/20200524134513299.png#pic_center" alt="在这里插入图片描述"></li>
<li>如果当前调用的 QPS 大于设定的QPS，即触发限流，那这个 qps 又是在什么时候被设置的呢？也是在加载系统限流规则时被设置，如果一个应用同一个限流点（LOAD、QPS)设置了多条规则，最小值生效。<br><img src="https://img-blog.csdnimg.cn/20200524134545735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step3：关于线程数、响应时间限流模式与QPS类似，就不再重复介绍。<br><img src="https://img-blog.csdnimg.cn/20200524134621142.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step4：如果当前系统的负载超过了设定的阔值的处理逻辑，这里就是自适应的核心所在，并不是超过负载就限流，而是需要根据当前系统的请求处理能力进行综合判断，具体逻辑在 checkBbr 方法中实现。关于如何获得系统负载与 checkBbr 方法稍后会详细介绍。<br><img src="https://img-blog.csdnimg.cn/20200524134709868.png#pic_center" alt="在这里插入图片描述"><br>Step5：如果当前CPU的负载超过了设置的阔值，触发限流，那在JAVA中是如何获取CPU的使用率的呢？稍后详细介绍。</li>
</ul>
<a id="more"></a>

<h4 id="2-2-根据系统负载自适应算法详解"><a href="#2-2-根据系统负载自适应算法详解" class="headerlink" title="2.2 根据系统负载自适应算法详解"></a>2.2 根据系统负载自适应算法详解</h4><p>正如上面的第4步骤，根据系统 Load 的会采用 TCP BBR 算法来评估是否限流，具体实现代码如下：<br>SystemRuleManager#checkSystem<br><img src="https://img-blog.csdnimg.cn/2020052413473576.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在 Sentinel 中估算系统的容量是以 1s 为度量长度，用该秒内通过的最大 qps 与 最小响应时间的乘积来表示，具体的计算细节：</p>
<ul>
<li>maxSuccessQps 的计算取当前采样窗口的最大值乘以1s内滑动窗口的个数，这里其实并不是十分准确。</li>
<li>minRt 最小响应时间取自当前采样窗口中的最小响应时间。<br>故得出了上述计算公式，除以1000是因为 minRt 的时间单位是毫秒，统一为秒。从这里可以看出根据系统负载做限流，最终的判断依据是线程数量。</li>
</ul>
<h4 id="2-3-JAVA如何获得操作系统负载情况"><a href="#2-3-JAVA如何获得操作系统负载情况" class="headerlink" title="2.3 JAVA如何获得操作系统负载情况"></a>2.3 JAVA如何获得操作系统负载情况</h4><p>在 Sentinel 中获取操作系统负载情况的类是：SystemStatusListener，每秒采集一次。<br>SystemStatusListener#run<br><img src="https://img-blog.csdnimg.cn/20200524134821496.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>原来可以通过JDK中的 com.sun.management.OperatingSystemMXBean 获取操作系统相关的信息。<br>温馨提示：上述只对 Linux/Unix 操作系统有效，对 windows 无效。</p>
<h2 id="3、实践思考"><a href="#3、实践思考" class="headerlink" title="3、实践思考"></a>3、实践思考</h2><p>经过上面的分析，Sentinel 中的系统自适应其实指的是按照应用所在机器的操作系统负载，再结合应用本身的请求处理能力进行的自适应，操作系统的负载情况可以通过 top 命令输出，其示例如下：<br><img src="https://img-blog.csdnimg.cn/20200524134839941.png#pic_center" alt="在这里插入图片描述"><br>尽管 Sentienl 的系统规则配置类型分为 LOAD、CPU、RT、线程数、入口QPS等维度进行限流，但自适应主要是针对 LOAD 这种情况的。<br>Sentinel 系统级别的限流规则并不是针对某一个资源，而是针对应用所有定义EntryType.IN的资源，在使用时尤其需要注意，特别是如果一个机器上部署了多个应用，可能会造成应用本身负载不高，但所在的机器由于其他应用程序导致资源负载偏高，从而触发限流。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>系统自适应</tag>
        <tag>SystemSlot</tag>
      </tags>
  </entry>
  <entry>
    <title>Sentinel 调用上下文环境实现原理</title>
    <url>/posts/e7bbdda0.html</url>
    <content><![CDATA[<div id="vip-container"><p>用源码与图解的方式详细探究 Sentinel 调用上下文环境是如何管理的。</p>
<p>本节将详细介绍 Sentienl 的上下文环境管理机制。</p>
<h2 id="1、Sentinel-Context-调用上下文环境管理"><a href="#1、Sentinel-Context-调用上下文环境管理" class="headerlink" title="1、Sentinel Context 调用上下文环境管理"></a>1、Sentinel Context 调用上下文环境管理</h2><p>我们从  sentinel-apache-dubbo-adapter 模块的 SentinelDubboProviderFilter 的实现中不难看出，在其入口处会首先调用 ContextUtil.enter(resourceName, application) 。那我们就从该方法开始来探究上下文环境管理机制。</p>
<p>说到 Sentinel 的调用上下文环境，那调用上下文环境中会保存哪些信息呢？我们先来看看 Context。</p>
<h4 id="1-1-Context-详解"><a href="#1-1-Context-详解" class="headerlink" title="1.1 Context 详解"></a>1.1 Context 详解</h4><p>Context 类图如下：<br><img src="https://img-blog.csdnimg.cn/2020011209183558.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li><p>Context<br>其核心属性与核心方法如下：</p>
<ul>
<li>String name<br>Sentinel 调用上下文环境的名称。</li>
<li>DefaultNode entranceNode<br>调用链的入口节点信息。</li>
<li>Entry curEntry<br>调用链中当前节点的信息。</li>
<li>boolean async<br>是否是异步调用上下文环境。</li>
<li>Entry<br>保存当前的调用信息，其主要核心属性：</li>
<li>private long createTime<br>资源调用的时间戳。</li>
<li>private Node curNode<br>该资源所对应的实时采集信息。</li>
<li>protected ResourceWrapper resourceWrapper<br>资源对象。</li>
</ul>
</li>
<li><p>CtEntry<br>同步调用调用信息封装对象。</p>
</li>
<li><p>AsyncEntry<br>异步调用调用信息的封装对象。</p>
</li>
</ul>
<p>对应的核心方法将在下文具体用到时再详细介绍。</p>
<h4 id="1-2-创建调用上下文环境"><a href="#1-2-创建调用上下文环境" class="headerlink" title="1.2 创建调用上下文环境"></a>1.2 创建调用上下文环境</h4><p>ContextUtil#enter</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Context <span class="title">enter</span><span class="params">(String name, String origin)</span> </span>&#123;  <span class="comment">// @1</span></span><br><span class="line">	<span class="keyword">if</span> (Constants.CONTEXT_DEFAULT_NAME.equals(name)) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ContextNameDefineException(</span><br><span class="line">                <span class="string">&quot;The &quot;</span> + Constants.CONTEXT_DEFAULT_NAME + <span class="string">&quot; can&#x27;t be permit to defined!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> trueEnter(name, origin);   <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先我们来看一下其参数：</p>
<ul>
<li>String name<br>上下文环境 Context 的名称。</li>
<li>String origin<br>该参数的含义在介绍集群限流时会详细介绍，从 dubbo 模块的适配来看，通常该值会传入当前应用的 application 名称。</li>
</ul>
<p>代码@2：通过调用内部的 trueEnter 方法。</p>
<p>在进入 trueEnter 方法之前，我们先来看一下 ContextUtil 中两个最核心的属性：<br><img src="https://img-blog.csdnimg.cn/20200112092204338.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>首先使用 ThreadLocal 对象来存储线程上下文环境对象 Context。Map&lt;String, DefaultNode&gt; contextNameNodeMap ，其键为 context 的名称，用来缓存其对应的 EntranceNode 。</p>
<p>ContextUtil#trueEnter</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">static</span> Context <span class="title">trueEnter</span><span class="params">(String name, String origin)</span> </span>&#123;</span><br><span class="line">    Context context = contextHolder.get();   <span class="comment">// @1 </span></span><br><span class="line">    <span class="keyword">if</span> (context == <span class="keyword">null</span>) &#123;</span><br><span class="line">	Map&lt;String, DefaultNode&gt; localCacheNameMap = contextNameNodeMap;</span><br><span class="line">        DefaultNode node = localCacheNameMap.get(name);   <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">if</span> (node == <span class="keyword">null</span>) &#123;</span><br><span class="line">		<span class="keyword">if</span> (localCacheNameMap.size() &gt; Constants.MAX_CONTEXT_NAME_SIZE) &#123;   <span class="comment">// @3</span></span><br><span class="line">                 	setNullContext();</span><br><span class="line">               	 	<span class="keyword">return</span> NULL_CONTEXT;</span><br><span class="line">           	 &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                	<span class="keyword">try</span> &#123;</span><br><span class="line">                    		LOCK.lock();</span><br><span class="line">                    		node = contextNameNodeMap.get(name);   <span class="comment">// @4</span></span><br><span class="line">                    		<span class="keyword">if</span> (node == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        		<span class="keyword">if</span> (contextNameNodeMap.size() &gt; Constants.MAX_CONTEXT_NAME_SIZE) &#123;  </span><br><span class="line">                            			setNullContext();</span><br><span class="line">                            			<span class="keyword">return</span> NULL_CONTEXT;</span><br><span class="line">                        		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                           			 node = <span class="keyword">new</span> EntranceNode(<span class="keyword">new</span> StringResourceWrapper(name, EntryType.IN), <span class="keyword">null</span>);  <span class="comment">// @5</span></span><br><span class="line">                            			<span class="comment">// Add entrance node.</span></span><br><span class="line">                            			Constant.ROOT.addChild(node);                                                                                     <span class="comment">// @6</span></span><br><span class="line">						Map&lt;String, DefaultNode&gt; newMap = <span class="keyword">new</span> HashMap&lt;&gt;(contextNameNodeMap.size() + <span class="number">1</span>);</span><br><span class="line">                            			newMap.putAll(contextNameNodeMap);</span><br><span class="line">                            			newMap.put(name, node);</span><br><span class="line">                            			contextNameNodeMap = newMap;</span><br><span class="line">                        		&#125;</span><br><span class="line">                    		&#125;</span><br><span class="line">                	&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    		LOCK.unlock();</span><br><span class="line">               		&#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        context = <span class="keyword">new</span> Context(node, name);    <span class="comment">// @7</span></span><br><span class="line">        context.setOrigin(origin);</span><br><span class="line">        contextHolder.set(context);    <span class="comment">// @8</span></span><br><span class="line">   &#125;</span><br><span class="line">  <span class="keyword">return</span> context;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：从 threadLocal 中获取 Context 对象，线程首次获取时为空。</p>
<p>代码@2：根据 context 的名称尝试从缓存中去找对应的 Node，通常是 EntranceNode。即用来表示入口的节点Node 为 EntranceNode。</p>
<p>代码@3：如果 localCacheNameMap 已缓存的对象容量默认超过2000，则不纳入 Sentinel 限流，熔断等机制中来，即一个应用，默认不能定义 2000个 资源统计入口，以 一个 Dubbo 服务为例，一个 Dubbo 服务应用，如果超过2000个服务，则超过的部分不会应用 Sentinel 限流与熔断机制。</p>
<p>代码@4：锁应用的经典场景，dubbo check。</p>
<p>代码@5：为该 context name 创建一个对应的 EntranceNode。</p>
<p>代码@6：将创建的 EntranceNode 加入到根节点的子节点中，稍后重点讨论一下。</p>
<p>代码@7：创建 Context 对象，将 Context 对象中的入口节点设置为 新创建的 EntranceNode。</p>
<p>代码@8：将新创建的 Context 对象存入当前线程本地环境变量中(ThreadLocal)。</p>
<p>接下来先来探讨代码@6 Constants.ROOT.addChild(node)。</p>
<p>在 Sentinel 中，会定义一个固定根节点，其定义如下：<br><img src="https://img-blog.csdnimg.cn/20200112092324439.png" alt="在这里插入图片描述"><br>其资源名称为：machine-root。addChild 方法就是将节点添加到如下数据结构中：<br><img src="https://img-blog.csdnimg.cn/20200112092345428.png" alt="在这里插入图片描述"></p>
<h4 id="1-3-移除调用上下文环境"><a href="#1-3-移除调用上下文环境" class="headerlink" title="1.3 移除调用上下文环境"></a>1.3 移除调用上下文环境</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">exit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Context context = contextHolder.get();</span><br><span class="line">    <span class="keyword">if</span> (context != <span class="keyword">null</span> &amp;&amp; context.getCurEntry() == <span class="keyword">null</span>) &#123;</span><br><span class="line">        contextHolder.set(<span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>退出当前上下文环境，这里有一个条件就是当前的上下文环境的当前调用节点已经退出，否则无法移除，故使用建议：ContextUtil . exit 一定要在持有的 Entry 退出之后再调用。</p>
<a id="more"></a>

<h4 id="1-4-异步上下文环境切换"><a href="#1-4-异步上下文环境切换" class="headerlink" title="1.4 异步上下文环境切换"></a>1.4 异步上下文环境切换</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">runOnContext</span><span class="params">(Context context, Runnable f)</span> </span>&#123;</span><br><span class="line">	Context curContext = replaceContext(context);  <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">		f.run();  <span class="comment">// @2</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        replaceContext(curContext);  <span class="comment">// @3</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里是异步调用上下文环境切换的实现原理，我们知道存在 ThreadLocal 中的数据是无法跨线程访问的，故一个线程中启动另外一个线程，上下文环境是无法直接被传递的，Sentinel 的思想是为先创建的线程再创建一个 Context，在运行子线程时，调用 runOnContext 来切换上下文环境。</p>
<p>Context 就介绍到这里了，我们接下来再来看一个与上下文环境管理密切相关的 Sentinel Slot 处理器：NodeSelectorSlot，通常也是 Sentinel Slot 处理链的第一个节点。</p>
<h2 id="2、NodeSelectorSlot"><a href="#2、NodeSelectorSlot" class="headerlink" title="2、NodeSelectorSlot"></a>2、NodeSelectorSlot</h2><h4 id="2-1-NodeSelectorSlot-调用链概述"><a href="#2-1-NodeSelectorSlot-调用链概述" class="headerlink" title="2.1 NodeSelectorSlot 调用链概述"></a>2.1 NodeSelectorSlot 调用链概述</h4><p>从该类的注释可以得出如下的结论：该类的作用是构建一颗虚拟调用树，我们接下来以一个Dubbo调用示例来说明。<br><img src="https://img-blog.csdnimg.cn/20200112092639143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>正如上图所示：应用 A 向应用 order-servie 服务发起一个 RPC 服务，下订单，order-service 应用引入了 sentinel-apache-dubbo-adapter 相关依懒，会执行 SentinelDubboProviderFilter 过滤器，调用 Sentinel 相关的方法，对资源进行保护，然后下单服务中，首先会操作数据库，将本次数据库操作定义为资源：insertOrderSQL，然后再操作 redis，redis 的操作命名为资源 setRedisOp。其对应在内存中会生成如下调用链的结构图。<br><img src="https://img-blog.csdnimg.cn/20200112092720275.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>那上面这个调用链保存在线程上下文环境中，即 ThreadLocal 中。在 Sentinel 中使用 Node 来表示一个一个调用节点，其中 EntranceNode  表示调用链的入口，DefaultNode 表示普通节点，ClusterNode 表示集群节点，即同一个资源会统计整个集群中的信息。</p>
<p>从该类的注释我们可以得出上述的结论，接下来我们从源码的角度对其进行分析与理解。</p>
<h4 id="2-2-源码分析-NodeSelectorSlot"><a href="#2-2-源码分析-NodeSelectorSlot" class="headerlink" title="2.2 源码分析 NodeSelectorSlot"></a>2.2 源码分析 NodeSelectorSlot</h4><p>NodeSelectorSlot 中只声明了一个唯一的成员变量，其声明如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> Map&lt;String, DefaultNode&gt; map = <span class="keyword">new</span> HashMap&lt;String, DefaultNode&gt;(<span class="number">10</span>);</span><br></pre></td></tr></table></figure>
<p>定义一个 Map，其键为上下文环境 Context 的名称，通常是进入节点的名称，例如上面提到的 EntranceNode（ dubbo:provider:com.a.b.OrderService:saveOrder(java.lang.String)）。</p>
<blockquote>
<p>注意：一个 NodeSelectorSlot 对象会被多个线程使用，其共享的维度为资源，即多个线程进入同一个资源保护的代码时，执行的是同一个 NodeSelectorSlot 对象。详细实现请参考上文中 CtSph # lookProcessChain 部分详解。</p>
</blockquote>
<p>接下来重点看一下 NodeSelectorSlot 的核心方法 entry。</p>
<p>NodeSelectorSlot#entry</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">entry</span><span class="params">(Context context, ResourceWrapper resourceWrapper, Object obj, <span class="keyword">int</span> count, <span class="keyword">boolean</span> prioritized, Object... args)</span> <span class="comment">// @1</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">    DefaultNode node = map.get(context.getName());   <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">if</span> (node == <span class="keyword">null</span>) &#123;                                                       <span class="comment">// @3</span></span><br><span class="line">	    <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;                                          <span class="comment">// @4</span></span><br><span class="line">	        node = map.get(context.getName());</span><br><span class="line">                <span class="keyword">if</span> (node == <span class="keyword">null</span>) &#123;</span><br><span class="line">			node = <span class="keyword">new</span> DefaultNode(resourceWrapper, <span class="keyword">null</span>);    <span class="comment">// @5</span></span><br><span class="line">              	        HashMap&lt;String, DefaultNode&gt; cacheMap = <span class="keyword">new</span> HashMap&lt;String, DefaultNode&gt;(map.size());</span><br><span class="line">                	cacheMap.putAll(map);</span><br><span class="line">                	cacheMap.put(context.getName(), node);</span><br><span class="line">                	map = cacheMap;</span><br><span class="line">               	 	<span class="comment">// Build invocation tree</span></span><br><span class="line">                	((DefaultNode) context.getLastNode()).addChild(node);   <span class="comment">// @6</span></span><br><span class="line">          	&#125;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    context.setCurNode(node);                                                                  <span class="comment">// @7</span></span><br><span class="line">    fireEntry(context, resourceWrapper, node, count, prioritized, args);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：我们先来看看其参数：</p>
<ul>
<li>Context context<br>调用上下文环境，该对象存储在 ThreadLocal，其名称在调用链的入口处设置。</li>
<li>ResourceWrapper resourceWrapper<br>资源的包装类，注意留意其 equals 与 hashCode 方法，判断两个对象是否相等的依据是资源名<br>称是否相同。</li>
<li>Object obj<br>参数。</li>
<li>int count<br>本次需要消耗的令牌数量。</li>
<li>boolean prioritized<br>请求是否按优先级排列。</li>
<li>Object… args<br>额外参数。</li>
</ul>
<p>代码@2：如果缓存中存在对应该上下文环境的节点，则直接使用，并将其节点设置当前调用上下文的当前节点中(Context)。</p>
<p>代码@3：如果节点为空，则进入到节点创建流程，此过程需要加锁，见代码@4。</p>
<p>代码@5：创建一个新的 DefaultNode 。</p>
<p>代码@6：构建调用链，由于 NodeSelectorSlot 是第一个进入的处理器，故此时 Context 的 curEntry 为 null ，故这里就是创建与的上下文环境名称对应的节点会被添加到 ContextUtil 的 entry 创建的调用链入口节点(EntranceNode)，然后顺便更新 Context 中的 Entry curEntry 属性，即再次验证了上面的图。</p>
<p>我们来总结一下 NodeSelectorSlot 作用：从官方的注释来看：构建一条调用链，更直接一点就是设置 Context 的 curEntry 属性。</p>
<p>关于 Sentinel 调用上下文环境实现原理就介绍到这里了。</p>
<p>思考题：首先在这里先“剧透”一下，Node 在 Sentinel 中的作用是持有资源的实时统计信息，将在下一篇文章介绍 StatisticSlot 时详细介绍。 NodeSelectorSlot 中的  Map&lt;String, DefaultNode&gt; 中的键为什么是 Context 的 名称呢？这样设计的目的是什么，能有什么好处？针对该问题将在笔者维护的知识星球中与各位星友展开讨论，欢迎您的加入。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>调用上下文</tag>
        <tag>NodeSelectorSlot</tag>
      </tags>
  </entry>
  <entry>
    <title>java Reference 引用学习总结</title>
    <url>/posts/3c69fbc4.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、Java引用的类型"><a href="#1、Java引用的类型" class="headerlink" title="1、Java引用的类型"></a>1、Java引用的类型</h2><p>强引用、软引用(java.lang.ref.SoftReference)、弱引用(java.lang.ref.WeakReference)、虚引用(　java.lang.ref.PhantomReference　)。</p>
<p>java默认的引用类型为强引用，比如 Object a = new Object();其中 a 为强引用，new Object()为一个具体的对象。</p>
<p>至于软应用，弱引用，虚引用，就是 JAVA 虚拟机管理对象的范畴了，可以这样理解，SoftReference、WeakReference、PlantomReference 只是一种标记，JAVA 虚拟机在垃圾回收时，对上述不同的标记【引用的对象】采取不同的措施。采取措施如下：</p>
<ul>
<li><p>软引用(SoftReference)：当内存足够时，该引用【引用的对象】不会被回收，那什么是内存足够呢？进行年轻代的垃圾回收不会触发SoftReference所指向对象的回收,如果触发Full GC，那SoftReference所指向的对象将被回收。</p>
</li>
<li><p>弱引用(WeakReference) :当进行年轻代垃圾回收时，该引用指向的对象，就会被回收。</p>
</li>
<li><p>虚引用(PhantomeReference) 该引用指向的对象，无法对垃圾收集器收集对象时产生任何影响，唯一有用的是，如果被垃圾收集器收集的对象，被PhantomeReference标记，垃圾收集器会通过注册在PhantomeReference上的队列来通知应用程序，该引用指向的对象，已经被垃圾收集器回收。</p>
</li>
</ul>
<p>从上文的描述，也清楚的知道，上述应用是直接JVM打交道，更直接的说是与垃圾回收器直接的交互。</p>
<a id="more"></a>

<h2 id="2、java-lang-ref-Reference-详解"><a href="#2、java-lang-ref-Reference-详解" class="headerlink" title="2、java.lang.ref.Reference 详解"></a>2、java.lang.ref.Reference 详解</h2><h4 id="2-1-关键数据结构"><a href="#2-1-关键数据结构" class="headerlink" title="2.1 关键数据结构"></a>2.1 关键数据结构</h4><ul>
<li><p>private T referent;     /* Treated specially by GC */</p>
</li>
<li><p>private ReferenceQueue&lt;? super T&gt; queue;</p>
</li>
<li><p>private Reference next;<br>非常关键：Reference 本身可以当场一个 Reference 链表使用，在 ReferenceHandler 线程中从 pending 队列中，取出一个Reference, 如果该 Reference 相关的 queue 不为null,则执行入队操作，r.queue.enqueue(r); 参数为当前的引用，在入队列操作时，只要第一次进入队列，该引用的queue会被设置为 ReferenceQueue.ENQUEUE,也就算是再次调用进入队列操作，此时也无法再次与构造方法中传入的队 列绑定  在一起了。</p>
</li>
<li><p>private static Reference pending = null<br>关键中的关键；此队列维护着需要进入通知队列的引用，由 JVM 虚拟机垃圾回收器在检测到被引用指向的对象可达性发生改变后，如果该对象的引用（Referecnce）注册了引用队列 (ReferenceQueue),则 JVM 虚拟机垃圾收集器会将该引用加入到 pending 队列，注意这个 pending 队列是一个静态类变量。</p>
<p>为了便于理解上述的观点，先展示一下引用如何使用。</p>
<p>SoftReference sf = new SoftReference( new Object() );</p>
<p>其中sf 为引用，new Object为 sf指向的对象，其实也就是建立了 sf 到 new Object 对象的引用（关联），然后垃圾回收器发现 new Object 的可达性发生变化（其实就是变为不可达后），此时JVM虚拟机会根据引用对象 sf 的 queue 是否为空，如果为空，则直接将引用的状态变为 InActivie(非激活，离真正回收不远了)</p>
</li>
<li><p>ReferenceQueue queue = new ReferenceQueue();<br>  如果 SoftReference sf2 = new SoftRerence( new Object(),  queue );如果垃圾回收器检测到 new Object 的可达性发生变化后，会将该引用添加到 pending 引用链上，然后有专门的线程 ReferenceHandle 线程来将引用加入到引用链中（入队），也就是应用程序可以从 queue 中获取到所以垃圾回收器回收的对象的应用，也就是 queue是 垃圾回收器通知应用程序 被引用指向的对象已经被垃圾回收的消息。</p>
</li>
</ul>
<p>####　2.2 Reference 的状态</p>
<ul>
<li><p>Active<br>激活状态（可达），一般新建的引用就是该状态，该状态的属性特点  next = null; queue = ReferenceQueue.Null(默认值) 或者  构造方法指定的 queue  Reference( T referent, ReferenceQueue queue)。</p>
<p>当垃圾回收器检测到可达性发生变化（变为不可达时），如果 queue == ReferenceQueue.Null 的话，状态直接变为 InActive, 如果 queue 不为空，则加入到 Reference 的静态变量 pending 的队列中，并将状态设置为 Pending。</p>
</li>
<li><p>Pending</p>
<p>会有一个专门的线程 ReferenceHandler 来处理pengding链表中的引用[pending链表，应该是后进先出的特点]，将该引用入队（如果有注册队列，也可以看出是垃圾回收器以此来通知应用程序做些事情【请参考 WeakHashMap 的实现】）。在r.queue.enque(r) 方法中，有个关键点，保证一个引用，只能入队一次，入队后，该引用就与原来的引用队列失去关联；为了清晰展示次过程，将该代码附加上（来源于 java.lang.ref.Reference）。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boolean enqueue(Reference&lt;? extends T&gt; r) &#123; &#x2F;* Called only by Reference class *&#x2F;</span><br><span class="line">        synchronized (r) &#123;</span><br><span class="line">            if (r.queue &#x3D;&#x3D; ENQUEUED) return false; &#x2F;&#x2F;关注这里</span><br><span class="line">            synchronized (lock) &#123;</span><br><span class="line">                r.queue &#x3D; ENQUEUED;                &#x2F;&#x2F; 关注这里</span><br><span class="line">                r.next &#x3D; (head &#x3D;&#x3D; null) ? r : head;</span><br><span class="line">                head &#x3D; r;</span><br><span class="line">                queueLength++;</span><br><span class="line">                if (r instanceof FinalReference) &#123;</span><br><span class="line">                    sun.misc.VM.addFinalRefCount(1);</span><br><span class="line">                &#125;</span><br><span class="line">                lock.notifyAll();</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动"></p>
</li>
<li><p>Enqueue<br>进入队列中的Reference 中的 next 为队列中一个引用，或等于this(表示当前引用为最后一个), queue = ReferenceQueue.ENQUEUE。</p>
</li>
<li><p>InActive</p>
<p>queue = ReferenceQueue.NULL; next = this</p>
</li>
</ul>
<p>JAVA 四种引用的理解就到这了，其实 JAVA 中还有一种引用，java.lang.ref.FinalReference 应用，不过修饰符是 default, 包访问权限，主要用于 finalizer方法的执行，请关注下一篇博文。</p>
<p>再统一聊聊 java 引用中涉及到的引用的几个队列。</p>
<p>Reference中涉及到的队列(链表)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Reference next;</span><br><span class="line"></span><br><span class="line">private static Reference pending &#x3D; null;</span><br><span class="line"></span><br><span class="line">private ReferenceQueue queue;</span><br></pre></td></tr></table></figure>

<p>每个引用可以关联一个引用队列，该引用队列由应用程序创建的，，然后垃圾回收器在检测到引用不可达时，将该引用加入到该队列，应用程序可以根据该引用队列来做些处理。（也就是该引用队列 成为 垃圾回收器与应用程序的通信机制）。</p>
<p>ReferenceQueue 自身的结构</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private volatile Reference&lt;? extends T&gt; head &#x3D; null;</span><br></pre></td></tr></table></figure>

<p>首先，应用程序如下使用引用：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class TestReference &#123;</span><br><span class="line"></span><br><span class="line">           private static ReferenceQueue aQueue &#x3D; new ReferenceQueue();</span><br><span class="line"></span><br><span class="line">           public static void main(String args) &#123;</span><br><span class="line"></span><br><span class="line">                  Object a &#x3D; new Object();   &#x2F;&#x2F; 代码1</span><br><span class="line"></span><br><span class="line">                  WeakReference ref &#x3D; new WeakReference( a, aQueue );  </span><br><span class="line"></span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>然后在程序运行过程，内存不断消耗，直至触发垃圾回收操作。此时，垃圾收集器发现 代码1处的 a 所指向的对象，只有 ref引用它，从根路径不可达，故垃圾回收器，会将 ref 引用加入到  static Reference pending 链表中。</p>
<blockquote>
<p>注意，此代码是写在JVM实现中的】</p>
</blockquote>
<p>所处理的操作无非就是</p>
<p>1、如果pending 为空，则将当前引用(ref) 设置为pengding,,并且将 ref对象的next指针指向自己； 如果pending不为空，则将当前的引用(ref)的next指向pengding,然后pengding = 当前的引用ref,所以 pengding 其实就是 一个后进新出的链表单向链表结构。</p>
<p>2、由此总结出  ref 与 pengding链表关联的第一步  由JVM垃圾回收器完成。<br>从pengding 链表中取出引用，进行入队操作。该操作由专门的线程(ReferenceHandle 线程处理)，我重点将 ReferenceHandle线程的源代码贴出已供分析。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private static class ReferenceHandler extends Thread &#123;</span><br><span class="line">        ReferenceHandler(ThreadGroup g, String name) &#123;</span><br><span class="line">            super(g, name);</span><br><span class="line">        &#125;</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            for (;;) &#123;</span><br><span class="line">                Reference r;</span><br><span class="line">                synchronized (lock) &#123;</span><br><span class="line">                    if (pending !&#x3D; null) &#123;        </span><br><span class="line">                        &#x2F;&#x2F; 如果pengding不为空，则取出pengding 的第一个引用，</span><br><span class="line">                        &#x2F;&#x2F; 然后重新设置pengding 的值（为原来的pending.next,见如下代码   a,b,c）</span><br><span class="line">                        r &#x3D; pending;                &#x2F;&#x2F; a 将pending取出，准备入队操作</span><br><span class="line">                        Reference rn &#x3D; r.next;  &#x2F;&#x2F; b 先获取原先pending 的 next</span><br><span class="line">                        pending &#x3D; (rn &#x3D;&#x3D; r) ? null : rn;  </span><br><span class="line">                        &#x2F;&#x2F; c  如果pending的next等于本身，则设在pending为空，否则为链表的下一个。</span><br><span class="line">                        &#x2F;&#x2F; 从这里更加看出 pending 是后进先出队列。</span><br><span class="line">                        r.next &#x3D; r;</span><br><span class="line">                    &#125; else &#123; </span><br><span class="line">                        &#x2F;&#x2F; 如果 pending 为空，则线程阻塞，等待垃圾回收器添加新的引用到 pending链表中</span><br><span class="line">                        try &#123;</span><br><span class="line">                            lock.wait();</span><br><span class="line">                        &#125; catch (InterruptedException x) &#123; &#125;</span><br><span class="line">                        continue;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                &#x2F;&#x2F; Fast path for cleaners</span><br><span class="line">                if (r instanceof Cleaner) &#123;</span><br><span class="line">                    ((Cleaner)r).clean();</span><br><span class="line">                    continue;</span><br><span class="line">                &#125;</span><br><span class="line">                ReferenceQueue q &#x3D; r.queue;</span><br><span class="line">                if (q !&#x3D; ReferenceQueue.NULL) q.enqueue(r);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>reference</tag>
      </tags>
  </entry>
  <entry>
    <title>Sentinel 集群限流设计原理</title>
    <url>/posts/a815ae71.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、集群限流使用场景"><a href="#1、集群限流使用场景" class="headerlink" title="1、集群限流使用场景"></a>1、集群限流使用场景</h2><p>首先一个服务有三个服务提供者，但这三台集群的硬件配置不一样，如图所示：<br><img src="https://img-blog.csdnimg.cn/20200503232733111.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>为了充分利用硬件的资源，诸如 Dubbo 都提供了基于权重的负载均衡机制，例如可以将8C16G的机器设置的权重是4C8G的两倍，这样充分利用硬件资源，假如现在需要引入 Sentinel 的限流机制，例如为一个 Dubbo 服务设置限流规则，这样由于三台集群分担的流量不均匀，会导致无法重复利用高配机器的资源。</p>
<p>假设经过压测，机器配置为C48G最高能承受的TPS为 1500，而机器配置为8C16G能承受的TPS为2800，那如果采取单机限流，其阔值只能设置为1500，因为如果超过1500，会将4C8G的机器压垮。</p>
<p>解决这种办法的方式就是针对整个集群进行限流，即为整个集群设置一个阔值，例如设置限流TPS为6000。</p>
<h2 id="2、集群限流与单机限流的异同思考"><a href="#2、集群限流与单机限流的异同思考" class="headerlink" title="2、集群限流与单机限流的异同思考"></a>2、集群限流与单机限流的异同思考</h2><p>限流的一个基本作用就是按照限流规则生成访问许可(Token)，然后根据当前实时的调用信息进行判断是否可以获得许可而决定是否放行。</p>
<p>集群与单机限流在实时调用信息收集方面应该差别不大，都可以基于滑动窗口进行统计信息的收集。</p>
<p>集群与单机限流的最主要区别在与许可的生成，单机模式的许可直接在本地生成，但集群限流必须有一个统一的 Token 发放机制，以此来协调当前集群内多机调用，从而基于当前“调用总数”进行限流。</p>
<h2 id="3、探究集群限流实现原理"><a href="#3、探究集群限流实现原理" class="headerlink" title="3、探究集群限流实现原理"></a>3、探究集群限流实现原理</h2><p>在探究集群限流实现原理之前先来回顾一下单机限流的执行流程图。<br><img src="https://img-blog.csdnimg.cn/20200503232832535.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>结合流程我们可以看出集群限流的几个关键点 ClusterBuilderSlot、FlowSlot。</p>
<h4 id="3-1-ClusterBuilderSlot-详解"><a href="#3-1-ClusterBuilderSlot-详解" class="headerlink" title="3.1 ClusterBuilderSlot 详解"></a>3.1 ClusterBuilderSlot 详解</h4><p>在对一个资源进行流控规则判断时，首先将进入到 NodeSelectorSlot，然后就会进入到 ClusterBuilderSlot，为了与单机限流模式，介绍 ClusterBuilderSlot 时与 NodeSelectorSlot 进行一个对比。</p>
<p>NodeSelectorSlot 的核心实现截图如下所示：<br><img src="https://img-blog.csdnimg.cn/20200503232919521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>温馨提示：从该系列之前的文章也能得知，一个 资源对应的一个 NodeSelectorSlot  实例，即多线程访问一个资源时，都会调用同一个 NodeSelectorSlot 实例。</p>
</blockquote>
<p>NodeSelectorSlot 的关键点如下：</p>
<ul>
<li>Map&lt;String, DefaultNode&gt; map<br>在 NodeSelectorSlot 中是以 context Id 为维度进行缓存的，例如官方给出的 Dubbo 适配方法，contexId 为 dubbo 服务的全路径名。即 Dubbo的入口节点对应的缓存 Key 为 context<br>id。</li>
<li>fireEntry 的 node 参数<br>由于 NodeSelectorSlot 是第一个过滤器，故第一次调用 fireEntry 方法时的 node 参数就是上面创建的 Node，即与 context 相关链的 Node，即所谓的入口节点即 Entrance Node。</li>
</ul>
<p>接下来重点关注一下 ClusterBuilderSlot 的关键点：<br><img src="https://img-blog.csdnimg.cn/20200503233012141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>ClusterBuilderSlot 的关键点如下：</p>
<ul>
<li>Map&lt;ResourceWrapper, ClusterNode&gt; clusterNodeMap<br>持有的集群节点缓存表，其键为 Entrance Node 所对应的资源ID，即 Context 中关联的节点信息。</li>
<li>Node originNode<br>所谓的 orginNode，即在调用 ContextUtil 中 enter(String name, String origin) 方法中的第二个参数，表示这条调用链的源头，在 Dubbo 中默认为 应用的 application。</li>
</ul>
<p>经过上面两个Slot，整个调用链就基本创建好了，接下来我们来看一下 FlowSlot 关于集群限流的相关处理逻辑。</p>
<h4 id="3-2-集群限流模式实现原理"><a href="#3-2-集群限流模式实现原理" class="headerlink" title="3.2 集群限流模式实现原理"></a>3.2 集群限流模式实现原理</h4><p><img src="https://img-blog.csdnimg.cn/20200503233045696.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>FlowSlow FlowSlot 的核心处理逻辑主要是调用 FlowRuleChecker 的 canPassCheck 方法，正如上面看到的一样，根据配置规则，如果是集群模式，则调用的是其 passClusterCheck 方法，接下来我们将重点探讨该方法。<br><img src="https://img-blog.csdnimg.cn/20200503233111258.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="FlowRuleChecker#passClusterCheck"><br>代码@1：获取一个 TokenService 服务类。这里实现关键点：</p>
<ul>
<li>如果当前节点的角色为 CLIENT，返回的 TokenService 为 DefaultClusterTokenClient。</li>
<li>如果当前节点的角色为 SERVER，返回的 TokenService 为 ClusterTokenServer，这里使用了SPI极致，可以通过查看 META-INF/services 目录下的 com.alibaba.csp.sentinel.cluster.TokenService 文件，默认服务端返回 DefaultTokenService。</li>
</ul>
<p>代码@2：如果无法获取到集群限流Token服务，如果该限流规则配置了可以退化为单机限流模式，则退化为单机限流。</p>
<p>代码@3：获取集群限流的流程ID，该 flowId 全局唯一。</p>
<p>代码@4：通过 TokenService 去申请 token，这里是与单机限流模式最大的差别。</p>
<p>接下来将分别从 DefaultClusterTokenClient、DefaultTokenService 分别探究集群限流相关的实现原理与细节，更好的指导我们如何使用集群限流功能。</p>
<h5 id="3-2-1-DefaultClusterTokenClient-详解"><a href="#3-2-1-DefaultClusterTokenClient-详解" class="headerlink" title="3.2.1 DefaultClusterTokenClient 详解"></a>3.2.1 DefaultClusterTokenClient 详解</h5><p>从我们的经验也得知，TokenClient 的主要职责就是发送请求到 TokenService 端，主要是网络相关的细节将不在此篇文章中给出，如果有兴趣，大家可以关注我的 Netty 专栏。</p>
<p>首先 Sentinel 提供了 SPI 机制，故允许用户自定义 TokenClient 的实现类，官方与 SPI 默认配置的文件如下：<br><img src="https://img-blog.csdnimg.cn/2020050323322512.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>关于 TokenClient 主要关注其初始化代码，因为我们需要关注一个非常重要的点：<br>DefaultClusterTokenClient#initNewConnection<br><img src="https://img-blog.csdnimg.cn/20200503233259244.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在客户端启动的时候会创建与 TokenServer 之间的链接，即这边需要配置服务端的 IP 与端口号，那如何配置呢？其实配置方式完全由自己去实现对应的解析器，下面根据官方的 Demo 示例如下：<br><img src="https://img-blog.csdnimg.cn/20200503233319545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这里需要说明的其配置项由 ClusterGroupEntity 来定义，其字段的定义如下：</p>
<ul>
<li>clientSet<br>客户端 Set 集合。</li>
<li>ip<br>Token 服务端的 IP。</li>
<li>machinedId<br>Token 服务端的机器ID。</li>
<li>port<br>Token 服务端的机器端口。</li>
</ul>
<p>其配置示例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[&#123;&quot;clientSet&quot;:[&quot;112.12.88.66@8729&quot;,&quot;112.12.88.67@8727&quot;],&quot;ip&quot;:&quot;112.12.88.68&quot;,&quot;machineId&quot;:&quot;112.12.88.68@8728&quot;,&quot;port&quot;:11111&#125;]</span><br></pre></td></tr></table></figure>

<p>Client 端接下来就是向服务端发送请求，与网络相关的不在本文的讨论范围内，接下来将重点探讨服务端是如何发放许可的。</p>
<h5 id="3-2-2-DefaultTokenService-详解"><a href="#3-2-2-DefaultTokenService-详解" class="headerlink" title="3.2.2 DefaultTokenService 详解"></a>3.2.2 DefaultTokenService 详解</h5><p>Token Server 端收到客户的请求，其处理入口为 FlowRequestProcessor，其处理方法为：processRequest，最终会调用 DefaultTokenService 的 requestToken 方法。<br>DefaultTokenService#requestToken<br><img src="https://img-blog.csdnimg.cn/20200503233418165.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>代码@1：根据 ruleId 获取指定的限流规则。</p>
<p>代码@2：然后调用 ClusterFlowChecker 的 acquierClusterToken 方法，申请许可。</p>
<p>许可的发放流程主要由 ClusterFlowChecker 的 acquierClusterToken 方法实现。<br><img src="https://img-blog.csdnimg.cn/20200503233520315.png#pic_center" alt="在这里插入图片描述"><br>Step1：首先判断是否允许本次许可申请，这是因为 TokenServe 支持嵌入式，即支持在应用节点中嵌入一个 TokenServer，为了保证许可申请的请求不对正常业务造成比较大的影响，故对申请许可这个动作进行了限流。</p>
<p>一旦触发了限流，将向客户端返回 TOO_MANY_REQUEST 状态码，Sentinel 支持按 namespace 进行限流，具体由 GlobalRequestLimiter 实现，该类的内部同样基于滑动窗口进行收集，原理与 FlowSlot 相似，故这里不加以展开，默认的限流TPS为3W，有关于 Sentinel 相关的配置，将在后续文章专门梳理。<br><img src="https://img-blog.csdnimg.cn/20200503233607726.png#pic_center" alt="在这里插入图片描述"><br>Step2：根据流程ID获取指标采集器。<br><img src="https://img-blog.csdnimg.cn/20200503233630847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step3：计算 latestQps、globalThreashold、 nextRemaining 三个阔值，三个的含义分别如下：</p>
<ul>
<li>latestQps<br>获取当前正常访问的QPS。</li>
<li>globalThreashold<br>根据限流配置规则得出其总许可数量，其主要根据阔值的方式其有所不同，其配置阔值有两种方式：<br>1）FLOW_THRESHOLD_GLOBAL<br>总数，即集群中的许可等于限流规则中配置的 count 值。<br>2）FLOW_THRESHOLD_AVG_LOCAL<br>单机分摊模式，此时限流规则中配置的值只是单机的 count 值，集群中的许可数等于 count * 集群中客户端的个数。<br>注意：这里还可以通过 exceedCount 设置来运行超过其最大阔值，默认为1表示不允许超过。</li>
<li>nextRemainging<br>表示处理完本次请求后剩余的许可数量。<br><img src="https://img-blog.csdnimg.cn/20200503233707407.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">Step4：如果剩余的许可数大于0，则本次申请成功，将当前的调用计入指标采集器中，然后返回给客户即可。</li>
</ul>
<p>接下来所有流程步骤都是基于没有剩余许可数的处理逻辑。<br><img src="https://img-blog.csdnimg.cn/20200503233730680.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step5：当前许可数不足的情况，并且该请求为高优先级的处理逻辑：</p>
<ul>
<li>获取当前等待的TPS（即1s为维度，当前等待的请求数量）</li>
<li>如果当前等待的TPS低于可借用未来窗口的许可阔值时，可通过，但设置其等待时间，可以通过 maxOccupyRatio 来设置借用的最大比值。<br><img src="https://img-blog.csdnimg.cn/20200503233758997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">Step6：如果当前许可不足，并且该请求为普通优先级的处理逻辑，增加阻塞相关指标的统计数，并返回 BLOCKED。</li>
</ul>
<p>TokenServer 返回申请许可之后，那 Token Client 如何处理呢？其处理代码在 FlowRuleChecker#applyTokenResult<br><img src="https://img-blog.csdnimg.cn/20200503233827875.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>我们可以发现，如果服务端返回OK，则顺利通过，返回BLOCKED，则直接返回 false，会抛出 FlowException，如果是 token 限流，如果规则运行退化为单机限流模式，则进行单机限流。</p>
<p>集群限流的基本实现原理就介绍到这里了。</p>
<h2 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h2><p>集群限流的基本原理接介绍到这里了，与单机限流模式最大的区别就是集群限流模式的需要引入 TokenService，提供许可的发放服务，该服务可以嵌入应用节点，也可以独立于应用之外。这边借用官方文档上的两张图来简单介绍一下嵌入模式与独立模式的架构：<br><img src="https://img-blog.csdnimg.cn/20200503233858200.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200503233858165.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>集群模式使用注意，如果使用的是集群模式限流，则如下两个配置则失效：<br><img src="https://img-blog.csdnimg.cn/20200503233920874.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>最后抛出一个思考题：集群模式应该算是高大上，但我们项目中真的需要吗？集群限流模式有哪些缺点、哪些优点，欢迎大家留言探讨。</strong></p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>源码</tag>
        <tag>集群限流</tag>
      </tags>
  </entry>
  <entry>
    <title>一次 RocketMQ 进程自动退出排查经验分享（实战篇）</title>
    <url>/posts/fc4470e5.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、背景"><a href="#1、背景" class="headerlink" title="1、背景"></a>1、背景</h2><p>公司一个 RocketMQ 集群由4主4从组成，突然其中3台服务器“竟然”在同一时间下线，其监控显示如下：<br><img src="https://img-blog.csdnimg.cn/20191026211319978.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>依次查看三台机器的监控图形，时间戳几乎完美“吻合”，不可思议吧。</p>
<h2 id="2、故障分析"><a href="#2、故障分析" class="headerlink" title="2、故障分析"></a>2、故障分析</h2><p>出现问题，先二话不说，马上重启各服务器，尽快恢复集群，降低对业务的影响，接下来开始对日志进行分析。</p>
<p>Java 进程自动退出(rocketmq 本身就是一个java进程)，一种最常见的问题是由于内存溢出或由于内存泄漏导致进程发送Crash等。由于我们的启动参数中未配置-XX:+HeapDumpOnOutOfMemoryError<br>-XX:HeapDumpPath=/opt/jvmdump 这两个参数，不能直接根据 是否生成 dump 文件，那退而求其次去查看其GC日志，将GC日志下载到本地，然后可以使用一个在线gc日志分析工具：<a href="https://gceasy.io/">https://gceasy.io/</a> ，将 gc 日志上传后会给出图形化的展示，其图如下：<br><img src="https://img-blog.csdnimg.cn/20191026211454570.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191026211519396.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>发现垃圾回收很正常。</p>
<p>既然 Java 进程不是由于内存溢出等问题导致的退出，那又会是什么原因呢？那我们来看一下那个点的broker的日志，其关键日志截图如下：<br><img src="https://img-blog.csdnimg.cn/20191026211607400.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>发现 broker 日志中有打印出 shutdownHook，表示在进程退出之前执行了启动时注册时的退出钩子函数，说明 broker 是正常停止的，并且也不可能是 kill -9 命令，肯定是显示的执行了 shutodown 或 kill 命令，于是立马使用 history 命令 查看历史命令，都未在指定时间执行过该命令，并且切换到 root 命令后，同样使用 history 命令，并未发现端倪。</p>
<p>但我始终相信，肯定是执行了手动执行了 kill 命令导致进程退出的，经过网上查找查，得知可以通过查阅系统日志/var/log/messages 来查看系统命令的调用，于是乎把日志文件下载到本地，开始搜索 kill 关键字，发现如下日志：<br><img src="https://img-blog.csdnimg.cn/20191026211722459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>发现最近一次 kill 命令是在25号的凌晨1点多，停止 rocketmq 集群，并使用 bin/mqbroker -c conf/broker-b.conf &amp; 进行了重新启动。</p>
<p>这个命令是有问题的，没有使用 nohup ，如果会话失效，该进程就会被退出，为了验证，我们再查一下进程退出时的日志：</p>
<a id="more"></a>

<p><img src="https://img-blog.csdnimg.cn/20191026211818275.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>发现在故障发生点确实有 Removed 相关的日志。</p>
<p>故障原因基本分析到位了，运维在启动的时候没有使用 nohup 来启动，故马上排查刚启动的集群的方式，重新重启刚启动的 Broker。</p>
<p>RocketMQ优雅重启小建议：</p>
<ol>
<li><p>首先将 broker 的写权限关闭，命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin&#x2F;mqadmin updateBrokerConfig -b 192.168.x.x:10911 -n 192.168.x.x:9876 -k brokerPermission -v 4</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过 rocketmq-console 查看该broker的写入TPS，当写入TPS降为0后，再使用 kill pid 关闭 rocketmq 进程。温馨提示：将broker的写权限关闭后，非顺序消息不会立马拒绝，而是需要等客户端路由信息更新后，不会在往该broker上发送消息，故这个过程需要等待。</p>
</li>
<li><p>启动 rocketmq</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nohup bin&#x2F;mqbroker -c conf&#x2F;broker-a.conf  &#x2F;dev&#x2F;null  2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：nohup。</p>
</blockquote>
</li>
<li><p>恢复该节点的写权限</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin&#x2F;mqadmin updateBrokerConfig -b 192.168.x.x:10911 -n 192.168.x.x:9876 -k brokerPermission -v 6</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>本文的故障分析与处理就介绍到这里，本文重点讲解了故障的分析过程以及 RocketMQ Broker 优雅停机的方案。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>实战</tag>
        <tag>自动退出</tag>
      </tags>
  </entry>
  <entry>
    <title>使用流收集数据之toList、joining、groupBy(多字段分组)</title>
    <url>/posts/79082d0a.html</url>
    <content><![CDATA[<div id="vip-container"><p>本文将从Collectos中构建收集器入手，详细介绍java8提供了哪些收集器，重点介绍:toList、toSet、toCollection、joining、groupBy(包含多级分组)、reducing的核心实现原理与使用示例。</p>
<h2 id="1、toList、toSet、toCollection"><a href="#1、toList、toSet、toCollection" class="headerlink" title="1、toList、toSet、toCollection"></a>1、toList、toSet、toCollection</h2><p>首先对流中的数据进行计算，最终返回的数据类型为集合。Collectors中定义了如下3集合类收集器，其声明如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Collector&lt;T, ?, List&lt;T&gt;&gt; toList()</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Collector&lt;T, ?, Set&lt;T&gt;&gt; toSet()</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T, C extends Collection&lt;T&gt;&gt; Collector&lt;T, ?, C&gt; toCollection(Supplier&lt;C&gt; collectionFactory)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>温馨提示：建议根据上篇的理论，再来反推一下这些Collector中的核心属性的值，例如supplier、accumulator、combiner、characteristics。不过特别注意，toList、toCollection是不支持并行运行的，但toSet()方法支持并行运行。</p>
</blockquote>
<p>我们首先来看一个一直使用的示例，返回菜单中所有菜品的名称：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_toList</span><span class="params">(List&lt;Dish&gt; menu)</span> </span>&#123;</span><br><span class="line">    List&lt;String&gt; names = menu.stream().map(Dish::getName)</span><br><span class="line">                        .collect(Collectors.toList());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于toList方法的实现原理已经在 <a href="https://blog.csdn.net/prestigeding/article/details/90813819">java8读书笔记：探究java8流收集数据原理</a>中也详细介绍，故本篇不再重点介绍。</p>
<h2 id="2、joining"><a href="#2、joining" class="headerlink" title="2、joining"></a>2、joining</h2><p>Collectors定义了如下3个重载方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Collector&lt;CharSequence, ?, String&gt; joining()</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Collector&lt;CharSequence, ?, String&gt; joining(CharSequence delimiter)</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Collector&lt;CharSequence, ?, String&gt; joining(CharSequence delimiter,</span><br><span class="line">    CharSequence prefix, CharSequence suffix)</span><br></pre></td></tr></table></figure>
<h3 id="2-1-joining"><a href="#2-1-joining" class="headerlink" title="2.1 joining"></a>2.1 joining</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Collector&lt;CharSequence, ?, String&gt; joining() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> CollectorImpl&lt;CharSequence, StringBuilder, String&gt;(</span><br><span class="line">        StringBuilder::<span class="keyword">new</span>, StringBuilder::append,</span><br><span class="line">        (r1, r2) -&gt; &#123; r1.append(r2); <span class="keyword">return</span> r1; &#125;,</span><br><span class="line">        StringBuilder::toString, CH_NOID);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Supplier&lt; A&gt; supplier()<br>其函数为StringBuilder::new，即通过该方法创建一个StringBuilder方法，作为累积器的初始值。</li>
<li>BiConsumer&lt;A, T&gt; accumulator<br>累积器：StringBuilder::append，即会对流中的元素执行追加。</li>
<li>BinaryOperator&lt; A&gt; combiner<br>组合器，也是调用append方法，进行字符串的规约。</li>
<li>Function&lt;A,R&gt; finisher<br>转换器：由于累积器返回的最终对象为StringBuilder，并不是目标String类型，故需要调用StringBuilder#toString方法进行转换</li>
<li>Set&lt; Characteristics&gt; characteristics<br>无任何行为。</li>
</ul>
<p>从上面的函数定义我们可以得出该方法的作用：针对字符串流，会对流中的元素执行字符的追加动作，流元素之间没有分隔符号，示例如下：<br><img src="https://img-blog.csdnimg.cn/20190609173712998.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="2-2-joining-CharSequence-delimiter"><a href="#2-2-joining-CharSequence-delimiter" class="headerlink" title="2.2 joining(CharSequence delimiter)"></a>2.2 joining(CharSequence delimiter)</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Collector&lt;CharSequence, ?, String&gt; joining(CharSequence delimiter) &#123;</span><br><span class="line">    <span class="keyword">return</span> joining(delimiter, <span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Collector&lt;CharSequence, ?, String&gt; joining(CharSequence delimiter,</span><br><span class="line">                                                         CharSequence prefix,</span><br><span class="line">                                                         CharSequence suffix) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> CollectorImpl&lt;&gt;(</span><br><span class="line">            () -&gt; <span class="keyword">new</span> StringJoiner(delimiter, prefix, suffix),</span><br><span class="line">            StringJoiner::add, StringJoiner::merge,</span><br><span class="line">            StringJoiner::toString, CH_NOID);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Supplier&lt; A&gt; supplier()<br>其函数为() -&gt; new StringJoiner(delimiter, prefix, suffix)，累积器的初始值为StringJoiner。</li>
<li>BiConsumer&lt;A, T&gt; accumulator<br>累积器：StringJoiner::append，即会对流中的元素执行追加。</li>
<li>BinaryOperator&lt; A&gt; combiner<br>组合器，StringJoiner::merge。</li>
<li>Function&lt;A,R&gt; finisher<br>转换器：由于累积器返回的最终对象为StringBuilder，并不是目标String类型，故需要调用StringBuilder#toString方法进行转换</li>
<li>Set&lt; Characteristics&gt; characteristics<br>无任何行为。</li>
</ul>
<p>其示例如下：<br><img src="https://img-blog.csdnimg.cn/20190609173901452.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="3、聚合相关收集器"><a href="#3、聚合相关收集器" class="headerlink" title="3、聚合相关收集器"></a>3、聚合相关收集器</h2><p>聚合相关收集器，主要包括minBy、maxBy、sum、avg等相关函数，其主要方法声明如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Collector&lt;T, ?, Optional&lt;T&gt;&gt; minBy(Comparator&lt;? <span class="keyword">super</span> T&gt; comparator)</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Collector&lt;T, ?, Optional&lt;T&gt;&gt; maxBy(Comparator&lt;? <span class="keyword">super</span> T&gt; comparator)</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Collector&lt;T, ?, Integer&gt; summingInt(ToIntFunction&lt;? <span class="keyword">super</span> T&gt; mapper)</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Collector&lt;T, ?, Long&gt; summingLong(ToLongFunction&lt;? <span class="keyword">super</span> T&gt; mapper)</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Collector&lt;T, ?, Double&gt; summingDouble(ToDoubleFunction&lt;? <span class="keyword">super</span> T&gt; mapper)</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Collector&lt;T, ?, Double&gt; averagingInt(ToIntFunction&lt;? <span class="keyword">super</span> T&gt; mapper)</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Collector&lt;T, ?, Double&gt; averagingLong(ToLongFunction&lt;? <span class="keyword">super</span> T&gt; mapper)</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Collector&lt;T, ?, Double&gt; averagingDouble(ToDoubleFunction&lt;? <span class="keyword">super</span> T&gt; mapper)</span><br></pre></td></tr></table></figure>
<p>上面这些方法比较简单，下面举个简单的例子介绍其使用：<br><img src="https://img-blog.csdnimg.cn/20190609174021453.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="4-分组"><a href="#4-分组" class="headerlink" title="4 分组"></a>4 分组</h2><p>Collectors提供了3个groupingBy重载方法，我们一个一个来理解。</p>
<h3 id="4-1-从示例入手"><a href="#4-1-从示例入手" class="headerlink" title="4.1 从示例入手"></a>4.1 从示例入手</h3><p>我们从其中一个最简单的函数说起，从而慢慢引出</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T, K&gt; Collector&lt;T, ?, Map&lt;K, List&lt;T&gt;&gt;&gt; groupingBy(</span><br><span class="line">             Function&lt;? <span class="keyword">super</span> T, ? extends K&gt; classifier)</span><br></pre></td></tr></table></figure>
<ul>
<li>Collector&lt;T, ?, Map&lt;K, List&lt; T&gt;&gt;&gt;<br>首先我们先来关注该方法的返回值Collector&lt;T, ?, Map&lt;K,List&lt; T&gt;&gt;，其最终返回的数据类型为：Map&lt;K, List&lt; T&gt;&gt;</li>
<li>Function&lt;? super T, ? extends K&gt; classifier<br>分类函数。</li>
</ul>
<p>示例如下：例如如下是购物车实体类，并且初始化数据如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShopCar</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> id;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> sellerId;</span><br><span class="line">    <span class="keyword">private</span> String sellerName;</span><br><span class="line">    <span class="keyword">private</span> String goodsName;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> buyerId;</span><br><span class="line">    <span class="keyword">private</span> String buyerName;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> num;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 初始化数据如下：</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;ShopCar&gt; <span class="title">initShopCar</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Arrays.asList(</span><br><span class="line">            <span class="keyword">new</span> ShopCar(<span class="number">1</span>, <span class="number">1</span>, <span class="string">&quot;天猫&quot;</span> , <span class="string">&quot;华为手机&quot;</span>, <span class="number">1</span> , <span class="string">&quot;dingw&quot;</span>, <span class="number">5</span>),</span><br><span class="line">            <span class="keyword">new</span> ShopCar(<span class="number">1</span>, <span class="number">2</span>, <span class="string">&quot;京东&quot;</span> , <span class="string">&quot;华为手机&quot;</span>, <span class="number">2</span> , <span class="string">&quot;ly&quot;</span>, <span class="number">2</span>),</span><br><span class="line">            <span class="keyword">new</span> ShopCar(<span class="number">1</span>, <span class="number">1</span>, <span class="string">&quot;京东&quot;</span> , <span class="string">&quot;小米手机&quot;</span>, <span class="number">3</span> , <span class="string">&quot;zhl&quot;</span>, <span class="number">3</span>),</span><br><span class="line">            <span class="keyword">new</span> ShopCar(<span class="number">1</span>, <span class="number">2</span>, <span class="string">&quot;1号店&quot;</span> , <span class="string">&quot;华为手机&quot;</span>, <span class="number">1</span> , <span class="string">&quot;dingw&quot;</span>, <span class="number">5</span>),</span><br><span class="line">            <span class="keyword">new</span> ShopCar(<span class="number">1</span>, <span class="number">2</span>, <span class="string">&quot;天猫&quot;</span> , <span class="string">&quot;苹果手机&quot;</span>, <span class="number">1</span> , <span class="string">&quot;dingw&quot;</span>, <span class="number">2</span>)</span><br><span class="line">    );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先我们看一下java8之前的写法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_group_jdk7</span><span class="params">(List&lt;ShopCar&gt; shopCars)</span> </span>&#123;</span><br><span class="line">    Map&lt;String, List&lt;ShopCar&gt;&gt; shopBySellerNameMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span>(ShopCar c : shopCars ) &#123;</span><br><span class="line">        <span class="keyword">if</span>(shopBySellerNameMap.containsKey( c.getSellerName() )) &#123;</span><br><span class="line">            shopBySellerNameMap.get(c.getSellerName()).add(c);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            List&lt;ShopCar&gt; aList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            shopBySellerNameMap.put(c.getSellerName(), aList);</span><br><span class="line">            aList.add(c);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    print(shopBySellerNameMap);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码应该很容易理解，根据商家名称进行分组，拥有相同商家的名称的购物车项组成一个集合，最终返回Map&lt;String, List&lt; ShopCar &gt;&gt;类型的数据。</p>
<p>那如何使用java8的流分组特性来编写对应的代码呢？下面的思考过程非常关键，经过前面的学习，我想大家应该也具备了如下分析与编写的能力？</p>
<p>首先其声明如下：public static &lt;T, K&gt; Collector&lt;T, ?, Map&lt;K, List&lt; T&gt;&gt;&gt; groupingBy(Function&lt;? super T, ? extends K&gt; classifier)，那在本例中，T,K这两个参数代表什么意思呢？</p>
<ul>
<li>T : ShopCar</li>
<li>K : String (sellerName的类型)<br>其判断的主要依据为groupingBy方法返回的参数Collector&lt;T, ?, Map&lt;K, List&lt; T&gt;&gt;&gt;，代表&lt;T, A, R&gt;，其中最后一个泛型参数R对应的就是本例需要返回的Map&lt;K, List&lt; T&gt;&gt;，故分析出T,K代表的含义。</li>
</ul>
<p>然后再看其参数：Function&lt;? super T, ? extends K&gt; classifier,即接受的函数式编程接口为T -&gt; K，即通过ShopCar 返回一个String，又根据其名称可知，该函数为一个分类函数，故基本可以写成如下代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_group_jdk8</span><span class="params">(List&lt;ShopCar&gt; shopCars)</span> </span>&#123;</span><br><span class="line">    Map&lt;String, List&lt;ShopCar&gt;&gt; shopBySellerNameMap =  </span><br><span class="line">                 shopCars</span><br><span class="line">                     .stream()</span><br><span class="line">                     .collect(Collectors.groupingBy(ShopCar::getSellerName));</span><br><span class="line">                   <span class="comment">//.collect(Collectors.groupingBy( (ShopCar c) -&gt; c.getSellerName() ))</span></span><br><span class="line">    print(shopBySellerNameMap);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其运行效果如下：<br><img src="https://img-blog.csdnimg.cn/20190609174540775.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">为了加深对groupingBy方法的理解，接下来我们重点分析一下其源码的实现。</p>
<h3 id="4-2-源码分析groupingBy方法"><a href="#4-2-源码分析groupingBy方法" class="headerlink" title="4.2 源码分析groupingBy方法"></a>4.2 源码分析groupingBy方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T, K&gt; Collector&lt;T, ?, Map&lt;K, List&lt;T&gt;&gt;&gt; groupingBy(Function&lt;? <span class="keyword">super</span> T, ? extends K&gt; classifier) &#123;  <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span> groupingBy(classifier, toList());                                                                     <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：分类参数，已经在上文中详细介绍。<br>代码@2：调用groupingBy重载方法，传入的参数为toList()，有点意思，传入的参数为Collectors.toList()，结合上文中的示例，需要返回值类型为：Map&lt;String, List&lt; ShopCar&gt;&gt;，与这里的List对应起来了。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T, K, A, D&gt; Collector&lt;T, ?, Map&lt;K, D&gt;&gt; groupingBy(Function&lt;? <span class="keyword">super</span> T, ? extends K&gt; classifier, Collector&lt;? <span class="keyword">super</span> T, A, D&gt; downstream) &#123;</span><br><span class="line">    <span class="keyword">return</span> groupingBy(classifier, HashMap::<span class="keyword">new</span>, downstream);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该重载方法，再次调用3个参数的groupingBy方法，其中第二个参数为HashMap::new，即创建一个Map对象，我们重点关注3个参数的groupingBy。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T, K, D, A, M extends Map&lt;K, D&gt;&gt; Collector&lt;T, ?, M&gt; groupingBy(</span><br><span class="line">                          Function&lt;? <span class="keyword">super</span> T, ? extends K&gt; classifier, </span><br><span class="line">Supplier&lt;M&gt; mapFactory,</span><br><span class="line">Collector&lt;? <span class="keyword">super</span> T, A, D&gt; downstream) &#123; <span class="comment">// @1</span></span><br><span class="line">    Supplier&lt;A&gt; downstreamSupplier = downstream.supplier();        <span class="comment">// @2 start</span></span><br><span class="line">    BiConsumer&lt;A, ? <span class="keyword">super</span> T&gt; downstreamAccumulator = downstream.accumulator();</span><br><span class="line">    BiConsumer&lt;Map&lt;K, A&gt;, T&gt; accumulator = (m, t) -&gt; &#123;</span><br><span class="line">        K key = Objects.requireNonNull(classifier.apply(t), <span class="string">&quot;element cannot be mapped to a null key&quot;</span>);</span><br><span class="line">        A container = m.computeIfAbsent(key, k -&gt; downstreamSupplier.get());</span><br><span class="line">        downstreamAccumulator.accept(container, t);</span><br><span class="line">    &#125;; <span class="comment">// @2 end</span></span><br><span class="line"></span><br><span class="line">    BinaryOperator&lt;Map&lt;K, A&gt;&gt; merger = Collectors.&lt;K, A, Map&lt;K, A&gt;&gt;mapMerger(downstream.combiner());   <span class="comment">// @3</span></span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">    Supplier&lt;Map&lt;K, A&gt;&gt; mangledFactory = (Supplier&lt;Map&lt;K, A&gt;&gt;) mapFactory;                            </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (downstream.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH)) &#123;           <span class="comment">// @4</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> CollectorImpl&lt;&gt;(mangledFactory, accumulator, merger, CH_ID);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;                                                                                            <span class="comment">// @5</span></span><br><span class="line">        <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">        Function&lt;A, A&gt; downstreamFinisher = (Function&lt;A, A&gt;) downstream.finisher();</span><br><span class="line">        Function&lt;Map&lt;K, A&gt;, M&gt; finisher = intermediate -&gt; &#123;</span><br><span class="line">            intermediate.replaceAll((k, v) -&gt; downstreamFinisher.apply(v));</span><br><span class="line">            <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">            M castResult = (M) intermediate;</span><br><span class="line">            <span class="keyword">return</span> castResult;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> CollectorImpl&lt;&gt;(mangledFactory, accumulator, merger, finisher, CH_NOID);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：参数介绍：</p>
<ul>
<li>Function&lt;? super T, ? extends K&gt; classifier<br>分类函数。</li>
<li>Supplier&lt; M&gt; mapFactory<br>map构建函数。（）-&gt; Map</li>
<li>Collector&lt;? super T, A, D&gt; downstream<br>下游收集器，在上面的示例中，该参数为Collectos.toList()。</li>
</ul>
<p>代码@2：构建最终的累积器。其实现要点如下：</p>
<ul>
<li>对流中的元素，使用Function&lt;? super T, ? extends K&gt; classifier，获取对应的分类键值。</li>
<li>使用mangledFactory创建累积初始值，并调用Map#computeIfAbsent方法，放入的值为：downstreamSupplier.get()。可以类比上例中Map&lt;String, List&lt; T&gt;&gt;，请结合如下代码进行理解：<br><img src="https://img-blog.csdnimg.cn/20190609174846127.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li>
</ul>
<p>代码@3：构建最终的组合器，这里使用的是Collectos.mapMerger，其内部的实现就是对每个元素，执行map#merge方法。</p>
<p>代码@4：如果收集器的行为为IDENTITY_FINISH，直接根据上面已创建的累积器、组合器，创建一个最终的收集器。</p>
<p>代码@5：如果收集器的行为不包含IDENTITY_FINISH，则需要最终调用原收集器的finisher方法。才能最终需要返回的类型。</p>
<p>groupingBy的原理就讲解到这里，我们接下来思考如下场景：<br>还是上面的购物车场景，现在要求先按照供应商名称分组，然后按照购买人分组（即多级分组），类似于SQL group by sellerId,buyerId。</p>
<p>思考过程：首先二级分类需要返回的数据类型为Map&lt;String /** sellerName*/,   Map&lt;String、/** buyerId*/，List&lt; ShopCar&gt;&gt; &gt;,而只有一个参数的groupingBy(Function&lt;? super T, ? extends K&gt; classifier)，只接受一个分类参数，其内部会调用两个参数的groupingBy(Function&lt;? super T, ? extends K&gt; classifier,Collector&lt;? super T, A, D&gt; downstream)，默认第二个参数为Collectors.toList()，故我们可以做的文章是改变这个默认值，传入符合业务场景的收集器，结合目前的需求，很显然，该参数应该是支持分组的收集器，即应该可以通过嵌套groupingBy方法，实现二级分组，其具体代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 二级分组示例</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> shopCars</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_level_group</span><span class="params">(List&lt;ShopCar&gt; shopCars)</span> </span>&#123;</span><br><span class="line">    Map&lt;String, Map&lt;String, List&lt;ShopCar&gt;&gt;&gt;  result = </span><br><span class="line">        shopCars.stream().collect(Collectors.groupingBy(ShopCar::getSellerName,</span><br><span class="line">                                    Collectors.groupingBy(ShopCar::getBuyerName)));</span><br><span class="line">    System.out.println(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>温馨提示：上面介绍的分组，主要的Map存储结构为HashMap，java8为ConcurrentMap对应类继承体系提供了对应的分组函数：groupingByConcurrent，其使用方法与groupingBy方法类型，故不重复介绍。</p>
<h2 id="5、-partitioningBy"><a href="#5、-partitioningBy" class="headerlink" title="5、 partitioningBy"></a>5、 partitioningBy</h2><p>分区，分区可以看出是分组的特殊化，接受的分类函数返回boolean类型，即是谓词Predicate&lt;? super T&gt; predicate。其声明如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Collector&lt;T, ?, Map&lt;Boolean, List&lt;T&gt;&gt;&gt; partitioningBy(Predicate&lt;? <span class="keyword">super</span> T&gt; predicate)</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T, D, A&gt; Collector&lt;T, ?, Map&lt;Boolean, D&gt;&gt; partitioningBy(Predicate&lt;? <span class="keyword">super</span> T&gt; predicate, Collector&lt;? <span class="keyword">super</span> T, A, D&gt; downstream) </span><br></pre></td></tr></table></figure>
<p>由于其用法与分组类似，故这里就一笔带过了。</p>
<h2 id="6、-reducing"><a href="#6、-reducing" class="headerlink" title="6、 reducing"></a>6、 reducing</h2><p>规约。其函数声明如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T, U&gt; Collector&lt;T, ?, U&gt; reducing(U identity, Function&lt;? <span class="keyword">super</span> T, ? extends U&gt; mapper, BinaryOperator&lt;U&gt; op)</span><br></pre></td></tr></table></figure>
<p>其参数如下：</p>
<ul>
<li>U identity<br>规约初始值。</li>
<li>Function&lt;? super T, ? extends U&gt; mapper<br>累加器函数。</li>
<li>BinaryOperator<U> op<br>组合器函数。<br>关于Collectors.reducing，建议可以直接使用Stream自身提供的reducing方法。</li>
</ul>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>java8</category>
      </categories>
      <tags>
        <tag>java8</tag>
        <tag>Lambda</tag>
        <tag>流计算</tag>
      </tags>
  </entry>
  <entry>
    <title>再谈 RocketMQ broker busy(实战篇)</title>
    <url>/posts/cf8acd90.html</url>
    <content><![CDATA[<div id="vip-container"><p>本文将在 <a href="https://blog.csdn.net/prestigeding/article/details/92800672">RocketMQ 消息发送system busy、broker busy原因分析与解决方案</a> 的基础上，结合生产上的日志尝试再次理解 broker busy 以及探讨解决方案。</p>
<p>首先，broker busy 相关的日志关键字如下：</p>
<ul>
<li>[REJECTREQUEST]system busy</li>
<li>too many requests and system thread pool busy</li>
<li>[PC_SYNCHRONIZED]broker busy</li>
<li>[PCBUSY_CLEAN_QUEUE]broker busy</li>
<li>[TIMEOUT_CLEAN_QUEUE]broker busy</li>
</ul>
<p>上述前面4个关键字在上篇文章中已详细介绍，本文先对出现上述错误进行一个总结，具体的分析过程请查阅上篇文章。</p>
<p>本文先给出一张流程图，展示上述5种 broker busy 分别会在消息发送的哪个阶段抛出，以便大家能够清晰的了解其发生的原因。<br><img src="https://img-blog.csdnimg.cn/20191024084015845.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>针对前4种 broker busy 出现的问题已经在上篇文章中详细介绍，主要是由于 Broker 在追加消息时持有的锁时间超过了设置的1s，Broker 为了自我保护，会抛出错误，客户端会选择其他 broker 服务器进行重试。如果对不是金融级服务，建议将 transientStorePoolEnable = true，可以有效避免前面 4 种 broker ，因为开启这个参数，消息首先会存储在堆外内存中，并且 RocketMQ 提供了内存锁定的功能，其追加性能能得到一定的保障，这样可以做到在内存使用层面的读写分离，即写消息是直接写入堆外内存，消费消息直接从 pagecache中读，然后定时将堆外内存的消息写入 pagecache。但这种方案随之带来的就是可能存在消息丢失，如果对消息非常严谨的话，建议扩容集群，或迁移topic到新的集群。</strong></p>
<a id="more"></a>

<p>同时在做 Broker 服务器巡检的时候，可以通过去通过如下命令去查看 broker 一次消息追加是否会超过 500 ms。<br><img src="https://img-blog.csdnimg.cn/20191024084128742.png" alt="在这里插入图片描述"><br>在这个图中我们看到在设置了 transientStorePoolEnable 为 true 的情况下，虽然一天只有一条超过500ms的消息，但也值得警惕了，由于对系统内核参数掌握程度不够，这种情况，估计只能走集群扩容的路子了。但如果一天消息量巨大而且出现频率不高的情况，由于有重试机制，倒不会带来太大的问题。如果出现太多的错误，<strong>建议集群扩容</strong>。</p>
<p>本文接下来想重点探讨一下 [TIMEOUT_CLEAN_QUEUE]broker busy 这种情况。</p>
<p>BrokerFastFailure#cleanExpiredRequest</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (!<span class="keyword">this</span>.brokerController.getSendThreadPoolQueue().isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">final</span> Runnable runnable = <span class="keyword">this</span>.brokerController.getSendThreadPoolQueue().peek();</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">null</span> == runnable) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">final</span> RequestTask rt = castRunnable(runnable);</span><br><span class="line">            <span class="keyword">if</span> (rt == <span class="keyword">null</span> || rt.isStopRun()) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> behind = System.currentTimeMillis() - rt.getCreateTimestamp();</span><br><span class="line">            <span class="keyword">if</span> (behind &gt;= <span class="keyword">this</span>.brokerController.getBrokerConfig().getWaitTimeMillsInSendQueue()) &#123;</span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">this</span>.brokerController.getSendThreadPoolQueue().remove(runnable)) &#123;</span><br><span class="line">                    rt.setStopRun(<span class="keyword">true</span>);</span><br><span class="line">                    rt.returnResponse(RemotingSysResponseCode.SYSTEM_BUSY, String.format(<span class="string">&quot;[TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: %sms, size of queue: %d&quot;</span>, behind, <span class="keyword">this</span>.brokerController.getSendThreadPoolQueue().size()));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable ignored) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看出来，抛出这种错误，在 broker 还没有发送“严重”的 pagecache 繁忙，即消息追加到内存中的最大时延没有超过 1s，通常追加是很快的，绝大部分都会低于1ms，但可能会由于出现一个超过200ms的追加时间，导致排队中的任务等待时间超过了200ms，则此时会触发broker 端的快速失败，让请求快速失败，便于客户端快速重试。但是这种请求并不是实时的，而是每隔10s 检查一遍。</p>
<p>值得注意的是，一旦出现 TIMEOUT_CLEAN_QUEUE，可能在一个点会有多个这样的错误信息，具体多少与当前积压在待发送队列中的个数有关。</p>
<p><strong>关于 [TIMEOUT_CLEAN_QUEUE]broker busy 我们也可以适当调整 waitTimeMillsInSendQueue，默认值为200ms，可以适当调整到400ms。</strong></p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>broker busy</tag>
        <tag>TIMEOUT_CLEAN_QUEUE</tag>
        <tag>PCBUSY_CLEAN_QUEUE</tag>
      </tags>
  </entry>
  <entry>
    <title>初始 Kafka Consumer 消费者</title>
    <url>/posts/d9d4c345.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、KafkaConsumer-概述"><a href="#1、KafkaConsumer-概述" class="headerlink" title="1、KafkaConsumer 概述"></a>1、KafkaConsumer 概述</h2><p>根据 KafkaConsumer 类上的注释上来看 KafkaConsumer 具有如下特征：</p>
<ul>
<li><p>在 Kafka 中 KafkaConsumer 是线程不安全的。</p>
</li>
<li><p>2.2.1 版本的KafkaConsumer 兼容 kafka 0.10.0 和 0.11.0 等低版本。</p>
</li>
<li><p>消息偏移量与消费偏移量(消息消费进度)<br>Kafka 为分区中的每一条消息维护一个偏移量，即消息偏移量。这个偏移量充当该分区内记录的唯一标识符。消费偏移量(消息消费进度)存储的是消费组当前的处理进度。消息消费进度的提交在 kafka 中可以定时自动提交也可以手动提交。手动提交可以调用 ommitSync() 或 commitAsync 方法。</p>
</li>
<li><p>消费组 与 订阅关系<br>多个消费这可以同属于一个消费组，消费组内的所有消费者共同消费主题下的所有消息。一个消费组可以订阅多个主题。</p>
</li>
<li><p>队列负载机制<br>既然同一个消费组内的消费者共同承担主题下所有队列的消费，那他们如何进行分工呢？默认情况下采取平均分配，例如一个消费组有两个消费者c1、c2，一个 topic 的分区数为6，那 c1 会负责3个分区的消费，同样 c2 会负责另外3个分区的分配。</p>
<p>那如果其中一个消费者宕机或新增一个消费者，那队列能动态调整吗？</p>
<p>答案是会重新再次平衡，例如如果新增一个消费者 c3，则c1,c2,c3都会负责2个分区的消息消费，分区重平衡会在后续文章中重点介绍。消费者也可以通过 assign 方法手动指定分区，此时会禁用默认的自动分配机制。</p>
</li>
<li><p>消费者故障检测机制<br>当通过 subscribe 方法订阅某些主题时，此时该消费者还未真正加入到订阅组，只有当 consumeer#poll 方法被调用后，并且会向 broker 定时发送心跳包，如果 broker 在 session.timeout.ms 时间内未收到心跳包，则 broker 会任务该消费者已宕机，会将其剔除，并触发消费端的分区重平衡。</p>
<p>消费者也有可能遇到“活体锁”的情况，即它继续发送心跳，但没有任何进展。在这种情况下，为了防止消费者无限期地占用它的分区，可以使用max.poll.interval.ms 设置提供了一个活性检测机制。基本上，如果您调用轮询的频率低于配置的最大间隔，那么客户机将主动离开组，以便另一个消费者可以接管它的分区。当这种情况发生时,您可能会看到一个偏移提交失败(由调用{@link #commitSync()}抛出的{@link CommitFailedException}表示)。</p>
</li>
<li><p>kafka 对 poll loop 行为的控制参数<br>Kafka 提供了如下两个参数来控制 poll 的行为：</p>
<ul>
<li> max.poll.interval.ms<br>允许 两次调用 poll 方法的最大间隔，即设置每一批任务最大的处理时间。</li>
<li> max.poll.records<br>每一次 poll 最大拉取的消息条数。</li>
</ul>
<p>对于消息处理时间不可预测的情况下上述两个参数可能不够用，那将如何是好呢？</p>
<p>通常的建议将消息拉取与消息消费分开，一个线程负责 poll 消息，处理这些消息使用另外的线程，这里就需要手动提交消费进度。为了控制消息拉起的过快，您可能会需要用到 Consumer#pause(Collection) 方法，暂时停止向该分区拉起消息。RocketMQ 的推模式就是采用了这种策略。如果大家有兴趣的话，可以从笔者所著的《RocketMQ技术内幕》一书中详细了解。</p>
</li>
</ul>
<a id="more"></a>

<h2 id="2、KafkaConsume-使用示例"><a href="#2、KafkaConsume-使用示例" class="headerlink" title="2、KafkaConsume 使用示例"></a>2、KafkaConsume 使用示例</h2><h3 id="2-1-自动提交消费进度"><a href="#2-1-自动提交消费进度" class="headerlink" title="2.1 自动提交消费进度"></a>2.1 自动提交消费进度</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testConsumer1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">    props.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;localhost:9092,localhost:9082,localhost:9072&quot;</span>);</span><br><span class="line">    props.setProperty(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;C_ODS_ORDERCONSUME_01&quot;</span>);</span><br><span class="line">    props.setProperty(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">    props.setProperty(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;1000&quot;</span>);</span><br><span class="line">    props.setProperty(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">    props.setProperty(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">    KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">    consumer.subscribe(Arrays.asList(<span class="string">&quot;TOPIC_ORDER&quot;</span>));</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        ConsumerRecords&lt;String, String&gt;  records = consumer.poll(Duration.ofMillis(<span class="number">100</span>));</span><br><span class="line">        <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;消息消费中&quot;</span>);</span><br><span class="line">            System.out.printf(<span class="string">&quot;offset = %d, key = %s, value = %s%n&quot;</span>, record.offset(), record.key(), record.value());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-2-手动提交消费进度"><a href="#2-2-手动提交消费进度" class="headerlink" title="2.2 手动提交消费进度"></a>2.2 手动提交消费进度</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testConsumer2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;localhost:9092&quot;</span>);</span><br><span class="line">        props.setProperty(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;test&quot;</span>);</span><br><span class="line">        props.setProperty(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;false&quot;</span>);</span><br><span class="line">        props.setProperty(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        props.setProperty(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;&gt;(props);</span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>));</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> minBatchSize = <span class="number">200</span>;</span><br><span class="line">        List&lt;ConsumerRecord&lt;String, String&gt;&gt; buffer = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(<span class="number">100</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                buffer.add(record);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (buffer.size() &gt;= minBatchSize) &#123;</span><br><span class="line">                <span class="comment">// insertIntoDb(buffer);</span></span><br><span class="line">                <span class="comment">// 省略处理逻辑</span></span><br><span class="line">                consumer.commitSync();</span><br><span class="line">                buffer.clear();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="3、认识-Consumer-接口"><a href="#3、认识-Consumer-接口" class="headerlink" title="3、认识 Consumer 接口"></a>3、认识 Consumer 接口</h2><p>要认识 Kafka 的消费者，个人认为最好的办法就是从它的类图着手，下面给出 Consumer 接口的类图。<br><img src="https://img-blog.csdnimg.cn/20191124101227865.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>接下来对起重点方法进行一个初步的介绍，从下篇文章开始将对其进行详细设计。</p>
<ul>
<li>Set&lt; TopicPartition&gt; assignment()<br>获取该消费者的队列分配列表。</li>
<li>Set&lt; String&gt; subscription()<br>获取该消费者的订阅信息。</li>
<li>void subscribe(Collection&lt; String&gt; topics)<br>订阅主题。</li>
<li>void subscribe(Collection&lt; String&gt; topics, ConsumerRebalanceListener callback)<br>订阅主题，并指定队列重平衡的监听器。</li>
<li>void assign(Collection&lt; TopicPartition&gt; partitions)<br>取代 subscription，手动指定消费哪些队列。</li>
<li>void unsubscribe()<br>取消订阅关系。</li>
<li>ConsumerRecords&lt;K, V&gt; poll(Duration timeout)<br>拉取消息，是 KafkaConsumer 的核心方法，将在下文详细介绍。</li>
<li>void commitSync()<br>同步提交消费进度，为本批次的消费提交，将在后续文章中详细介绍。</li>
<li>void commitSync(Duration timeout)<br>同步提交消费进度，可设置超时时间。</li>
<li>void commitSync(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets)<br>显示同步提交消费进度， offsets 指明需要提交消费进度的信息。</li>
<li>void commitSync(final Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, final Duration timeout)<br>显示同步提交消费进度，带超时间。</li>
<li>void seek(TopicPartition partition, long offset)<br>重置 consumer#poll 方法下一次拉消息的偏移量。</li>
<li>void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata)<br>seek 方法重载方法。</li>
<li>void seekToBeginning(Collection&lt; TopicPartition&gt; partitions)<br>将 poll 方法下一次的拉取偏移量设置为队列的初始偏移量。</li>
<li>void seekToEnd(Collection&lt; TopicPartition&gt; partitions)<br>将 poll 方法下一次的拉取偏移量设置为队列的最大偏移量。</li>
<li>long position(TopicPartition partition)<br>获取将被拉取的偏移量。</li>
<li>long position(TopicPartition partition, final Duration timeout)<br>同上。</li>
<li>OffsetAndMetadata committed(TopicPartition partition)<br>获取指定分区已提交的偏移量。</li>
<li>OffsetAndMetadata committed(TopicPartition partition, final Duration timeout)<br>同上。</li>
<li>Map&lt;MetricName, ? extends Metric&gt; metrics()<br>统计指标。</li>
<li>List&lt; PartitionInfo&gt; partitionsFor(String topic)<br>获取主题的路由信息。</li>
<li>List&lt; PartitionInfo&gt; partitionsFor(String topic, Duration timeout)<br>同上。</li>
<li>Map&lt;String, List&lt; PartitionInfo&gt;&gt; listTopics()<br>获取所有 topic 的路由信息。</li>
<li>Map&lt;String, List&lt; PartitionInfo&gt;&gt; listTopics(Duration timeout)<br>同上。</li>
<li>Set&lt; TopicPartition&gt; paused()<br>获取已挂起的分区信息。</li>
<li>void pause(Collection&lt; TopicPartition&gt; partitions)<br>挂起分区，下一次 poll 方法将不会返回这些分区的消息。</li>
<li>void resume(Collection&lt; TopicPartition&gt; partitions)<br>恢复挂起的分区。</li>
<li>Map&lt;TopicPartition, OffsetAndTimestamp&gt; offsetsForTimes(Map&lt;TopicPartition, Long&gt; timestampsToSearch)<br>根据时间戳查找最近的一条消息的偏移量。</li>
<li>Map&lt;TopicPartition, OffsetAndTimestamp&gt; offsetsForTimes(Map&lt;TopicPartition, Long&gt; timestampsToSearch, Duration timeout)<br>同上。</li>
<li>Map&lt;TopicPartition, Long&gt; beginningOffsets(Collection&lt; TopicPartition&gt; partitions)<br>查询指定分区当前最小的偏移量。</li>
<li>Map&lt;TopicPartition, Long&gt; beginningOffsets(Collection&lt; TopicPartition&gt; partitions, Duration timeout)<br>同上。</li>
<li>Map&lt;TopicPartition, Long&gt; endOffsets(Collection&lt; TopicPartition&gt; partitions)<br>查询指定分区当前最大的偏移量。</li>
<li>Map&lt;TopicPartition, Long&gt; endOffsets(Collection&lt; TopicPartition&gt; partitions, Duration timeout)<br>同上。</li>
<li>void close()<br>关闭消费者。</li>
<li>void close(Duration timeout)<br>关闭消费者。</li>
<li>void wakeup()<br>唤醒消费者。</li>
</ul>
<h2 id="4、初始-KafkaConsumer"><a href="#4、初始-KafkaConsumer" class="headerlink" title="4、初始 KafkaConsumer"></a>4、初始 KafkaConsumer</h2><p><img src="https://img-blog.csdnimg.cn/20191124122831676.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>接下来笔者根据其构造函数，对一一介绍其核心属性的含义，为接下来讲解其核心方法打下基础。</p>
<ul>
<li>String groupId<br>消费组ID。同一个消费组内的多个消费者共同消费一个主题下的消息。</li>
<li>String clientId<br>发出请求时传递给服务器的id字符串。设置该值的目的是方便在服务器端请求日志中包含逻辑应用程序名称，从而能够跟踪ip/端口之外的请求源。该值可以设置为应用名称。</li>
<li>ConsumerCoordinator coordinator<br>消费协调器，后续会详细介绍。</li>
<li>Deserializer&lt; K&gt; keyDeserializer<br>key 序列化器。</li>
<li>Deserializer&lt; V&gt; valueDeserializer<br>值序列化器。</li>
<li>ConsumerNetworkClient client<br>网络通讯客户端。</li>
<li>SubscriptionState subscriptions<br>用于管理订阅状态的类，用于跟踪 topics, partitions, offsets 等信息。后续会详细介绍。</li>
<li>ConsumerMetadata metadata<br>消费者元数据信息，包含路由信息。</li>
<li>long retryBackoffMs<br>如果向 broker 发送请求失败后，发起重试之前需要等待的间隔时间，通过属性 retry.backoff.ms　指定。</li>
<li>long requestTimeoutMs<br>一次请求的超时时间。</li>
<li>int defaultApiTimeoutMs<br>为所有可能阻塞的API设置一个默认的超时时间。</li>
<li>List&lt; PartitionAssignor&gt; assignors<br>分区分配算法（分区负载算法）。</li>
</ul>
<p>Kafka Consumer 消费者就介绍到这里了，从下篇文章开始将开始详细介绍 Kafka 关于消息消费的方方面面。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>源码</tag>
        <tag>KafkaConsumer</tag>
      </tags>
  </entry>
  <entry>
    <title>初识 Kafka Producer 生产者</title>
    <url>/posts/b579d244.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、KafkaProducer-概述"><a href="#1、KafkaProducer-概述" class="headerlink" title="1、KafkaProducer 概述"></a>1、KafkaProducer 概述</h2><p>根据 KafkaProducer 类上的注释上来看 KafkaProducer 具有如下特征：</p>
<ul>
<li>KafkaProducer 是线程安全的，可以被多个线程交叉使用。</li>
<li>KafkaProducer 内部包含一个缓存池，存放待发送消息，即 ProducerRecord 队列，与此同时会开启一个IO线程将 ProducerRecord 对象发送到 Kafka 集群。</li>
<li>KafkaProducer 的消息发送 API send 方法是异步，只负责将待发送消息 ProducerRecord 发送到缓存区中，立即返回，并返回一个结果凭证 Future。</li>
<li>acks<br>KafkaProducer 提供了一个核心参数 acks 用来定义消息“已提交”的条件(标准)，就是 Broker 端向客户端承偌已提交的条件，可选值如下：<ul>
<li>0<br>表示生产者不关系该条消息在 broker 端的处理结果，只要调用 KafkaProducer 的 send 方法返回后即认为成功，显然这种方式是最不安全的，因为 Broker 端可能压根都没有收到该条消息或存储失败。</li>
<li>all 或 -1<br>表示消息不仅需要 Leader 节点已存储该消息，并且要求其副本（准确的来说是 ISR 中的节点）全部存储才认为已提交，才向客户端返回提交成功。这是最严格的持久化保障，当然性能也最低。</li>
<li>1<br>表示消息只需要写入 Leader 节点后就可以向客户端返回提交成功。</li>
</ul>
</li>
</ul>
<a id="more"></a>

<ul>
<li>retries<br>kafka 在生产端提供的另外一个核心属性，用来控制消息在发送失败后的重试次数，设置为 0 表示不重试，重试就有可能造成消息在发送端的重复。</li>
<li>batch.size<br>  kafka 消息发送者为每一个分区维护一个未发送消息积压缓存区，其内存大小由batch.size指定，默认为 16K。<br>  但如果缓存区中不足100条，但发送线程此时空闲，是需要等到缓存区中积满100条才能发送还是可以立即发送呢？默认是立即发送，即 batch.size 的作用其实是客户端一次发送到broker的最大消息数量。</li>
<li>linger.ms<br>  ​    为了提高 kafka 消息发送的高吞吐量，即控制在缓存区中未积满 batch.size  时来控制 消息发送线程的行为，是立即发送还是等待一定时间，如果linger.ms 设置为 0表示立即发送，如果设置为大于0，则消息发送线程会等待这个值后才会向broker发送。该参数者会增加响应时间，但有利于增加吞吐量。有点类似于 TCP 领域的 Nagle 算法。</li>
<li>buffer.memory<br>用于控制消息发送者缓存的总内存大小，如果超过该值，往缓存区中添加消息会被阻塞，具体会在下文的消息发送流程中详细介绍，阻塞的最大时间可通过参数 max.block.ms 设置，阻塞超过该值会抛出超时异常。</li>
<li>key.serializer<br>指定 key 的序列化处理器。</li>
<li>value.serializer<br>指定 消息体的序列化处理器。</li>
<li>enable.idempotence<br>从 kafka0.11版本开始，支持消息传递幂等，可以做到消息只会被传递一次，通过 enable.idempotence 为 true 来开启。如果该值设置为 true，其 retries 将设置为 Integer.MAX_VALUE，acks 将被设置为 all。为了确保消息发送幂等性，必须避免应用程序端的任何重试，并且如果消息发送API如果返回错误，应用端应该记录最后成功发送的消息，避免消息的重复发送。</li>
</ul>
<p>从Kafka 0.11开始，kafka 也支持事务消息。</p>
<h2 id="2、KafkaProducer-类图"><a href="#2、KafkaProducer-类图" class="headerlink" title="2、KafkaProducer 类图"></a>2、KafkaProducer 类图</h2><p><img src="https://img-blog.csdnimg.cn/20191103130908591.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在 Kafka  中，生产者通过接口 Producer 定义，通过该接口的方法，我们基本可以得知 KafkaProducer 将具备如下基本能力：</p>
<ul>
<li>void initTransactions()<br>初始化事务，如果需要使用事务方法，该方法必须首先被调用。</li>
<li>void beginTransaction()<br>开启事务。</li>
<li>void sendOffsetsToTransaction(Map&lt; TopicPartition, OffsetAndMetadata&gt; offsets,String consumerGroupId)<br>向消费组提交当前事务中的消息偏移量，将在介绍 Kafka 事务相关文章中详细介绍。</li>
<li>void commitTransaction()<br>提交事务。</li>
<li>void abortTransaction()<br>回滚事务。</li>
<li>Future&lt; RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record)<br>消息发送，该方法默认为异步发送，如果要实现同步发送的效果，对返回结果调用  get 方法即可，该方法将在下篇文章中详细介绍。</li>
<li>Future&lt; RecordMetadata&gt; send(ProducerRecord&lt;K, V&gt; record, Callback callback)<br> ​    消息发送，支持回调。</li>
<li>void flush()<br>忽略 linger.ms 的值，直接唤醒发送线程，将缓冲区中的消息全部发送到 broker。</li>
<li>List&lt; PartitionInfo&gt; partitionsFor(String topic)<br>获取 topic 的路由信息（分区信息）。</li>
<li>Map&lt; MetricName, ? extends Metric&gt; metrics()<br>获取由生产者收集的统计信息。</li>
<li>void close()<br>关闭发送者。</li>
<li>void close(Duration timeout)<br>定时关闭消息发送者。</li>
</ul>
<p>上面的方法我们会根据需要在后续文章中进行详细的介绍。接下来我们看一下 KafkaProducer 的核心属性的含义。</p>
<ul>
<li>String clientId<br>客户端ID。在创建 KafkaProducer 时可通过 client.id 定义 clientId，如果未指定，则默认 producer- seq，seq 在进程内递增，强烈建议客户端显示指定 clientId。</li>
<li>Metrics metrics<br>度量的相关存储容器，例如消息体大小、发送耗时等与监控相关的指标。</li>
<li>Partitioner partitioner<br>分区负载均衡算法，通过参数 partitioner.class 指定。</li>
<li>int maxRequestSize<br>调用 send 方法发送的最大请求大小，包括 key、消息体序列化后的消息总大小不能超过该值。通过参数 max.request.size 来设置。</li>
<li>long totalMemorySize<br>生产者缓存所占内存的总大小，通过参数 buffer.memory 设置。</li>
<li>Metadata metadata<br>元数据信息，例如 topic 的路由信息，由 KafkaProducer 自动更新。</li>
<li>RecordAccumulator accumulator<br>消息记录累积器，将在消息发送部分详细介绍。</li>
<li>Sender sender<br>用于封装消息发送的逻辑，即向 broker 发送消息的处理逻辑。</li>
<li>Thread ioThread<br>用于消息发送的后台线程，一个独立的线程，内部使用 Sender 来向 broker 发送消息。</li>
<li>CompressionType compressionType<br>压缩类型，默认不启用压缩，可通过参数 compression.type 配置。可选值：none、gzip、snappy、lz4、zstd。</li>
<li>Sensor errors<br>错误信息收集器，当成一个 metrics，用来做监控的。</li>
<li>Time time<br>用于获取系统时间或线程睡眠等。</li>
<li>Serializer&lt; K&gt; keySerializer<br>用于对消息的 key 进行序列化。</li>
<li>Serializer&lt; V&gt; valueSerializer<br>对消息体进行序列化。</li>
<li>ProducerConfig producerConfig<br>生产者的配置信息。</li>
<li>long maxBlockTimeMs<br>最大阻塞时间，当生产者使用的缓存已经达到规定值后，此时消息发送会阻塞，通过参数 max.block.ms 来设置最多等待多久。</li>
<li>ProducerInterceptors&lt;K, V&gt; interceptors<br>生产者端的拦截器，在消息发送之前进行一些定制化处理。</li>
<li>ApiVersions apiVersions<br>维护 api 版本的相关元信息，该类只能在 kafka 内部使用。</li>
<li>TransactionManager transactionManager<br>kafka 消息事务管理器。</li>
<li>TransactionalRequestResult initTransactionsResult<br>kafka 生产者事务上下文环境初始结果。</li>
</ul>
<p>经过上面的梳理，详细读者朋友对 KafkaProducer 消息生产者有了一个大概的认识，下一篇会重点介绍消息发送流程。接下来我们以一个简单的示例结束本文的学习。</p>
<h2 id="3、KafkaProducer-简单示例"><a href="#3、KafkaProducer-简单示例" class="headerlink" title="3、KafkaProducer 简单示例"></a>3、KafkaProducer 简单示例</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> persistent.prestige.demo.kafka;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Producer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.RecordMetadata;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Future;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaProducerTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;localhost:9092,localhost:9082,localhost:9072,&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        Producer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;&gt;(props);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">                Future&lt;RecordMetadata&gt;  future = producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">&quot;TOPIC_ORDER&quot;</span>, Integer.toString(i), Integer.toString(i)));</span><br><span class="line">                RecordMetadata recordMetadata = future.get();</span><br><span class="line">                System.out.printf(<span class="string">&quot;offset:&quot;</span> + recordMetadata.offset());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            producer.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>本文就介绍到这里，其主要的目的是了解Kafka 的 Producer，引出后续需要学习的内容，下一篇将重点讲述 Kafka 消息的发送流程，敬请关注。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>源码</tag>
        <tag>KafkaProducer</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 Flink 实现解决数据库分库分表任务拆分</title>
    <url>/posts/57908f75.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、场景描述"><a href="#1、场景描述" class="headerlink" title="1、场景描述"></a>1、场景描述</h2><p>例如订单库进行了分库分表，其示例如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201115203825639.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>现在的需求是希望创建一个任务就将数据同步到MQ集群，而不是为每一个数据库实例单独创建一个任务，将其数据导入到MQ集群，因为同步任务除了库不同之外，表的结构、数据映射规则都是一致的。</p>
<h2 id="2、flinkx-的解决方案详解"><a href="#2、flinkx-的解决方案详解" class="headerlink" title="2、flinkx 的解决方案详解"></a>2、flinkx 的解决方案详解</h2><h4 id="2-1-fink-Stream-API-开发基本流程"><a href="#2-1-fink-Stream-API-开发基本流程" class="headerlink" title="2.1 fink Stream API 开发基本流程"></a>2.1 fink Stream API 开发基本流程</h4><p>使用 Flink Stream API 编程的通用步骤如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201115203839996.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>温馨提示：有关 Stream API 的详细内容将在后续的文章中展开，本文主要是关注 InputFormatSourceFunction，重点关注数据源的拆分。</p>
</blockquote>
<h4 id="2-2-flinkx-Reader-数据源-核心类图"><a href="#2-2-flinkx-Reader-数据源-核心类图" class="headerlink" title="2.2 flinkx Reader(数据源)核心类图"></a>2.2 flinkx Reader(数据源)核心类图</h4><p><img src="https://img-blog.csdnimg.cn/20201115203855115.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在 flinkx 中将不同的数据源封装成一个个 Reader，其基类为 BaseDataReader，上图中主要罗列了如下几个关键的类体系：</p>
<ul>
<li><p>InputFormat<br>flink 核心API，主要是对输入源进行数据切分、读取数据的抽象，其核心接口说明如下：</p>
<ul>
<li><p>void configure(Configuration parameters)<br>对输入源进行额外的配置，该方法在 Input 的生命周期中只需调用一次。</p>
</li>
<li><p>BaseStatistics getStatistics(BaseStatistics cachedStatistics)<br>返回 input 的统计数据，如果不需要统计，在实现的时候可以直接返回 null。</p>
</li>
<li><p>T[] createInputSplits(int minNumSplits)<br>对输入数据进行数据切片，使之支持并行处理，数据切片相关类体系见：InputSplit。</p>
</li>
<li><p>InputSplitAssigner getInputSplitAssigner(T[] inputSplits)<br>获取 InputSplit 分配器，主要是在具体执行任务时如何获取下一个 InputSplit，其声明如下图所示：<br><img src="https://img-blog.csdnimg.cn/20201115204001187.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_right#pic_center" alt="在这里插入图片描述"></p>
</li>
<li><p>void open(T split)<br>根据指定的数据分片 (InputSplit) 打开数据通道。为了加深对该方法的理解，下面看一下 Flinkx 关于 jdbc、es 的写入示例：<br><img src="https://img-blog.csdnimg.cn/20201115203933977.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_right#pic_center" alt="在这里插入图片描述"></p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>boolean reachedEnd()<br>数据是否已结束，在 Flink 中通常 InputFormat 的数据源通常表示有界数据 (DataSet)。</p>
</li>
<li><p>OT nextRecord(OT reuse)</p>
<p>从通道中获取下一条记录。</p>
</li>
<li><p>void close()<br>关闭。</p>
</li>
<li><p>InputSplit<br>数据分片根接口，只定义了如下方法：</p>
<ul>
<li>int getSplitNumber()<br>获取当前分片所在所有分片中的序号。</li>
</ul>
<p>本文先简单介绍一下其通用实现子类：GenericInputSplit。</p>
<ul>
<li>int partitionNumber<br>当前 split 所在的序号</li>
<li>int totalNumberOfPartitions<br>总分片数</li>
</ul>
<p>为了方便理解我们可以思考一下如下场景，对于一个数据量超过千万级别的表，在进行数据切分时可以考虑使用10个线程，即切割成 10分，那每一个数据线程查询数据时可以 id % totalNumberOfPartitions = partitionNumber，进行数据读取。</p>
</li>
<li><p>SourceFunction<br>Flink 源的抽象定义。</p>
<ul>
<li><p>RichFunction<br>富函数，定义了生命周期、可获取运行时环境上下文。</p>
</li>
<li><p>ParallelSourceFunction<br>支持并行的 source function。</p>
</li>
<li><p>RichParallelSourceFunction</p>
<p>并行的富函数</p>
</li>
<li><p>InputFormatSourceFunction</p>
<p>Flink 默认提供的 RichParallelSourceFunction 实现类，可以当成是RichParallelSourceFunction 的通用写法，其内部的数据读取逻辑由 InputFormat 实现。</p>
</li>
</ul>
</li>
<li><p>BaseDataReader</p>
<p>flinkx 数据读取基类，在 flinkx 中将所有的数据读取源封装成 Reader 。</p>
</li>
</ul>
<h4 id="2-3-flinkx-Reader构建-DataStream-流程"><a href="#2-3-flinkx-Reader构建-DataStream-流程" class="headerlink" title="2.3 flinkx Reader构建 DataStream 流程"></a>2.3 flinkx Reader构建 DataStream 流程</h4><p>经过了上面类图的梳理，大家应该 flink 中提到的上述类的含义有了一个大概的理解，但如何运用呢？接下来将通过查阅 flinkx 的 DistributedJdbcDataReader(BaseDataReader的子类)的 readData 调用流程，体会一下其使用方法。<br><img src="https://img-blog.csdnimg.cn/20201115204021519.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>基本遵循创建 InputFormat、从而创建对应的 SourceFunction，然后通过 StreamExecutionEnvironment 的 addSource 方法将 SourceFunction 创建对应的 DataStreamSource。</p>
<a id="more"></a>

<h4 id="2-4-flinkx-针对数据库分库分表任务拆分解决方案"><a href="#2-4-flinkx-针对数据库分库分表任务拆分解决方案" class="headerlink" title="2.4 flinkx 针对数据库分库分表任务拆分解决方案"></a>2.4 flinkx 针对数据库分库分表任务拆分解决方案</h4><p>正如本文开头部分的场景描述那样，某订单系统被设计成4库8表，每一个库(Schema)中包含2个表，如何提高数据导出的性能呢，如何提高数据的抽取性能呢？通常的解决方案如下：</p>
<ol>
<li>首先按库按表进行拆分，即4库8表，可以进行切分8份，每一个数据分配处理一个实例中的1个表。</li>
<li>单个表的数据抽取再进行拆分，例如按ID进行取模进一步分解。</li>
</ol>
<p>flinkx 就是采取上面的策略，我们来看一下其具体做法。<br><img src="https://img-blog.csdnimg.cn/20201115204036878.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step1：首先先根据数据库实例、表进行拆分，按表维度组织成一个 DataSource 列表，后续将基于这个原始数据执行拆分算法。</p>
<p>接下来具体的任务拆分在 InputFormat 中实现，本实例在 DistributedJdbcInputFormat 的 createInputSplitsInternal 中。</p>
<p>DistributedJdbcInputFormat#createInputSplitsInternal </p>
<p><img src="https://img-blog.csdnimg.cn/20201115204049462.png#pic_center" alt="在这里插入图片描述"><br>Step2：根据分区创建 inputSplit 数组，这里分区的概念就相当于上文提到方案中的第一条。</p>
<p>DistributedJdbcInputFormat#createInputSplitsInternal<br><img src="https://img-blog.csdnimg.cn/20201115204101452.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step3：如果指定了 splitKey 的任务拆分算法，首先 DistributedJdbcInputSplit 继承自 GenericInputSplit，总分区数为 numPartitions，然后生成数据库的参数，这里主要是生成 SQL Where 语句中的 splitKey mod totalNumberOfPartitions = partitionNumber，其中 splitKey 为分片键，例如 id，而 totalNumberOfPartitions 表示分区总数，partitionNumber 表示当前分片的序号，通过 SQL 取模函数进行数据拆分。</p>
<p>DistributedJdbcInputFormat#createInputSplitsInternal<br><img src="https://img-blog.csdnimg.cn/20201115204119134.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>Step4：如果未指定表级别的数据拆分键，则拆分策略是对 sourceList 进行拆分，即一些分区处理其中几个表。</p>
<p>关于 flinkx 中关于任务切分的介绍就到这里了。</p>
<h2 id="3、总结"><a href="#3、总结" class="headerlink" title="3、总结"></a>3、总结</h2><p>本文主要是基于 flinkx 介绍 MySQL 分库分表情况下如何基于 flink 进行任务切分，简单介绍了 Flink 中关于基本的编程范式、InputFormat、SourceFunction 的基本类体系。</p>
<blockquote>
<p>温馨提示：本文并没有太详细对 Flink API 进行深入研究，后续会单独对 Flink 内容进行逐一剖析，但 Flink 系列的文章组织，其文章的组织并不具备顺序性，笔者会在不断实践 Flink 的过程中对 FLink 进行剖析。</p>
</blockquote>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>flink</category>
      </categories>
      <tags>
        <tag>flink</tag>
        <tag>分库分表</tag>
        <tag>InputSplit</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 raft 协议的 RocketMQ DLedger 多副本日志复制设计原理</title>
    <url>/posts/9ef855bf.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、RocketMQ-DLedger-多副本日志复制流程图"><a href="#1、RocketMQ-DLedger-多副本日志复制流程图" class="headerlink" title="1、RocketMQ DLedger 多副本日志复制流程图"></a>1、RocketMQ DLedger 多副本日志复制流程图</h2><h3 id="1-1-RocketMQ-DLedger-日志转发-append-请求流程图"><a href="#1-1-RocketMQ-DLedger-日志转发-append-请求流程图" class="headerlink" title="1.1 RocketMQ DLedger 日志转发(append) 请求流程图"></a>1.1 RocketMQ DLedger 日志转发(append) 请求流程图</h3><p><img src="https://img-blog.csdnimg.cn/20190928183406295.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="1-2-RocketMQ-DLedger-日志仲裁流程图"><a href="#1-2-RocketMQ-DLedger-日志仲裁流程图" class="headerlink" title="1.2 RocketMQ DLedger 日志仲裁流程图"></a>1.2 RocketMQ DLedger 日志仲裁流程图</h3><p><img src="https://img-blog.csdnimg.cn/20190928183709529.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="1-3-RocketMQ-DLedger-从节点日志复制流程图"><a href="#1-3-RocketMQ-DLedger-从节点日志复制流程图" class="headerlink" title="1.3 RocketMQ DLedger 从节点日志复制流程图"></a>1.3 RocketMQ DLedger 从节点日志复制流程图</h3><p><img src="https://img-blog.csdnimg.cn/20190928183733569.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="2、RocketMQ-DLedger-多副本日志复制实现要点"><a href="#2、RocketMQ-DLedger-多副本日志复制实现要点" class="headerlink" title="2、RocketMQ DLedger 多副本日志复制实现要点"></a>2、RocketMQ DLedger 多副本日志复制实现要点</h2><p><img src="https://img-blog.csdnimg.cn/20190928183915385.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>上图是一个简易的日志复制的模型：图中客户端向 DLedger 集群发起一个写请求，集群中的 Leader 节点来处理写请求，首先数据先存入 Leader 节点，然后需要广播给它的所有从节点，从节点接收到 Leader 节点的数据推送对数据进行存储，然后向主节点汇报存储的结果，Leader 节点会对该日志的存储结果进行仲裁，如果超过集群数量的一半都成功存储了该数据，主节点则向客户端返回写入成功，否则向客户端写入写入失败。</p>
<p>接下来我们来探讨日志复制的核心设计要点。</p>
<h3 id="2-1-日志编号"><a href="#2-1-日志编号" class="headerlink" title="2.1 日志编号"></a>2.1 日志编号</h3><p>为了方便对日志进行管理与辨别，raft 协议为一条一条的消息进行编号，每一条消息达到主节点时会生成一个全局唯一的递增号，这样可以根据日志序号来快速的判断数据在主从复制过程中数据是否一致，在 DLedger 的实现中对应 DLedgerMemoryStore 中的 ledgerBeginIndex、ledgerEndIndex，分别表示当前节点最小的日志序号与最大的日志序号，下一条日志的序号为 ledgerEndIndex + 1 。</p>
<p>与日志序号还与一个概念绑定的比较紧密，即当前的投票轮次。</p>
<h3 id="2-2-追加与提交机制"><a href="#2-2-追加与提交机制" class="headerlink" title="2.2 追加与提交机制"></a>2.2 追加与提交机制</h3><p>请思考如下问题，Leader 节点收到客户端的数据写入请求后，通过解析请求，提取数据部分，构建日志对象，并生成日志序号，用 seq 表示，然后存储到 Leader 节点中，然后将日志广播(推送)到其从节点，由于这个过程中存在网络时延，如果此时客户端向主节点查询 seq 的日志，由于日志已经存储在 Leader 节点中了，如果直接返回给客户端显然是有问题的，那该如何来避免这种情况的发生呢？</p>
<p>为了解决上述问题，DLedger 的实现(应该也是 raft 协议的一部分)引入了已提交指针(committedIndex)。即当主节点收到客户端请求时，首先先将数据存储，但此时数据是未提交的，此过程可以称之为追加，此时客户端无法访问，只有当集群内超过半数的节点都将日志追加完成后，才会更新 committedIndex 指针，得以是数据能否客户端访问。</p>
<p>一条日志要能被提交的充分必要条件是日志得到了集群内超过半数节点成功追加，才能被认为已提交。</p>
<h3 id="2-3-日志一致性如何保证"><a href="#2-3-日志一致性如何保证" class="headerlink" title="2.3 日志一致性如何保证"></a>2.3 日志一致性如何保证</h3><p>从上文得知，一个拥有3个节点的 DLedger 集群，只要主节点和其中一个从节点成功追加日志，则认为已提交，客户端即可通过主节点访问。由于部分数据存在延迟，在 DLedger 的实现中，读写请求都将由 Leader 节点来负责。那落后的从节点如何再次跟上集群的步骤呢？</p>
<p>要重新跟上主节点的日志记录，首先要知道的是如何判断从节点已丢失数据呢？</p>
<p>DLedger 的实现思路是，DLedger 会按照日志序号向从节点源源不断的转发日志，从节点接收后将这些待追加的数据放入一个待写队列中。关键中的关键：从节点并不是从挂起队列中处理一个一个的追加请求，而是首先查阅从节点当前已追加的最大日志序号，用 ledgerEndIndex 表示，然后尝试追加 (ledgerEndIndex + 1)的日志，用该序号从代写队列中查找，如果该队列不为空，并且没有 (ledgerEndIndex + 1)的日志条目，说明从节点未接收到这条日志，发生了数据缺失。然后从节点在响应主节点 append 的请求时会告知数据不一致，然后主节点的日志转发线程其状态会变更为COMPARE，将向该从节点发送COMPARE命令，用来比较主从节点的数据差异，根据比较的差异重新从主节点同步数据或删除从节点上多余的数据，最终达到一致。于此同时，主节点也会对PUSH超时推送的消息发起重推，尽最大可能帮助从节点及时更新到主节点的数据。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>多副本</tag>
        <tag>主从切换</tag>
        <tag>raft</tag>
        <tag>DLedger</tag>
      </tags>
  </entry>
  <entry>
    <title>复合Lambda表达式</title>
    <url>/posts/4c12373d.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、比较器复合"><a href="#1、比较器复合" class="headerlink" title="1、比较器复合"></a>1、比较器复合</h2><p><img src="https://img-blog.csdnimg.cn/20190515201329740.png" alt="在这里插入图片描述"><br>上面是JDK8中java.util.Comparator接口，相比jdk1.7增加了好多方法，也许你会觉得奇怪，为什么接口中还能定义方法，原因是JDK8中，可以为接口添加默认实现，使用default关键字定义。</p>
<p>例如，我们可以这样定义一个比较器：<br>Comparator&lt; Apple&gt;  c = Comparator.comparing(Apple::getWeight());<br>其等价为：<br>Comparator&lt; Apple&gt;  c = Comparator.comparing(  (a) -&gt; a.getWeight()  );</p>
<p>为什么可以这样写呢？因为Comparator定义了如下静态方法：<br><img src="https://img-blog.csdnimg.cn/20190515202531959.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h4 id="1-1-逆序"><a href="#1-1-逆序" class="headerlink" title="1.1 逆序"></a>1.1 逆序</h4><p>Comparator定义了一个静态方法，reversed，故我们不需要重新再定义一个比较器，我们可以这样就能实现逆序排序：<br>List&lt; Apple&gt; apples = new ArrayList&lt;&gt;();<br>apples.sort(  Comparator.comparing(Apple::getWeight()).reversed()  );</p>
<h4 id="1-2-比较器链"><a href="#1-2-比较器链" class="headerlink" title="1.2 比较器链"></a>1.2 比较器链</h4><p>如果要支持多重排序呢？例如先根据苹果的重量，如果重量相同就按照颜色排序，那如何来实现呢？<br>apples.sort(  Comparator.comparing(Apple::getWeight()).thenComparing(  Apple::getColor()  ) );<br>之所以可以使用上述表达式，是因为Comparator定义了如下方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">default &lt;U extends Comparable&lt;? super U&gt;&gt; Comparator&lt;T&gt; thenComparing( Function&lt;? super T, ? extends U&gt; keyExtractor)</span><br><span class="line">&#123;</span><br><span class="line">    return thenComparing(comparing(keyExtractor));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>温馨提示：Comparator中定义很多thenComparing重载方法,在具体使用过程中，可以先看看其函数声明。</p>
</blockquote>
<a id="more"></a>

<h4 id="2、谓词复合"><a href="#2、谓词复合" class="headerlink" title="2、谓词复合"></a>2、谓词复合</h4><p>提到谓词复合，我们就不得不提Predicate&lt; T &gt;函数式编程接口，其类图如下所示：<br><img src="https://img-blog.csdnimg.cn/20190515203712938.png" alt="在这里插入图片描述"></p>
<ul>
<li>and：与</li>
<li>negate：非</li>
<li>or：或</li>
</ul>
<blockquote>
<p>温馨提示：and 和 or 方法是按照在表达式链中的位置，从左向右确定优先级的。因此， a.or(b).and(c) 可以看作 (a || b) &amp;&amp; c 。</p>
</blockquote>
<p>使用示例：从苹果列表中找出所有红色的，并且重量超过150的苹果：</p>
<p>apples.filter(   (a -&gt; “red”.equals(a.getColor()) ).and(  a -&gt; a.getWeight() &gt; 150  )   );</p>
<p>a -&gt; “red”.equals(a.getColor())  是 (Apple a ) -&gt; “red”.equals(a.getColor())的简写。</p>
<h2 id="3、函数复合"><a href="#3、函数复合" class="headerlink" title="3、函数复合"></a>3、函数复合</h2><p>函数复合，其对应的函数式编程接口为Function&lt;T,R&gt;，其类图如下：<br><img src="https://img-blog.csdnimg.cn/20190515204237920.png" alt="在这里插入图片描述"></p>
<ul>
<li>addThen<br>andThen 方法会返回一个函数，它先对输入应用一个给定函数，再对输出应用另一个函数。<br>例如：<br>Function&lt;Integer, Integer&gt; f = x -&gt; x + 1;<br>Function&lt;Integer, Integer&gt; g = x -&gt; x * 2;<br>Function&lt;Integer, Integer&gt; h = f.andThen(g);<br>int result = h.apply(1);  // 其结果返回4，类似与数学公式  f(g(x))。</li>
<li>compose<br>先把给定的函数用作 compose 的参数里面给的那个函数，然后再把函数本身用于结果。与addThen的函数应用方向相反，同样举例说明如下：<br>Function&lt;Integer, Integer&gt; f = x -&gt; x + 1;<br>Function&lt;Integer, Integer&gt; g = x -&gt; x * 2;<br>Function&lt;Integer, Integer&gt; h = f.compose(g);<br>int result = h.apply(1);  // 其结果返回3，类似与数学公式  g(f(x))。</li>
</ul>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>java8</category>
      </categories>
      <tags>
        <tag>java8</tag>
        <tag>Lambda</tag>
        <tag>函数式编程</tag>
      </tags>
  </entry>
  <entry>
    <title>寻找一把进入 Alibaba Sentinel 的钥匙(文末附流程图)</title>
    <url>/posts/550fbf45.html</url>
    <content><![CDATA[<div id="vip-container"><p>经过前面几篇文章的铺垫，我们正式来探讨 Sentinel 的 entry 方法的实现流程。</p>
<p>即探究进入 Alibaba Sentinel 核心的一把钥匙。<br>无论是从 Sentinel 适配 Dubbo 也好，还是 SphU 源码中的注释中能看出，对一个资源进行限流或熔断，通常需要调用 SphU 的 entry 方法，例如如下示例代码。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	Entry entry = <span class="keyword">null</span>;</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		entry = SphU.entry(<span class="string">&quot;abc&quot;</span>);</span><br><span class="line">	&#125; <span class="keyword">catch</span> (BlockException blockException) &#123;</span><br><span class="line">		<span class="comment">// when goes there, it is blocked</span></span><br><span class="line">		<span class="comment">// add blocked handle logic here</span></span><br><span class="line">	&#125; <span class="keyword">catch</span> (Throwable bizException) &#123;</span><br><span class="line">		<span class="comment">// business exception</span></span><br><span class="line">		Tracer.trace(bizException);</span><br><span class="line">	&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">		<span class="comment">// ensure finally be executed</span></span><br><span class="line">		<span class="keyword">if</span> (entry != <span class="keyword">null</span>)&#123;</span><br><span class="line">			entry.exit();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那本文将来探讨 SphU.entry 的实现原理。SphU 类定义了很多 entry 重载方法，我们就以下面这个方法为例来探究其实现原理。</p>
<h2 id="1、SphU-entry-流程分析"><a href="#1、SphU-entry-流程分析" class="headerlink" title="1、SphU.entry 流程分析"></a>1、SphU.entry 流程分析</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Entry <span class="title">entry</span><span class="params">(String name, EntryType type, <span class="keyword">int</span> count, Object... args)</span> <span class="keyword">throws</span>  BlockException </span>&#123;  <span class="comment">// @1</span></span><br><span class="line">	<span class="keyword">return</span> Env.sph.entry(name, type, count, args);  <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：我们先来简单介绍其核心参数的含义：</p>
<ul>
<li>String name<br>资源的名称。</li>
<li>EntryType type<br>进入资源的方式，主要包含 EntryType.IN、EntryType.OUT。</li>
<li>int count<br>可以理解为本次进入需要消耗的“令牌数”。</li>
<li>Object… args<br>其他参数。</li>
</ul>
<p>代码@2：调用 Env.sph.entry 的方法，其最终会调用 CtSph 的 entry 方法。</p>
<p>接下来我们将重点查看 CtSph 的 entry 方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Entry <span class="title">entry</span><span class="params">(String name, EntryType type, <span class="keyword">int</span> count, Object... args)</span> <span class="keyword">throws</span> BlockException </span>&#123;</span><br><span class="line">    StringResourceWrapper resource = <span class="keyword">new</span> StringResourceWrapper(name, type); <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span> entry(resource, count, args);  <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：由于该方法用来表示资源的方式为一个字符串，故创建一个 StringResourceWrapper  对象来表示一个 Sentinel 中的资源，另外一个实现为 MethodResourceWrapper，用来表示方法类的资源。</p>
<p>代码@2：继续调用 CtSph 的另外一个 entry 重载方法，最终会调用 entryWithPriority 方法。</p>
<p>CtSph#entryWithPriority </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Entry <span class="title">entryWithPriority</span><span class="params">(ResourceWrapper resourceWrapper, <span class="keyword">int</span> count, <span class="keyword">boolean</span> prioritized, Object... args)</span> <span class="comment">// @1</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> BlockException </span>&#123;</span><br><span class="line">    Context context = ContextUtil.getContext();  <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">if</span> (context <span class="keyword">instanceof</span> NullContext) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> CtEntry(resourceWrapper, <span class="keyword">null</span>, context); </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (context == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// Using default context.</span></span><br><span class="line">        context = InternalContextUtil.internalEnter(Constants.CONTEXT_DEFAULT_NAME);</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="keyword">if</span> (!Constants.ON) &#123;   <span class="comment">// @3</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> CtEntry(resourceWrapper, <span class="keyword">null</span>, context);</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    ProcessorSlot&lt;Object&gt; chain = lookProcessChain(resourceWrapper);   <span class="comment">// @4</span></span><br><span class="line">    <span class="keyword">if</span> (chain == <span class="keyword">null</span>) &#123;</span><br><span class="line">	    <span class="keyword">return</span> <span class="keyword">new</span> CtEntry(resourceWrapper, <span class="keyword">null</span>, context);</span><br><span class="line">    &#125;</span><br><span class="line">    Entry e = <span class="keyword">new</span> CtEntry(resourceWrapper, chain, context);     <span class="comment">// @5</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">	    chain.entry(context, resourceWrapper, <span class="keyword">null</span>, count, prioritized, args);   <span class="comment">// @6</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (BlockException e1) &#123;                                                                    <span class="comment">// @7</span></span><br><span class="line">	    e.exit(count, args);</span><br><span class="line">        <span class="keyword">throw</span> e1;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e1) &#123;</span><br><span class="line">        RecordLog.info(<span class="string">&quot;Sentinel unexpected exception&quot;</span>, e1);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> e;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：我们先来介绍一下该方法的参数：</p>
<ul>
<li>ResourceWrapper resourceWrapper<br>资源的包装类型，可以是字符串类型的资源描述，也可以是方法类的。</li>
<li>int count<br>此次需要消耗的令牌。</li>
<li>boolean prioritized<br>是否注重优先级。</li>
<li>Object… args<br>额外参数。</li>
</ul>
<p>代码@2：获取方法调用的上下文环境，上下环境对象存储在线程本地变量：ThreadLocal 中，这里先“剧透”一下，上下文环境中存储的是整个调用链，后续文章会重点介绍。</p>
<p>代码@3：Sentinel 提供一个全局关闭的开关，如果关闭，返回的 CtEntry 中的 chain 为空，从这里可以看出，如果 chain 为空，则不会触发 Sentinel 流控相关的逻辑，从侧面也反应了该属性的重要性。</p>
<p>代码@4：为该资源加载处理链链，这里是最最重要的方法，将在下文详细介绍。</p>
<p>代码@5：根据资源ID、处理器链、上下文环境构建 CtEntry 对象。</p>
<p>代码@6：调用 chain 的 entry 方法。</p>
<p>代码@7：如果出现 BlockException ，调用 CtEntry 的 exit 方法。</p>
<h2 id="2、Sentienl-ProcessorSlot-处理链"><a href="#2、Sentienl-ProcessorSlot-处理链" class="headerlink" title="2、Sentienl ProcessorSlot 处理链"></a>2、Sentienl ProcessorSlot 处理链</h2><p>我们接下来重点看一下 lookProcessChain 方法的实现细节。<br>CtSph#lookProcessChain</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">ProcessorSlot&lt;Object&gt; <span class="title">lookProcessChain</span><span class="params">(ResourceWrapper resourceWrapper)</span> </span>&#123;</span><br><span class="line">    ProcessorSlotChain chain = chainMap.get(resourceWrapper);  <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (chain == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (LOCK) &#123;</span><br><span class="line">	    chain = chainMap.get(resourceWrapper);</span><br><span class="line">            <span class="keyword">if</span> (chain == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">// Entry size limit.</span></span><br><span class="line">                <span class="keyword">if</span> (chainMap.size() &gt;= Constants.MAX_SLOT_CHAIN_SIZE) &#123;        <span class="comment">// @2</span></span><br><span class="line">		    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                chain = SlotChainProvider.newSlotChain();                                      <span class="comment">// @3</span></span><br><span class="line">                Map&lt;ResourceWrapper, ProcessorSlotChain&gt; newMap = <span class="keyword">new</span> HashMap&lt;ResourceWrapper, ProcessorSlotChain&gt;(</span><br><span class="line">                        chainMap.size() + <span class="number">1</span>);</span><br><span class="line">                newMap.putAll(chainMap);</span><br><span class="line">                newMap.put(resourceWrapper, chain);</span><br><span class="line">                chainMap = newMap;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> chain;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：chainMap 一个全局的缓存表，即同一个资源 ResourceWrapper (同一个资源名称) 会共同使用同一个 ProcessorSlotChain ，即不同的线程在访问同一个资源保护的代码时，这些线程将共同使用 ProcessorSlotChain  中的各个 ProcessorSlot 。注意留意 ResourceWrapper 的 equals 方法与 hashCode 方法。</p>
<p>代码@2：这里重点想突出，如果同时在进入的资源个数超过 MAX_SLOT_CHAIN_SIZE，默认为 6000，会返回 null，则不对本次请求执行限流，熔断计算，而是直接跳过，这个点还是值得我们注意的。</p>
<p>代码@3：通过 SlotChainProvider 创建对应的处理链。</p>
<p>SlotChainProvider#newSlotChain</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ProcessorSlotChain <span class="title">newSlotChain</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (slotChainBuilder != <span class="keyword">null</span>) &#123;     <span class="comment">// @1</span></span><br><span class="line">		<span class="keyword">return</span> slotChainBuilder.build();</span><br><span class="line">        &#125;</span><br><span class="line">	slotChainBuilder = SpiLoader.loadFirstInstanceOrDefault(SlotChainBuilder.class, DefaultSlotChainBuilder.class);   <span class="comment">// @2</span></span><br><span class="line">	<span class="keyword">if</span> (slotChainBuilder == <span class="keyword">null</span>) &#123;                                                                                                                                        <span class="comment">// @3</span></span><br><span class="line">		RecordLog.warn(<span class="string">&quot;[SlotChainProvider] Wrong state when resolving slot chain builder, using default&quot;</span>);</span><br><span class="line">                slotChainBuilder = <span class="keyword">new</span> DefaultSlotChainBuilder();</span><br><span class="line">         &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		RecordLog.info(<span class="string">&quot;[SlotChainProvider] Global slot chain builder resolved: &quot;</span></span><br><span class="line">                + slotChainBuilder.getClass().getCanonicalName());</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">return</span> slotChainBuilder.build();                                                                                                                                   <span class="comment">// @4</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果 slotChainBuilder 不为空，则直接调用其 build 方法构建处理器链。</p>
<p>代码@2：如果为空，首先通过 JAVA 的 SPI 机制，尝试加载自定义的 Slot Chain 构建器实现类。如果需要实现自定义的 Chain 构建器，只需实现  SlotChainBuilder 接口，然后将其放在 classpath 下即可，如果存在多个，以找到的第一个为准。</p>
<p>代码@3：如果从 SPI 机制中加载失败，则使用默认的构建器：DefaultSlotChainBuilder。</p>
<p>代码@4：调用其 build 方法构造 Slot Chain。</p>
<p>那接下来我们先来看看 Sentinel 的 SlotChainBuilder 类体系，然后看看 DefaultSlotChainBuilder 的 build 方法。</p>
<h4 id="2-1-SlotChainBuilder-类体系"><a href="#2-1-SlotChainBuilder-类体系" class="headerlink" title="2.1 SlotChainBuilder  类体系"></a>2.1 SlotChainBuilder  类体系</h4><p><img src="https://img-blog.csdnimg.cn/2020010513491784.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>主要有三个实现类，对应热点、接口网关以及普通场景。我们接下来将重点介绍 DefaultSlotChainBuilder ，关于热点限流与网关限流将在后面的文章中详细探讨。</p>
<h4 id="2-2-DefaultSlotChainBuilder-build-方法"><a href="#2-2-DefaultSlotChainBuilder-build-方法" class="headerlink" title="2.2 DefaultSlotChainBuilder build 方法"></a>2.2 DefaultSlotChainBuilder build 方法</h4><p>DefaultSlotChainBuilder#build</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DefaultSlotChainBuilder</span> <span class="keyword">implements</span> <span class="title">SlotChainBuilder</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProcessorSlotChain <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ProcessorSlotChain chain = <span class="keyword">new</span> DefaultProcessorSlotChain();</span><br><span class="line">        chain.addLast(<span class="keyword">new</span> NodeSelectorSlot());</span><br><span class="line">        chain.addLast(<span class="keyword">new</span> ClusterBuilderSlot());</span><br><span class="line">        chain.addLast(<span class="keyword">new</span> LogSlot());</span><br><span class="line">        chain.addLast(<span class="keyword">new</span> StatisticSlot());</span><br><span class="line">        chain.addLast(<span class="keyword">new</span> AuthoritySlot());</span><br><span class="line">        chain.addLast(<span class="keyword">new</span> SystemSlot());</span><br><span class="line">        chain.addLast(<span class="keyword">new</span> FlowSlot());</span><br><span class="line">        chain.addLast(<span class="keyword">new</span> DegradeSlot());</span><br><span class="line">        <span class="keyword">return</span> chain;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>就问大家激不激动，开不开心，从这些 Slot 的名字基本就能得出其含义。</p>
<ul>
<li>NodeSelectorSlot<br>主要用于构建调用链。</li>
<li>ClusterBuilderSlot<br>用于集群限流、熔断。</li>
<li>LogSlot<br>用于记录日志。</li>
<li>StatisticSlot<br>用于实时收集实时消息。</li>
<li>AuthoritySlot<br>用于权限校验的。</li>
<li>SystemSlot<br>用于验证系统级别的规则。</li>
<li>FlowSlot<br>实现限流机制。</li>
<li>DegradeSlot<br>实现熔断机制。</li>
</ul>
<a id="more"></a>

<blockquote>
<p>经过上面的方法，就构建一条 Slot 处理链。其实到这里我们就不难发现，调用 ProcessorSlotChain 的 entry 方法，就是依次调用这些 slot 的方法。关于 ProcessorSlotChain 的类层次结构就不再多说明了，其实现比较简单，大家如果有兴趣的话，可以关注这部分的实现，这里代表一类场景：一对多、责任链的设计模式。</p>
<h2 id="3、Sentinel-SphU-entry-处理流程图"><a href="#3、Sentinel-SphU-entry-处理流程图" class="headerlink" title="3、Sentinel SphU.entry 处理流程图"></a>3、Sentinel SphU.entry 处理流程图</h2><p>经过上面的探索，我们其实已经找到了 Sentinel 的关于限流、熔断核心处理逻辑的入口，就是 FlowSlot、DegradeSlot。接下来我们以一张流程图来结束本文的讲解。<br><img src="https://img-blog.csdnimg.cn/20200105135205468.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>本文的目的就是打开 Sentinel 的大门，即寻找实时数据收集、限流、熔断实现机制的入口，从而正式探寻 Sentienl 的核心实现原理，更多精彩请继续期待该专栏的后续内容。</p>
</blockquote>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
      </tags>
  </entry>
  <entry>
    <title>快速排序算法java版实现</title>
    <url>/posts/42760d48.html</url>
    <content><![CDATA[<div id="vip-container"><p>快速排序思想：从待排序序列中找到一个关键字（默认为第一个元素） 然后将比关键字少的数据排列在左边，大于关键字的排在右边，然后对关键字左右两边的序列继续上面步骤，直至关键字两边的序列都已经排好序。具体算法如下：</p>
<p>设要排序的数组是A[0]……A[N-1]，首先任意选取一个数据（通常选用数组的第一个数）作为关键数据，</p>
<p> 然后将所有比它小的数都放到它前面，所有比它大的数都放到它后面，这个过程称为一趟快速排序。<br> 值得注意的是，快速排序不是一种稳定的排序算法，也就是说，多个相同的值的相对位置也许会在算法结束时产生变动。<br> 一趟快速排序的算法是：<br> 1）设置两个变量i、j，排序开始的时候：i=0，j=N-1；<br> 2）以第一个数组元素作为关键数据，赋值给key，即key=A[0]；<br> 3）从j开始向前搜索，即由后开始向前搜索(j–)，找到第一个小于key的值A[j]，将A[j]和A[i]互换；<br> 4）从i开始向后搜索，即由前开始向后搜索(i++)，找到第一个大于key的A[i]，将A[i]和A[j]互换；<br> 5）重复第3、4步，直到i=j； (3,4步中，没找到符合条件的值，即3中A[j]不小于key,<br> 4中A[i]不大于key的时候改变j、i的值，使得j=j-1，i=i+1，直至找到为止。</p>
<p> 找到符合条件的值，进行交换的时候i， j指针位置不变。另外，i==j这一过程一定正好是i+或j-完成的时候，此时令循环结束）。</p>
<blockquote>
<p>温馨提示：上述算法的描述来源与百度，大家也可以按照上面的算法，用自己熟悉的语言尝试实现一遍。</p>
</blockquote>
<p>一言不合继续用代码说话。</p>
<a id="more"></a>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> persistent.prestige.console.algorithm;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * 设要排序的数组是A[0]……A[N-1]，首先任意选取一个数据（通常选用数组的第一个数）作为关键数据，</span></span><br><span class="line"><span class="comment"> * 然后将所有比它小的数都放到它前面，所有比它大的数都放到它后面，这个过程称为一趟快速排序。</span></span><br><span class="line"><span class="comment"> * 值得注意的是，快速排序不是一种稳定的排序算法，也就是说，多个相同的值的相对位置也许会在算法结束时产生变动。</span></span><br><span class="line"><span class="comment"> * 一趟快速排序的算法是：</span></span><br><span class="line"><span class="comment"> * 1）设置两个变量i、j，排序开始的时候：i=0，j=N-1；</span></span><br><span class="line"><span class="comment"> * 2）以第一个数组元素作为关键数据，赋值给key，即key=A[0]；</span></span><br><span class="line"><span class="comment"> * 3）从j开始向前搜索，即由后开始向前搜索(j--)，找到第一个小于key的值A[j]，将A[j]和A[i]互换；</span></span><br><span class="line"><span class="comment"> * 4）从i开始向后搜索，即由前开始向后搜索(i++)，找到第一个大于key的A[i]，将A[i]和A[j]互换；</span></span><br><span class="line"><span class="comment"> * 5）重复第3、4步，直到i=j； (3,4步中，没找到符合条件的值，即3中A[j]不小于key,</span></span><br><span class="line"><span class="comment"> * 4中A[i]不大于key的时候改变j、i的值，使得j=j-1，i=i+1，直至找到为止。</span></span><br><span class="line"><span class="comment"> * 找到符合条件的值，进行交换的时候i， j指针位置不变。另外，i==j这一过程一定正好是i+或j-完成的时候，此时令循环结束）。</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> lenovo</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuickSort</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">quickSort</span><span class="params">(<span class="keyword">int</span>[] a, <span class="keyword">int</span> low, <span class="keyword">int</span> hign )</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span>(hign &lt;= low) <span class="keyword">return</span>; <span class="comment">// 如果hign 小于等于 low ,说明待排序队列只包含一个元素，无法再排序</span></span><br><span class="line">		<span class="keyword">int</span> keyIdx = asort(a, low, hign); </span><br><span class="line">		<span class="keyword">if</span>( ! (keyIdx == low &amp;&amp; low == hign) ) &#123; <span class="comment">// keyIdx == low &amp;&amp; low == hign 则说明不可分</span></span><br><span class="line">			<span class="keyword">if</span>(keyIdx == low ) &#123; <span class="comment">//说明左边已经排好序了</span></span><br><span class="line">				quickSort(a, low + <span class="number">1</span>, hign);</span><br><span class="line">			&#125; <span class="keyword">else</span> <span class="keyword">if</span>  (keyIdx == hign ) &#123;  <span class="comment">// 说明右边已经排序好了</span></span><br><span class="line">				quickSort(a, low, hign -<span class="number">1</span>);</span><br><span class="line">			&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				quickSort(a, low , keyIdx -<span class="number">1</span>); <span class="comment">// 关键字左边排序</span></span><br><span class="line">				quickSort(a, keyIdx + <span class="number">1</span>, hign); <span class="comment">// 关键字右边排序</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 快速排序   一趟排序算法实现</span></span><br><span class="line"><span class="comment">	 * 一趟快速排序的算法是：(来源于百度百科)</span></span><br><span class="line"><span class="comment">	 * 1）设置两个变量i、j，排序开始的时候：i=0，j=N-1；</span></span><br><span class="line"><span class="comment">	 * 2）以第一个数组元素作为关键数据，赋值给key，即key=A[0]；</span></span><br><span class="line"><span class="comment">	 * 3）从j开始向前搜索，即由后开始向前搜索(j--)，找到第一个小于key的值A[j]，将A[j]和A[i]互换；</span></span><br><span class="line"><span class="comment">	 * 4）从i开始向后搜索，即由前开始向后搜索(i++)，找到第一个大于key的A[i]，将A[i]和A[j]互换；</span></span><br><span class="line"><span class="comment">	 * 5）重复第3、4步，直到i=j； (3,4步中，没找到符合条件的值，即3中A[j]不小于key,</span></span><br><span class="line"><span class="comment">	 * 4中A[i]不大于key的时候改变j、i的值，使得j=j-1，i=i+1，直至找到为止。</span></span><br><span class="line"><span class="comment">	 * 找到符合条件的值，进行交换的时候i， j指针位置不变。另外，i==j这一过程一定正好是i+或j-完成的时候，此时令循环结束）。</span></span><br><span class="line"><span class="comment">	 * </span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> a			待排序数组</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> low       待排序起始下标</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> hign      待排序结束下标  (low hign) 限制排序数组范围</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span>          本轮排序后，关键字所在位置(下标)</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">asort</span><span class="params">(<span class="keyword">int</span>[] a, <span class="keyword">int</span> low, <span class="keyword">int</span> hign)</span> </span>&#123;</span><br><span class="line"> 		<span class="keyword">int</span> key = a[low];</span><br><span class="line">		loop :</span><br><span class="line">		<span class="keyword">while</span> (<span class="keyword">true</span>) &#123; <span class="comment">// low 与 hign 相等时退出</span></span><br><span class="line">			<span class="keyword">while</span>( hign &gt; <span class="number">0</span> ) &#123;</span><br><span class="line">				<span class="keyword">if</span>( a[hign] &lt; key ) &#123;</span><br><span class="line">					swap(a, low, hign);   <span class="comment">// 从后向前找，找到第一个比关键字小的元素后交换元素后跳出本次比较</span></span><br><span class="line">					<span class="keyword">break</span>;</span><br><span class="line">				&#125;</span><br><span class="line">				hign --;</span><br><span class="line">				<span class="keyword">if</span>(low == hign) <span class="keyword">break</span> loop;</span><br><span class="line">			&#125;</span><br><span class="line">			low ++; </span><br><span class="line">			<span class="keyword">if</span>(low == hign) <span class="keyword">break</span> loop;</span><br><span class="line">			<span class="keyword">while</span>( low &lt; a.length ) &#123;</span><br><span class="line">				<span class="keyword">if</span>( a[low] &gt; key ) &#123;   <span class="comment">// 从前向后找，找到第一个比关键字大的元素时交换元素后跳出本次比较</span></span><br><span class="line">					swap(a, low, hign);</span><br><span class="line">					<span class="keyword">break</span>;</span><br><span class="line">				&#125;</span><br><span class="line">				low ++; </span><br><span class="line">				<span class="keyword">if</span>(low == hign) <span class="keyword">break</span> loop;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> low;<span class="comment">//关键字所在的位置</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 交换数组中两个元素的位置</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> a</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> i</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> j</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span>[] a, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">int</span> tmp = a[i];</span><br><span class="line">		a[i] = a[j];</span><br><span class="line">		a[j] = tmp;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		<span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">		System.out.println(<span class="string">&quot;待排序数据：(5,8,2,10,6,9,21,18,19,7)&quot;</span>);</span><br><span class="line">		<span class="keyword">int</span>[] a = <span class="keyword">new</span> <span class="keyword">int</span>[] &#123;<span class="number">5</span>,<span class="number">8</span>,<span class="number">2</span>,<span class="number">10</span>,<span class="number">6</span>,<span class="number">9</span>,<span class="number">21</span>,<span class="number">18</span>,<span class="number">19</span>,<span class="number">7</span>&#125;;</span><br><span class="line">		quickSort(a, <span class="number">0</span>, a.length -<span class="number">1</span>);</span><br><span class="line">		System.out.println(<span class="string">&quot;排序后结果：&quot;</span>);</span><br><span class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i : a) &#123;</span><br><span class="line">			System.out.print(i + <span class="string">&quot; &quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		System.out.println(<span class="string">&quot; ---------------------&quot;</span>);</span><br><span class="line">		System.out.println(<span class="string">&quot;待排序数据：(5,8,2,10,5,9,21,18,8,7)&quot;</span>);</span><br><span class="line">		a = <span class="keyword">new</span> <span class="keyword">int</span>[] &#123;<span class="number">5</span>,<span class="number">8</span>,<span class="number">2</span>,<span class="number">10</span>,<span class="number">5</span>,<span class="number">9</span>,<span class="number">21</span>,<span class="number">18</span>,<span class="number">8</span>,<span class="number">7</span>&#125;;</span><br><span class="line">		quickSort(a, <span class="number">0</span>, a.length -<span class="number">1</span>);</span><br><span class="line">		System.out.println(<span class="string">&quot;排序后结果：&quot;</span>);</span><br><span class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i : a) &#123;</span><br><span class="line">			System.out.print(i + <span class="string">&quot; &quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>我的另一种参与 RocketMQ 开源社区的方式</title>
    <url>/posts/97996927.html</url>
    <content><![CDATA[<div id="vip-container"><p>首先先“SHOW”一波我在 RocketMQ 开源社区所获得的成就：2019年RocketMQ社区授予我优秀布道师荣誉称号，证书很高大上，奖品丰厚哦。<br><img src="https://img-blog.csdnimg.cn/20200608190532198.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>布道师是什么？开源项目不是都在追求如何成为一名 Committer？其实这个就是参与开源项目的两种不同方式。如何参与一个开源项目，容我慢慢道来。</p>
<p>@<a href="%E6%9C%AC%E8%8A%82%E7%9B%AE%E5%BD%95">TOC</a></p>
<h2 id="1、与-RocketMQ-相识、相知到“在一起”"><a href="#1、与-RocketMQ-相识、相知到“在一起”" class="headerlink" title="1、与 RocketMQ 相识、相知到“在一起”"></a>1、与 RocketMQ 相识、相知到“在一起”</h2><p>在2017年听到阿里巴巴将 RocketMQ 捐赠给 Apache基金会成为 Apache 的顶级项目，我内心是无比激动，因为终于可以一睹一款高性能的消息中间件的实现原理。</p>
<p>通过阅读 RocketMQ 官方文档，以下几个特别的点吸引了我的注意，让我下定决心深入研究一番。</p>
<ul>
<li>RocketMQ 为什么性能高效，到底运用了什么“厉害”的技术</li>
<li>RocketMQ 如何实现刷盘（可以类比一下数据库方面的刷盘、redo、undo日志）</li>
<li>RocketMQ 文件存储设计理念、基于文件的 Hash 索引是怎么实现的</li>
<li>定时消息、消息过滤等实现原理</li>
<li>如何进行网络编程（Netty实战）</li>
</ul>
<p>心动不如行动，下定决心后便开始了我的源码分析 RocketMQ 之旅，大概在4个多月的时间中连续发表了30余篇文章，从 Nameserver、消息发送高可用设计、消息存储、消息消费、消息过滤、事务消息等各个方面对其进行了体系化的剖析，边写边分享，边分享边传播，终于得到了机械工业出版社华章分社的杨福川老师的认可，邀请我出书。</p>
<p>在杨老师和张工的帮助与指点下，经过将近半年的努力，书稿基本完稿。</p>
<p>由于我当时是一位名不经传的新人，按照出版行业的惯例，需要找一些该领域内专家大牛帮忙做序或写写推荐语。</p>
<p>当时我是初生牛犊不怕虎，蹦出了一个非常大胆的想法，是不是可以联系 RocketMQ 官方的一些大佬，最终我直接锁定了 RocketMQ 创始人冯嘉大神，希望他能帮我作序推荐。</p>
<p>令人惊喜的是冯嘉大神非常平易见人，得知我的来意后，他说了这样一句话：“我是非常愿意为写书的朋友作序，但需要评估一下书稿的质量，如果质量OK，非常愿意效劳”。</p>
<p>我备受鼓舞，在和出版社初步沟通后，将试读稿件再加上消息存储整章的内容发给冯嘉大神后，经冯嘉大神认真审稿后，决定帮忙推荐作序，真的让我备受鼓舞。</p>
<p>随着《RocketMQ技术内幕》一书的正式出版上市，并得到广大读者朋友的认可，与官方的联系也越来越多，后面在 RocketMQ 中国社区负责人青峰大佬的筹备下，我还参与了 RocketMQ 官方社区的源码解析直播活动、官方文档审稿等工作，并在社区得到了不错的反响。</p>
<p><strong>说到这里大家是不是觉得非常奇怪，是不是都认为你只是在写文章，写书，没有真正参与开源社区呀，没有贡献代码，这个算哪门子参与开源社区？</strong></p>
<p>其实我一开始连我自己也没有意识到我正在参与一个开源项目，直到我在冯嘉大神为我写的序言中看到他给了我一个新的称号：<strong>RocketMQ布道师</strong>，从而才真正了解到参与开源的另外一种方式：做一个开源项目的传播者，让更多人更容易的使用它，即降低大众对它的使用门槛。</p>
<p>我后面也特意去查了一下开源项目的布道师是一个什么的角色，或者说什么样的人能被称之为布道师。个人的理解就是首先认可并热爱这项技术，并持续输出高质量的技术类文章、文档等有助于技术传播的素材，让更多人更容易理解并使用它。</p>
<p>有了新的称号，那就得更加努力，朝着优秀努力，在2019年我又陆续发表了20几篇关于RocketMQ相关的文章，这些文章含金量极高，不仅及时跟进了RocketMQ4.3之后的新特性：消息轨迹、ACL、主从切换等机制，更是发表了数篇实战类文章，详细指出在生产环境下一些使用误区，更是输出了几篇生产环境真实故障与解决方案。最终于2019年 RocketMQ 官方社区授予我优秀布道师荣誉称号。</p>
<p>RocketMQ 成就了现在的我，我也会继续努力，为传播RocketMQ尽一份力所能及的力量。2020年，继续努力。</p>
<h2 id="2、如何成为开源项目的-Committer"><a href="#2、如何成为开源项目的-Committer" class="headerlink" title="2、如何成为开源项目的 Committer"></a>2、如何成为开源项目的 Committer</h2><p>有一些粉丝在问我，您对 RocketMQ 研究的这么深入，为什么不考虑贡献代码，成为一名 Committer 呢？这是因为参与开源项目需要具备一些基本条件，当下我的实际情况不符合，那成为一个开源项目的 Committer 有些什么条件呢？</p>
<a id="more"></a>

<ul>
<li><p>扎实的Java基础功底<br>一个开源项目的底层都会涉及到存储，这就要求具备一定的数据结构基础，JAVA集合框架中的类自然成为了我们突破数据结构最好的老师，其次是java并发，即多线程、并发容器、锁等课题，这方面可以好好学习一下JUC框架。最后最好是具备一些网络方面的知识，例如NIO、Netty。</p>
</li>
<li><p>持续输出能力<br>成为一个开源项目的 contributions 非常容易，提交一个PR并被通过即可，甚至于提交一个文档被接受也同样可以，难的是持续贡献，最终被开源项目的PMC认为对该项目有着突出贡献。</p>
</li>
</ul>
<p>我比较“苦逼”，在带娃方面我的资源只有我和我老婆，父母在老家无法分身，故下班后我没有连续的空闲时间专心投入一项任务中，而开源最需要的是精益求精，不只是需要完成功能，而是要编写结构优良的代码，设计所占据的时间比代码开发时间要多的多，故我个人认为我暂时不方便走代码贡献这条道路。但我零碎时间还是充足的，故现阶段我会好好利用这些零碎时间，继续通过写文章的方式为开源项目贡献自己的一份力量。</p>
<p><strong>接下来我们回到本节的主题，那如何参与一个开源项目呢？</strong></p>
<p>在参与一个开源项目之前，我觉得第一个最基本的步骤还是要打牢基础，这里的基础至少要包括 JAVA集合、JAVA并发（JUC)这两项，这是最最基本的，至少要阅读其源码，理解其设计理念，至于NIO，Netty 这些可以后续在需要使用时再去专门学习，有针对性的学习，结合使用需求，或许学习动力更强劲，学习效率更高效。</p>
<p>当具备一定的基础后，如何从零开始参与进开源项目呢？通常有如下几个方法：</p>
<ul>
<li>看看官方文档，特别是设计手册，从整体上把握其设计理念。</li>
<li>写写源码分析类文章，从整体上把控这个框架，这个花费时间较多，如果框架正在起步阶段，不建议该方法；如果框架比较成熟，非常建议采用该方法。</li>
<li>尝试看看开源项目中的 issues，看能不能解决，从问题入手，快速融入该项目。</li>
<li>尝试写写单元测试用例，测试驱动开发，借此学习该框架。</li>
</ul>
<p>后面的事情就是坚持不懈，朝着目标不断前进，中途可以放慢速度，但千万别放弃，因为只有坚持，才能胜利，只要前进，就离目标更近。</p>
<p>参与开源，一个最基本的条件是拥有大量的连续时间，想要成为一个开源框架的 Committer ,唯有坚持不懈，持续投入，持续产出。</p>
<p><strong>布道师与代码贡献者都是参与开源项目的方式，大家可以结合自己的实际情况选择不同的方式，都能为一个开源社区贡献自己的力量，也能得到开源社区的认可，间接打造自身影响力，最终助力职场。</strong></p>
<p>最后再次感谢RocketMQ社区对我的鼓励，最后用我的一句座右铭与大家共勉：心动不如行动，越努力越幸运，唯有坚持不懈。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>程序人生</tag>
        <tag>rocketmq</tag>
        <tag>开源</tag>
      </tags>
  </entry>
  <entry>
    <title>排序二叉树JAVA版实现</title>
    <url>/posts/3b6094a6.html</url>
    <content><![CDATA[<div id="vip-container"><p>1、排序二叉树特点</p>
<ul>
<li>根节点的值大于等于左子树的节点</li>
<li>根节点的值小于等于它右子树的节点。</li>
</ul>
<p>2、遍历二叉树的方法</p>
<ul>
<li>先序遍历：先遍历根节点，然后遍历左子树，再遍历右子树</li>
<li>中序遍历：先遍历左子树，然后遍历根节点，再遍历右子树</li>
<li>后续遍历  </li>
</ul>
<p><strong>如果要保证节点从小到大排序，采用中序遍历</strong>；</p>
<p>一言不合就写代码实现，提供详细的可视化角度（代码可运行）。</p>
<p>目前代码中，已经实现 新增单个元素、删除单个元素、中序遍历整颗树。</p>
<a id="more"></a>


<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package persistent.prestige.study.datastructures.tree;</span><br><span class="line"></span><br><span class="line">import java.io.Serializable;</span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.Collections;</span><br><span class="line">import java.util.Comparator;</span><br><span class="line">import java.util.List;</span><br><span class="line">&#x2F;**</span><br><span class="line"> * 二叉树学习</span><br><span class="line"> * </span><br><span class="line">在数据结构里，</span><br><span class="line">就是对一棵二叉树所有结点的访问</span><br><span class="line">前序遵循“根左右”</span><br><span class="line">中序遵循“左根右”</span><br><span class="line">后序遵循“左右根”</span><br><span class="line">根：根节点</span><br><span class="line">左：左子女</span><br><span class="line">右：右子女</span><br><span class="line">如：一棵二叉树 ：</span><br><span class="line">           A</span><br><span class="line">          &#x2F; \</span><br><span class="line">         B   C</span><br><span class="line">        &#x2F; \ </span><br><span class="line">       D   E</span><br><span class="line">前序访问顺序就是：ABDEC（根一定第一个）</span><br><span class="line">中序访问顺序就是：DBEAC（根一定在中间）</span><br><span class="line">后序访问顺序就是：DEBCA（根一定在最后）</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> * </span><br><span class="line"> * </span><br><span class="line"> * </span><br><span class="line"> * @author prestigeding@126.com</span><br><span class="line"> *</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class BinaryTree&lt;E&gt; implements Serializable &#123;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * </span><br><span class="line">	 *&#x2F;</span><br><span class="line">	private static final long serialVersionUID &#x3D; -3970337667739333043L;</span><br><span class="line">	</span><br><span class="line">	private Comparator&lt;E&gt; comparator;</span><br><span class="line"></span><br><span class="line">	private TreeNode&lt;E&gt; root;</span><br><span class="line"></span><br><span class="line">	public BinaryTree() &#123;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public BinaryTree(Comparator&lt;E&gt; comparator) &#123;</span><br><span class="line">		super();</span><br><span class="line">		this.comparator &#x3D; comparator;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * 增加元素</span><br><span class="line">	 * @param e</span><br><span class="line">	 * @return</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	public boolean add(E e) &#123;</span><br><span class="line">		if(e &#x3D;&#x3D; null) return false;</span><br><span class="line">		</span><br><span class="line">		if(root &#x3D;&#x3D; null ) &#123;</span><br><span class="line">			root &#x3D; new TreeNode&lt;E&gt;(e, null);</span><br><span class="line">			return true;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		add0(root, e);</span><br><span class="line">		return true;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * </span><br><span class="line">	 * </span><br><span class="line">	 *                          10</span><br><span class="line">	 *                     &#x2F;          \</span><br><span class="line">	 *                    3           18</span><br><span class="line">	 *                  &#x2F;   \        &#x2F;   \               </span><br><span class="line">	 *                 2     4      13    21       </span><br><span class="line">	 *                         \</span><br><span class="line">	 *                          9</span><br><span class="line">	 *                        &#x2F;   \</span><br><span class="line">	 *                       8     9 </span><br><span class="line">	 * </span><br><span class="line">	 * </span><br><span class="line">	 * @param root</span><br><span class="line">	 * @param e</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	private TreeNode&lt;E&gt; add0(TreeNode&lt;E&gt; root, E e) &#123;</span><br><span class="line">		final TreeNode&lt;E&gt; curNode &#x3D; root;</span><br><span class="line">		</span><br><span class="line">		int cmp &#x3D; compare(e, curNode.value);</span><br><span class="line">		if(cmp &lt; 0 ) &#123; &#x2F;&#x2F;表示待插入的节点值，比当前节点值小</span><br><span class="line">			if(curNode.left &#x3D;&#x3D; null) &#123;</span><br><span class="line">				&#x2F;&#x2F;创建当前节点的左节点</span><br><span class="line">				TreeNode&lt;E&gt; newNode &#x3D; new TreeNode&lt;E&gt;(e, curNode);</span><br><span class="line">				curNode.left &#x3D; newNode;</span><br><span class="line">				return newNode;</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				return add0(curNode.left, e);&#x2F;&#x2F;遍历左子树</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; else &#123; &#x2F;&#x2F; 大于等于0，右子树</span><br><span class="line">			if(curNode.right &#x3D;&#x3D; null ) &#123;</span><br><span class="line">				&#x2F;&#x2F;创建当前节点的右节点</span><br><span class="line">				TreeNode&lt;E&gt; newNode &#x3D; new TreeNode&lt;E&gt;(e, curNode);</span><br><span class="line">				curNode.right &#x3D; newNode;</span><br><span class="line">				return newNode;</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				return add0(curNode.right, e);&#x2F;&#x2F;遍历右子树</span><br><span class="line">			&#125;</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * 比较两个元素的大小</span><br><span class="line">	 * @param e1</span><br><span class="line">	 * @param e2</span><br><span class="line">	 * @return</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	@SuppressWarnings(&quot;unchecked&quot;)</span><br><span class="line">	private int compare(E e1, E e2) &#123;</span><br><span class="line">		return comparator &#x3D;&#x3D; null ?  ((Comparable&lt;E&gt;) e1 ).compareTo(e2) : comparator.compare(e1, e2);  </span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * </span><br><span class="line">	 * 删除元素</span><br><span class="line">	 * @param e  </span><br><span class="line">	 * @return  如果返回ture,表示删除成功,如果返回false,表示删除失败，没有找到元素</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	public boolean remove(E e) &#123;</span><br><span class="line">		if( e &#x3D;&#x3D; null ) return false;</span><br><span class="line">		</span><br><span class="line">		TreeNode&lt;E&gt; cur &#x3D; root;</span><br><span class="line">		int cmp;</span><br><span class="line">		while (cur !&#x3D; null ) &#123;</span><br><span class="line">			if(e.equals(cur.value)) &#123;</span><br><span class="line">				break;</span><br><span class="line">			&#125;</span><br><span class="line">			cmp &#x3D; compare(e, root.value);</span><br><span class="line">			if(cmp &lt; 0 ) &#123; &#x2F;&#x2F;表示待删除的节点值，比当前节点值小</span><br><span class="line">				cur &#x3D; cur.left;</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				cur &#x3D; cur.right;</span><br><span class="line">			&#125;</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		if(cur !&#x3D; null ) &#123; &#x2F;&#x2F;找到了元素，需要删除该元素</span><br><span class="line">			TreeNode&lt;E&gt; cLeft &#x3D; cur.left;</span><br><span class="line">			TreeNode&lt;E&gt; cRight &#x3D; cur.right;</span><br><span class="line">			</span><br><span class="line">			if(cLeft !&#x3D; null ) &#123; &#x2F;&#x2F;如果被删除节点的左子树不为空，则将左子树放入当前节点的位置</span><br><span class="line">				remove0(cLeft, cur);</span><br><span class="line">				if(cLeft.right !&#x3D; null &amp;&amp;  cur.right !&#x3D; null) &#123; &#x2F;&#x2F;需要移动相应节点</span><br><span class="line">					TreeNode&lt;E&gt; wNode &#x3D; cLeft.right;</span><br><span class="line">					cLeft.right &#x3D; cur.right;</span><br><span class="line">					wNode.parent &#x3D; null;</span><br><span class="line">					TreeNode&lt;E&gt; newNode &#x3D; add0(cLeft, wNode.value);</span><br><span class="line">					newNode.left &#x3D; wNode.left;</span><br><span class="line">					newNode.right &#x3D; wNode.right;</span><br><span class="line">					wNode &#x3D; null;</span><br><span class="line">				&#125;</span><br><span class="line">				</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				remove0(cRight, cur);</span><br><span class="line">			&#125;</span><br><span class="line">			</span><br><span class="line">			&#x2F;&#x2F;将当前节点释放，，help GC</span><br><span class="line">			cur.value &#x3D; null;</span><br><span class="line">			cur.right &#x3D; null;</span><br><span class="line">			cur.left &#x3D; null;</span><br><span class="line">			cur.parent &#x3D; null;</span><br><span class="line">			cur &#x3D; null;</span><br><span class="line">			</span><br><span class="line">			return true;</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">		return false;</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		 </span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	private void remove0(TreeNode&lt;E&gt; newNode, TreeNode&lt;E&gt; cur) &#123;</span><br><span class="line">		TreeNode&lt;E&gt; parent &#x3D; cur.parent;</span><br><span class="line">		newNode.parent &#x3D; parent;</span><br><span class="line">		if(cur.parent.left &#x3D;&#x3D; cur) &#123;</span><br><span class="line">			cur.parent.left &#x3D; newNode;</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			cur.parent.right &#x3D; newNode;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * 中序遍历</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	public void middleOrderTraversal() &#123;</span><br><span class="line">		System.out.println(&quot;----------中序遍历开始---------\n&quot;);</span><br><span class="line">		if (root &#x3D;&#x3D; null) &#123;</span><br><span class="line">			System.out.print(&quot;二叉树&quot;);</span><br><span class="line">			System.out.println(&quot;----------中序遍历结束---------\n&quot;);</span><br><span class="line">			return;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		middleOrderTraversal0(root);</span><br><span class="line"></span><br><span class="line">		System.out.println(&quot;\n----------中序遍历结束---------\n&quot;);</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * 中序遍历</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	private void middleOrderTraversal0(TreeNode&lt;E&gt; root) &#123;</span><br><span class="line">		if (root &#x3D;&#x3D; null)</span><br><span class="line">			return;</span><br><span class="line"></span><br><span class="line">		final TreeNode&lt;E&gt; cur &#x3D; root;</span><br><span class="line">		if (cur.left !&#x3D; null) &#123;</span><br><span class="line">			middleOrderTraversal0(cur.left);</span><br><span class="line">			System.out.print(toObjectString(cur.value) + &quot;,&quot;);</span><br><span class="line">			middleOrderTraversal0(cur.right);</span><br><span class="line">		&#125; else if (cur.right !&#x3D; null) &#123;</span><br><span class="line">			System.out.print(cur.value + &quot;,&quot;);</span><br><span class="line">			middleOrderTraversal0(cur.right);</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			&#x2F;&#x2F; 此时输出节点</span><br><span class="line">			System.out.print(cur.value + &quot;,&quot;);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public TreeNode&lt;E&gt; getRoot() &#123;</span><br><span class="line">		return root;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public void setRoot(TreeNode&lt;E&gt; root) &#123;</span><br><span class="line">		this.root &#x3D; root;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	private String toObjectString(E value) &#123;</span><br><span class="line">		return value &#x3D;&#x3D; null ? &quot;&quot; : value.toString();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * 二叉数</span><br><span class="line">	 * </span><br><span class="line">	 * @author Administrator</span><br><span class="line">	 *</span><br><span class="line">	 * @param &lt;E&gt;</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	@SuppressWarnings(&quot;unused&quot;)</span><br><span class="line">	private final static class TreeNode&lt;E&gt; implements Serializable &#123;</span><br><span class="line"></span><br><span class="line">		private static final long serialVersionUID &#x3D; 6540618639489225256L;</span><br><span class="line"></span><br><span class="line">		public E value;</span><br><span class="line">		public TreeNode&lt;E&gt; left;</span><br><span class="line">		public TreeNode&lt;E&gt; right;</span><br><span class="line"></span><br><span class="line">		public TreeNode&lt;E&gt; parent;</span><br><span class="line"></span><br><span class="line">		public TreeNode(E value, TreeNode&lt;E&gt; parent) &#123;</span><br><span class="line">			super();</span><br><span class="line">			this.value &#x3D; value;</span><br><span class="line">			this.parent &#x3D; parent;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		public TreeNode(E value, TreeNode&lt;E&gt; left, TreeNode&lt;E&gt; right, TreeNode&lt;E&gt; parent) &#123;</span><br><span class="line">			super();</span><br><span class="line">			this.value &#x3D; value;</span><br><span class="line">			this.left &#x3D; left;</span><br><span class="line">			this.right &#x3D; right;</span><br><span class="line">			this.parent &#x3D; parent;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		@Override</span><br><span class="line">		public String toString() &#123;</span><br><span class="line">			if(value !&#x3D; null)</span><br><span class="line">				return value.toString();</span><br><span class="line">			</span><br><span class="line">			return super.toString();</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;** *******************测试 start ***************************&#x2F;</span><br><span class="line">	public static void main(String[] args) &#123;</span><br><span class="line">		&#x2F;&#x2F; TODO Auto-generated method stub</span><br><span class="line">		System.out.println(&quot;测试开始&quot;);</span><br><span class="line">		</span><br><span class="line">&#x2F;&#x2F;		BinaryTree&lt;Integer&gt; t &#x3D; new BinaryTree&lt;Integer&gt;();</span><br><span class="line">&#x2F;&#x2F;		t.setRoot(t.initTree());</span><br><span class="line">&#x2F;&#x2F;		t.middleOrderTraversal();</span><br><span class="line">		</span><br><span class="line">		&#x2F;&#x2F;先研究一下 Comparator o1 &gt; o2 的排序逻辑</span><br><span class="line">		&#x2F;&#x2F;testSort();</span><br><span class="line">		</span><br><span class="line">&#x2F;*		 *                          10</span><br><span class="line">		 *                     &#x2F;              \</span><br><span class="line">		 *                    3                18</span><br><span class="line">		 *                  &#x2F;   \            &#x2F;   \               </span><br><span class="line">		 *                 2     4          13    21       </span><br><span class="line">		 *                         \       &#x2F;  \  </span><br><span class="line">		 *                          9     11    15  </span><br><span class="line">		 *                        &#x2F;   \</span><br><span class="line">		 *                       8     9 </span><br><span class="line">*&#x2F;</span><br><span class="line">		</span><br><span class="line">		&#x2F;&#x2F; add 方法测试</span><br><span class="line">		BinaryTree&lt;Integer&gt; t &#x3D; new BinaryTree&lt;Integer&gt;();</span><br><span class="line">		</span><br><span class="line">&#x2F;&#x2F;		t.add(new Integer(10));</span><br><span class="line">&#x2F;&#x2F;		t.add(new Integer(18));</span><br><span class="line">&#x2F;&#x2F;		t.add(new Integer(3));</span><br><span class="line">&#x2F;&#x2F;		t.add(new Integer(2));</span><br><span class="line">&#x2F;&#x2F;		t.add(new Integer(4));</span><br><span class="line">&#x2F;&#x2F;		t.add(new Integer(8));</span><br><span class="line">&#x2F;&#x2F;		t.add(new Integer(9));</span><br><span class="line">&#x2F;&#x2F;		t.add(new Integer(9));</span><br><span class="line">&#x2F;&#x2F;		t.add(new Integer(21));</span><br><span class="line">&#x2F;&#x2F;		t.add(new Integer(13));</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		t.add(new Integer(10));</span><br><span class="line">		t.add(new Integer(18));</span><br><span class="line">		t.add(new Integer(3));</span><br><span class="line">		t.add(new Integer(9));</span><br><span class="line">		t.add(new Integer(8));</span><br><span class="line">		t.add(new Integer(2));</span><br><span class="line">		t.add(new Integer(21));</span><br><span class="line">		t.add(new Integer(4));</span><br><span class="line">		t.add(new Integer(9));</span><br><span class="line">		t.add(new Integer(13));</span><br><span class="line">		t.add(new Integer(11));</span><br><span class="line">		t.add(new Integer(15));</span><br><span class="line">		</span><br><span class="line">		&#x2F;&#x2F;查看数结构，中序遍历</span><br><span class="line">		t.middleOrderTraversal();</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		&#x2F;&#x2F;测试删除</span><br><span class="line">		System.out.println(&quot;删除节点18&quot;);</span><br><span class="line">		t.remove(new Integer(18));</span><br><span class="line">		System.err.println(&quot;删除节点18号的排序二叉树&quot;);</span><br><span class="line">		t.middleOrderTraversal();</span><br><span class="line">		</span><br><span class="line">		System.out.println(&quot;测试结束&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * 当用升序排序时，则 o1 &gt; o2 时要返回大于0的数</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	public static void testSort() &#123;</span><br><span class="line">		</span><br><span class="line">		List&lt;Integer&gt; a &#x3D; new ArrayList&lt;Integer&gt;();</span><br><span class="line">		a.add(1);</span><br><span class="line">		a.add(8);</span><br><span class="line">		a.add(9);</span><br><span class="line">		a.add(3);</span><br><span class="line">		a.add(5);</span><br><span class="line">		</span><br><span class="line">		Collections.sort(a, new Comparator&lt;Integer&gt;() &#123;</span><br><span class="line"></span><br><span class="line">			@Override</span><br><span class="line">			public int compare(Integer o1, Integer o2) &#123;</span><br><span class="line">				</span><br><span class="line">				return o1.intValue() &gt; o2.intValue() ? 1 : -1;</span><br><span class="line">			&#125;</span><br><span class="line">			</span><br><span class="line">		&#125;);</span><br><span class="line">		</span><br><span class="line">		System.out.println(a);</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * 用来测试的，后续会完善 加入元素</span><br><span class="line">	 * </span><br><span class="line">	 * </span><br><span class="line">	 *                          </span><br><span class="line">	 *                          10</span><br><span class="line">	 *                     &#x2F;          \</span><br><span class="line">	 *                    3           18</span><br><span class="line">	 *                  &#x2F;   \        &#x2F;   \               </span><br><span class="line">	 *                 2     4      13    21       </span><br><span class="line">	 *                         \</span><br><span class="line">	 *                          9</span><br><span class="line">	 *                        &#x2F;   \</span><br><span class="line">	 *                       8     9 </span><br><span class="line">	 *                       </span><br><span class="line">	 *                       </span><br><span class="line"></span><br><span class="line">	 * @return</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	@Deprecated</span><br><span class="line">	public TreeNode&lt;Integer&gt; initTree() &#123;</span><br><span class="line">		TreeNode&lt;Integer&gt; _root &#x3D; new TreeNode&lt;Integer&gt;(new Integer(10), null); &#x2F;&#x2F; 根节点</span><br><span class="line"></span><br><span class="line">		TreeNode&lt;Integer&gt; l3 &#x3D; new TreeNode&lt;Integer&gt;(new Integer(3), _root);</span><br><span class="line">		_root.left &#x3D; l3;</span><br><span class="line"></span><br><span class="line">		TreeNode&lt;Integer&gt; l2 &#x3D; new TreeNode&lt;Integer&gt;(new Integer(2), l3);</span><br><span class="line">		l3.left &#x3D; l2;</span><br><span class="line"></span><br><span class="line">		TreeNode&lt;Integer&gt; l4 &#x3D; new TreeNode&lt;Integer&gt;(new Integer(4), l3);</span><br><span class="line">		l3.right &#x3D; l4;</span><br><span class="line"></span><br><span class="line">		TreeNode&lt;Integer&gt; l91 &#x3D; new TreeNode&lt;Integer&gt;(new Integer(9), l4);</span><br><span class="line">		l4.right &#x3D; l91;</span><br><span class="line"></span><br><span class="line">		TreeNode&lt;Integer&gt; l8 &#x3D; new TreeNode&lt;Integer&gt;(new Integer(8), l91);</span><br><span class="line">		l91.left &#x3D; l8;</span><br><span class="line"></span><br><span class="line">		TreeNode&lt;Integer&gt; l92 &#x3D; new TreeNode&lt;Integer&gt;(new Integer(9), l91);</span><br><span class="line">		l91.right &#x3D; l92;</span><br><span class="line"></span><br><span class="line">		TreeNode&lt;Integer&gt; l18 &#x3D; new TreeNode&lt;Integer&gt;(new Integer(18), _root);</span><br><span class="line">		_root.right &#x3D; l18;</span><br><span class="line"></span><br><span class="line">		TreeNode&lt;Integer&gt; l13 &#x3D; new TreeNode&lt;Integer&gt;(new Integer(13), l18);</span><br><span class="line">		l18.left &#x3D; l13;</span><br><span class="line"></span><br><span class="line">		TreeNode&lt;Integer&gt; l21 &#x3D; new TreeNode&lt;Integer&gt;(new Integer(21), l18);</span><br><span class="line">		l18.right &#x3D; l21;</span><br><span class="line"></span><br><span class="line">		return _root;</span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;** *******************测试 end ***************************&#x2F;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>探究java8流收集数据原理</title>
    <url>/posts/bfa9fca1.html</url>
    <content><![CDATA[<div id="vip-container"><p>本文揭示如何学习一门新技术，从示例入手，重点阐述Stream#collect方法的实现原理，为更好的使用java8中流来收集数据。</p>
<p>我们在前面的文章中反复使用的场景：获取菜单中所有菜品的名称，返回一个集合，其代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_toList</span><span class="params">(List&lt;Dish&gt; menu)</span> </span>&#123;</span><br><span class="line">    List&lt;String&gt; names = menu.stream().map(Dish::getName)</span><br><span class="line">                        .collect(Collectors.toList()); <span class="comment">// @1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(String s : names) &#123;</span><br><span class="line">        System.out.println(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过Stream.collect这个终端操作进行数据收集，至于如何收集，则由该方法的参数来决定(Collector)，即行为参数化。</p>
<p>代码@1：collect(Collectors.toList()) 的意思就是返回List，这里涉及到两个关键，一个是Stream#collect方法，另外一个就是其参数Collectors.toList()。</p>
<p>接下来我们将以上述两个突破点来揭开如何使用java8的流来收集数据。</p>
<h2 id="1、Stream-collect"><a href="#1、Stream-collect" class="headerlink" title="1、Stream#collect"></a>1、Stream#collect</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ReferencePipeline#collect</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> &lt;R, A&gt; <span class="function">R <span class="title">collect</span><span class="params">(Collector&lt;? <span class="keyword">super</span> P_OUT, A, R&gt; collector)</span> </span>&#123;   <span class="comment">// @1</span></span><br><span class="line">    A container;</span><br><span class="line">    <span class="keyword">if</span> (isParallel()</span><br><span class="line">            &amp;&amp; (collector.characteristics().contains(Collector.Characteristics.CONCURRENT))</span><br><span class="line">            &amp;&amp; (!isOrdered() || collector.characteristics().contains(Collector.Characteristics.UNORDERED))) &#123;   <span class="comment">// @2</span></span><br><span class="line">        container = collector.supplier().get();                                                                 <span class="comment">// @3</span></span><br><span class="line">        BiConsumer&lt;A, ? <span class="keyword">super</span> P_OUT&gt; accumulator = collector.accumulator();</span><br><span class="line">        forEach(u -&gt; accumulator.accept(container, u));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;                                                                                                     <span class="comment">// @4</span></span><br><span class="line">        container = evaluate(ReduceOps.makeRef(collector));                                                                                              </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> collector.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH)                    <span class="comment">// @5</span></span><br><span class="line">           ? (R) container</span><br><span class="line">           : collector.finisher().apply(container);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：函数声明，该方法返回的结果类型为R，传入的行为参数接口为Collector。<br>代码@2：判断是否符合并行化累积与规约的条件。</p>
<ul>
<li>是否是并行流，例如上例中创建流的代码为menu.stream()，该方法的流是非并行化流，如果要支持并行化执行，需要满足的第一个条件就是需要使用menu.parallelStream()方法返回的流。</li>
<li>Collector(收集器，行为化参数)中收集器行为集合中是否包含Characteristics.CONCURRENT(并行执行)，如果不包含该行为，则不支持并行执行。</li>
<li>原始流是否有顺序 或 者 收集器的行为集合中明确包含Characteristics.UNORDERED(不要求顺序性)。<br>上述三个条件必须同时满足，才能并行执行，否则串行执行。</li>
</ul>
<p>代码@3：并行执行收集动作。</p>
<p>代码@4：串行执行收集动作。</p>
<p>代码@5：如果收集器收集行为集合中包含Characteristics.IDENTITY_FINISH，则直接返回原始值，否则使用Collector.finishier()方式对计算的值进行函数式计算。</p>
<p>通过上面的代码，我们应该对Characteristics枚举类型中的3个值不难得出如下类型：</p>
<ul>
<li>CONCURRENT<br>收集器行为，表示收集其中的累积函数是否支持并行执行。</li>
<li>Characteristics.UNORDERED<br>收集器行为，表示整个收集期间，没有顺序要求。</li>
<li>Characteristics.IDENTITY_FINISH<br>收集器行为，表示可以忽略Collector.finsher()定义的最终转换函数，直接返回累积之后的结果即可。</li>
</ul>
<blockquote>
<p>疑问？代码@3,这段代码不是很好理解，该怎么继续往下深入呢？</p>
</blockquote>
<p>针对上面看不太懂的代码，我的处理办法是先转移思路，看一下Collector接口以及示例中Collectos.toList()返回的收集器是什么(重点关注返回的Collector中具体属性)。</p>
<a id="more"></a>

<h2 id="2、Collector接口"><a href="#2、Collector接口" class="headerlink" title="2、Collector接口"></a>2、Collector接口</h2><p><img src="https://img-blog.csdnimg.cn/20190604211337662.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>收集器中的泛型参数说明如下：</p>
<ul>
<li>T ：累积器中一个操作数类型</li>
<li>A： 累积器中的初始值类型</li>
<li>R：返回值的类型，例如List&lt; R &gt;。</li>
</ul>
<p>其属性一览如下：</p>
<ul>
<li>Supplier&lt; A &gt; supplier()<br>该函数式接口，大家应该都非常熟悉了，其函数声明如下：() -&gt; T，通常用于构建对象，那这里是构建什么对象呢？这是下一个待解疑问。</li>
<li>BiConsumer&lt;A, T&gt; accumulator()<br>从名字命名来看，应该是返回累积器，（T,U）-&gt; void。通常用于输入两个参数，对其进行处理，但返回void类型。</li>
<li>BinaryOperator&lt; A &gt; combiner()<br>从名字命令来看，应该是组合器（请参考流计算函数reduce)。</li>
<li>Function&lt;A, R&gt; finisher()<br>最终函数，如果收集器行为包含IDENTITY_FINISH，则无需使用该函数对累积器产生的结果进行处理，否则使用该函数对累积器结果进行最后的处理。</li>
<li>Set&lt; Characteristics &gt; characteristics()<br>累积器行为，在上文已做详细介绍。</li>
</ul>
<p>其supplier函数到底是干什么的呢？对上面的方法都是基于名字来推测的（当然JDK代码非常优雅，根据名字去猜测，准确度还是很高的），但如何确认呢？这个时候我们还是结合Collectos.toList()方法返回的Collector来做进一步推断。</p>
<h2 id="3、Collectors-toList"><a href="#3、Collectors-toList" class="headerlink" title="3、Collectors.toList()"></a>3、Collectors.toList()</h2><p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Collector&lt;T, ?, List&lt;T&gt;&gt; toList() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> CollectorImpl&lt;&gt;((Supplier&lt;List&lt;T&gt;&gt;) ArrayList::<span class="keyword">new</span>, List::add,</span><br><span class="line">                               (left, right) -&gt; &#123; left.addAll(right); <span class="keyword">return</span> left; &#125;,</span><br><span class="line">                               CH_ID);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Collector的第一个参数Supplier，在这里为ArrayList::new，即调用supper.get()方法将返回一个List。</li>
<li>Collector的第二个参数accumulator:累积器，这里是List:add方法。</li>
<li>Collector的第三个参数combiner:组合器，这里就是(left, right) -&gt; {left.addAll(right);return left;}</li>
<li>Collector的第四个函数characteristics：收集器的行为，这里为CH_IL，其选项为：IDENTITY_FINISH。</li>
</ul>
<p>有了上面这些知识，我们再来看如下这段代码：<br><img src="https://img-blog.csdnimg.cn/2019060421180264.png" alt="在这里插入图片描述"><br>1、A container：累积器的初始值，如果使用Collectors.toList()，则这里会返回List<T>的对象。<br>2、获取collector中定义的累积器。<br>3、遍历流，执行累积器动作，其中形式参数u，代表流中的一个个元素。</p>
<p>至于forEach方法，底层流的具体实现，本文就不再往深探究。</p>
<h2 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h2><p>java8 使用流来收集数据的基本用法：</p>
<ul>
<li>使用流stream的collect对象进行数据收集，其参数为Collector函数是编程接口，具体的收集逻辑由该接口来指定。</li>
<li>流的收集其具备基本的属性即作用：<ul>
<li>Supplier&lt; A &gt; supplier()<br>通过该函数式编程接口，返回累积器的初始值。</li>
<li>BiConsumer&lt;A, T&gt; accumulator<br>累积器函数。</li>
<li>BinaryOperator&lt; A &gt; combiner<br>组合器，可以参考函数式编程接口的reduce方法。</li>
<li>Set&lt; Characteristics &gt; characteristics<br>收集器行为。</li>
</ul>
</li>
<li>java8中的Collectors提供了很多默认的收集器，例如Collectors.toList()方法，下一节我们会根据该类，详细介绍在java8中默认提供的收集器，指导我们如何使用java8中的流来收集数据。</li>
</ul>
<p>下一节，将以Collectos类为入口，详细介绍java8中默认提供的收集器，已经如何使用。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>java8</category>
      </categories>
      <tags>
        <tag>java8</tag>
        <tag>Lambda</tag>
        <tag>流计算</tag>
      </tags>
  </entry>
  <entry>
    <title>数值流、Stream创建与Optional类的使用</title>
    <url>/posts/fcb673e6.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、数值流"><a href="#1、数值流" class="headerlink" title="1、数值流"></a>1、数值流</h2><p>不知大家还记不得，在介绍函数式编程接口中为了避免基础数据类型的装箱/拆箱带来的性能损耗，特意为函数式接口引入了基础数据类型的函数式编程接口，例如IntPredicate、LongPredicate、DoublePredicate。同样，流API也考虑到基本数据类型的装箱/拆箱会带来性能损耗，引入了数值流，例如IntStream、LongStream、DoubleStream。</p>
<h3 id="1-1-原始数据特化流"><a href="#1-1-原始数据特化流" class="headerlink" title="1.1 原始数据特化流"></a>1.1 原始数据特化流</h3><p>java8中提供了3个原始数据特化流，分别为IntStream、LongStream、DoubleStream。本文将以IntStream进行讲解，其他流类似，只是数据类型分别代表Long或Double。</p>
<h4 id="1-1-1-映射到数据流"><a href="#1-1-1-映射到数据流" class="headerlink" title="1.1.1 映射到数据流"></a>1.1.1 映射到数据流</h4><p>首先我们还是从一个示例开始本节的学习：计算菜单中所有菜品的卡路里之和。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_reduce_caluli</span><span class="params">(List&lt;Dish&gt; menu)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> calories = menu.stream()</span><br><span class="line">                    .map(Dish::getCalories)</span><br><span class="line">                    .reduce(<span class="number">0</span>, Integer::sum);</span><br><span class="line">    System.out.println(<span class="string">&quot;菜品中的总卡路里：&quot;</span> + calories);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面包含了一个基本数据类型的装箱/拆箱动作，java8的流API提供了mapToInt方法，直接返回int类型的流</p>
<p>我们先稍微看一下mapToInt的方法声明：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">IntStream <span class="title">mapToInt</span><span class="params">(ToIntFunction&lt;? <span class="keyword">super</span> T&gt; mapper)</span></span></span><br></pre></td></tr></table></figure>
<p>接受一个T-&gt;int的函数式编程接口，直接返回IntStream流对象，而且IntStream本身提供了一些常用的聚合函数，例如sum。<br>使用IntStream来实现计算菜单中所有菜品的卡路里之和，其示例如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_reduce_caluli_intStream</span><span class="params">(List&lt;Dish&gt; menu)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> calories = menu.stream()</span><br><span class="line">            .mapToInt(Dish::getCalories)</span><br><span class="line">            .sum();</span><br><span class="line">    System.out.println(<span class="string">&quot;菜品中的总卡路里：&quot;</span> + calories);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="1-1-2-转换回对象流"><a href="#1-1-2-转换回对象流" class="headerlink" title="1.1.2 转换回对象流"></a>1.1.2 转换回对象流</h4><p>使用了特化流例如IntStream后，将不能再自动转换为其对应的封装对象流Stream&lt; T &gt;了，我们可以随意从IntStream对象中对应的通用方法的函数声明，例如IntStream#map函数的声明如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">IntStream <span class="title">map</span><span class="params">(IntUnaryOperator mapper)</span></span>;</span><br></pre></td></tr></table></figure>
<p>只能接受int -&gt; int的函数式编程接口，如果想将IntStream转回到Stream&lt; Integer &gt;，该如何处理呢？</p>
<p>IntStream提供了boxed()方法来实现将基础数据类型转换回对应的包装类型的流。</p>
<h4 id="1-1-3-常用函数"><a href="#1-1-3-常用函数" class="headerlink" title="1.1.3 常用函数"></a>1.1.3 常用函数</h4><p>Stream中定义的方法，IntStream也可以使用，例如map、flatMap、distinict等，IntStream除这些之外，还提供了常用的聚合函数，例如sum、min、max、average(平均数)。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">OptionalDouble <span class="title">average</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function">OptionalInt <span class="title">max</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function">OptionalInt <span class="title">min</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sum</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>
<p>有关Optional相关的类将在下文详细介绍。</p>
<p>另外除了上面提到的聚合函数，IntStream还提供了两个与数值范围的方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> IntStream <span class="title">range</span><span class="params">(<span class="keyword">int</span> startInclusive, <span class="keyword">int</span> endExclusive)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> IntStream <span class="title">rangeClosed</span><span class="params">(<span class="keyword">int</span> startInclusive, <span class="keyword">int</span> endExclusive)</span></span>;</span><br></pre></td></tr></table></figure>
<p>rangeClosed与range的区别就是rangeClosed包含结束边界，举一个简单示例如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_range</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> count = IntStream.range(<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">                        .filter( i -&gt; i % <span class="number">2</span> == <span class="number">0</span> )</span><br><span class="line">                         .count();</span><br><span class="line">    System.out.println(<span class="string">&quot;count:&quot;</span> + count);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>计算【1，100）中包含的偶数个数，将输出49。如果将range(1,100)修改为rangeClosed(1,100)，在输出的个数为50。</p>
<h2 id="2、构建流"><a href="#2、构建流" class="headerlink" title="2、构建流"></a>2、构建流</h2><h3 id="2-1-通过值构建流"><a href="#2-1-通过值构建流" class="headerlink" title="2.1 通过值构建流"></a>2.1 通过值构建流</h3><p>java 8的Stream提供了两个重载的of函数来显示的构建流，其声明如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span>&lt;T&gt; Stream&lt;T&gt; <span class="title">of</span><span class="params">(T t)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span>&lt;T&gt; Stream&lt;T&gt; <span class="title">of</span><span class="params">(T... values)</span></span></span><br></pre></td></tr></table></figure>

<h3 id="2-2-通过数组构建流"><a href="#2-2-通过数组构建流" class="headerlink" title="2.2 通过数组构建流"></a>2.2 通过数组构建流</h3><p>通过Arrays.stream构建流，其声明如下：<br>Arrays#stream</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">Stream&lt;T&gt; <span class="title">stream</span><span class="params">(T[] array)</span></span></span><br></pre></td></tr></table></figure>
<h3 id="2-3-通过文件流"><a href="#2-3-通过文件流" class="headerlink" title="2.3 通过文件流"></a>2.3 通过文件流</h3><p>可以通过文件流创建流，在java.nio.file.Files类中定义了如下创建流的方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Stream&lt;Path&gt; <span class="title">list</span><span class="params">(Path dir)</span> <span class="keyword">throws</span> IOException</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Stream&lt;Path&gt; <span class="title">walk</span><span class="params">(Path start, <span class="keyword">int</span> maxDepth, FileVisitOption... options)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Stream&lt;Path&gt; <span class="title">walk</span><span class="params">(Path start, FileVisitOption... options)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Stream&lt;Path&gt; <span class="title">find</span><span class="params">(Path start, <span class="keyword">int</span> maxDepth,BiPredicate&lt;Path, BasicFileAttributes&gt; matcher,   </span></span></span><br><span class="line"><span class="function"><span class="params">    FileVisitOption... options)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Stream&lt;String&gt; <span class="title">lines</span><span class="params">(Path path, Charset cs)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Stream&lt;String&gt; <span class="title">lines</span><span class="params">(Path path)</span> <span class="keyword">throws</span> IOException</span></span><br></pre></td></tr></table></figure>
<p>下面我们举一个示例：找出一个文件中不同词的个数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_file_stram</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> uniqueWords = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">try</span>(Stream&lt;String&gt; lines = Files.lines(Paths.get(<span class="string">&quot;d:/tmp/words.txt&quot;</span>), Charset.defaultCharset())) &#123;  </span><br><span class="line">        uniqueWords = lines.flatMap(line -&gt; Arrays.stream(line.split(<span class="string">&quot;&quot;</span> )))</span><br><span class="line">                .distinct()</span><br><span class="line">                .count();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;不重复字符个数：&quot;</span> + uniqueWords);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<a id="more"></a>

<h3 id="2-4-函数生成流：创建无限流"><a href="#2-4-函数生成流：创建无限流" class="headerlink" title="2.4 函数生成流：创建无限流"></a>2.4 函数生成流：创建无限流</h3><p>Stream API提供了两个静态方法从函数生成流：iterate、generate，我们先来看一下其函数声明：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span>&lt;T&gt; Stream&lt;T&gt; <span class="title">iterate</span><span class="params">(<span class="keyword">final</span> T seed, <span class="keyword">final</span> UnaryOperator&lt;T&gt; f)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span>&lt;T&gt; Stream&lt;T&gt; <span class="title">generate</span><span class="params">(Supplier&lt;T&gt; s)</span></span></span><br></pre></td></tr></table></figure>
<h4 id="2-4-1-iterate"><a href="#2-4-1-iterate" class="headerlink" title="2.4.1 iterate"></a>2.4.1 iterate</h4><p>iterate方法的第一个参数类型为T，表示其初始值，第二个参数如下：<br><img src="https://img-blog.csdnimg.cn/20190602202005106.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>即其函数式声明为为T-T。其示例如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_iterate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Stream.iterate(<span class="number">0</span>, a -&gt; a + <span class="number">2</span>)</span><br><span class="line">            .limit(<span class="number">10</span>)</span><br><span class="line">            .forEach(System.out::println);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：由于是无限流，故千万记得使用limit截断流，否则会无限循环下去。</p>
</blockquote>
<h4 id="2-4-2-generate"><a href="#2-4-2-generate" class="headerlink" title="2.4.2 generate"></a>2.4.2 generate</h4><p>其参数为Supplier&lt; T &gt;，其定义如下：<br><img src="https://img-blog.csdnimg.cn/20190602202222354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>即构造一个T类型的对象，举例如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_iterate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Stream.iterate(<span class="number">0</span>, a -&gt; a + <span class="number">2</span>)</span><br><span class="line">            .limit(<span class="number">10</span>)</span><br><span class="line">            .forEach(System.out::println);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-5-集合对象的stream"><a href="#2-5-集合对象的stream" class="headerlink" title="2.5 集合对象的stream"></a>2.5 集合对象的stream</h3><p>这个在前面的示例中用的最多，就不做过多介绍。</p>
<h2 id="3、Optional类"><a href="#3、Optional类" class="headerlink" title="3、Optional类"></a>3、Optional类</h2><p>为了更优雅的处理null值，避免空指针错误，java8中引入Optional类。<br><img src="https://img-blog.csdnimg.cn/20190602202332539.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>接下来对这些方法一一做个介绍。</p>
<ul>
<li>public static&lt; T&gt; Optional&lt; T&gt; empty()<br>创建一个Optional对象，其内部持有的对象为null。</li>
<li>public static &lt; T &gt; Optional&lt; T &gt; of(T value)<br>使用value的值，创建一个Optional对象。</li>
<li>public static &lt; T &gt; Optional&lt; T &gt; ofNullable(T value)<br>使用v去创建一个Optional对象，如果value为null，则返回empty()。</li>
<li>public T get()<br>从Optional对象获取内嵌的对象，如果为空，则抛出NoSuchElementException。</li>
<li>public boolean isPresent()<br>判断Optional对象中包含的值是否存在。</li>
<li>public void ifPresent(Consumer<? super T> consumer)
如果Optional包裹的对象存在，则消费该对象。Consumer<?>的函数式编程接口：T -&gt; void。</li>
<li>public Optional&lt; T &gt; filter(Predicate&lt;? super T&gt; predicate)<br>如果Optional中包裹的对象为空，则返回自身，否则如果包裹的对象满足predicate表达式，则返回自身，否则返回empty()。</li>
<li>public&lt; U &gt; Optional&lt; U &gt; map(Function&lt;? super T, ? extends U&gt; mapper)<br>如果Optional对象中包裹的对象为空，则返回empty()，否则运用(T-U)，包裹U,当然如果U为空，则返回empty()。</li>
<li>public&lt; U &gt; Optional&lt; U &gt; flatMap(Function&lt;? super T, Optional&lt; U &gt;&gt; mapper)<br>如果Option对象中包裹的对象为空，则返回empty()，否则使用对Optional中的包裹的对象value应用Function，最终返回Optional对象。</li>
<li>public T orElse(T other)<br>返回Optional中包裹的对象，如果其值为空，则返回other。</li>
<li>public T orElseGet(Supplier&lt;? extends T&gt; other)<br>返回Optional中包裹的对象，如果其值为空，则返回 Supplier函数式编辑接口中创建的值。</li>
<li>public &lt; X extends Throwable&gt; T orElseThrow(Supplier&lt; ? extends X&gt; exceptionSupplier) throws X<br>返回Optional中包裹的对象，如果其值为空，则抛出自定义一次，由Supplier函数式编程接口返回。</li>
</ul>
<p> 其示例代码如下：<br> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">test_option</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Map&lt;String, String&gt; data = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    Optional&lt;String&gt; value = Optional.ofNullable(data.get(<span class="string">&quot;userName&quot;</span>));</span><br><span class="line">    <span class="comment">// 如果存在userName值，则输出</span></span><br><span class="line">    value.ifPresent(System.out::println);  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>本文就介绍到这里了，本文详细介绍了java8中的数值流、Stream的创建以及java8中Optional类的使用。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>java8</category>
      </categories>
      <tags>
        <tag>java8</tag>
        <tag>Lambda</tag>
        <tag>流计算</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析 Alibaba sentinel 滑动窗口实现原理(文末附原理图)</title>
    <url>/posts/a618bda.html</url>
    <content><![CDATA[<div id="vip-container"><p>要实现限流、熔断等功能，首先要解决的问题是如何实时采集服务(资源)调用信息。例如将某一个接口设置的限流阔值 1W/tps，那首先如何判断当前的 TPS 是多少？Alibaba Sentinel 采用滑动窗口来实现实时数据的统计。</p>
<blockquote>
<p>温馨提示：如果对源码不太感兴趣，可以先跳到文末，看一下滑动窗口的设计原理图，再决定是否需要阅读源码。</p>
</blockquote>
<h2 id="1、滑动窗口核心类图"><a href="#1、滑动窗口核心类图" class="headerlink" title="1、滑动窗口核心类图"></a>1、滑动窗口核心类图</h2><p><img src="https://img-blog.csdnimg.cn/20191229144055643.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们先对上述核心类做一个简单的介绍，重点关注核心类的作用与核心属性（重点需要探究其核心数据结构）。</p>
<ul>
<li>Metric<br>指标收集核心接口，主要定义一个滑动窗口中成功的数量、异常数量、阻塞数量，TPS、响应时间等数据。</li>
<li>ArrayMetric<br>滑动窗口核心实现类。</li>
<li>LeapArray<br>滑动窗口顶层数据结构，包含一个一个的窗口数据。</li>
<li>WindowWrap<br>每一个滑动窗口的包装类，其内部的数据结构用 MetricBucket 表示。</li>
<li>MetricBucket<br>指标桶，例如通过数量、阻塞数量、异常数量、成功数量、响应时间，已通过未来配额（抢占下一个滑动窗口的数量）。</li>
<li>MetricEvent<br>指标类型，例如通过数量、阻塞数量、异常数量、成功数量、响应时间等。</li>
</ul>
<h2 id="2、滑动窗口实现原理"><a href="#2、滑动窗口实现原理" class="headerlink" title="2、滑动窗口实现原理"></a>2、滑动窗口实现原理</h2><h4 id="2-1-ArrayMetric"><a href="#2-1-ArrayMetric" class="headerlink" title="2.1 ArrayMetric"></a>2.1 ArrayMetric</h4><p>滑动窗口的入口类为 ArrayMetric ，我们先来看一下其核心代码。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> LeapArray&lt;MetricBucket&gt; data;   <span class="comment">// @1</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ArrayMetric</span><span class="params">(<span class="keyword">int</span> sampleCount, <span class="keyword">int</span> intervalInMs)</span> </span>&#123;    <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">this</span>.data = <span class="keyword">new</span> OccupiableBucketLeapArray(sampleCount, intervalInMs);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ArrayMetric</span><span class="params">(<span class="keyword">int</span> sampleCount, <span class="keyword">int</span> intervalInMs, <span class="keyword">boolean</span> enableOccupy)</span> </span>&#123;   <span class="comment">// @3</span></span><br><span class="line">	<span class="keyword">if</span> (enableOccupy) &#123;</span><br><span class="line">		<span class="keyword">this</span>.data = <span class="keyword">new</span> OccupiableBucketLeapArray(sampleCount, intervalInMs);</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="keyword">this</span>.data = <span class="keyword">new</span> BucketLeapArray(sampleCount, intervalInMs);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：ArrayMetric 类唯一的属性，用来存储各个窗口的数据，这个是接下来我们探究的重点。</p>
<p>代码@2，代码@3  该类提供了两个构造方法，其核心参数为：</p>
<ul>
<li>int intervalInMs<br>表示一个采集的时间间隔，例如1秒，1分钟。</li>
<li>int sampleCount<br>在一个采集间隔中抽样的个数，默认为 2，例如当 intervalInMs = 1000时，抽象两次，则一个采集间隔中会包含两个相等的区间，一个区间就是滑动窗口。</li>
<li>boolean enableOccupy<br>是否允许抢占，即当前时间戳已经达到限制后，是否可以占用下一个时间窗口的容量，这里对应 LeapArray 的两个实现类，如果允许抢占，则为 OccupiableBucketLeapArray，否则为   BucketLeapArray。</li>
</ul>
<blockquote>
<p>注意，LeapArray 的泛型类为 MetricBucket，意思就是指标桶，可以认为一个 MetricBucket 对象可以存储一个抽样时间段内所有的指标，例如一个抽象时间段中通过数量、阻塞数量、异常数量、成功数量、响应时间，其实现的奥秘在 LongAdder 中，本文先不对该类进行详细介绍，后续文章会单独来探究其实现原理。</p>
</blockquote>
<p>这次，我们先不去看子类，反其道而行，先去看看其父类。</p>
<h4 id="2-2-LongAdder"><a href="#2-2-LongAdder" class="headerlink" title="2.2 LongAdder"></a>2.2 LongAdder</h4><h5 id="2-2-1-类图与核心属性"><a href="#2-2-1-类图与核心属性" class="headerlink" title="2.2.1 类图与核心属性"></a>2.2.1 类图与核心属性</h5><p><img src="https://img-blog.csdnimg.cn/20191229144447580.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>LeapArray 的核心属性如下：</p>
<ul>
<li>int windowLengthInMs<br>每一个窗口的时间间隔，单位为毫秒。</li>
<li>int sampleCount<br>抽样个数，就一个统计时间间隔中包含的滑动窗口个数，在 intervalInMs 相同的情况下，sampleCount 越多，抽样的统计数据就越精确，相应的需要的内存也越多。</li>
<li>int intervalInMs<br>一个统计的时间间隔。</li>
<li>AtomicReferenceArray&lt;WindowWrap&lt; T&gt;&gt; array<br>一个统计时间间隔中滑动窗口的数组，从这里也可以看出，一个滑动窗口就是使用的 WindowWrap&lt; MetricBucket &gt; 来表示。</li>
</ul>
<p>上面的各个属性的含义是从其构造函数得出来的，请其看构造函数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LeapArray</span><span class="params">(<span class="keyword">int</span> sampleCount, <span class="keyword">int</span> intervalInMs)</span> </span>&#123;</span><br><span class="line">    AssertUtil.isTrue(sampleCount &gt; <span class="number">0</span>, <span class="string">&quot;bucket count is invalid: &quot;</span> + sampleCount);</span><br><span class="line">    AssertUtil.isTrue(intervalInMs &gt; <span class="number">0</span>, <span class="string">&quot;total time interval of the sliding window should be positive&quot;</span>);</span><br><span class="line">    AssertUtil.isTrue(intervalInMs % sampleCount == <span class="number">0</span>, <span class="string">&quot;time span needs to be evenly divided&quot;</span>);</span><br><span class="line">    <span class="keyword">this</span>.windowLengthInMs = intervalInMs / sampleCount;</span><br><span class="line">    <span class="keyword">this</span>.intervalInMs = intervalInMs;</span><br><span class="line">    <span class="keyword">this</span>.sampleCount = sampleCount;</span><br><span class="line">    <span class="keyword">this</span>.array = <span class="keyword">new</span> AtomicReferenceArray&lt;&gt;(sampleCount);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那我们继续来看 LeapArray 中的方法，深入探究滑动窗口的实现细节。</p>
<h5 id="2-2-2-currentWindow-详解"><a href="#2-2-2-currentWindow-详解" class="headerlink" title="2.2.2 currentWindow() 详解"></a>2.2.2 currentWindow() 详解</h5><p>该方法主要是根据当前时间来确定处于哪一个滑动窗口中，即找到上图中的 WindowWrap，该方法内部就是调用其重载方法，参数为系统的当前时间，故我们重点来看一下重载方法的实现。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> WindowWrap&lt;T&gt; <span class="title">currentWindow</span><span class="params">(<span class="keyword">long</span> timeMillis)</span> </span>&#123; </span><br><span class="line">	<span class="keyword">if</span> (timeMillis &lt; <span class="number">0</span>) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">int</span> idx = calculateTimeIdx(timeMillis);  <span class="comment">// @1</span></span><br><span class="line">	<span class="keyword">long</span> windowStart = calculateWindowStart(timeMillis); <span class="comment">// @2</span></span><br><span class="line">	<span class="keyword">while</span> (<span class="keyword">true</span>) &#123; <span class="comment">// 死循环查找当前的时间窗口，这里之所有需要循环，是因为可能多个线程都在获取当前时间窗口。</span></span><br><span class="line">		WindowWrap&lt;T&gt; old = array.get(idx);  <span class="comment">// @3</span></span><br><span class="line">       		 <span class="keyword">if</span> (old == <span class="keyword">null</span>) &#123;  <span class="comment">// @4</span></span><br><span class="line">			WindowWrap&lt;T&gt; window = <span class="keyword">new</span> WindowWrap&lt;T&gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis));</span><br><span class="line">           		 <span class="keyword">if</span> (array.compareAndSet(idx, <span class="keyword">null</span>, window)) &#123;  <span class="comment">// @5</span></span><br><span class="line">				<span class="keyword">return</span> window;</span><br><span class="line">           		 &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				Thread.yield();</span><br><span class="line">           		 &#125;</span><br><span class="line">       		 &#125; <span class="keyword">else</span> <span class="keyword">if</span> (windowStart == old.windowStart()) &#123; <span class="comment">// @6</span></span><br><span class="line">			<span class="keyword">return</span> old;</span><br><span class="line">       		 &#125; <span class="keyword">else</span> <span class="keyword">if</span> (windowStart &gt; old.windowStart()) &#123;  <span class="comment">// @7</span></span><br><span class="line">			<span class="keyword">if</span> (updateLock.tryLock()) &#123;</span><br><span class="line">               			 <span class="keyword">try</span> &#123;</span><br><span class="line">					<span class="keyword">return</span> resetWindowTo(old, windowStart);</span><br><span class="line">                		&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">					updateLock.unlock();</span><br><span class="line">              			&#125;</span><br><span class="line">           		 &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">				Thread.yield();</span><br><span class="line">            		&#125;</span><br><span class="line">        	&#125; <span class="keyword">else</span> <span class="keyword">if</span> (windowStart &lt; old.windowStart()) &#123; <span class="comment">// @8</span></span><br><span class="line">            		<span class="keyword">return</span> <span class="keyword">new</span> WindowWrap&lt;T&gt;(windowLengthInMs, windowStart, newEmptyBucket(timeMillis));</span><br><span class="line">        	&#125;</span><br><span class="line">    	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：计算当前时间会落在一个采集间隔 ( LeapArray ) 中哪一个时间窗口中，即在 LeapArray 中属性 AtomicReferenceArray &lt;WindowWrap&lt; T&gt;&gt; array 的下标。其实现算法如下：</p>
<ul>
<li>首先用当前时间除以一个时间窗口的时间间隔，得出当前时间是多少个时间窗口的倍数，用 n 表示。</li>
<li>然后我们可以看出从一系列时间窗口，从 0 开始，一起向前滚动 n 隔得到当前时间戳代表的时间窗口的位置。现在我们要定位到这个时间窗口的位置是落在 LeapArray 中数组的下标，而一个 LeapArray 中包含 sampleCount 个元素，要得到其下标，则使用 n % sampleCount 即可。</li>
</ul>
<p>代码@2：计算当前时间戳所在的时间窗口的开始时间，即要计算出 WindowWrap 中 windowStart 的值，其实就是要算出小于当前时间戳，并且是 windowLengthInMs 的整数倍最大的数字，Sentinel 给出是算法为 ( timeMillis - timeMillis % windowLengthInMs )。</p>
<p>代码@3：尝试从 LeapArray 中的 WindowWrap 数组查找指定下标的元素。</p>
<p>代码@4：如果指定下标的元素为空，则需要创建一个 WindowWrap 。 其中 WindowWrap 中的 MetricBucket 是调用其抽象方法 newEmptyBucket (timeMillis)，由不同的子类去实现。</p>
<p>代码@5：这里使用了 CAS 机制来更新 LeapArray 数组中的 元素，因为同一时间戳，可能有多个线程都在获取当前时间窗口对象，但该时间窗口对象还未创建，这里就是避免创建多个，导致统计数据被覆盖，如果用 CAS 更新成功的线程，则返回新建好的 WindowWrap ，CAS 设置不成功的线程继续跑这个流程，然后会进入到代码@6。</p>
<p>代码@6：如果指定索引下的时间窗口对象不为空并判断起始时间相等，则返回。</p>
<p>代码@7：如果原先存在的窗口开始时间小于当前时间戳计算出来的开始时间，则表示 bucket 已被弃用。则需要将开始时间重置到新时间戳对应的开始时间戳，重置的逻辑将在下文详细介绍。</p>
<p>代码@8：应该不会进入到该分支，因为当前时间算出来时间窗口不会比之前的小。</p>
<h5 id="2-2-3-isWindowDeprecated-详解"><a href="#2-2-3-isWindowDeprecated-详解" class="headerlink" title="2.2.3 isWindowDeprecated() 详解"></a>2.2.3 isWindowDeprecated() 详解</h5><p>接下来我们来看一下窗口的过期机制。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isWindowDeprecated</span><span class="params">(<span class="comment">/*@NonNull*/</span> WindowWrap&lt;T&gt; windowWrap)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> isWindowDeprecated(TimeUtil.currentTimeMillis(), windowWrap);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isWindowDeprecated</span><span class="params">(<span class="keyword">long</span> time, WindowWrap&lt;T&gt; windowWrap)</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> time - windowWrap.windowStart() &gt; intervalInMs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>判断滑动窗口是否生效的依据是当系统时间与滑动窗口的开始时间戳的间隔大于一个采集时间，即表示过期。即从当前窗口开始，通常包含的有效窗口为 sampleCount 个有效滑动窗口。</p>
<h5 id="2-2-4-getPreviousWindow-详解"><a href="#2-2-4-getPreviousWindow-详解" class="headerlink" title="2.2.4 getPreviousWindow() 详解"></a>2.2.4 getPreviousWindow() 详解</h5><p>根据当前时间获取前一个有效滑动窗口，其代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> WindowWrap&lt;T&gt; <span class="title">getPreviousWindow</span><span class="params">(<span class="keyword">long</span> timeMillis)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (timeMillis &lt; <span class="number">0</span>) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> idx = calculateTimeIdx(timeMillis - windowLengthInMs); <span class="comment">// @1</span></span><br><span class="line">    timeMillis = timeMillis - windowLengthInMs;</span><br><span class="line">    WindowWrap&lt;T&gt; wrap = array.get(idx);</span><br><span class="line">    <span class="keyword">if</span> (wrap == <span class="keyword">null</span> || isWindowDeprecated(wrap)) &#123;                 <span class="comment">// @2</span></span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="keyword">if</span> (wrap.windowStart() + windowLengthInMs &lt; (timeMillis)) &#123;   <span class="comment">// @3</span></span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> wrap;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其实现的关键点如下：<br>代码@1：用当前时间减去一个时间窗口间隔，然后去定位所在 LeapArray 中 数组的下标。<br>代码@2：如果为空或已过期，则返回 null。<br>代码@3：如果定位的窗口的开始时间再加上 windowLengthInMs 小于 timeMills ，说明失效，则返回 null，通常是不会走到该分支。</p>
<h5 id="2-2-5-滑动窗口图示"><a href="#2-2-5-滑动窗口图示" class="headerlink" title="2.2.5 滑动窗口图示"></a>2.2.5 滑动窗口图示</h5><p>经过上面的分析，虽然还有一个核心方法 (resetWindowTo) 未进行分析，但我们应该可以画出滑动窗口的实现的实现原理图了。<br><img src="https://img-blog.csdnimg.cn/20191229144957318.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>接下来对上面的图进行一个简单的说明：下面的示例以采集间隔为 1 s，抽样次数为 2。</p>
<a id="more"></a>

<p>首先会创建一个 LeapArray，内部持有一个数组，元素为 2,一开始进行采集时，数组的第一个，第二个下标都会 null，例如当前时间经过 calculateTimeIdx 定位到下标为 0，此时没有滑动窗口，会创建一个滑动窗口，然后该滑动窗口会采集指标，随着进入 1s 的后500ms，后会创建第二个抽样窗口。</p>
<p>然后时间前进 1s，又会定位到下标为 0 的地方，但此时不会为空，因为有上一秒的采集数据，故需要将这些采集数据丢弃 ( MetricBucket value )，然后重置该窗口的 windowStart，这就是 resetWindowTo 方法的作用。</p>
<p>在 ArrayMetric 的构造函数出现了 LeapArray 的两个实现类型 BucketLeapArray 与 OccupiableBucketLeapArray。</p>
<p>其中 BucketLeapArray 比较简单，在这里就不深入研究了， 我们接下来将重点探讨一下 OccupiableBucketLeapArray 的实现原理，即支持抢占未来的“令牌”。</p>
<h2 id="3、OccupiableBucketLeapArray-详解"><a href="#3、OccupiableBucketLeapArray-详解" class="headerlink" title="3、OccupiableBucketLeapArray 详解"></a>3、OccupiableBucketLeapArray 详解</h2><p>所谓的 OccupiableBucketLeapArray ，实现的思想是当前抽样统计中的“令牌”已耗尽，即达到用户设定的相关指标的阔值后，可以向下一个时间窗口，即借用未来一个采样区间。接下来我们详细来探讨一下它的核心实现原理。</p>
<p>3.1 类图<br><img src="https://img-blog.csdnimg.cn/20191229145158240.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们重点关注一下 OccupiableBucketLeapArray 引入了一个 FutureBucketLeapArray 的成员变量，其命名叫 borrowArray，即为借用的意思。</p>
<h4 id="3-2-构造函数"><a href="#3-2-构造函数" class="headerlink" title="3.2 构造函数"></a>3.2 构造函数</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">OccupiableBucketLeapArray</span><span class="params">(<span class="keyword">int</span> sampleCount, <span class="keyword">int</span> intervalInMs)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(sampleCount, intervalInMs);</span><br><span class="line">    <span class="keyword">this</span>.borrowArray = <span class="keyword">new</span> FutureBucketLeapArray(sampleCount, intervalInMs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从构造函数可以看出，不仅创建了一个常规的 LeapArray，对应一个采集周期，还会创建一个  borrowArray ，也会包含一个采集周期。</p>
<h4 id="3-3-newEmptyBucket"><a href="#3-3-newEmptyBucket" class="headerlink" title="3.3 newEmptyBucket"></a>3.3 newEmptyBucket</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> MetricBucket <span class="title">newEmptyBucket</span><span class="params">(<span class="keyword">long</span> time)</span> </span>&#123;</span><br><span class="line">	MetricBucket newBucket = <span class="keyword">new</span> MetricBucket();   <span class="comment">// @1</span></span><br><span class="line">	MetricBucket borrowBucket = borrowArray.getWindowValue(time);  <span class="comment">// @2</span></span><br><span class="line">	<span class="keyword">if</span> (borrowBucket != <span class="keyword">null</span>) &#123;  </span><br><span class="line">		newBucket.reset(borrowBucket);  </span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> newBucket;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们知道 newEmptyBucket 是在获取当前窗口时，对应的数组下标为空的时会创建。<br>代码@1：首先新建一个 MetricBucket。<br>代码@2：在新建的时候，如果曾经有借用过未来的滑动窗口，则将未来的滑动窗口上收集的数据 copy 到新创建的采集指标上，再返回。</p>
<h4 id="3-4-resetWindowTo"><a href="#3-4-resetWindowTo" class="headerlink" title="3.4 resetWindowTo"></a>3.4 resetWindowTo</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> WindowWrap&lt;MetricBucket&gt; <span class="title">resetWindowTo</span><span class="params">(WindowWrap&lt;MetricBucket&gt; w, <span class="keyword">long</span> time)</span> </span>&#123;      </span><br><span class="line">    w.resetTo(time);</span><br><span class="line">    MetricBucket borrowBucket = borrowArray.getWindowValue(time);</span><br><span class="line">    <span class="keyword">if</span> (borrowBucket != <span class="keyword">null</span>) &#123;</span><br><span class="line">        w.value().reset();</span><br><span class="line">        w.value().addPass((<span class="keyword">int</span>)borrowBucket.pass());</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        w.value().reset();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> w;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>遇到过期的滑动窗口时，需要对滑动窗口进行重置，这里的思路和 newEmptyBucket 的核心思想是一样的，即如果存在已借用的情况，在重置后需要加上在未来已使用过的许可，就不一一展开了。</p>
<h4 id="3-5-addWaiting"><a href="#3-5-addWaiting" class="headerlink" title="3.5 addWaiting"></a>3.5 addWaiting</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addWaiting</span><span class="params">(<span class="keyword">long</span> time, <span class="keyword">int</span> acquireCount)</span> </span>&#123;</span><br><span class="line">	WindowWrap&lt;MetricBucket&gt; window = borrowArray.currentWindow(time);</span><br><span class="line">	window.value().add(MetricEvent.PASS, acquireCount);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>经过上面的分析，先做一个大胆的猜测，该方法应该是当前滑动窗口中的“令牌”已使用完成，借用未来的令牌。将在下文给出证明。</p>
<p>滑动窗口的实现原理就介绍到这里了。大家可以按照上面的代码结合下图做一个理解。<br><img src="https://img-blog.csdnimg.cn/20191229145357710.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<blockquote>
<p>思考题，大家可以画一下 OccupiableBucketLeapArray 滑动窗口的图示。</p>
</blockquote>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>滑动窗口</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析 RateLimiter SmoothBursty 实现原理(文末附流程图)</title>
    <url>/posts/f4f9d0d8.html</url>
    <content><![CDATA[<div id="vip-container"><p>上篇详细介绍了<a href="https://blog.csdn.net/prestigeding/article/details/104884255">Sentinel FlowSlot 限流实现原理(文末附流程图与总结)</a>的限流实现机制，但主要介绍的策略限流的快速失败机制，在Sentinel 中除了快速失败，还提供了匀速排队，预热等限流策略，但我发现 Sentinel 的匀速排队、预热机制是基于 guava 的 RateLimiter，为了更加彻底的理解 Sentienl 限流相关的内容，从本文开始先来学习一下 RateLimiter 的相关实现原理。</p>
<blockquote>
<p>温馨提示：文章的末尾会总结 SmoothBursty 的核心流程图与实现原理，本文将展示笔者是如何一步一步揭晓其实现原理的方法。</p>
<p>@<a href="%E6%9C%AC%E8%8A%82%E7%9B%AE%E5%BD%95">TOC</a></p>
</blockquote>
<h2 id="1、RateLimiter-类设计图"><a href="#1、RateLimiter-类设计图" class="headerlink" title="1、RateLimiter 类设计图"></a>1、RateLimiter 类设计图</h2><p><img src="https://img-blog.csdnimg.cn/20200322143507663.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>RateLimiter<br>限流抽象类，定义限流器的基本接口。</li>
<li>SmoothRateLimiter<br>平滑限流实现器，也是一个抽象类。</li>
<li>SmoothWarmingUp<br>自带预热机制的限流器实现类型。</li>
<li>SmoothBursty<br>适应于突发流量的限流器。</li>
</ul>
<p>上述类这些属性，在讲解 SmoothBursty、SmoothWarmingUp 时再详细介绍。</p>
<blockquote>
<p>温馨提示：可以看看这些类上的注释，先初步了解其设计思想。</p>
</blockquote>
<h2 id="2、寻找入口"><a href="#2、寻找入口" class="headerlink" title="2、寻找入口"></a>2、寻找入口</h2><p>我们首先从 guava 的测试用例中尝试寻找一下 RateLimiterTest。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testSimple</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    RateLimiter limiter = RateLimiter.create(stopwatch, <span class="number">5.0</span>);</span><br><span class="line">    limiter.acquire(); <span class="comment">// R0.00, since it&#x27;s the first request</span></span><br><span class="line">    limiter.acquire(); <span class="comment">// R0.20</span></span><br><span class="line">    limiter.acquire(); <span class="comment">// R0.20</span></span><br><span class="line">    assertEvents(<span class="string">&quot;R0.00&quot;</span>, <span class="string">&quot;R0.20&quot;</span>, <span class="string">&quot;R0.20&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从这里基本可以看出，首先通过 RateLimiter.create 的静态方法创建一个限流器，然后应用程序在执行业务逻辑之前先调研限流器的 acquire 方法申请许可，接下来我们将循着这个流程来探讨其实现思路。</p>
<h2 id="3、探究-SmoothBursty-实现原理"><a href="#3、探究-SmoothBursty-实现原理" class="headerlink" title="3、探究 SmoothBursty 实现原理"></a>3、探究 SmoothBursty 实现原理</h2><h4 id="3-1-SmoothBursty-创建流程"><a href="#3-1-SmoothBursty-创建流程" class="headerlink" title="3.1 SmoothBursty 创建流程"></a>3.1 SmoothBursty 创建流程</h4><p>从上面的示例来看，应用程序首先通过 RateLimiter 的静态方法创建一个限流器，其代码如下：<br>RateLimiter#create</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> RateLimiter <span class="title">create</span><span class="params">(SleepingStopwatch stopwatch, <span class="keyword">double</span> permitsPerSecond)</span> </span>&#123; <span class="comment">// @1</span></span><br><span class="line">    RateLimiter rateLimiter = <span class="keyword">new</span> SmoothBursty(stopwatch, <span class="number">1.0</span>);                                  <span class="comment">// @2</span></span><br><span class="line">    rateLimiter.setRate(permitsPerSecond);                                                                    <span class="comment">// @3</span></span><br><span class="line">    <span class="keyword">return</span> rateLimiter;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先先介绍方法的参数：</p>
<ul>
<li>SleepingStopwatch stopwatch<br>秒表，主要是实现当前从启动开始已消耗的时间，有点类似计算一个操作耗时，实现精度纳秒。</li>
<li>double permitsPerSecond<br>每秒的许可数，即通常我们说的限流TPS。</li>
</ul>
<p>代码@2：创建 SmoothBursty 对象。</p>
<p>代码@3：调用 setRate API 设置其速率器。<br>接下来我们对其进行展开。</p>
<h5 id="3-1-1-SmoothBursty-构造函数"><a href="#3-1-1-SmoothBursty-构造函数" class="headerlink" title="3.1.1 SmoothBursty 构造函数"></a>3.1.1 SmoothBursty 构造函数</h5><p>SmoothBursty 构造函数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">SmoothBursty(SleepingStopwatch stopwatch, <span class="keyword">double</span> maxBurstSeconds) &#123;</span><br><span class="line">    <span class="keyword">super</span>(stopwatch);</span><br><span class="line">    <span class="keyword">this</span>.maxBurstSeconds = maxBurstSeconds;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里主要是为 stopWatch 与 maxBurstSeconds 赋值，其中 maxBurstSeconds 为允许的突发流量的时间，这里默认为 1.0，表示一秒，会影响最大可存储的许可数。</p>
<h5 id="3-1-2-RateLimiter-setRate-方法详解"><a href="#3-1-2-RateLimiter-setRate-方法详解" class="headerlink" title="3.1.2 RateLimiter setRate 方法详解"></a>3.1.2 RateLimiter setRate 方法详解</h5><p>RateLimiter#setRate</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">setRate</span><span class="params">(<span class="keyword">double</span> permitsPerSecond)</span> </span>&#123;</span><br><span class="line">    checkArgument(</span><br><span class="line">        permitsPerSecond &gt; <span class="number">0.0</span> &amp;&amp; !Double.isNaN(permitsPerSecond), <span class="string">&quot;rate must be positive&quot;</span>);</span><br><span class="line">    <span class="keyword">synchronized</span> (mutex()) &#123; <span class="comment">// @1</span></span><br><span class="line">      doSetRate(permitsPerSecond, stopwatch.readMicros()); <span class="comment">// @2</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：该方法需要获取该类的监视器，在同步代码块中执行，实现线程安全性。</p>
<p>代码@2：调用 doSetRate 设置速率，将调用其具体实现类 SmoothRateLimiter 的 doSetRate 方法。</p>
<p>SmoothRateLimiter#doSetRate</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">doSetRate</span><span class="params">(<span class="keyword">double</span> permitsPerSecond, <span class="keyword">long</span> nowMicros)</span> </span>&#123; <span class="comment">// @1</span></span><br><span class="line">    resync(nowMicros);   <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">double</span> stableIntervalMicros = SECONDS.toMicros(<span class="number">1L</span>) / permitsPerSecond;  <span class="comment">// @3</span></span><br><span class="line">    <span class="keyword">this</span>.stableIntervalMicros = stableIntervalMicros;                                              </span><br><span class="line">    doSetRate(permitsPerSecond, stableIntervalMicros);                                      <span class="comment">// @4</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：先来介绍一下该方法的参数的含义：</p>
<ul>
<li>double permitsPerSecond<br>每秒的许可数，即TPS。</li>
<li>long nowMicros<br>系统已运行时间。</li>
</ul>
<p>代码@2：基于当前时间重置 SmoothRateLimiter 内部的 storedPermits (已存储的许可数量) 与 nextFreeTicketMicros (下一次可以免费获取许可的时间) 值，所谓的免费指的是无需等待就可以获取设定速率的许可，该方法对理解限流许可的产生非常关键，稍后详细介绍。</p>
<a id="more"></a>

<p>代码@3：根据 TPS 算出一个稳定的获取1个许可的时间。以一秒发放5个许可，即限速为5TPS，那发放一个许可的世界间隔为 200ms，stableIntervalMicros 变量是以微妙为单位。</p>
<p>代码@4：调用 SmoothRateLimiter 的抽象方法 doSetRate 设置速率，这里会调用 SmoothBursty 的 doSetRate 方法。</p>
<p>在介绍 SmoothBursty 的 doSetRate 方法之前，我们先来看看 resync 方法的实现细节。</p>
<p>SmoothRateLimiter#resync</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">resync</span><span class="params">(<span class="keyword">long</span> nowMicros)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (nowMicros &gt; nextFreeTicketMicros) &#123;  <span class="comment">// @1 </span></span><br><span class="line">      <span class="keyword">double</span> newPermits = (nowMicros - nextFreeTicketMicros) / coolDownIntervalMicros();  <span class="comment">// @2</span></span><br><span class="line">      storedPermits = min(maxPermits, storedPermits + newPermits);    <span class="comment">// @3</span></span><br><span class="line">      nextFreeTicketMicros = nowMicros;   <span class="comment">// @4</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果当前已启动时间大于 nextFreeTicketMicros（下一次可以免费获取许可的时间），则需要重新计算许可，即又可以向许可池中添加许可。</p>
<p>代码@2：根据当前时间可增加的许可数量，在 SmoothBursty 的  coolDownIntervalMicros 方法返回的就是上文提到的 stableIntervalMicros (发放一个许可所需要的时间)，故本次可以增加的许可数的算法也好理解，即用当前时间戳减去 nextFreeTicketMicros 的差值，再除以发送一个许可所需要的时间即可。</p>
<p>代码@3：计算当前可用的许可。</p>
<p>代码@4：更新下一次可增加计算许可的时间。</p>
<p>接下来再继续看 SmoothBursty 的 doSetRate 方法。</p>
<p>SmoothBursty#doSetRate</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">doSetRate</span><span class="params">(<span class="keyword">double</span> permitsPerSecond, <span class="keyword">double</span> stableIntervalMicros)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> oldMaxPermits = <span class="keyword">this</span>.maxPermits;</span><br><span class="line">    maxPermits = maxBurstSeconds * permitsPerSecond;</span><br><span class="line">    <span class="keyword">if</span> (oldMaxPermits == Double.POSITIVE_INFINITY) &#123;</span><br><span class="line">        storedPermits = maxPermits;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        storedPermits =</span><br><span class="line">            (oldMaxPermits == <span class="number">0.0</span>)</span><br><span class="line">                ? <span class="number">0.0</span> <span class="comment">// initial state</span></span><br><span class="line">                : storedPermits * maxPermits / oldMaxPermits;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里主要是初始化 storedPermits 的值，该限速器支持在运行过程中动态改变 permitsPerSecond 的值。</p>
<h4 id="3-2-SmoothBursty-acquire-工作流程"><a href="#3-2-SmoothBursty-acquire-工作流程" class="headerlink" title="3.2 SmoothBursty acquire 工作流程"></a>3.2 SmoothBursty acquire 工作流程</h4><p>RateLimiter 中的 acquire 方法如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">acquire</span><span class="params">(<span class="keyword">int</span> permits)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> microsToWait = reserve(permits);    <span class="comment">// @1</span></span><br><span class="line">    stopwatch.sleepMicrosUninterruptibly(microsToWait);   <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> * microsToWait / SECONDS.toMicros(<span class="number">1L</span>);   <span class="comment">// @3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：根据当前剩余的许可与本次申请的许可来判断本次申请需要等待的时长，如果返回0则表示无需等待。</p>
<p>代码@2：如果需要等待的时间不为0，表示触发限速，睡眠指定时间后唤醒。</p>
<p>代码@3：返回本次申请等待的时长。</p>
<p>接下来重点介绍 reserve 方法的实现原理。</p>
<p>RateLimiter#reserve</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">long</span> <span class="title">reserve</span><span class="params">(<span class="keyword">int</span> permits)</span> </span>&#123;</span><br><span class="line">    checkPermits(permits);</span><br><span class="line">    <span class="keyword">synchronized</span> (mutex()) &#123;  <span class="comment">// @1</span></span><br><span class="line">      <span class="keyword">return</span> reserveAndGetWaitLength(permits, stopwatch.readMicros()); <span class="comment">// @2</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：限速器主要维护的重要数据字段( storedPermits )，对其进行维护时都需要先获取锁。</p>
<p>代码@2：调用内部方法 reserveAndGetWaitLength 来计算需要等待时间。</p>
<p>继续跟踪 reserveAndGetWaitLength 方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">long</span> <span class="title">reserveAndGetWaitLength</span><span class="params">(<span class="keyword">int</span> permits, <span class="keyword">long</span> nowMicros)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> momentAvailable = reserveEarliestAvailable(permits, nowMicros);   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span> max(momentAvailable - nowMicros, <span class="number">0</span>);  <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：根据当前拥有的许可数量、当前时间判断待申请许可最早能得到满足的最早时间，用momentAvailable 表示。</p>
<p>代码@2：然后计算 momentAvailable 与 nowMicros 的差值与0做比较，得出需要等待的时间。</p>
<p>继续跟踪 reserveEarliestAvailable方法，该方法在 RateLimiter 中一个抽象方法，具体实现在其子类 SmoothRateLimiter 中。</p>
<p>SmoothRateLimiter#reserveEarliestAvailable</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">long</span> <span class="title">reserveEarliestAvailable</span><span class="params">(<span class="keyword">int</span> requiredPermits, <span class="keyword">long</span> nowMicros)</span> </span>&#123;</span><br><span class="line">    resync(nowMicros);   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">long</span> returnValue = nextFreeTicketMicros;</span><br><span class="line">    <span class="keyword">double</span> storedPermitsToSpend = min(requiredPermits, <span class="keyword">this</span>.storedPermits); <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">double</span> freshPermits = requiredPermits - storedPermitsToSpend; <span class="comment">// @3</span></span><br><span class="line">    <span class="keyword">long</span> waitMicros =</span><br><span class="line">        storedPermitsToWaitTime(<span class="keyword">this</span>.storedPermits, storedPermitsToSpend)</span><br><span class="line">            + (<span class="keyword">long</span>) (freshPermits * stableIntervalMicros);  <span class="comment">// @4</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.nextFreeTicketMicros = LongMath.saturatedAdd(nextFreeTicketMicros, waitMicros);  <span class="comment">// @5</span></span><br><span class="line">    <span class="keyword">this</span>.storedPermits -= storedPermitsToSpend;    <span class="comment">// @6</span></span><br><span class="line">    <span class="keyword">return</span> returnValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：在尝试申请许可之前，先根据当前时间即发放许可速率更新 storedPermits 与 nextFreeTicketMicros（下一次可以免费获取许可的时间）。</p>
<p>代码@2：计算本次能从 storedPermits 中消耗的许可数量，取需要申请的许可数量与当前可用的许可数量的最小值，用 storedPermitsToSpend 表示。</p>
<p>代码@3：如果需要申请的许可数量( requiredPermits )大于当前剩余许可数量( storedPermits )，则还需要等待新的许可生成，用 freshPermits 表示，即如果该值大于0，则表示本次申请需要阻塞一定时间。</p>
<p>代码@4：计算本次申请需要等待的时间，storedPermitsToWaitTime 方法在 SmoothBursty 的实现中默认返回 0，即 SmoothBursty 的等待时间主要来自按照速率生成 freshPermits 个许可的时间，生成一个许可的时间为 stableIntervalMicros，故需要等待的时长为 freshPermits * stableIntervalMicros。</p>
<p>代码@5：更新 nextFreeTicketMicros 为当前时间加上需要等待的时间。</p>
<p>代码@6：更新 storedPermits 的值，即减少本次已消耗的许可数量。</p>
<p>代码@7：请注意这里返回的 returnValue 的值，并没有包含由于剩余许可需要等待创建新许可的时间，即允许一定的突发流量，故本次计算需要的等待时间将对下一次请求生效，这也是框架作者将该限速器取名为 SmoothBursty 的缘由。</p>
<p>SmoothBursty 的 acquire 方法就介绍到这里了。</p>
<h2 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h2><p>由于源码分析会显得枯燥与不直观，我们先给出如下流程图：<br><img src="https://img-blog.csdnimg.cn/20200322144556364.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>SmoothBursty 的核心设计思想基本与令牌桶类似，但还是有些不同。<br>基本思想：</p>
<ol>
<li>SmoothBursty 以指定的速率生成许可，在 SmoothBursty 中用 storedPermits 表示。</li>
<li>当一个请求需要申请许可时，如果需要申请的许可数小于 storedPermits ，则消耗指定许可，直接返回，无需等待。</li>
<li>当一个请求需要申请的许可大于 storedPermits 时，则计算需要等待的时间，更新下一次许可可发放时间，直接返回，即当请求消耗掉所有许可后，当前请求并不会阻塞，而是影响下一个请求，即支持突发流量。</li>
</ol>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>源码</tag>
        <tag>RateLimiter</tag>
        <tag>SmoothBursty</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析 RocketMQ DLedger 多副本存储实现</title>
    <url>/posts/f03d9942.html</url>
    <content><![CDATA[<div id="vip-container"><p>RocketMQ DLedger 的存储实现思路与 RocketMQ 的存储实现思路相似，本文就不再从源码角度详细剖析其实现，只是点出其实现关键点。我们不妨简单回顾一下 CommitLog 文件、ConsumeQueue 文件设计思想。</p>
<p>其文件组成形式如下：<br><img src="https://img-blog.csdnimg.cn/20190831215052708.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>正如上图所示，多个 commitlog 文件组成一个逻辑上的连续文件，使用 MappedFileQueue 表示，单个 commitlog 文件使用 MappedFile 表示。</p>
<blockquote>
<p>温馨提示：如果想详细了解 RocketMQ 关于存储部分的讲解，可以关注笔者的《RocketMQ 技术内幕》一书。</p>
</blockquote>
<h2 id="1、DLedger-存储相关类图"><a href="#1、DLedger-存储相关类图" class="headerlink" title="1、DLedger 存储相关类图"></a>1、DLedger 存储相关类图</h2><p><img src="https://img-blog.csdnimg.cn/20190831215151796.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="1-1-DLedgerStore"><a href="#1-1-DLedgerStore" class="headerlink" title="1.1 DLedgerStore"></a>1.1 DLedgerStore</h3><p>存储抽象类，定义如下核心方法：</p>
<ul>
<li>public abstract DLedgerEntry appendAsLeader(DLedgerEntry entry)<br>向主节点追加日志(数据)。</li>
<li>public abstract DLedgerEntry appendAsFollower(DLedgerEntry entry, long leaderTerm, String leaderId)<br>向从节点同步日志。</li>
<li>public abstract DLedgerEntry get(Long index)<br>根据日志下标查找日志。</li>
<li>public abstract long getCommittedIndex()<br>获取已提交的下标。</li>
<li>public abstract long getLedgerEndTerm()<br>获取 Leader 当前最大的投票轮次。</li>
<li>public abstract long getLedgerEndIndex()<br>获取 Leader 下一条日志写入的下标（最新日志的下标）。</li>
<li>public abstract long getLedgerBeginIndex()<br>获取 Leader 第一条消息的下标。</li>
<li>public void updateCommittedIndex(long term, long committedIndex)<br>更新commitedIndex的值，为空实现，由具体的存储子类实现。</li>
<li>protected void updateLedgerEndIndexAndTerm()<br>更新 Leader 维护的 ledgerEndIndex 和 ledgerEndTerm 。</li>
<li>public void flush()<br>刷写，空方法，由具体子类实现。</li>
<li>public long truncate(DLedgerEntry entry, long leaderTerm, String leaderId)<br>删除日志，空方法，由具体子类实现。</li>
<li>public void startup()<br>启动存储管理器，空方法，由具体子类实现。</li>
<li>public void shutdown()<br>关闭存储管理器，空方法，由具体子类实现。</li>
</ul>
<h3 id="1-2-DLedgerMemoryStore"><a href="#1-2-DLedgerMemoryStore" class="headerlink" title="1.2 DLedgerMemoryStore"></a>1.2 DLedgerMemoryStore</h3><p>Dledger 基于内存实现的日志存储。</p>
<h3 id="1-3-DLedgerMmapFileStore"><a href="#1-3-DLedgerMmapFileStore" class="headerlink" title="1.3  DLedgerMmapFileStore"></a>1.3  DLedgerMmapFileStore</h3><p>基于文件内存映射机制的存储实现。其核心属性如下：</p>
<ul>
<li>long ledgerBeginIndex =  -1<br>日志的起始索引，默认为 -1。<br>l- ong ledgerEndIndex = -1<br>下一条日志下标，默认为 -1。</li>
<li>long committedIndex = -1<br>已提交的日志索引。</li>
<li>long ledgerEndTerm<br>当前最大的投票轮次。</li>
<li>DLedgerConfig dLedgerConfig<br>DLedger 的配置信息。</li>
<li>MemberState memberState<br>状态机。</li>
<li>MmapFileList dataFileList<br>日志文件(数据文件)的内存映射Queue。</li>
<li>MmapFileList indexFileList<br>索引文件的内存映射文件集合。（可对标 RocketMQ MappedFIleQueue )。</li>
<li>ThreadLocal&lt; ByteBuffer&gt; localIndexBuffer<br>本地线程变量，用来缓存索引ByteBuffer。</li>
<li>ThreadLocal&lt; ByteBuffer&gt; localEntryBuffer<br>本地线程变量，用来缓存数据索引ByteBuffer。</li>
<li>FlushDataService flushDataService<br>数据文件刷盘线程。</li>
<li>CleanSpaceService cleanSpaceService<br>清除过期日志文件线程。</li>
<li>boolean isDiskFull = false<br>磁盘是否已满。</li>
<li>long lastCheckPointTimeMs<br>上一次检测点（时间戳）。</li>
<li>AtomicBoolean hasLoaded<br>是否已经加载，主要用来避免重复加载(初始化)日志文件。</li>
<li>AtomicBoolean hasRecovered<br> ​    是否已恢复。</li>
</ul>
<a id="more"></a>

<h2 id="2、DLedger-存储-对标-RocketMQ-存储"><a href="#2、DLedger-存储-对标-RocketMQ-存储" class="headerlink" title="2、DLedger 存储 对标 RocketMQ 存储"></a>2、DLedger 存储 对标 RocketMQ 存储</h2><p>存储部分主要包含存储映射文件、消息存储格式、刷盘、文件加载与文件恢复、过期文件删除等，由于这些内容在 RocketMQ 存储部分都已详细介绍，故本文点到为止，其对应的参考映射如下：<br><img src="https://img-blog.csdnimg.cn/20190831215536527.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在 RocketMQ 中使用 MappedFile 来表示一个物理文件，而在 DLedger 中使用 DefaultMmapFIle 来表示一个物理文件。</p>
<p>在 RocketMQ 中使用 MappedFile 来表示多个物理文件(逻辑上连续)，而在 DLedger 中则使用MmapFileList。</p>
<p>在 RocketMQ 中使用 DefaultMessageStore 来封装存储逻辑，而在 DLedger 中则使用DLedgerMmapFileStore来封装存储逻辑。</p>
<p>在 RocketMQ 中使用 Commitlog$FlushCommitLogService 来实现 commitlog 文件的刷盘，而在 DLedger 中则使用DLedgerMmapFileStore$FlushDataService来实现文件刷盘。</p>
<p>在 RocketMQ 中使用 DefaultMessageStore$CleanCommitlogService 来实现 commitlog 过期文件的删除，而 DLedger 中则使用 DLedgerMmapFileStore$CleanSpaceService来实现。</p>
<p>由于其实现原理相同，上述部分已经在《RocketMQ 技术内幕》第4章中详细剖析，故这里就不重复分析了。</p>
<h2 id="3、DLedger-数据存储格式"><a href="#3、DLedger-数据存储格式" class="headerlink" title="3、DLedger 数据存储格式"></a>3、DLedger 数据存储格式</h2><p><img src="https://img-blog.csdnimg.cn/2019083121572821.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>存储格式字段的含义如下：</p>
<ul>
<li>magic<br>魔数，4字节。</li>
<li>size<br>条目总长度，包含 Header(协议头) + 消息体，占4字节。</li>
<li>entryIndex<br>当前条目的 index，占8字节。</li>
<li>entryTerm<br>当前条目所属的 投票轮次，占8字节。</li>
<li>pos<br>该条目的物理偏移量，类似于 commitlog 文件的物理偏移量，占8字节。</li>
<li>channel<br>保留字段，当前版本未使用，占4字节。</li>
<li>chain crc<br>当前版本未使用，占4字节。</li>
<li>body crc<br>body 的 CRC 校验和，用来区分数据是否损坏，占4字节。</li>
<li>body size<br>用来存储 body 的长度，占4个字节。</li>
<li>body<br>具体消息的内容。</li>
</ul>
<p>源码参考点：DLedgerMmapFileStore#recover、DLedgerEntry、DLedgerEntryCoder。</p>
<h2 id="4、DLedger-索引存储格式"><a href="#4、DLedger-索引存储格式" class="headerlink" title="4、DLedger 索引存储格式"></a>4、DLedger 索引存储格式</h2><p><img src="https://img-blog.csdnimg.cn/20190831215844719.png" alt="在这里插入图片描述"><br>即一个索引条目占32个字节。</p>
<h2 id="5、思考"><a href="#5、思考" class="headerlink" title="5、思考"></a>5、思考</h2><p>DLedger 存储相关就介绍到这里，为了与大家增加互动，特提出如下两个思考题，欢迎与作者互动，这些问题将在该系列的后面文章专题探讨。</p>
<p>1、DLedger 如果整合 RocketMQ 中的 commitlog 文件，使之支持多副本？<br>2、从老版本如何升级到新版本，需要考虑哪些因素呢？</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>源码</tag>
        <tag>多副本</tag>
        <tag>主从切换</tag>
        <tag>DLedger</tag>
        <tag>存储</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析 Sentinel 之 Dubbo适配原理</title>
    <url>/posts/2496ec4.html</url>
    <content><![CDATA[<div id="vip-container"><p>在<a href="https://blog.csdn.net/prestigeding/article/details/103544443">Alibaba Sentinel 限流与熔断初探(技巧篇)</a> 的示例中我选择了 sentinel-demo-apache-dubbo 作为突破点，故本文就从该项目入手，看看 Sentinel 是如何对 Dubbo 做的适配，让项目使用方无感知，只需要引入对应的依即可。</p>
<p>sentinel-apache-dubbo-adapter 比较简单，展开如下：<br><img src="https://img-blog.csdnimg.cn/20191222163854410.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>上面的代码应该比较简单，在正式进入源码研究之前，我先抛出如下二个问题：</p>
<ul>
<li>1、限流、熔断相关的功能是在 Dubbo 的客户端实现还是服务端实现？为什么？</li>
<li>2、如何对 Dubbo 进行功能扩展而无需改动业务代码？</li>
</ul>
<p>Dubbo 提供了 Filter 机制对功能进行无缝扩展，有关 Dubbo Filter 机制，大家可以查阅笔者的源码研究 Dubbo 系列：<a href="https://mp.weixin.qq.com/s/uv7ev-D-9wo3Oct3NCcKTQ">Dubbo Filter机制概述</a>。</p>
<p>接下来我们带着上面的问题1开始本章的研究。</p>
<h2 id="1、源码分析-SentinelDubboConsumerFilter"><a href="#1、源码分析-SentinelDubboConsumerFilter" class="headerlink" title="1、源码分析 SentinelDubboConsumerFilter"></a>1、源码分析 SentinelDubboConsumerFilter</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Activate(group = &quot;consumer&quot;)</span>   <span class="comment">// @1</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SentinelDubboConsumerFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SentinelDubboConsumerFilter</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        RecordLog.info(<span class="string">&quot;Sentinel Apache Dubbo consumer filter initialized&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Result <span class="title">invoke</span><span class="params">(Invoker&lt;?&gt; invoker, Invocation invocation)</span> <span class="keyword">throws</span> RpcException </span>&#123;</span><br><span class="line">        Entry interfaceEntry = <span class="keyword">null</span>;</span><br><span class="line">        Entry methodEntry = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            String resourceName = DubboUtils.getResourceName(invoker, invocation, DubboConfig.getDubboConsumerPrefix());   <span class="comment">// @2</span></span><br><span class="line">            interfaceEntry = SphU.entry(invoker.getInterface().getName(),</span><br><span class="line">                ResourceTypeConstants.COMMON_RPC, EntryType.OUT);     <span class="comment">// @3</span></span><br><span class="line">            methodEntry = SphU.entry(resourceName, ResourceTypeConstants.COMMON_RPC, EntryType.OUT);    <span class="comment">// @4</span></span><br><span class="line"></span><br><span class="line">            Result result = invoker.invoke(invocation);            <span class="comment">// @5</span></span><br><span class="line">            <span class="keyword">if</span> (result.hasException()) &#123;                                     <span class="comment">// @6</span></span><br><span class="line">                Throwable e = result.getException();</span><br><span class="line">                <span class="comment">// Record common exception.</span></span><br><span class="line">                Tracer.traceEntry(e, interfaceEntry);</span><br><span class="line">                Tracer.traceEntry(e, methodEntry);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> result;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (BlockException e) &#123;        </span><br><span class="line">            <span class="keyword">return</span> DubboFallbackRegistry.getConsumerFallback().handle(invoker, invocation, e);  <span class="comment">// @7</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (RpcException e) &#123;    </span><br><span class="line">            Tracer.traceEntry(e, interfaceEntry);</span><br><span class="line">            Tracer.traceEntry(e, methodEntry);</span><br><span class="line">            <span class="keyword">throw</span> e;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (methodEntry != <span class="keyword">null</span>) &#123;   <span class="comment">// @8</span></span><br><span class="line">                methodEntry.exit();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (interfaceEntry != <span class="keyword">null</span>) &#123;</span><br><span class="line">                interfaceEntry.exit();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：通过 @Activate 注解定义该 Filter 在客户端生效。</p>
<p>代码@2：在 Sentinel 中一个非常核心的概念就是资源，即要定义限流的目标，当出现什么异常（匹配用户配置的规则）对什么进行熔断操作，Dubbo 服务中的资源通常是 Dubbo 服务，分为服务接口级或方法级，故该方法返回 Dubbo 的资源名，其主要实现特征如下：</p>
<ul>
<li>如果启用用户定义资源的前缀，默认为 false ，可以通过配置属性：csp.sentinel.dubbo.resource.use.prefix 来定义是否需要启用前缀。如果启用前缀，消费端的默认前缀为 dubbo:consumer:，可以通过配置属性 csp.sentinel.dubbo.resource.consumer.prefix 来自定义消费端的资源前缀。</li>
<li>Dubbo 资源的名称表示方法为：interfaceName + “:” + methodName + “(“ + “paramTyp1参数列表，多个用 , 隔开” + “)”。</li>
</ul>
<p>代码@3：调用 Sentinel 核心API  SphU.entry 进入 Dubbo InterfaceName。从方法的名称我们也能很容易的理解，就是使用 Sentienl API 进入资源名为 Dubbo 接口提供者类全路径限定名，即认为调用该方法，Sentienl 会收集该资源的调用信息，然后Sentinel 根据运行时收集的信息，再配合限流规则，熔断等规则进行计算是否需要限流或熔断。本节我们不打算深入研究 SphU 的核心方法研究，先初步了解该方法：</p>
<ul>
<li><p>String name 资源的名称。</p>
</li>
<li><p>int resourceType 资源的类型，在 Sentinel 中目前定义了 如下五中资源：</p>
<ul>
<li>ResourceTypeConstants.COMMON<br>同样类型。</li>
<li>ResourceTypeConstants.COMMON_WEB<br>WEB 类资源。</li>
<li>ResourceTypeConstants.COMMON_RPC<br>RPC 类型。</li>
<li>ResourceTypeConstants.COMMON_API_GATEWAY<br>接口网关。</li>
<li>ResourceTypeConstants.COMMON_DB_SQL<br>数据库 SQL 语句。</li>
</ul>
</li>
<li><p>EntryType type<br>进入资源的方式，主要分为 EntryType.OUT、EntryType.IN，只有 EntryType.IN 方式才能对资源进行阻塞。</p>
</li>
</ul>
<p>代码@4：调用 Sentinel 核心API SphU.entry 进入 Dubbo method 级别。</p>
<p>代码@5：调用 Dubbo 服务提供者方法。</p>
<p>代码@6：如果出现调用异常，可以通过 Sentinel 的 Tracer.traceEntry 跟踪本次调用资源进入的情况，详细 API 将在该系列的后续文章中详细介绍。</p>
<p>代码@7：如果是由于触发了限流、熔断等操作，抛出了阻塞异常，可通过 注册 ConsumerFallback 来实现消费者快速失败，将在下文详细介绍。</p>
<p>代码@8： SphU.entry 与 资源的 exit 方法需要成对出现，否则会出现统计错误。</p>
<a id="more"></a>

<h2 id="2、源码分析-SentienlDubboProviderFilters"><a href="#2、源码分析-SentienlDubboProviderFilters" class="headerlink" title="2、源码分析 SentienlDubboProviderFilters"></a>2、源码分析 SentienlDubboProviderFilters</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Activate(group = &quot;provider&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SentinelDubboProviderFilter</span> <span class="keyword">implements</span> <span class="title">Filter</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SentinelDubboProviderFilter</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        RecordLog.info(<span class="string">&quot;Sentinel Apache Dubbo provider filter initialized&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Result <span class="title">invoke</span><span class="params">(Invoker&lt;?&gt; invoker, Invocation invocation)</span> <span class="keyword">throws</span> RpcException </span>&#123;</span><br><span class="line">        <span class="comment">// Get origin caller.</span></span><br><span class="line">        String application = DubboUtils.getApplication(invocation, <span class="string">&quot;&quot;</span>);</span><br><span class="line">        Entry interfaceEntry = <span class="keyword">null</span>;</span><br><span class="line">        Entry methodEntry = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            String resourceName = DubboUtils.getResourceName(invoker, invocation, DubboConfig.getDubboProviderPrefix());   <span class="comment">// @1</span></span><br><span class="line">            String interfaceName = invoker.getInterface().getName();</span><br><span class="line">            <span class="comment">// Only need to create entrance context at provider side, as context will take effect</span></span><br><span class="line">            <span class="comment">// at entrance of invocation chain only (for inbound traffic).</span></span><br><span class="line">            ContextUtil.enter(resourceName, application);</span><br><span class="line">            interfaceEntry = SphU.entry(interfaceName, ResourceTypeConstants.COMMON_RPC, EntryType.IN);  <span class="comment">// @2</span></span><br><span class="line">            methodEntry = SphU.entry(resourceName, ResourceTypeConstants.COMMON_RPC,</span><br><span class="line">                EntryType.IN, invocation.getArguments());</span><br><span class="line">            Result result = invoker.invoke(invocation);</span><br><span class="line">            <span class="keyword">if</span> (result.hasException()) &#123;</span><br><span class="line">                Throwable e = result.getException();</span><br><span class="line">                <span class="comment">// Record common exception.</span></span><br><span class="line">                Tracer.traceEntry(e, interfaceEntry);</span><br><span class="line">                Tracer.traceEntry(e, methodEntry);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> result;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (BlockException e) &#123; </span><br><span class="line">            <span class="keyword">return</span> DubboFallbackRegistry.getProviderFallback().handle(invoker, invocation, e);   <span class="comment">// @3</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (RpcException e) &#123;</span><br><span class="line">            Tracer.traceEntry(e, interfaceEntry);</span><br><span class="line">            Tracer.traceEntry(e, methodEntry);</span><br><span class="line">            <span class="keyword">throw</span> e;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (methodEntry != <span class="keyword">null</span>) &#123;</span><br><span class="line">                methodEntry.exit(<span class="number">1</span>, invocation.getArguments());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (interfaceEntry != <span class="keyword">null</span>) &#123;</span><br><span class="line">                interfaceEntry.exit();</span><br><span class="line">            &#125;</span><br><span class="line">            ContextUtil.exit();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Dubbo 服务提供者与消费端的适配套路差不多，这里就重点阐述一下其不同点。<br>代码@1：如果启用前缀，默认服务提供者的资源会加上前缀：dubbo:provider:，可以通过在配置文件中配置属性 csp.sentinel.dubbo.resource.provider.prefix 改变其默认值。</p>
<p>代码@2：服务端调用 SphU.entry 时其进入类型为 EntryType.IN。</p>
<p>代码@3：同样可以在 抛出阻塞异常(BlockException) 时指定快速失败回调处理逻辑。</p>
<h2 id="3、Sentienl-Dubbo-FallBack-机制"><a href="#3、Sentienl-Dubbo-FallBack-机制" class="headerlink" title="3、Sentienl Dubbo FallBack 机制"></a>3、Sentienl Dubbo FallBack 机制</h2><p>Sentinel Dubbo FallBack 机制比较简单，就是提供一个全局的 FallBack 回调，可以分别为服务提供端，服务消费端指定。只需实现 DubboFallback 接口，其声明如下：<br><img src="https://img-blog.csdnimg.cn/2019122216430790.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>然后需要调用 DubboFallbackRegistry 的 setConsumerFallback 和 setProviderFallback 方法分别注册消费端，服务端相关的监听器。通常只需要在启动应用的时候，将其进行注册即可。</p>
<h2 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h2><p>本文只是以 Sentienl 对 Dubbo 的适配实现来了解 Sentinel 核心相关的 API，其核心实现就是利用 Dubbo 的 Filter 机制进行无缝的过滤拦截。但本文只是提到 Sentinel 如下核心方法：</p>
<ul>
<li>SphU.entry</li>
<li>Entry.exit</li>
<li>Tracer.traceEntry</li>
</ul>
<p>上述这些方法，将在后面的文章中进行深入探究，即从下一篇文章开始，我们将真正进入 Sentinel 的世界中，让我们一探究竟限流、熔断通常是如何实现的。</p>
<p>本文就介绍到这里了，点赞是一种美德，您的点赞是我持续分享的最大动力，谢谢。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>Dubbo适配</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析 Sentinel DegradeSlot 熔断实现原理</title>
    <url>/posts/45a744cd.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、DegradeSlot-概述"><a href="#1、DegradeSlot-概述" class="headerlink" title="1、DegradeSlot 概述"></a>1、DegradeSlot 概述</h2><p>Sentinel 中的熔断实现类为 DegradeSlot。DegradeSlot 的类定义如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200412153916327.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>由此可见，熔断主要实现逻辑定义在 DegradeRuleManager 的 checkDegrade 方法中。<br>DegradeRuleManager#checkDegrade<br><img src="https://img-blog.csdnimg.cn/20200412153949610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">代码@1：首先从 degradeRules 熔断规则缓存中获取资源的熔断规则。</p>
<p>代码@2：遍历熔断规则列表。</p>
<p>代码@3：调用熔断规则 DegradeRule 的  passCheck，如果该方法返回 false，则表示需要熔断，则抛出 DegradeException 异常。</p>
<p>即实现熔断的核心逻辑在 DegradeRule 中。</p>
<a id="more"></a>

<h2 id="2、DegradeRule-详解"><a href="#2、DegradeRule-详解" class="headerlink" title="2、DegradeRule 详解"></a>2、DegradeRule 详解</h2><p>在介绍 DegradeRule 之前我们先来看看 sentinel-dashboard 关于熔断降级规则的配置：<br><img src="https://img-blog.csdnimg.cn/20200412154228974.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>我们可以直观的得知，降级规则可以根据如下三个指标进行设置：RT(响应时间)、异常比例、异常数。</p>
<h4 id="2-1-DegradeRule-类图"><a href="#2-1-DegradeRule-类图" class="headerlink" title="2.1 DegradeRule 类图"></a>2.1 DegradeRule 类图</h4><p><img src="https://img-blog.csdnimg.cn/20200412154252374.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>double count<br>上面配置规则中对应的配置值，例如当降级策略为RT时，表示设置的响应时间值，其他类似。</li>
<li>int timeWindow<br>降级发生后多久进行恢复，即结束降级，单位为毫秒。</li>
<li>int grade<br>降级策略，可以选值如下：<br>1）DEGRADE_GRADE_RT<br>响应时间。<br>2）DEGRADE_GRADE_EXCEPTION_RATIO<br>异常数比例。<br>3）DEGRADE_GRADE_EXCEPTION_COUNT<br>异常数量。</li>
<li>int rtSlowRequestAmount<br>触发 RT 响应熔断出现的最小连续慢响应请求数量。</li>
<li>int minRequestAmount<br>触发熔断最小的请求数量。</li>
</ul>
<h4 id="2-2-passCheck方法详解"><a href="#2-2-passCheck方法详解" class="headerlink" title="2.2 passCheck方法详解"></a>2.2 passCheck方法详解</h4><p>根据当前请求的情况触发熔断的判断逻辑由 passCheck 方法实现。在介绍这个方法之前，我们根据该方法调用上下文得知，该方法返回 false，则触发熔断。<br>DegradeRule#passCheck</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (cut.get()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step1：如果当前正在处于熔断降级中，将直接返回 false，请求将被限流。</p>
<p>DegradeRule#passCheck</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ClusterNode clusterNode = ClusterBuilderSlot.getClusterNode(<span class="keyword">this</span>.getResource());</span><br><span class="line">    <span class="keyword">if</span> (clusterNode == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：根据资源名称获得对应的集群类节点，有关集群限流将在后续文章中详细介绍。</p>
<p>DegradeRule#passCheck</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (grade == RuleConstant.DEGRADE_GRADE_RT) &#123;</span><br><span class="line">    <span class="keyword">double</span> rt = clusterNode.avgRt();</span><br><span class="line">    <span class="keyword">if</span> (rt &lt; <span class="keyword">this</span>.count) &#123;</span><br><span class="line">        passCount.set(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (passCount.incrementAndGet() &lt; rtSlowRequestAmount) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>step3：降级策略为基于响应时间的判断规则，其核心实现关键点：</p>
<ul>
<li>首先获取节点的平均响应时间。</li>
<li>如果当前平均响应时间小于阔值，则放行，并重置 passCount 为 0。</li>
<li>如果当前平均响应时间大于阔值，但连续次数小于 rtSlowRequestAmount，依然放行，只有当连续 rtSlowRequestAmount 次响应慢才会触发降级。</li>
</ul>
<p>DegradeRule#passCheck</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (grade == RuleConstant.DEGRADE_GRADE_EXCEPTION_RATIO) &#123;</span><br><span class="line">    <span class="keyword">double</span> exception = clusterNode.exceptionQps();</span><br><span class="line">    <span class="keyword">double</span> success = clusterNode.successQps();</span><br><span class="line">    <span class="keyword">double</span> total = clusterNode.totalQps();</span><br><span class="line">    <span class="keyword">if</span> (total &lt; minRequestAmount) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="keyword">double</span> realSuccess = success - exception;</span><br><span class="line">    <span class="keyword">if</span> (realSuccess &lt;= <span class="number">0</span> &amp;&amp; exception &lt; minRequestAmount) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="keyword">if</span> (exception / success &lt; count) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step4：降级策略为根据异常比例，其判断规则核心如下：</p>
<ul>
<li>分别获取成功QPS，异常QPS，总TPS。</li>
<li>如果当前总 QPS 小于 minRequestAmount，则直接返回成功，表示暂不进行熔断规则判断。</li>
<li>如果成功数小于异常数并且异常数量小于 minRequestAmount，则返回true，表示暂不进熔断规则的判断。</li>
<li>如果异常比例小于阔值，同样返回 true，表示暂不进熔断规则的判断。</li>
</ul>
<p>DegradeRule#passCheck</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (grade == RuleConstant.DEGRADE_GRADE_EXCEPTION_COUNT) &#123;</span><br><span class="line">    <span class="keyword">double</span> exception = clusterNode.totalException();</span><br><span class="line">    <span class="keyword">if</span> (exception &lt; count) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;        </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step5：降级策略为根据异常数量，这策略只是简单的判断错误数量即可。</p>
<p>DegradeRule#passCheck</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (cut.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>)) &#123;</span><br><span class="line">    ResetTask resetTask = <span class="keyword">new</span> ResetTask(<span class="keyword">this</span>);</span><br><span class="line">    pool.schedule(resetTask, timeWindow, TimeUnit.SECONDS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step6：如果符合触发熔断的规则，则原子更新 cut，并且开启一个调度任务，在指定时间过后进行降级恢复。</p>
<p>Sentinel 的熔断机制实现比较简单，就介绍到这了，下一篇将介绍 Sentinel 基于集群的限流策略。</p>
<p><strong>好了，我亲爱的读者朋友，以上就是本文的全部内容了，对Sentinel 的熔断实现原理是否已Get。原创不易，莫要白票，请你为本文点赞个吧，这将是我写作更多优质文章的最强动力。</strong></p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>熔断</tag>
        <tag>源码</tag>
        <tag>DegradeSlot</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析 Sentinel 实时数据采集实现原理</title>
    <url>/posts/5f8f7185.html</url>
    <content><![CDATA[<div id="vip-container"><p>本篇将重点关注 Sentienl 实时数据收集，即 Sentienl 具体是如何收集调用信息，以此来判断是否需要触发限流或熔断。</p>
<p>Sentienl 实时数据收集的入口类为 StatisticSlot。</p>
<p>我们先简单来看一下 StatisticSlot 该类的注释，来看一下该类的整体定位。</p>
<p>StatisticSlot，专用于实时统计的 slot。在进入一个资源时，在执行 Sentienl 的处理链条中会进入到该 slot 中，需要完成如下计算任务：</p>
<ul>
<li>集群维度计算资源的总统计信息，用于集群限流，后续文章将详细探讨。</li>
<li>来自不同调用方/来源的群集节点的统计信息。</li>
<li>特定调用上下文环境的统计信息。</li>
<li>统计所有入口的统计信息。</li>
</ul>
<p>接下来用源码分析的手段来详细分析 StatisticSlot 的实现原理。</p>
<h2 id="1、源码分析-StatisticSlot"><a href="#1、源码分析-StatisticSlot" class="headerlink" title="1、源码分析 StatisticSlot"></a>1、源码分析 StatisticSlot</h2><h4 id="1-1-StatisticSlot-entry-详解"><a href="#1-1-StatisticSlot-entry-详解" class="headerlink" title="1.1 StatisticSlot entry 详解"></a>1.1 StatisticSlot entry 详解</h4><p>StatisticSlot#entry </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">entry</span><span class="params">(Context context, ResourceWrapper resourceWrapper, DefaultNode node, <span class="keyword">int</span> count,<span class="keyword">boolean</span> prioritized, Object... args)</span> <span class="keyword">throws</span> Throwable </span>&#123; </span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		<span class="comment">// Do some checking.</span></span><br><span class="line">                fireEntry(context, resourceWrapper, node, count, prioritized, args);  <span class="comment">// @1</span></span><br><span class="line">        	<span class="comment">// Request passed, add thread count and pass count.</span></span><br><span class="line">        	node.increaseThreadNum();                                                             <span class="comment">// @2</span></span><br><span class="line">       		node.addPassRequest(count);</span><br><span class="line">		<span class="keyword">if</span> (context.getCurEntry().getOriginNode() != <span class="keyword">null</span>) &#123;                           <span class="comment">// @3</span></span><br><span class="line">			<span class="comment">// Add count for origin node.</span></span><br><span class="line">            		context.getCurEntry().getOriginNode().increaseThreadNum();</span><br><span class="line">            		context.getCurEntry().getOriginNode().addPassRequest(count);</span><br><span class="line">       		 &#125;</span><br><span class="line">		<span class="keyword">if</span> (resourceWrapper.getEntryType() == EntryType.IN) &#123;                <span class="comment">// @4</span></span><br><span class="line">			<span class="comment">// Add count for global inbound entry node for global statistics.</span></span><br><span class="line">            		Constants.ENTRY_NODE.increaseThreadNum();</span><br><span class="line">           	 	Constants.ENTRY_NODE.addPassRequest(count);</span><br><span class="line">        	&#125;</span><br><span class="line">		<span class="comment">// Handle pass event with registered entry callback handlers.</span></span><br><span class="line">        	<span class="keyword">for</span> (ProcessorSlotEntryCallback&lt;DefaultNode&gt; handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) &#123;   <span class="comment">// @5</span></span><br><span class="line">            		handler.onPass(context, resourceWrapper, node, count, args);</span><br><span class="line">        	&#125;</span><br><span class="line">    	&#125; <span class="keyword">catch</span> (PriorityWaitException ex) &#123;                                                                                                                                <span class="comment">// @6</span></span><br><span class="line">		node.increaseThreadNum();</span><br><span class="line">		<span class="keyword">if</span> (context.getCurEntry().getOriginNode() != <span class="keyword">null</span>) &#123;</span><br><span class="line">			<span class="comment">// Add count for origin node.</span></span><br><span class="line">            		context.getCurEntry().getOriginNode().increaseThreadNum();</span><br><span class="line">       	 	&#125;</span><br><span class="line">		<span class="keyword">if</span> (resourceWrapper.getEntryType() == EntryType.IN) &#123;</span><br><span class="line">			<span class="comment">// Add count for global inbound entry node for global statistics.</span></span><br><span class="line">            		Constants.ENTRY_NODE.increaseThreadNum();</span><br><span class="line">        	&#125;</span><br><span class="line">        	<span class="comment">// Handle pass event with registered entry callback handlers.</span></span><br><span class="line">        	<span class="keyword">for</span> (ProcessorSlotEntryCallback&lt;DefaultNode&gt; handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) &#123;</span><br><span class="line">            		handler.onPass(context, resourceWrapper, node, count, args);</span><br><span class="line">        	&#125;</span><br><span class="line">    	&#125; <span class="keyword">catch</span> (BlockException e) &#123;     <span class="comment">// @7                                                                                                              </span></span><br><span class="line">        	<span class="comment">// Blocked, set block exception to current entry.</span></span><br><span class="line">        	context.getCurEntry().setError(e);</span><br><span class="line">		<span class="comment">// Add block count.</span></span><br><span class="line">        	node.increaseBlockQps(count);</span><br><span class="line">        	<span class="keyword">if</span> (context.getCurEntry().getOriginNode() != <span class="keyword">null</span>) &#123;</span><br><span class="line">            		context.getCurEntry().getOriginNode().increaseBlockQps(count);</span><br><span class="line">        	&#125;</span><br><span class="line">		<span class="keyword">if</span> (resourceWrapper.getEntryType() == EntryType.IN) &#123;</span><br><span class="line">            		<span class="comment">// Add count for global inbound entry node for global statistics.</span></span><br><span class="line">            		Constants.ENTRY_NODE.increaseBlockQps(count);</span><br><span class="line">        	&#125;</span><br><span class="line">        	<span class="comment">// Handle block event with registered entry callback handlers.</span></span><br><span class="line">        	<span class="keyword">for</span> (ProcessorSlotEntryCallback&lt;DefaultNode&gt; handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) &#123;</span><br><span class="line">            		handler.onBlocked(e, context, resourceWrapper, node, count, args);</span><br><span class="line">        	&#125;</span><br><span class="line">		<span class="keyword">throw</span> e;</span><br><span class="line">    	&#125; <span class="keyword">catch</span> (Throwable e) &#123;   <span class="comment">// @8</span></span><br><span class="line">        	<span class="comment">// Unexpected error, set error to current entry.</span></span><br><span class="line">        	context.getCurEntry().setError(e);</span><br><span class="line">		<span class="comment">// This should not happen.</span></span><br><span class="line">        	node.increaseExceptionQps(count);</span><br><span class="line">        	<span class="keyword">if</span> (context.getCurEntry().getOriginNode() != <span class="keyword">null</span>) &#123;</span><br><span class="line">            		context.getCurEntry().getOriginNode().increaseExceptionQps(count);</span><br><span class="line">        	&#125;</span><br><span class="line">		<span class="keyword">if</span> (resourceWrapper.getEntryType() == EntryType.IN) &#123;</span><br><span class="line">            		Constants.ENTRY_NODE.increaseExceptionQps(count);</span><br><span class="line">        	&#125;</span><br><span class="line">        	<span class="keyword">throw</span> e;</span><br><span class="line">    	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先调用 fireEntry，先调用 Sentinel Slot Chain 中其他的处理器，执行完其他处理器的逻辑，例如 FlowSlot、DegradeSlot，因为 StatisticSlot 的职责是收集统计信息。</p>
<p>代码@2：如果后续处理器成功执行，则将正在执行线程数统计指标加一，并将通过的请求数量指标增加对应的值。下文会对 Sentinel Node 体系进行详细的介绍，在 Sentinel 中使用 Node 来表示调用链中的某一个节点，每个节点关联一个资源，资源的实时统计信息就存储在 Node 中，故该部分也是调用 DefaultNode 的相关方法来改变线程数等，将在下文会向详细介绍。</p>
<p>代码@3：如果上下文环境中保存了调用的源头（调用方）的节点信息不为空，则更新该节点的统计数据：线程数与通过数量。</p>
<p>代码@4：如果资源的进入类型为 EntryType.IN，表示入站流量，更新入站全局统计数据(集群范围 ClusterNode)。</p>
<p>代码@5：执行注册的进入Handler，可以通过 StatisticSlotCallbackRegistry 的 addEntryCallback 注册相关监听器。</p>
<p>代码@6：如果捕获到 PriorityWaitException ，则认为是等待过一定时间，但最终还是算通过，只需增加线程的个数，但无需增加节点通过的数量，具体原因我们在详细分析限流部分时会重点讨论，也会再次阐述 PriorityWaitException 的含义。</p>
<p>代码@7：如果捕获到 BlockException，则主要增加阻塞的数量。</p>
<p>代码@8：如果是系统异常，则增加异常数量。</p>
<p>我想上面的代码应该不难理解，但涉及到统计指标数据的变化，都是调用 DefaultNode node 相关的方法，从这里也可以看出，Node 将是实时统计数据的直接持有者，那毋容置疑接下来将重点来学习 Node，为了知识体系的完备性，我们先来看一下 StatisticSlot 的 exit 方法。</p>
<a id="more"></a>

<h4 id="1-2-StatisticSlot-exit-详解"><a href="#1-2-StatisticSlot-exit-详解" class="headerlink" title="1.2 StatisticSlot exit 详解"></a>1.2 StatisticSlot exit 详解</h4><p>StatisticSlot#exit </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">exit</span><span class="params">(Context context, ResourceWrapper resourceWrapper, <span class="keyword">int</span> count, Object... args)</span> </span>&#123;</span><br><span class="line">	DefaultNode node = (DefaultNode)context.getCurNode();</span><br><span class="line">	<span class="keyword">if</span> (context.getCurEntry().getError() == <span class="keyword">null</span>) &#123;         <span class="comment">// @1</span></span><br><span class="line">		<span class="comment">// Calculate response time (max RT is TIME_DROP_VALVE).</span></span><br><span class="line">		<span class="keyword">long</span> rt = TimeUtil.currentTimeMillis() - context.getCurEntry().getCreateTime();</span><br><span class="line">		<span class="keyword">if</span> (rt &gt; Constants.TIME_DROP_VALVE) &#123;</span><br><span class="line">			rt = Constants.TIME_DROP_VALVE;</span><br><span class="line">        	&#125;</span><br><span class="line">		<span class="comment">// Record response time and success count.</span></span><br><span class="line">		node.addRtAndSuccess(rt, count);</span><br><span class="line">		<span class="keyword">if</span> (context.getCurEntry().getOriginNode() != <span class="keyword">null</span>) &#123;</span><br><span class="line">			context.getCurEntry().getOriginNode().addRtAndSuccess(rt, count);</span><br><span class="line">       	        &#125;</span><br><span class="line">        node.decreaseThreadNum();</span><br><span class="line">	       <span class="keyword">if</span> (context.getCurEntry().getOriginNode() != <span class="keyword">null</span>) &#123;</span><br><span class="line">		    context.getCurEntry().getOriginNode().decreaseThreadNum();</span><br><span class="line">                &#125;</span><br><span class="line">	       <span class="keyword">if</span> (resourceWrapper.getEntryType() == EntryType.IN) &#123;</span><br><span class="line">                   Constants.ENTRY_NODE.addRtAndSuccess(rt, count);</span><br><span class="line">                   Constants.ENTRY_NODE.decreaseThreadNum();</span><br><span class="line">               &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// Error may happen.</span></span><br><span class="line">        &#125;</span><br><span class="line">	<span class="comment">// Handle exit event with registered exit callback handlers.</span></span><br><span class="line">        Collection&lt;ProcessorSlotExitCallback&gt; exitCallbacks = StatisticSlotCallbackRegistry.getExitCallbacks();</span><br><span class="line">        <span class="keyword">for</span> (ProcessorSlotExitCallback handler : exitCallbacks) &#123;      <span class="comment">// @2</span></span><br><span class="line">		handler.onExit(context, resourceWrapper, count, args);</span><br><span class="line">         &#125;</span><br><span class="line">	fireExit(context, resourceWrapper, count);     <span class="comment">// @3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：成功执行，则重点关注响应时间，其实现亮点如下：<br>计算本次响应时间，将本次响应时间收集到 Node 中。<br>将当前活跃线程数减一。</p>
<p>代码@2：执行退出时的 callback。可以通过 StatisticSlotCallbackRegistry 的 addExitCallback 方法添加退出回调函数。</p>
<p>代码@3：传播 exit 事件。</p>
<p>接下来我们将重点介绍 DefaultNode，即 Sentinel 的 Node 体系，持有资源的实时调用信息。</p>
<h2 id="2、Sentienl-Node-体系"><a href="#2、Sentienl-Node-体系" class="headerlink" title="2、Sentienl Node 体系"></a>2、Sentienl Node 体系</h2><p>2.1 Node 类体系图<br><img src="https://img-blog.csdnimg.cn/20200119210911647.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们先简单介绍一下上述核心类的作用与核心接口或核心属性的含义。</p>
<ul>
<li>OccupySupport<br>支持抢占未来的时间窗口，有点类似借用“未来”的令牌。其核心方法如下：<ul>
<li>long tryOccupyNext(long currentTime, int acquireCount, double threshold)<br>尝试抢占未来的令牌，返回值为调用该方法的线程应该 sleep 的时间。<br>1、long currentTime<br>​        当前时间。<br>2、int acquireCount<br>本次需要申请的令牌个数。<br>​          3、double threshold<br>​              设置的阔值。</li>
</ul>
</li>
<li>long waiting()<br>获取当前已申请的未来的令牌的个数。</li>
<li>void addWaitingRequest(long futureTime, int acquireCount)<br>申请未来时间窗口中的令牌。</li>
<li>void addOccupiedPass(int acquireCount)<br>增加申请未来令牌通过的个数。</li>
<li>double occupiedPassQps()<br>当前抢占未来令牌的QPS。</li>
<li>Node<br>持有实时统计信息的节点。定义了收集统计信息与获取统计信息的接口，上面方法根据方法名称即可得知其含义，故这里就不一一罗列了。</li>
<li>StatisticNode<br>实现统计信息的默认实现类。</li>
<li>DefaultNode<br>用于在特定上下文环境中保存某一个资源的实时统计信息。</li>
<li>ClusterNode<br>实现基于集群限流模式的节点，将在集群限流模式部分详细介绍。</li>
<li>EntranceNode<br>用来表示调用链入口的节点信息。</li>
</ul>
<p>本文将详细介绍 DefaultNode 与  StatisticNode，重点阐述调用树与实时统计信息。DefaultNode 是 StatisticNode 的子类，我们先从 StatisticNode 开始 Node 体系的探究。</p>
<h2 id="2、StatisticNode-详解"><a href="#2、StatisticNode-详解" class="headerlink" title="2、StatisticNode 详解"></a>2、StatisticNode 详解</h2><h4 id="2-1-核心类图"><a href="#2-1-核心类图" class="headerlink" title="2.1 核心类图"></a>2.1 核心类图</h4><p><img src="https://img-blog.csdnimg.cn/20200119211057921.png" alt="在这里插入图片描述"><br>我们对其核心属性进行一一解读：</p>
<ul>
<li>Metric rollingCounterInSecond = new ArrayMetric(SampleCountProperty.SAMPLE_COUNT, IntervalProperty.INTERVAL)<br>每秒的实时统计信息，使用 ArrayMetric 实现，即基于滑动窗口实现，正是上篇文章详细介绍的，默认1s 采样 2次。即一个统计周期中包含两个滑动窗口。</li>
<li>Metric rollingCounterInMinute = new ArrayMetric(60, 60 * 1000, false)<br>每分钟实时统计信息，同样使用 ArrayMetric  实现，即基于滑动窗口实现。每1分钟，抽样60次，即包含60个滑动窗口，每一个窗口的时间间隔为 1s 。</li>
<li>LongAdder curThreadNum = new LongAdder()<br>当前线程计数器。</li>
<li>long lastFetchTime = -1<br>上一次获取资源的有效统计数据的时间，即调用 Node 的 metrics() 方法的时间。</li>
</ul>
<p>关于 ArrayMetric 滑动窗口设计与实现原理，请参考笔者的另一篇博文：<a href="https://mp.weixin.qq.com/s/tn8rSHyv_hiJi6QDhfxuIA">Alibaba Seninel 滑动窗口实现原理(文末附原理图)</a></p>
<p>接下来我们挑选几个具有代表性的方法进行探究。</p>
<h4 id="2-2-addPassRequest"><a href="#2-2-addPassRequest" class="headerlink" title="2.2 addPassRequest"></a>2.2 addPassRequest</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addPassRequest</span><span class="params">(<span class="keyword">int</span> count)</span> </span>&#123;</span><br><span class="line">	rollingCounterInSecond.addPass(count);</span><br><span class="line">	rollingCounterInMinute.addPass(count);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>增加通过请求数量。即将实时调用信息向滑动窗口中进行统计。addPassRequest 即报告成功的通过数量。就是分别调用 秒级、分钟即对应的滑动窗口中添加数量，然后限流规则、熔断规则将基于滑动窗口中的值进行计算。</p>
<h4 id="2-3-totalRequest"><a href="#2-3-totalRequest" class="headerlink" title="2.3 totalRequest"></a>2.3 totalRequest</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">totalRequest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> rollingCounterInMinute.pass() + rollingCounterInMinute.block();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>获取当前时间戳的总请求数，获取分钟级时间窗口中的统计信息。</p>
<h4 id="2-4-successQps"><a href="#2-4-successQps" class="headerlink" title="2.4 successQps"></a>2.4 successQps</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">successQps</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="keyword">return</span> rollingCounterInSecond.success() / rollingCounterInSecond.getWindowIntervalInSec();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>成功TPS，用秒级统计滑动窗口中统计的个数 除以 窗口的间隔得出其 tps，即抽样个数越大，其统计越精确。</p>
<blockquote>
<p>温馨提示：上面的方法在学习了上文的滑动窗口设计原理后将显得非常简单，大家在学习的过程中，可以总结出一个规律，什么时候时候使用秒级滑动窗口，什么时候使用分钟级滑动窗口。</p>
</blockquote>
<h4 id="2-5-metrics"><a href="#2-5-metrics" class="headerlink" title="2.5 metrics"></a>2.5 metrics</h4><p>由于 Sentienl 基于滑动窗口来实时收集统计信息，并存储在内存中，并随着时间的推移，旧的滑动窗口将失效，故需要提供一个方法，及时将所有的统计信息进行汇总输出，供监控客户端定时拉取，转储都其他客户端，例如数据库，方便监控数据的可视化，这也通常是中间件用于监控指标的监控与采集的通用设计方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Map&lt;Long, MetricNode&gt; <span class="title">metrics</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> currentTime = TimeUtil.currentTimeMillis();</span><br><span class="line">    currentTime = currentTime - currentTime % <span class="number">1000</span>;   <span class="comment">// @1</span></span><br><span class="line">    Map&lt;Long, MetricNode&gt; metrics = <span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class="line">    List&lt;MetricNode&gt; nodesOfEverySecond = rollingCounterInMinute.details();   <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">long</span> newLastFetchTime = lastFetchTime;</span><br><span class="line">    <span class="comment">// Iterate metrics of all resources, filter valid metrics (not-empty and up-to-date).</span></span><br><span class="line">    <span class="keyword">for</span> (MetricNode node : nodesOfEverySecond) &#123; </span><br><span class="line">        <span class="keyword">if</span> (isNodeInTime(node, currentTime) &amp;&amp; isValidMetricNode(node)) &#123;    <span class="comment">// @3</span></span><br><span class="line">	    metrics.put(node.getTimestamp(), node);</span><br><span class="line">            newLastFetchTime = Math.max(newLastFetchTime, node.getTimestamp());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    lastFetchTime = newLastFetchTime;</span><br><span class="line">    <span class="keyword">return</span> metrics;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：获取当前时间对应的滑动窗口的开始时间，可以对比上文计算滑动窗口的算法。</p>
<p>代码@2：获取一分钟内的所有滑动窗口中的统计数据，使用 MetricNode 表示。</p>
<p>代码@3：遍历所有节点，刷选出不是当前滑动窗口外的所有数据。这里的重点是方法：isNodeInTime。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isNodeInTime</span><span class="params">(MetricNode node, <span class="keyword">long</span> currentTime)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> node.getTimestamp() &gt; lastFetchTime &amp;&amp; node.getTimestamp() &lt; currentTime;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里只刷选出不是当前窗口的数据，即 metrics 方法返回的是“过去”的统计数据。</p>
<p>接下来我们再来看看 DefaultNode 相关的几个特性方法。</p>
<h2 id="3、DefaultNode-详解"><a href="#3、DefaultNode-详解" class="headerlink" title="3、DefaultNode  详解"></a>3、DefaultNode  详解</h2><h4 id="3-1-类图"><a href="#3-1-类图" class="headerlink" title="3.1 类图"></a>3.1 类图</h4><p><img src="https://img-blog.csdnimg.cn/20200119211434219.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>DefaultNode 是 StatisticNode 的子类，其额外增加的属性如下：</p>
<ul>
<li>private ResourceWrapper id<br>资源id，即 DefaultNode 才真正与资源挂钩，可以将 DefaultNode 看出是调用链中的一个节点，并且与资源关联。</li>
<li>private volatile Set&lt; Node &gt; childList<br>子节点结合。以此来维持其调用链。</li>
<li>private ClusterNode clusterNode<br>集群节点，同样为 StatisticNode 的子类，表示与资源集群相关的环境。</li>
</ul>
<p>接下来我们将来看一下 DefaultNode 的核心方法。</p>
<h4 id="3-2-increaseBlockQps"><a href="#3-2-increaseBlockQps" class="headerlink" title="3.2 increaseBlockQps"></a>3.2 increaseBlockQps</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">increaseBlockQps</span><span class="params">(<span class="keyword">int</span> count)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.increaseBlockQps(count);</span><br><span class="line">    <span class="keyword">this</span>.clusterNode.increaseBlockQps(count);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DefaultNode 的此类方法，通常是先调用 StatisticNode 的方法，然后再调用 clusterNode 的相关方法，最终就是使用在对应的滑动窗口中增加或减少计量值。</p>
<p>其他方法也比较简单，就不再细看了，我们可以通过 DefaultNode 的 printDefaultNode 方法来打印该节点的调用链。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>源码</tag>
        <tag>滑动窗口</tag>
        <tag>实时数据收集</tag>
        <tag>StatisticSlot</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析Mybatis MappedStatement的创建流程</title>
    <url>/posts/18c7756d.html</url>
    <content><![CDATA[<div id="vip-container"><p>上文<a href="https://blog.csdn.net/prestigeding/article/details/90415680">源码分析Mybatis MapperProxy创建流程</a>重点阐述MapperProxy的创建流程，但并没有介绍*.Mapper.java(UserMapper.java)是如何与*Mapper.xml文件中的SQL语句是如何建立关联的。本文将重点接开这个谜团。</p>
<p>接下来重点从源码的角度分析Mybatis MappedStatement的创建流程。</p>
<h2 id="1、上节回顾"><a href="#1、上节回顾" class="headerlink" title="1、上节回顾"></a>1、上节回顾</h2><p>我们注意到这里有两三个与Mapper相关的配置：</p>
<ol>
<li>SqlSessionFactory#mapperLocations，指定xml文件的配置路径。</li>
<li>SqlSessionFactory#configLocation，指定mybaits的配置文件，该配置文件也可以配置mapper.xml的配置路径信息。</li>
<li>MapperScannerConfigurer，扫描Mapper的java类(DAO)。</li>
</ol>
<p>我们已经详细介绍了Mybatis Mapper对象的扫描与构建，那接下来我们将重点介绍MaperProxy与mapper.xml文件是如何建立关联关系的。</p>
<p>根据上面的罗列以及上文的讲述，Mapper.xml与Mapper建立联系主要的入口有三：<br>1）MapperScannerConfigurer扫描Bean流程中，在调用MapperReigistry#addMapper时如果Mapper对应的映射文件(Mapper.xml)未加载到内存，会触发加载。<br>2）实例化SqlSessionFactory时，如果配置了mapperLocations。<br>3）示例化SqlSessionFactory时，如果配置了configLocation。</p>
<p>本节的行文思路：从SqlSessionFacotry的初始化开始讲起，因为mapperLocations、configLocation都是是SqlSessionFactory的属性。</p>
<blockquote>
<p>温馨提示：下面开始从源码的角度对其进行介绍，大家可以先跳到文末看看其调用序列图。</p>
</blockquote>
<a id="more"></a>

<h2 id="2、SqlSessionFacotry"><a href="#2、SqlSessionFacotry" class="headerlink" title="2、SqlSessionFacotry"></a>2、SqlSessionFacotry</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (xmlConfigBuilder != <span class="keyword">null</span>) &#123;  <span class="comment">// XMLConfigBuilder   // @1</span></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        xmlConfigBuilder.parse();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">          logger.debug(<span class="string">&quot;Parsed configuration file: &#x27;&quot;</span> + <span class="keyword">this</span>.configLocation + <span class="string">&quot;&#x27;&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NestedIOException(<span class="string">&quot;Failed to parse config resource: &quot;</span> + <span class="keyword">this</span>.configLocation, ex);</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        ErrorContext.instance().reset();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!isEmpty(<span class="keyword">this</span>.mapperLocations)) &#123;   <span class="comment">// @2</span></span><br><span class="line">      <span class="keyword">for</span> (Resource mapperLocation : <span class="keyword">this</span>.mapperLocations) &#123;</span><br><span class="line">        <span class="keyword">if</span> (mapperLocation == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          XMLMapperBuilder xmlMapperBuilder = <span class="keyword">new</span> XMLMapperBuilder(mapperLocation.getInputStream(),</span><br><span class="line">              configuration, mapperLocation.toString(), configuration.getSqlFragments());</span><br><span class="line">          xmlMapperBuilder.parse();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> NestedIOException(<span class="string">&quot;Failed to parse mapping resource: &#x27;&quot;</span> + mapperLocation + <span class="string">&quot;&#x27;&quot;</span>, e);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          ErrorContext.instance().reset();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">          logger.debug(<span class="string">&quot;Parsed mapper file: &#x27;&quot;</span> + mapperLocation + <span class="string">&quot;&#x27;&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">        logger.debug(<span class="string">&quot;Property &#x27;mapperLocations&#x27; was not specified or no matching resources found&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>上文有两个入口：<br>代码@1：处理configLocation属性。<br>代码@2：处理mapperLocations属性。</p>
<p>我们先从XMLConfigBuilder#parse开始进行追踪。该方法主要是解析configLocation指定的配置路径，对其进行解析，具体调用parseConfiguration方法。</p>
<h3 id="2-1-XMLConfigBuilder"><a href="#2-1-XMLConfigBuilder" class="headerlink" title="2.1 XMLConfigBuilder"></a>2.1 XMLConfigBuilder</h3><p>我们直接查看其parseConfiguration方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">parseConfiguration</span><span class="params">(XNode root)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      propertiesElement(root.evalNode(<span class="string">&quot;properties&quot;</span>)); <span class="comment">//issue #117 read properties first</span></span><br><span class="line">      typeAliasesElement(root.evalNode(<span class="string">&quot;typeAliases&quot;</span>));</span><br><span class="line">      pluginElement(root.evalNode(<span class="string">&quot;plugins&quot;</span>));</span><br><span class="line">      objectFactoryElement(root.evalNode(<span class="string">&quot;objectFactory&quot;</span>));</span><br><span class="line">      objectWrapperFactoryElement(root.evalNode(<span class="string">&quot;objectWrapperFactory&quot;</span>));</span><br><span class="line">      settingsElement(root.evalNode(<span class="string">&quot;settings&quot;</span>));</span><br><span class="line">      environmentsElement(root.evalNode(<span class="string">&quot;environments&quot;</span>)); <span class="comment">// read it after objectFactory and objectWrapperFactory issue #631</span></span><br><span class="line">      databaseIdProviderElement(root.evalNode(<span class="string">&quot;databaseIdProvider&quot;</span>));</span><br><span class="line">      typeHandlerElement(root.evalNode(<span class="string">&quot;typeHandlers&quot;</span>));</span><br><span class="line">      mapperElement(root.evalNode(<span class="string">&quot;mappers&quot;</span>));   <span class="comment">// @1</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> BuilderException(<span class="string">&quot;Error parsing SQL Mapper Configuration. Cause: &quot;</span> + e, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>重点关注mapperElement，从名称与参数即可以看出，该方法主要是处理中mappers的定义，即mapper sql语句的解析与处理。如果使用过Mapper的人应该不难知道，我们使用mapper节点，通过resource标签定义具体xml文件的位置。</p>
<h4 id="2-1-1XMLConfigBuilder-mapperElement"><a href="#2-1-1XMLConfigBuilder-mapperElement" class="headerlink" title="2.1.1XMLConfigBuilder#mapperElement"></a>2.1.1XMLConfigBuilder#mapperElement</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">mapperElement</span><span class="params">(XNode parent)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (parent != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (XNode child : parent.getChildren()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">&quot;package&quot;</span>.equals(child.getName())) &#123;</span><br><span class="line">          String mapperPackage = child.getStringAttribute(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">          configuration.addMappers(mapperPackage);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          String resource = child.getStringAttribute(<span class="string">&quot;resource&quot;</span>);</span><br><span class="line">          String url = child.getStringAttribute(<span class="string">&quot;url&quot;</span>);</span><br><span class="line">          String mapperClass = child.getStringAttribute(<span class="string">&quot;class&quot;</span>);</span><br><span class="line">          <span class="keyword">if</span> (resource != <span class="keyword">null</span> &amp;&amp; url == <span class="keyword">null</span> &amp;&amp; mapperClass == <span class="keyword">null</span>) &#123;</span><br><span class="line">            ErrorContext.instance().resource(resource);</span><br><span class="line">            InputStream inputStream = Resources.getResourceAsStream(resource);</span><br><span class="line">            XMLMapperBuilder mapperParser = <span class="keyword">new</span> XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments());    <span class="comment">// @1</span></span><br><span class="line">            mapperParser.parse();</span><br><span class="line">          &#125; <span class="keyword">else</span> <span class="keyword">if</span> (resource == <span class="keyword">null</span> &amp;&amp; url != <span class="keyword">null</span> &amp;&amp; mapperClass == <span class="keyword">null</span>) &#123;</span><br><span class="line">            ErrorContext.instance().resource(url);</span><br><span class="line">            InputStream inputStream = Resources.getUrlAsStream(url);</span><br><span class="line">            XMLMapperBuilder mapperParser = <span class="keyword">new</span> XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments());</span><br><span class="line">            mapperParser.parse();</span><br><span class="line">          &#125; <span class="keyword">else</span> <span class="keyword">if</span> (resource == <span class="keyword">null</span> &amp;&amp; url == <span class="keyword">null</span> &amp;&amp; mapperClass != <span class="keyword">null</span>) &#123;</span><br><span class="line">            Class&lt;?&gt; mapperInterface = Resources.classForName(mapperClass);</span><br><span class="line">            configuration.addMapper(mapperInterface);</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> BuilderException(<span class="string">&quot;A mapper element may only specify a url, resource or class, but not more than one.&quot;</span>);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码比较简单，不难看出，解析出Mapper标签，解析出resource标签的属性，创建对应的文件流，通过构建XMLMapperBuilder来解析对应的mapper.xml文件。此时大家会惊讶的发现，在SqlSessionFacotry的初始化代码中，处理mapperLocations时就是通过构建XMLMapperBuilder来解析mapper文件，其实也不难理解，因为这是mybatis支持的两个地方可以使用mapper标签来定义mapper映射文件，具体解析代码当然是一样的逻辑。那我们解析来重点把目光投向XMLMapperBuilder。</p>
<h3 id="2-2-XMLMapperBuilder"><a href="#2-2-XMLMapperBuilder" class="headerlink" title="2.2 XMLMapperBuilder"></a>2.2 XMLMapperBuilder</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">XMLMapperBuilder#parse</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">parse</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!configuration.isResourceLoaded(resource)) &#123;     <span class="comment">// @1</span></span><br><span class="line">      configurationElement(parser.evalNode(<span class="string">&quot;/mapper&quot;</span>));</span><br><span class="line">      configuration.addLoadedResource(resource);</span><br><span class="line">      bindMapperForNamespace();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    parsePendingResultMaps();                                    <span class="comment">// @2</span></span><br><span class="line">    parsePendingChacheRefs();                                   <span class="comment">// @3</span></span><br><span class="line">    parsePendingStatements();                                     <span class="comment">// @4</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果该映射文件(*.Mapper.xml)文件未加载，则首先先加载，完成xml文件的解析，提取xml中与mybatis相关的数据，例如sql、resultMap等等。<br>代码@2：处理mybatis xml中ResultMap。<br>代码@3：处理mybatis缓存相关的配置。<br>代码@4：处理mybatis statment相关配置，这里就是本篇关注的，Sql语句如何与Mapper进行关联的核心实现。</p>
<p>接下来我们重点探讨parsePendingStatements()方法，解析statement(对应SQL语句)。</p>
<h4 id="2-2-1-XMLMapperBuilder-parsePendingStatements"><a href="#2-2-1-XMLMapperBuilder-parsePendingStatements" class="headerlink" title="2.2.1 XMLMapperBuilder#parsePendingStatements"></a>2.2.1 XMLMapperBuilder#parsePendingStatements</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">parsePendingStatements</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	  Collection&lt;XMLStatementBuilder&gt; incompleteStatements = configuration.getIncompleteStatements();</span><br><span class="line">	  <span class="keyword">synchronized</span> (incompleteStatements) &#123;</span><br><span class="line">		  Iterator&lt;XMLStatementBuilder&gt; iter = incompleteStatements.iterator();    <span class="comment">// @1</span></span><br><span class="line">		  <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">			  <span class="keyword">try</span> &#123;</span><br><span class="line">				  iter.next().parseStatementNode();   <span class="comment">// @2</span></span><br><span class="line">				  iter.remove();</span><br><span class="line">			  &#125; <span class="keyword">catch</span> (IncompleteElementException e) &#123;</span><br><span class="line">				  <span class="comment">// Statement is still missing a resource...</span></span><br><span class="line">			  &#125;</span><br><span class="line">		  &#125;</span><br><span class="line">	  &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：遍历解析出来的所有SQL语句，用的是XMLStatementBuilder对象封装的，故接下来重点看一下代码@2，如果解析statmentNode。</p>
<h4 id="2-2-2-XMLStatementBuilder-parseStatementNode"><a href="#2-2-2-XMLStatementBuilder-parseStatementNode" class="headerlink" title="2.2.2 XMLStatementBuilder#parseStatementNode"></a>2.2.2 XMLStatementBuilder#parseStatementNode</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">parseStatementNode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    String id = context.getStringAttribute(<span class="string">&quot;id&quot;</span>);                                                                  <span class="comment">// @1 start</span></span><br><span class="line">    String databaseId = context.getStringAttribute(<span class="string">&quot;databaseId&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!databaseIdMatchesCurrent(id, databaseId, <span class="keyword">this</span>.requiredDatabaseId)) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    Integer fetchSize = context.getIntAttribute(<span class="string">&quot;fetchSize&quot;</span>);</span><br><span class="line">    Integer timeout = context.getIntAttribute(<span class="string">&quot;timeout&quot;</span>);</span><br><span class="line">    String parameterMap = context.getStringAttribute(<span class="string">&quot;parameterMap&quot;</span>);</span><br><span class="line">    String parameterType = context.getStringAttribute(<span class="string">&quot;parameterType&quot;</span>);</span><br><span class="line">    Class&lt;?&gt; parameterTypeClass = resolveClass(parameterType);</span><br><span class="line">    String resultMap = context.getStringAttribute(<span class="string">&quot;resultMap&quot;</span>);</span><br><span class="line">    String resultType = context.getStringAttribute(<span class="string">&quot;resultType&quot;</span>);</span><br><span class="line">    String lang = context.getStringAttribute(<span class="string">&quot;lang&quot;</span>);</span><br><span class="line">    LanguageDriver langDriver = getLanguageDriver(lang);</span><br><span class="line"></span><br><span class="line">    Class&lt;?&gt; resultTypeClass = resolveClass(resultType);</span><br><span class="line">    String resultSetType = context.getStringAttribute(<span class="string">&quot;resultSetType&quot;</span>);</span><br><span class="line">    StatementType statementType = StatementType.valueOf(context.getStringAttribute(<span class="string">&quot;statementType&quot;</span>, StatementType.PREPARED.toString()));</span><br><span class="line">    ResultSetType resultSetTypeEnum = resolveResultSetType(resultSetType);</span><br><span class="line"></span><br><span class="line">    String nodeName = context.getNode().getNodeName();</span><br><span class="line">    SqlCommandType sqlCommandType = SqlCommandType.valueOf(nodeName.toUpperCase(Locale.ENGLISH));</span><br><span class="line">    <span class="keyword">boolean</span> isSelect = sqlCommandType == SqlCommandType.SELECT;</span><br><span class="line">    <span class="keyword">boolean</span> flushCache = context.getBooleanAttribute(<span class="string">&quot;flushCache&quot;</span>, !isSelect);</span><br><span class="line">    <span class="keyword">boolean</span> useCache = context.getBooleanAttribute(<span class="string">&quot;useCache&quot;</span>, isSelect);</span><br><span class="line">    <span class="keyword">boolean</span> resultOrdered = context.getBooleanAttribute(<span class="string">&quot;resultOrdered&quot;</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Include Fragments before parsing</span></span><br><span class="line">    XMLIncludeTransformer includeParser = <span class="keyword">new</span> XMLIncludeTransformer(configuration, builderAssistant);</span><br><span class="line">    includeParser.applyIncludes(context.getNode());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Parse selectKey after includes and remove them.</span></span><br><span class="line">    processSelectKeyNodes(id, parameterTypeClass, langDriver);             <span class="comment">// @1 end</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Parse the SQL (pre: &lt;selectKey&gt; and &lt;include&gt; were parsed and removed)</span></span><br><span class="line">    SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass);                <span class="comment">// @2</span></span><br><span class="line">    String resultSets = context.getStringAttribute(<span class="string">&quot;resultSets&quot;</span>);</span><br><span class="line">    String keyProperty = context.getStringAttribute(<span class="string">&quot;keyProperty&quot;</span>);</span><br><span class="line">    String keyColumn = context.getStringAttribute(<span class="string">&quot;keyColumn&quot;</span>);</span><br><span class="line">    KeyGenerator keyGenerator;</span><br><span class="line">    String keyStatementId = id + SelectKeyGenerator.SELECT_KEY_SUFFIX;</span><br><span class="line">    keyStatementId = builderAssistant.applyCurrentNamespace(keyStatementId, <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">if</span> (configuration.hasKeyGenerator(keyStatementId)) &#123;</span><br><span class="line">      keyGenerator = configuration.getKeyGenerator(keyStatementId);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      keyGenerator = context.getBooleanAttribute(<span class="string">&quot;useGeneratedKeys&quot;</span>,</span><br><span class="line">          configuration.isUseGeneratedKeys() &amp;&amp; SqlCommandType.INSERT.equals(sqlCommandType))</span><br><span class="line">          ? <span class="keyword">new</span> Jdbc3KeyGenerator() : <span class="keyword">new</span> NoKeyGenerator();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    builderAssistant.addMappedStatement(id, sqlSource, statementType, sqlCommandType,                             <span class="comment">// @3</span></span><br><span class="line">        fetchSize, timeout, parameterMap, parameterTypeClass, resultMap, resultTypeClass,</span><br><span class="line">        resultSetTypeEnum, flushCache, useCache, resultOrdered, </span><br><span class="line">        keyGenerator, keyProperty, keyColumn, databaseId, langDriver, resultSets);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>这个方法有点长，其关注点主要有3个：<br>代码@1：构建基本属性，其实就是构建MappedStatement的属性，因为MappedStatement对象就是用来描述Mapper-SQL映射的对象。</p>
<p>代码@2：根据xml配置的内容，解析出实际的SQL语句，使用SqlSource对象来表示。</p>
<p>代码@3：使用MapperBuilderAssistant对象，根据准备好的属性，构建MappedStatement对象，最终将其存储在Configuration中。</p>
<h4 id="2-2-3-Configuration-addMappedStatement"><a href="#2-2-3-Configuration-addMappedStatement" class="headerlink" title="2.2.3 Configuration#addMappedStatement"></a>2.2.3 Configuration#addMappedStatement</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addMappedStatement</span><span class="params">(MappedStatement ms)</span> </span>&#123;</span><br><span class="line">   mappedStatements.put(ms.getId(), ms);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>MappedStatement的id为：mapperInterface + methodName，例如com.demo.dao.UserMapper.findUser。</p>
<p>即上述流程完成了xml的解析与初始化，对终极目标是创建MappedStatement对象，上一篇文章介绍了mapperInterface的初始化，最终会初始化为MapperProxy对象，那这两个对象如何关联起来呢？</p>
<p>从下文可知，MapperProxy与MappedStatement是在调用具Mapper方法时，可以根据mapperInterface.getName + methodName构建出MappedStatement的id，然后就可以从Configuration的mappedStatements容器中根据id获取到对应的MappedStatement对象，这样就建立起联系了。</p>
<p>其对应的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// MapperMethod 构造器</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">MapperMethod</span><span class="params">(Class&lt;?&gt; mapperInterface, Method method, Configuration config)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.command = <span class="keyword">new</span> SqlCommand(config, mapperInterface, method);</span><br><span class="line">    <span class="keyword">this</span>.method = <span class="keyword">new</span> MethodSignature(config, method);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// SqlCommand 构造器</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">SqlCommand</span><span class="params">(Configuration configuration, Class&lt;?&gt; mapperInterface, Method method)</span> <span class="keyword">throws</span> BindingException </span>&#123;</span><br><span class="line">      String statementName = mapperInterface.getName() + <span class="string">&quot;.&quot;</span> + method.getName();</span><br><span class="line">      MappedStatement ms = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">if</span> (configuration.hasStatement(statementName)) &#123;</span><br><span class="line">        ms = configuration.getMappedStatement(statementName);</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!mapperInterface.equals(method.getDeclaringClass().getName())) &#123; <span class="comment">// issue #35</span></span><br><span class="line">        String parentStatementName = method.getDeclaringClass().getName() + <span class="string">&quot;.&quot;</span> + method.getName();</span><br><span class="line">        <span class="keyword">if</span> (configuration.hasStatement(parentStatementName)) &#123;</span><br><span class="line">          ms = configuration.getMappedStatement(parentStatementName);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (ms == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> BindingException(<span class="string">&quot;Invalid bound statement (not found): &quot;</span> + statementName);</span><br><span class="line">      &#125;</span><br><span class="line">      name = ms.getId();</span><br><span class="line">      type = ms.getSqlCommandType();</span><br><span class="line">      <span class="keyword">if</span> (type == SqlCommandType.UNKNOWN) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> BindingException(<span class="string">&quot;Unknown execution method for: &quot;</span> + name);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>怎么样，从上面的源码分析中，大家是否已经了解MapperProxy与Xml中的SQL语句是怎样建立的关系了吗？为了让大家更清晰的了解上述过程，现给出其调用时序图：<br><img src="https://img-blog.csdnimg.cn/2019052321283257.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
        <tag>MappedStatement</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析Mybatis MapperProxy初始化之Mapper对象的扫描与构建</title>
    <url>/posts/47c4bb93.html</url>
    <content><![CDATA[<div id="vip-container"><p>MapperScannerConfigurer，Spring整合Mybatis的核心类，其作用是扫描项目中Dao类，将其创建为Mybatis的Maper对象即MapperProxy对象。</p>
<p>首先进入源码学习之前，我们先看一下在项目中的配置文件信息。<br><img src="https://img-blog.csdnimg.cn/20190521205718910.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们注意到这里有两三个与Mapper相关的配置：</p>
<ol>
<li>SqlSessionFactory#mapperLocations，指定xml文件的配置路径。</li>
<li>SqlSessionFactory#configLocation，指定mybaits的配置文件，该配置文件也可以配置mapper.xml的配置路径信息。</li>
<li>MapperScannerConfigurer，扫描Mapper的java类(DAO)。</li>
</ol>
<p>本文的行文思路如下：</p>
<ol>
<li>Mybatis MapperProxy对象的扫描与构建</li>
<li>Mapper类与SQL语句如何建立关联<br>这部分主要阐述Java类的运行实例Mapper对象（例如UserMapper、BookMapper)是如何与mapper.xml(UserMapper.xml、BookMapper.xml文件建立联系的)。</li>
</ol>
<h2 id="Mybatis-MapperProxy对象创建流程"><a href="#Mybatis-MapperProxy对象创建流程" class="headerlink" title="Mybatis MapperProxy对象创建流程"></a>Mybatis MapperProxy对象创建流程</h2><p>下面的源码分析或许会比较枯燥，进入源码分析之前，先给出MapperProxy的创建序列图。</p>
<h3 id="1-1-MapperProxy创建序列图"><a href="#1-1-MapperProxy创建序列图" class="headerlink" title="1.1 MapperProxy创建序列图"></a>1.1 MapperProxy创建序列图</h3><p><img src="https://img-blog.csdnimg.cn/20190521215333400.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="1-2-MapperScannerConfigurer详解"><a href="#1-2-MapperScannerConfigurer详解" class="headerlink" title="1.2 MapperScannerConfigurer详解"></a>1.2 MapperScannerConfigurer详解</h3><p>MapperScannerConfigurer的类图如下所示：<br><img src="https://img-blog.csdnimg.cn/20190521210119671.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>MapperScannerConfigurer实现Spring Bean生命周期相关的类：BeanNameAware、ApplicationContextAware、BeanFactoryPostProcessor、InitializingBean、BeanDefinitionRegistryPostProcessor，我们先来看一下这些接口对应的方法的调用时机：</p>
<a id="more"></a>

<ul>
<li>BeanNameAware<br>是Bean对自己的名称感知，也就是在Bean创建的时候，自动将Bean的名称设置在Bean中，外部应用程序不需要调用setBeanName，就可以通过getBeanName()方法获取其bean名称。</li>
<li>ApplicationContextAware<br>自动感知ApplicationContext对象，即在Bean创建的时候，Spring工厂会自动将当前的ApplicationContext注入该Bean中。</li>
<li>InitializingBean<br>实现该接口，Spring在初始化Bean后会自动调用InitializingBean#afterPropertiesSet方法。</li>
<li>BeanFactoryPostProcessor<br>BeanFactory后置处理器，这个时候只是创建好了Bean的定义信息(BeanDefinition)，在BeanFactoryPostProcessor接口的postProcessBeanFactory方法中，我们可以修改bean的定义信息，例如修改属性的值，修改bean的scope为单例或者多例。与其相似的是BeanPostProcessor，这个是在bean初始化前后对Bean执行，即bean的构造方法调用后，init-method前执行。</li>
<li>BeanDefinitionRegistryPostProcessor<br>主要用来增加Bean的定义，增加BeanDefinition。由于MapperScannerConfigurer主要的目的就是扫描特定的包，并创建对应的Mapper对象，估这里是MapperScannerConfigurer重点实现的接口。</li>
</ul>
<p>那我们接下来从BeanDefinitionRegistryPostProcessor的实现接口开始跟踪。</p>
<h4 id="BeanDefinitionRegistryPostProcessor-postProcessBeanDefinitionRegistry"><a href="#BeanDefinitionRegistryPostProcessor-postProcessBeanDefinitionRegistry" class="headerlink" title="BeanDefinitionRegistryPostProcessor#postProcessBeanDefinitionRegistry"></a>BeanDefinitionRegistryPostProcessor#postProcessBeanDefinitionRegistry</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123;</span><br><span class="line">    if (this.processPropertyPlaceHolders) &#123;</span><br><span class="line">      processPropertyPlaceHolders();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ClassPathMapperScanner scanner &#x3D; new ClassPathMapperScanner(registry);</span><br><span class="line">    scanner.setAddToConfig(this.addToConfig);</span><br><span class="line">    scanner.setAnnotationClass(this.annotationClass);</span><br><span class="line">    scanner.setMarkerInterface(this.markerInterface);</span><br><span class="line">    scanner.setSqlSessionFactory(this.sqlSessionFactory);     &#x2F;&#x2F; @1</span><br><span class="line">    scanner.setSqlSessionTemplate(this.sqlSessionTemplate);</span><br><span class="line">    scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName);   </span><br><span class="line">    scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName);</span><br><span class="line">    scanner.setResourceLoader(this.applicationContext);</span><br><span class="line">    scanner.setBeanNameGenerator(this.nameGenerator);</span><br><span class="line">    scanner.registerFilters();</span><br><span class="line">    scanner.scan(StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS));    &#x2F;&#x2F; @2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先设置SqlSessionFactory，从该Scan器生成的Mapper最终都是受该SqlSessionFactory的管辖。<br>代码@2：调用ClassPathMapperScanner的scan方法进行扫描动作，接下来详细介绍。</p>
<h4 id="ClassPathMapperScanner-doScan"><a href="#ClassPathMapperScanner-doScan" class="headerlink" title="ClassPathMapperScanner#doScan"></a>ClassPathMapperScanner#doScan</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) &#123;</span><br><span class="line">    Set&lt;BeanDefinitionHolder&gt; beanDefinitions &#x3D; super.doScan(basePackages);   &#x2F;&#x2F;@1</span><br><span class="line">    if (beanDefinitions.isEmpty()) &#123;</span><br><span class="line">      logger.warn(&quot;No MyBatis mapper was found in &#39;&quot; + Arrays.toString(basePackages) + &quot;&#39; package. Please check your configuration.&quot;);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      processBeanDefinitions(beanDefinitions);   &#x2F;&#x2F; @2</span><br><span class="line">    &#125;</span><br><span class="line">    return beanDefinitions;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先调用父类(org.springframework.context.annotation.ClassPathBeanDefinitionScanner)方法，根据扫描的文件，构建对应的BeanDefinitionHolder对象。<br>代码@2：对这些BeanDefinitions进行处理，对Bean进行加工，加入Mybatis特性。</p>
<h4 id="ClassPathMapperScanner-processBeanDefinitions"><a href="#ClassPathMapperScanner-processBeanDefinitions" class="headerlink" title="ClassPathMapperScanner#processBeanDefinitions"></a>ClassPathMapperScanner#processBeanDefinitions</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">private void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) &#123;</span><br><span class="line">    GenericBeanDefinition definition;</span><br><span class="line">    for (BeanDefinitionHolder holder : beanDefinitions) &#123;</span><br><span class="line">      definition &#x3D; (GenericBeanDefinition) holder.getBeanDefinition();</span><br><span class="line"></span><br><span class="line">      if (logger.isDebugEnabled()) &#123;</span><br><span class="line">        logger.debug(&quot;Creating MapperFactoryBean with name &#39;&quot; + holder.getBeanName() </span><br><span class="line">          + &quot;&#39; and &#39;&quot; + definition.getBeanClassName() + &quot;&#39; mapperInterface&quot;);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      &#x2F;&#x2F; the mapper interface is the original class of the bean</span><br><span class="line">      &#x2F;&#x2F; but, the actual class of the bean is MapperFactoryBean</span><br><span class="line">      definition.getPropertyValues().add(&quot;mapperInterface&quot;, definition.getBeanClassName());</span><br><span class="line">      definition.setBeanClass(this.mapperFactoryBean.getClass());   &#x2F;&#x2F; @1</span><br><span class="line">      definition.getPropertyValues().add(&quot;addToConfig&quot;, this.addToConfig);</span><br><span class="line">      boolean explicitFactoryUsed &#x3D; false;</span><br><span class="line">      if (StringUtils.hasText(this.sqlSessionFactoryBeanName)) &#123;    &#x2F;&#x2F; @2 start</span><br><span class="line">        definition.getPropertyValues().add(&quot;sqlSessionFactory&quot;, new RuntimeBeanReference(this.sqlSessionFactoryBeanName));</span><br><span class="line">        explicitFactoryUsed &#x3D; true;</span><br><span class="line">      &#125; else if (this.sqlSessionFactory !&#x3D; null) &#123;</span><br><span class="line">        definition.getPropertyValues().add(&quot;sqlSessionFactory&quot;, this.sqlSessionFactory);</span><br><span class="line">        explicitFactoryUsed &#x3D; true;</span><br><span class="line">      &#125;    &#x2F;&#x2F; @2 end</span><br><span class="line"></span><br><span class="line">      if (StringUtils.hasText(this.sqlSessionTemplateBeanName)) &#123;  &#x2F;&#x2F; @3</span><br><span class="line">        if (explicitFactoryUsed) &#123;</span><br><span class="line">          logger.warn(&quot;Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        definition.getPropertyValues().add(&quot;sqlSessionTemplate&quot;, new RuntimeBeanReference(this.sqlSessionTemplateBeanName));</span><br><span class="line">        explicitFactoryUsed &#x3D; true;</span><br><span class="line">      &#125; else if (this.sqlSessionTemplate !&#x3D; null) &#123;</span><br><span class="line">        if (explicitFactoryUsed) &#123;</span><br><span class="line">          logger.warn(&quot;Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        definition.getPropertyValues().add(&quot;sqlSessionTemplate&quot;, this.sqlSessionTemplate);</span><br><span class="line">        explicitFactoryUsed &#x3D; true;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      if (!explicitFactoryUsed) &#123;</span><br><span class="line">        if (logger.isDebugEnabled()) &#123;</span><br><span class="line">          logger.debug(&quot;Enabling autowire by type for MapperFactoryBean with name &#39;&quot; + holder.getBeanName() + &quot;&#39;.&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>该方法有3个关键点：<br>代码@1：BeanDefinition中的beanClass设置的类为MapperFactoryBean，即该BeanDefinition初始化的实例为MapperFactoryBean，其名字可以看出，这是一个FactoryBean对象，会通过其getObject方法进行构建具体实例。</p>
<p>代码@2：将为MapperFactoryBean设置属性，将SqlSessionFactory放入其属性中，在实例化时可以自动获取到该SqlSessionFactory。</p>
<p>代码@3：如果sqlSessionTemplate不为空，则放入到属性中，以便Spring在实例化MapperFactoryBean时可以得到对应的SqlSessionTemplate。</p>
<p>分析到这里，MapperScannerConfigurer的doScan方法就结束了，但并没有初始化Mapper，只是创建了很多的BeanDefinition,并且其beanClass为MapperFactoryBean，那我们将目光转向MapperFactoryBean。</p>
<h3 id="1-3-MapperFactoryBean"><a href="#1-3-MapperFactoryBean" class="headerlink" title="1.3 MapperFactoryBean"></a>1.3 MapperFactoryBean</h3><p>MapperFactoryBean的类图如下：<br><img src="https://img-blog.csdnimg.cn/20190521210725838.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>先对上述核心类做一个简述：</p>
<h4 id="DaoSupport"><a href="#DaoSupport" class="headerlink" title="DaoSupport"></a>DaoSupport</h4><p>Dao层的基类，定义一个模板方法，供其子类实现具体的逻辑，DaoSupport的模板方法如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public final void afterPropertiesSet() throws IllegalArgumentException, BeanInitializationException &#123;</span><br><span class="line">	&#x2F;&#x2F; Let abstract subclasses check their configuration.</span><br><span class="line">	checkDaoConfig(); &#x2F;&#x2F; @1</span><br><span class="line"></span><br><span class="line">	&#x2F;&#x2F; Let concrete implementations initialize themselves.</span><br><span class="line">	try &#123;</span><br><span class="line">		initDao();           &#x2F;&#x2F; @2</span><br><span class="line">	&#125; catch (Exception ex) &#123;</span><br><span class="line">		throw new BeanInitializationException(&quot;Initialization of DAO failed&quot;, ex);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：检查或构建dao的配置信息，该方法为抽象类，供子类实现，等下我们本节的主角MapperFactoryBean主要实现该方法，从而实现与Mybatis相关的整合信息。<br>代码@2：初始化Dao相关的方法，该方法为一个空实现。</p>
<h4 id="SqlSessionDaoSupport"><a href="#SqlSessionDaoSupport" class="headerlink" title="SqlSessionDaoSupport"></a>SqlSessionDaoSupport</h4><p>SqlSession支持父类，通过使用SqlSessionFactory或SqlSessionTemplate创建SqlSession，那下面两个方法会在什么时候被调用呢？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void setSqlSessionFactory(SqlSessionFactory sqlSessionFactory)</span><br><span class="line">public void setSqlSessionTemplate(SqlSessionTemplate sqlSessionTemplate)</span><br></pre></td></tr></table></figure>
<p>不知道大家还记不记得，在创建MapperFactoryBean的时候，其属性里会设置SqlSessionFacotry或SqlSessionTemplate，见上文代码(processBeanDefinitions)，这样的话在示例化Bean时，Spring会自动注入实例，即在实例化Bean时，上述方法中的一个或多个会被调用。</p>
<h4 id="MapperFactoryBean"><a href="#MapperFactoryBean" class="headerlink" title="MapperFactoryBean"></a>MapperFactoryBean</h4><p>主要看它是如何实现checkDaoConfig的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MapperFactoryBean#checkDaoConfig</span><br><span class="line">protected void checkDaoConfig() &#123;</span><br><span class="line">    super.checkDaoConfig();   &#x2F;&#x2F; @1</span><br><span class="line"></span><br><span class="line">    notNull(this.mapperInterface, &quot;Property &#39;mapperInterface&#39; is required&quot;);</span><br><span class="line"></span><br><span class="line">    Configuration configuration &#x3D; getSqlSession().getConfiguration();</span><br><span class="line">    if (this.addToConfig &amp;&amp; !configuration.hasMapper(this.mapperInterface)) &#123;     &#x2F;&#x2F; @2</span><br><span class="line">      try &#123;</span><br><span class="line">        configuration.addMapper(this.mapperInterface);                                        </span><br><span class="line">      &#125; catch (Throwable t) &#123;</span><br><span class="line">        logger.error(&quot;Error while adding the mapper &#39;&quot; + this.mapperInterface + &quot;&#39; to configuration.&quot;, t);</span><br><span class="line">        throw new IllegalArgumentException(t);</span><br><span class="line">      &#125; finally &#123;</span><br><span class="line">        ErrorContext.instance().reset();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先先调用父类的checkDaoConfig方法。<br>代码@2：mapperInterface，就是具体的Mapper的接口类，例如com.demo.dao.UserMapper，如果以注册，则抛出异常，否则调用configuration增加Mapper。</p>
<p>接下来进入到org.apache.ibatis.session.Configuration中。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123;</span><br><span class="line">    mapperRegistry.addMapper(type);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123;</span><br><span class="line">    return mapperRegistry.getMapper(type, sqlSession);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public boolean hasMapper(Class&lt;?&gt; type) &#123;</span><br><span class="line">   return mapperRegistry.hasMapper(type);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上面代码可以看出，正在注册(添加)、查询、获取Mapper的核心类为MapperRegistry。</p>
<h3 id="1-4-MapperRegistry"><a href="#1-4-MapperRegistry" class="headerlink" title="1.4 MapperRegistry"></a>1.4 MapperRegistry</h3><p>其核心类图如下所示：<br><img src="https://img-blog.csdnimg.cn/20190521211339211.png" alt="在这里插入图片描述"><br>对其属性做个简单的介绍：</p>
<ul>
<li>Configuration config<br>Mybatis全局配置对象。</li>
<li>Map&lt;Class<?>, MapperProxyFactory<?>&gt; knownMappers<br>已注册Map，这里的键值为mapper接口，例如com.demo.dao.UserMapper，值为MapperProxyFactory，创建MapperProxy的工厂。</li>
</ul>
<p>下面简单介绍MapperRegistry的几个方法，其实现都比较简单。</p>
<h4 id="MapperRegistry-addMapper"><a href="#MapperRegistry-addMapper" class="headerlink" title="MapperRegistry#addMapper"></a>MapperRegistry#addMapper</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123;</span><br><span class="line">    if (type.isInterface()) &#123;</span><br><span class="line">      if (hasMapper(type)) &#123;   &#x2F;&#x2F; @1</span><br><span class="line">        throw new BindingException(&quot;Type &quot; + type + &quot; is already known to the MapperRegistry.&quot;);</span><br><span class="line">      &#125;</span><br><span class="line">      boolean loadCompleted &#x3D; false;</span><br><span class="line">      try &#123;</span><br><span class="line">        knownMappers.put(type, new MapperProxyFactory&lt;T&gt;(type));    &#x2F;&#x2F; @2</span><br><span class="line">        MapperAnnotationBuilder parser &#x3D; new MapperAnnotationBuilder(config, type);    &#x2F;&#x2F; @3</span><br><span class="line">        parser.parse();</span><br><span class="line">        loadCompleted &#x3D; true;</span><br><span class="line">      &#125; finally &#123;</span><br><span class="line">        if (!loadCompleted) &#123;</span><br><span class="line">          knownMappers.remove(type);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果该接口已经注册，则抛出已经绑定的异常。<br>代码@2：为该接口注册MapperProxyFactory，但这里只是注册其创建MapperProxy的工厂，并不是创建MapperProxy。<br>代码@3：如果Mapper对应的xml资源未加载，触发xml的绑定操作，将xml中的sql语句与Mapper建立关系。本文将不详细介绍，在下一篇中详细介绍。</p>
<p>注意：addMapper方法，只是为*Mapper创建对应对应的MapperProxyFactory。</p>
<h4 id="MapperRegistry-getMapper"><a href="#MapperRegistry-getMapper" class="headerlink" title="MapperRegistry#getMapper"></a>MapperRegistry#getMapper</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123;</span><br><span class="line">    final MapperProxyFactory&lt;T&gt; mapperProxyFactory &#x3D; (MapperProxyFactory&lt;T&gt;) knownMappers.get(type);   &#x2F;&#x2F; @1</span><br><span class="line">    if (mapperProxyFactory &#x3D;&#x3D; null)</span><br><span class="line">      throw new BindingException(&quot;Type &quot; + type + &quot; is not known to the MapperRegistry.&quot;);</span><br><span class="line">    try &#123;</span><br><span class="line">      return mapperProxyFactory.newInstance(sqlSession);                                                                                 &#x2F;&#x2F; @2</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">      throw new BindingException(&quot;Error getting mapper instance. Cause: &quot; + e, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>根据Mapper接口与SqlSession创建MapperProxy对象。<br>代码@1：根据接口获取MapperProxyFactory。<br>代码@2：调用MapperProxyFactory的newInstance创建MapperProxy对象。</p>
<p>到目前为止Mybatis Mapper的初始化构造过程就完成一半了，即MapperScannerConfigurer通过包扫描，然后构建MapperProxy，但此时MapperProxy还未与mapper.xml文件中的sql语句建立关联，由于篇幅的原因，将在下一节重点介绍其关联关系建立的流程。接下来我们先一睹MapperProxy对象，毕竟这是本文最终要创建的对象，也为后续SQL的执行流程做个简单准备。</p>
<h3 id="1-5-MapperProxy"><a href="#1-5-MapperProxy" class="headerlink" title="1.5 MapperProxy"></a>1.5 MapperProxy</h3><p>类图如下：<br><img src="https://img-blog.csdnimg.cn/2019052121164389.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>上面的类都比较简单，MapperMethod，代表一个一个的Mapper方法，从SqlCommand可以看出，每一个MapperMethod都会对应一条SQL语句。</p>
<p>下面以一张以SqlSessionFacotry为视角的各核心类的关系图：<br><img src="https://img-blog.csdnimg.cn/20190521211724837.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<blockquote>
<p>温馨提示：本文只阐述了Mybatis MapperProxy的创建流程，MapperProxy与*.Mapper.xml即SQL是如何关联的本文未涉及到，这部分的内容请看下文，即将发布。</p>
</blockquote>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
        <tag>源码</tag>
        <tag>MapperProxy</tag>
        <tag>MapperScannerConfigurer</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析RateLimiter SmoothWarmingUp 实现原理(文末附流程图)</title>
    <url>/posts/6c0cb4a9.html</url>
    <content><![CDATA[<div id="vip-container"><p>上一篇详细介绍了 <a href="https://blog.csdn.net/prestigeding/article/details/105027563">SmoothBursty</a> 的实现原理，本文将介绍带有预热机制的限速器实现原理。</p>
<h2 id="1、类图"><a href="#1、类图" class="headerlink" title="1、类图"></a>1、类图</h2><p><img src="https://img-blog.csdnimg.cn/20200329155128855.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>从上文也详细介绍了 RateLimiter 相关的类图，本文就不详细介绍。</p>
<h2 id="2、SmoothWarmingUp-创建流程"><a href="#2、SmoothWarmingUp-创建流程" class="headerlink" title="2、SmoothWarmingUp 创建流程"></a>2、SmoothWarmingUp 创建流程</h2><p>创建 SmoothWarmingUp 限速器的入口为 RateLimiter 的 create 方法，其代码如下：<br>RateLimiter#create</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> RateLimiter <span class="title">create</span><span class="params">(<span class="keyword">double</span> permitsPerSecond, <span class="keyword">long</span> warmupPeriod, TimeUnit unit)</span> </span>&#123;  <span class="comment">// @1</span></span><br><span class="line">    checkArgument(warmupPeriod &gt;= <span class="number">0</span>, <span class="string">&quot;warmupPeriod must not be negative: %s&quot;</span>, warmupPeriod);</span><br><span class="line">    <span class="keyword">return</span> create(</span><br><span class="line">        SleepingStopwatch.createFromSystemTimer(), permitsPerSecond, warmupPeriod, unit, <span class="number">3.0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先先来看一下参数列表：</p>
<ul>
<li>double permitsPerSecond<br>每秒发放许可数量，即所谓的QPS。</li>
<li>long warmupPeriod<br>设置预热时间。</li>
<li>TimeUnit unit<br>warmupPeriod 的时间单位。</li>
</ul>
<p>代码@2：调用内部的重载方法创建 SmoothWarmingUp 。</p>
<p>RateLimiter#create</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> RateLimiter <span class="title">create</span><span class="params">( SleepingStopwatch stopwatch, <span class="keyword">double</span> permitsPerSecond, <span class="keyword">long</span> warmupPeriod, TimeUnit unit, <span class="keyword">double</span> coldFactor)</span> </span>&#123;</span><br><span class="line">    RateLimiter rateLimiter = <span class="keyword">new</span> SmoothWarmingUp(stopwatch, warmupPeriod, unit, coldFactor);  <span class="comment">// @1</span></span><br><span class="line">    rateLimiter.setRate(permitsPerSecond); <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">return</span> rateLimiter;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>创建 SmoothWarmingUp 两个主要步骤分别是调用其构造方法首先创建 SmoothWarmingUp 实例，然后调用其 setRate 方法进行初始化速率。这里先突出 coldFactor，默认为 3.0，该属性的作用将在下文详细介绍。</p>
<p>我们先来重点探讨一下 setRate 方法的实现。最终会调用其父类 SmoothRateLimiter 的doSetRate 方法。</p>
<p>SmoothRateLimiter#doSetRate</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">doSetRate</span><span class="params">(<span class="keyword">double</span> permitsPerSecond, <span class="keyword">long</span> nowMicros)</span> </span>&#123;</span><br><span class="line">    resync(nowMicros);   <span class="comment">// @1 </span></span><br><span class="line">    <span class="keyword">double</span> stableIntervalMicros = SECONDS.toMicros(<span class="number">1L</span>) / permitsPerSecond;   </span><br><span class="line">    <span class="keyword">this</span>.stableIntervalMicros = stableIntervalMicros;   <span class="comment">// @2</span></span><br><span class="line">    doSetRate(permitsPerSecond, stableIntervalMicros);  <span class="comment">// @3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：基于当前时间重置 SmoothRateLimiter 内部的 storedPermits(已存储的许可数量) 与 nextFreeTicketMicros(下一次可以免费获取许可的时间) 值，所谓的免费指的是无需等待就可以获取设定速率的许可，该方法对理解限流许可的产生非常关键，稍后详细介绍。</p>
<p>代码@2：根据QPS算出一个稳定的获取1个许可的时间。以一秒发放5个许可，即限速为5QPS，那发放一个许可的世界间隔为 200ms，stableIntervalMicros 变量是以微妙为单位。</p>
<p>代码@4：调用 SmoothRateLimiter 的抽象方法 doSetRate 设置速率，这里会调用 SmoothWarmingUp 的 doSetRate 方法。</p>
<p>在介绍 SmoothWarmingUp 的 doSetRate 方法之前，我们先来看一下 resync 方法的实现。</p>
<p>SmoothRateLimiter#resync</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">resync</span><span class="params">(<span class="keyword">long</span> nowMicros)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (nowMicros &gt; nextFreeTicketMicros) &#123;  <span class="comment">// @1 </span></span><br><span class="line">      <span class="keyword">double</span> newPermits = (nowMicros - nextFreeTicketMicros) / coolDownIntervalMicros();  <span class="comment">// @2</span></span><br><span class="line">      storedPermits = min(maxPermits, storedPermits + newPermits);    <span class="comment">// @3</span></span><br><span class="line">      nextFreeTicketMicros = nowMicros;   <span class="comment">// @4</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果当前已启动时间大于nextFreeTicketMicros（下一次可以免费获取许可的时间），则需要重新计算许可，即又可以向许可池中添加许可。</p>
<p>代码@2：根据当前时间可增加的许可数量，由于 SmoothWarmingUp 实现了预热机制，平均生成一个许可的时间并不是固定不变的。具体由 coolDownIntervalMicros 方法实现，稍候详细介绍。</p>
<p>代码@3：计算当前可用的许可，将新增的这些许可添加到许可池，但不会超过其最大值。</p>
<p>代码@4：更新下一次可增加计算许可的时间。 </p>
<p>SmoothWarmingUp#coolDownIntervalMicros</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">coolDownIntervalMicros</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> warmupPeriodMicros / maxPermits;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个方法的实现其实简单，用生成这些许可的总时间除以现在已经生成的许可数，即可得到当前时间点平均一个许可的生成时间。</p>
<a id="more"></a>

<ol>
<li><p>接下来重点探讨 SmoothWarmingUp 的 doSetRate 方法。<br>为了方便理解 SmoothWarmingUp doSetRate 方法，我根据 SmoothWarmingUp 类的注释，结合代码，给出如下示例图：<br><img src="https://img-blog.csdnimg.cn/20200329155338150.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>首先我们先来根据 SmoothWarmingUp 的相关注释来理解一下上述这张图的几个要点。</p>
<ul>
<li>图中有两个阴影面积，一个用 stable，另外一个warm up period。在预热算法中，这两个阴影面积的关系与冷却因子相关。</li>
<li>冷却因子 coldFactor 表示的含义为 coldIntervalMicros 与  stableIntervalMicros 的比值。</li>
<li>warm up period 阴影面积 与 stable 阴影面积的比值等于 (coldIntervalMicros -  stableIntervalMicros ) / stableIntervalMicros ，例如 SmoothWarmingUp 固定的冷却因子为3，那么 coldIntervalMicros 与 stableIntervalMicros 的比值为 3，那  (coldIntervalMicros -  stableIntervalMicros ) / stableIntervalMicros 则为 2。</li>
<li>在预热算法中与数学中的积分相关（笔者对这方面的数学知识一窍不通），故这里只展示结论，而不做推导，阴影 WARM UP PERIOD 的面积等于 warmupPeriod,那阴影stable的面积等于 warmupPeriod/2。</li>
<li>存在如下等式 warmupPeriod/2 = thresholdPermits * stableIntervalMicros (长方形的面积)</li>
<li>同样存在如下等式 warmupPeriod = 0.5 * (stableInterval + coldInterval) * (maxPermits - thresholdPermits) （梯形面积，(上底 + 下底 * 高 / 2) ）</li>
</ul>
<p>有了上述基本知识，我们再来看一下代码。</p>
<p>SmoothWarmingUp#doSetRate</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">doSetRate</span><span class="params">(<span class="keyword">double</span> permitsPerSecond, <span class="keyword">double</span> stableIntervalMicros)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">double</span> oldMaxPermits = maxPermits;</span><br><span class="line">    <span class="keyword">double</span> coldIntervalMicros = stableIntervalMicros * coldFactor;                <span class="comment">// @1</span></span><br><span class="line">    thresholdPermits = <span class="number">0.5</span> * warmupPeriodMicros / stableIntervalMicros;    <span class="comment">// @2</span></span><br><span class="line">    maxPermits =</span><br><span class="line">          thresholdPermits + <span class="number">2.0</span> * warmupPeriodMicros / (stableIntervalMicros + coldIntervalMicros);   <span class="comment">// @3</span></span><br><span class="line">    slope = (coldIntervalMicros - stableIntervalMicros) / (maxPermits - thresholdPermits);  <span class="comment">// @4</span></span><br><span class="line">    <span class="keyword">if</span> (oldMaxPermits == Double.POSITIVE_INFINITY) &#123;</span><br><span class="line">        storedPermits = <span class="number">0.0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        storedPermits =</span><br><span class="line">            (oldMaxPermits == <span class="number">0.0</span>)</span><br><span class="line">                ? maxPermits <span class="comment">// initial state is cold</span></span><br><span class="line">                : storedPermits * maxPermits / oldMaxPermits;    <span class="comment">// @5</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：根据冷却因子(coldFactor)来计算冷却间隔(单位为微秒)，等于冷却因子与 stableIntervalMicros 的乘积。从这里我们可以得出如下几个基本的概念。冷却因子 coldFactor 为 冷却间隔与稳定间隔的比例。</p>
<p>代码@2：通过  warmupPeriod/2 = thresholdPermits * stableIntervalMicros 等式，求出 thresholdPermits 的值。</p>
<p>代码@3：根据  warmupPeriod = 0.5 * (stableInterval + coldInterval) * (maxPermits - thresholdPermits)  表示可求出 maxPermits 的数量。</p>
<p>代码@4：斜率，表示的是从 stableIntervalMicros 到 coldIntervalMicros 这段时间，许可数量从 thresholdPermits 变为 maxPermits 的增长速率。</p>
<p>代码@5：根据 maxPermits 更新当前存储的许可，即当前剩余可消耗的许可数量。</p>
<h2 id="3、SmoothWarmingUp-acquire-流程"><a href="#3、SmoothWarmingUp-acquire-流程" class="headerlink" title="3、SmoothWarmingUp acquire 流程"></a>3、SmoothWarmingUp acquire 流程</h2><p>首先 acquire 的定义在其父类，这里是典型的模板模式，由其父类定义基本流程，由具体的子类实现其特定功能。RateLimiter 中的 acquire 方法如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">acquire</span><span class="params">(<span class="keyword">int</span> permits)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> microsToWait = reserve(permits);    <span class="comment">// @1</span></span><br><span class="line">    stopwatch.sleepMicrosUninterruptibly(microsToWait);   <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> * microsToWait / SECONDS.toMicros(<span class="number">1L</span>);   <span class="comment">// @3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：根据当前剩余的许可与本次申请的许可来判断本次申请需要等待的时长，如果返回0则表示无需等待。</p>
<p>代码@2：如果需要等待的时间不为0，表示触发限速，睡眠指定时间后唤醒。</p>
<p>代码@3：返回本次申请等待的时长。</p>
<p>接下来重点介绍 reserve 方法的实现原理。</p>
<p>RateLimiter#reserve</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">inal <span class="keyword">long</span> <span class="title">reserve</span><span class="params">(<span class="keyword">int</span> permits)</span> </span>&#123;</span><br><span class="line">    checkPermits(permits);</span><br><span class="line">    <span class="keyword">synchronized</span> (mutex()) &#123;  <span class="comment">// @1</span></span><br><span class="line">      <span class="keyword">return</span> reserveAndGetWaitLength(permits, stopwatch.readMicros()); <span class="comment">// @2</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：限速器主要维护的重要数据字段(storedPermits)，对其进行维护时都需要先获取锁。</p>
<p>代码@2：调用内部方法 reserveAndGetWaitLength 来计算需要等待时间。</p>
<p>继续跟踪 reserveAndGetWaitLength 方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">long</span> <span class="title">reserveAndGetWaitLength</span><span class="params">(<span class="keyword">int</span> permits, <span class="keyword">long</span> nowMicros)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> momentAvailable = reserveEarliestAvailable(permits, nowMicros);   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span> max(momentAvailable - nowMicros, <span class="number">0</span>);  <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：根据当前拥有的许可数量、当前时间判断待申请许可最早能得到满足的最早时间，用momentAvailable 表示。</p>
<p>代码@2：然后计算 momentAvailable 与 nowMicros 的差值与0做比较，得出需要等待的时间。</p>
<p>继续跟踪 reserveEarliestAvailable方法，该方法在 RateLimiter 中一个抽象方法，具体实现在其子类 SmoothRateLimiter 中。</p>
<p>SmoothRateLimiter#reserveEarliestAvailable</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">long</span> <span class="title">reserveEarliestAvailable</span><span class="params">(<span class="keyword">int</span> requiredPermits, <span class="keyword">long</span> nowMicros)</span> </span>&#123;</span><br><span class="line">    resync(nowMicros);   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">long</span> returnValue = nextFreeTicketMicros;</span><br><span class="line">    <span class="keyword">double</span> storedPermitsToSpend = min(requiredPermits, <span class="keyword">this</span>.storedPermits); <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">double</span> freshPermits = requiredPermits - storedPermitsToSpend; <span class="comment">// @3</span></span><br><span class="line">    <span class="keyword">long</span> waitMicros =</span><br><span class="line">        storedPermitsToWaitTime(<span class="keyword">this</span>.storedPermits, storedPermitsToSpend)</span><br><span class="line">            + (<span class="keyword">long</span>) (freshPermits * stableIntervalMicros);  <span class="comment">// @4</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.nextFreeTicketMicros = LongMath.saturatedAdd(nextFreeTicketMicros, waitMicros);  <span class="comment">// @5</span></span><br><span class="line">    <span class="keyword">this</span>.storedPermits -= storedPermitsToSpend;    <span class="comment">// @6</span></span><br><span class="line">    <span class="keyword">return</span> returnValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：在尝试申请许可之前，先根据当前时间即发放许可速率更新 storedPermits 与 nextFreeTicketMicros（下一次可以免费获取许可的时间）。</p>
<p>代码@2：计算本次能从 storedPermits 中消耗的许可数量，取需要申请的许可数量与当前可用的许可数量的最小值，用 storedPermitsToSpend 表示。</p>
<p>代码@3：如果需要申请的许可数量(requiredPermits)大于当前剩余许可数量(storedPermits)，则还需要等待新的许可生成，用freshPermits 表示，即如果该值大于0，则表示本次申请需要阻塞一定时间。</p>
<p>代码@4：计算本次申请需要等待的时间，等待的时间由两部分组成，一部分是由 storedPermitsToWaitTime 方法返回的，另外一部分以稳定速率生成需要的许可，其需要时间为 freshPermits * stableIntervalMicros,稍后我们详细分析一下 storedPermitsToWaitTime 方法的实现。</p>
<p>代码@5：更新 nextFreeTicketMicros 为当前时间加上需要等待的时间。</p>
<p>代码@6：更新 storedPermits 的值，即减少本次已消耗的许可数量。</p>
<p>代码@7：请注意这里返回的 returnValue 的值，并没有包含由于剩余许可需要等待创建新许可的时间，即允许一定的突发流量，故本次计算需要的等待时间将对下一次请求生效。</p>
<p>接下来重点探讨一下 SmoothWarmingUp 的 storedPermitsToWaitTime 方法。</p>
<p>SmoothWarmingUp#SmoothWarmingUp </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">storedPermitsToWaitTime</span><span class="params">(<span class="keyword">double</span> storedPermits, <span class="keyword">double</span> permitsToTake)</span> </span>&#123;  <span class="comment">// @1</span></span><br><span class="line">	<span class="keyword">double</span> availablePermitsAboveThreshold = storedPermits - thresholdPermits;   <span class="comment">// @2</span></span><br><span class="line">	<span class="keyword">long</span> micros = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">if</span> (availablePermitsAboveThreshold &gt; <span class="number">0.0</span>) &#123;  <span class="comment">// @3</span></span><br><span class="line">		<span class="keyword">double</span> permitsAboveThresholdToTake = min(availablePermitsAboveThreshold, permitsToTake);  <span class="comment">// @31 </span></span><br><span class="line">                <span class="comment">// TODO(cpovirk): Figure out a good name for this variable.</span></span><br><span class="line">                <span class="keyword">double</span> length = permitsToTime(availablePermitsAboveThreshold)</span><br><span class="line">                     + permitsToTime(availablePermitsAboveThreshold - permitsAboveThresholdToTake);             <span class="comment">// @32</span></span><br><span class="line">                micros = (<span class="keyword">long</span>) (permitsAboveThresholdToTake * length / <span class="number">2.0</span>);                                                      <span class="comment">// @33</span></span><br><span class="line">                permitsToTake -= permitsAboveThresholdToTake;                                                                          <span class="comment">// @34</span></span><br><span class="line">         &#125;</span><br><span class="line">        <span class="comment">// measuring the integral on the left part of the function (the horizontal line)</span></span><br><span class="line">        micros += (stableIntervalMicros * permitsToTake);   <span class="comment">// @4</span></span><br><span class="line">        <span class="keyword">return</span> micros;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先介绍其两个参数的含义：</p>
<ul>
<li>double storedPermits<br>当前存储的许可数量。</li>
<li>double permitsToTake<br>本次申请需要的许可数量。</li>
</ul>
<p>代码@2：availablePermitsAboveThreshold ，当前超出 thresholdPermits 的许可个数，如果超过 thresholdPermits ，申请许可将来源于超过的部分，只有其不足后，才会从 thresholdPermits 中申请，这部分的详细逻辑见代码@3。</p>
<p>代码@3：如果当前存储的许可数量超过了稳定许可 thresholdPermits，即存在预热的许可数量的申请逻辑，其实现关键点如下：</p>
<ul>
<li>获取本次从预热区间申请的许可数量。</li>
<li>从预热区间获取一个许可的时间其算法有点晦涩难懂，具体实现为@32~@34。</li>
</ul>
<p>代码@4：从稳定区间获取一个许可的时间，就容易理解，为固定的 stableIntervalMicros 。</p>
<blockquote>
<p>温馨提示：从预热区间计算获取多个许可的算法，与 slope 有关，笔者并未完成感悟，但至少我们需要明白的是，从 剩余许可(storedPermits)中申请许可时，优先消耗(大于thresholdPermits 的许可，即消耗 (thresholdPermits ~ maxPermit ) 之间的许可)。</p>
</blockquote>
<p>SmoothWarmingUp 的 acquire 流程就介绍到这里了。</p>
<h2 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h2><p>SmoothWarmingUp 的 acquire 的流程与 SmoothBursty 类似，故其流程图与下图通用，主要的区别生成一个许可的时间有变化，主要是提供了预热机制。<br><img src="https://img-blog.csdnimg.cn/20200329155751536.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
</li>
</ol>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>源码</tag>
        <tag>SmoothWarmingUp</tag>
        <tag>coldFactor</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析Mybatis插件(Plugin)机制与实战</title>
    <url>/posts/3e30e205.html</url>
    <content><![CDATA[<div id="vip-container"><blockquote>
<p>温馨提示：本文也是以提问式阅读与探究源码的技巧展示。</p>
</blockquote>
<h2 id="1、回顾"><a href="#1、回顾" class="headerlink" title="1、回顾"></a>1、回顾</h2><p>从前面的文章我们已经知道，Mybatis在执行SQL语句的扩展点为Executor、StatementHandler、ParameterHandler与ResultSetHandler，我们本节将以Executor为入口，向大家展示Mybatis插件的扩展机制。</p>
<p>我们先来看回顾一下Mybatis Executor的创建入口。</p>
<h3 id="1-1-Configuration-newExecutor"><a href="#1-1-Configuration-newExecutor" class="headerlink" title="1.1 Configuration#newExecutor"></a>1.1 Configuration#newExecutor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Executor <span class="title">newExecutor</span><span class="params">(Transaction transaction, ExecutorType executorType)</span> </span>&#123;</span><br><span class="line">  executorType = executorType == <span class="keyword">null</span> ? defaultExecutorType : executorType;</span><br><span class="line">  executorType = executorType == <span class="keyword">null</span> ? ExecutorType.SIMPLE : executorType;</span><br><span class="line">  Executor executor;</span><br><span class="line">  <span class="keyword">if</span> (ExecutorType.BATCH == executorType) &#123;</span><br><span class="line">    executor = <span class="keyword">new</span> BatchExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ExecutorType.REUSE == executorType) &#123;</span><br><span class="line">    executor = <span class="keyword">new</span> ReuseExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    executor = <span class="keyword">new</span> SimpleExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (cacheEnabled) &#123;</span><br><span class="line">    executor = <span class="keyword">new</span> CachingExecutor(executor);</span><br><span class="line">  &#125;</span><br><span class="line">  executor = (Executor) interceptorChain.pluginAll(executor);   <span class="comment">// @1</span></span><br><span class="line">  <span class="keyword">return</span> executor;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1,：使用InterceptorChain.pluginAll(executor)进行拆件化处理。</p>
<p>思考：使用该方法调用后，会返回一个什么对象呢？如何自定义拆件，自定义插件如何执行呢？</p>
<p>那接下来我们带着上述疑问，从InterceptorChain类开始进行深入学习。</p>
<h2 id="2、InterceptorChain"><a href="#2、InterceptorChain" class="headerlink" title="2、InterceptorChain"></a>2、InterceptorChain</h2><p>从名字上看其大意为拦截器链。</p>
<h3 id="2-1-类图"><a href="#2-1-类图" class="headerlink" title="2.1 类图"></a>2.1 类图</h3><p><img src="https://img-blog.csdnimg.cn/20190530205753805.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li>InterceptorChain<br>拦截器链，其内部维护一个interceptors,表示拦截器链中所有的拦截器，并提供增加或获取拦截器链的方法，下面会重点分析pluginAll方法。</li>
<li>Interceptor<br>拦截器接口，用户自定义的拦截器需要实现该接口。</li>
<li>Invocation<br>拦截器执行时的上下文环境，其实就是目标方法的调用信息，包含目标对象、调用的方法信息、参数信息。其中包含一个非常重要的方法：proceed。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">proceed</span><span class="params">()</span> <span class="keyword">throws</span> InvocationTargetException, IllegalAccessException </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> method.invoke(target, args);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
该方法的主要目的就是进行处理链的传播，执行完拦截器的方法后，最终需要调用目标方法的invoke方法。</li>
</ul>
<p>记下来中先重点分析一下InterceptorChain方法的pluginAll方法，因为从开头也知道,Mybatis在创建对象时，是调用该方法，完成目标对象的包装。</p>
<a id="more"></a>

<h3 id="2-2-核心方法一览"><a href="#2-2-核心方法一览" class="headerlink" title="2.2 核心方法一览"></a>2.2 核心方法一览</h3><h4 id="2-2-1-pluginAll"><a href="#2-2-1-pluginAll" class="headerlink" title="2.2.1 pluginAll"></a>2.2.1 pluginAll</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">pluginAll</span><span class="params">(Object target)</span> </span>&#123;   <span class="comment">// @1</span></span><br><span class="line">  <span class="keyword">for</span> (Interceptor interceptor : interceptors) &#123;   <span class="comment">// @2</span></span><br><span class="line">    target = interceptor.plugin(target);         </span><br><span class="line">  <span class="comment">// @3</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> target;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：目标对象，需要被代理的对象。</p>
<p>代码@2：遍历InterceptorChain的拦截器链，分别调用Intercpetor对象的Plugin进行拦截(@3)。</p>
<p>那接下来有三个疑问？<br>问题1：InterceptorChain中的interceptors是从什么时候初始化的呢，即拦截链中的拦截器从何而来。<br>问题2：从前面也得知，无论是创建Executor，还是创建StatementHandler等，都是调用InterceptorChain#pluginAll方法，那是不是拦截器中的拦截器都会作用与目标对象，这应该是有问题的，该如何处理？<br>问题3：代理对象是如何创建的。</p>
<h4 id="2-2-1-addInterceptor"><a href="#2-2-1-addInterceptor" class="headerlink" title="2.2.1 addInterceptor"></a>2.2.1 addInterceptor</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addInterceptor</span><span class="params">(Interceptor interceptor)</span> </span>&#123;</span><br><span class="line">  interceptors.add(interceptor);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>要想知道interceptors是如何初始化的，我们只需要查看该方法的调用链即可。</p>
<p>一路跟踪到源头，我们会发现在初始化SqlSessionFactory时，会解析一个标签plugin，就可以得知，会在SqlSessionFacotry的一个属性中配置所有的拦截器。<br>具体配置示例如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;sqlSessionFactory&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;dataSource&quot;</span> <span class="attr">ref</span>=<span class="string">&quot;shardingDataSource&quot;</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;mapperLocations&quot;</span> <span class="attr">value</span>=<span class="string">&quot;classpath*:META-INF/mybatis/mappers/OrderMapper.xml&quot;</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;plugins&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">array</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span> = <span class="string">&quot;teneantInteceptor&quot;</span> <span class="attr">class</span>=<span class="string">&quot;com.demo.inteceptor.TenaInteceptor&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">array</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>问题1已经解决。但后面两个问题似乎没有什么突破口。由于目前所涉及的三个类，显然不足以给我们提供答案，我们先将目光移到InterceptorChain所在包中的其他类，看看其他类的职责如何。</p>
<h2 id="3、Intercepts与Signature"><a href="#3、Intercepts与Signature" class="headerlink" title="3、Intercepts与Signature"></a>3、Intercepts与Signature</h2><p>在org.apache.ibatis.plugin中存在如下两个注解类：Intercepts与Signature，从字面意思就是用来配置拦截的方法信息。<br><img src="https://img-blog.csdnimg.cn/2019053021040719.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li>Siganature注解的属性说明如下：<ul>
<li>Class&lt;?&gt; type ：需要拦截目标对象的类。</li>
<li>String method：需要拦截目标类的方法名。</li>
<li>Class&lt;?&gt;[] args：需要拦截目标类的方法名的参数类型签名。</li>
</ul>
</li>
</ul>
<p>备注：至于如何得知上述字段的含义，请看下文的Plugin#getSignatureMap方法。</p>
<p>但另外一个类型Plugin类确引起了我的注意。接下来我们将重点分析Plugin方法。</p>
<h2 id="4、Plugin详解"><a href="#4、Plugin详解" class="headerlink" title="4、Plugin详解"></a>4、Plugin详解</h2><h3 id="4-1-Plugin类图"><a href="#4-1-Plugin类图" class="headerlink" title="4.1 Plugin类图"></a>4.1 Plugin类图</h3><p><img src="https://img-blog.csdnimg.cn/20190530210628459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其中InvocationHandler为JDK的动态代理机制中的事件执行器，我们可以隐约阈值代理对象的生成将基于JDK内置的动态代理机制。</p>
<p>Plugin的核心属性如下：</p>
<ul>
<li>Object target<br>目标对象。</li>
<li>Interceptor interceptor<br>拦截器对象。</li>
<li>Map&lt;Class&lt;?&gt;, Set&lt; Method&gt;&gt; signatureMap<br>拦截器中的签名映射。</li>
</ul>
<h2 id="4-2-构造函数"><a href="#4-2-构造函数" class="headerlink" title="4.2  构造函数"></a>4.2  构造函数</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">Plugin</span><span class="params">(Object target, Interceptor interceptor, Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.target = target;</span><br><span class="line">    <span class="keyword">this</span>.interceptor = interceptor;</span><br><span class="line">    <span class="keyword">this</span>.signatureMap = signatureMap;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>注意：其构造函数为私有的，那如何构建Plugin呢，其构造方法为Plugin的镜头方法wrap中被调用。</p>
<h3 id="4-3-核心方法详解"><a href="#4-3-核心方法详解" class="headerlink" title="4.3 核心方法详解"></a>4.3 核心方法详解</h3><h4 id="4-3-1-wrap"><a href="#4-3-1-wrap" class="headerlink" title="4.3.1 wrap"></a>4.3.1 wrap</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">wrap</span><span class="params">(Object target, Interceptor interceptor)</span> </span>&#123;</span><br><span class="line">  Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor);  <span class="comment">// @1</span></span><br><span class="line">  Class&lt;?&gt; type = target.getClass();   </span><br><span class="line">  Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap);   <span class="comment">// @2</span></span><br><span class="line">  <span class="keyword">if</span> (interfaces.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> Proxy.newProxyInstance(    <span class="comment">// @3</span></span><br><span class="line">        type.getClassLoader(),</span><br><span class="line">        interfaces,</span><br><span class="line">        <span class="keyword">new</span> Plugin(target, interceptor, signatureMap));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> target;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：获取待包装的Interceptor的方法签名映射表，稍后详细分析。</p>
<p>代码@2：获取需要代理的对象的Class上声明的所有接口。</p>
<p>代码@3：使用JDK内置的Proxy创建代理对象。Proxy创建代理对象的方法声明如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">newProxyInstance</span><span class="params">(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h)</span>，</span></span><br></pre></td></tr></table></figure>
<p>注意其事件处理器为Plugin，故在动态运行过程中会执行Plugin的invoker方法。</p>
<p>在进入Plugin#invoker方法学习之前，我们先重点查看一下getSignatureMap、getAllInterfaces的实现。</p>
<h4 id="4-3-2-getSignatureMap"><a href="#4-3-2-getSignatureMap" class="headerlink" title="4.3.2 getSignatureMap"></a>4.3.2 getSignatureMap</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; getSignatureMap(Interceptor interceptor) &#123;</span><br><span class="line">  Intercepts interceptsAnnotation = interceptor.getClass().getAnnotation(Intercepts.class);  <span class="comment">// @1</span></span><br><span class="line">  <span class="keyword">if</span> (interceptsAnnotation == <span class="keyword">null</span>) &#123; <span class="comment">// issue #251                                          // @2</span></span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> PluginException(<span class="string">&quot;No @Intercepts annotation was found in interceptor &quot;</span> + interceptor.getClass().getName());      </span><br><span class="line">  &#125;</span><br><span class="line">  Signature[] sigs = interceptsAnnotation.value();   <span class="comment">// @3</span></span><br><span class="line">  Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = <span class="keyword">new</span> HashMap&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt;(); </span><br><span class="line">  <span class="keyword">for</span> (Signature sig : sigs) &#123;</span><br><span class="line">    Set&lt;Method&gt; methods = signatureMap.get(sig.type());</span><br><span class="line">    <span class="keyword">if</span> (methods == <span class="keyword">null</span>) &#123;</span><br><span class="line">      methods = <span class="keyword">new</span> HashSet&lt;Method&gt;();</span><br><span class="line">      signatureMap.put(sig.type(), methods);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      Method method = sig.type().getMethod(sig.method(), sig.args());    </span><br><span class="line">      methods.add(method);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (NoSuchMethodException e) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> PluginException(<span class="string">&quot;Could not find method on &quot;</span> + sig.type() + <span class="string">&quot; named &quot;</span> + sig.method() + <span class="string">&quot;. Cause: &quot;</span> + e, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> signatureMap;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先从Interceptor的类上获取Intercepts注解。</p>
<p>代码@2：如果Interceptor的类上没有定义Intercepts注解，则抛出异常，说明我们在自定义插件时，必须要有Intercepts注解。</p>
<p>代码@3：解析Interceptor的values属性（Signature[]）数组，然后存入HashMap&lt;Class&lt;?&gt;, Set&lt; Method&gt;&gt;容器内。</p>
<blockquote>
<p>温馨提示：从这里可以得知：自定义的插件必须定义Intercepts注解，其注解的value值为Signature。</p>
</blockquote>
<h4 id="4-3-3-getAllInterfaces"><a href="#4-3-3-getAllInterfaces" class="headerlink" title="4.3.3 getAllInterfaces"></a>4.3.3 getAllInterfaces</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Class&lt;?&gt;[] getAllInterfaces(Class&lt;?&gt; type, Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap) &#123;</span><br><span class="line">  Set&lt;Class&lt;?&gt;&gt; interfaces = <span class="keyword">new</span> HashSet&lt;Class&lt;?&gt;&gt;();</span><br><span class="line">  <span class="keyword">while</span> (type != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> (Class&lt;?&gt; c : type.getInterfaces()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (signatureMap.containsKey(c)) &#123;</span><br><span class="line">        interfaces.add(c);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    type = type.getSuperclass();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> interfaces.toArray(<span class="keyword">new</span> Class&lt;?&gt;[interfaces.size()]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法的实现比较简单，并不是获取目标对象所实现的所有接口，而是返回需要拦截的方法所包括的接口。</p>
<h4 id="4-3-4-invoke"><a href="#4-3-4-invoke" class="headerlink" title="4.3.4 invoke"></a>4.3.4 invoke</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123; <span class="comment">// @1</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass());</span><br><span class="line">    <span class="keyword">if</span> (methods != <span class="keyword">null</span> &amp;&amp; methods.contains(method)) &#123;   <span class="comment">// @2</span></span><br><span class="line">      <span class="keyword">return</span> interceptor.intercept(<span class="keyword">new</span> Invocation(target, method, args));   <span class="comment">// @3</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> method.invoke(target, args);                           <span class="comment">// @4</span></span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> ExceptionUtil.unwrapThrowable(e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先对其参数列表做一个简单的说明：</p>
<ul>
<li>Object proxy 当前的代理对象</li>
<li>Method method 当前执行的方法</li>
<li>Object[] args 当前执行方法的参数</li>
</ul>
<p>代码@2：获取当前执行方法所属的类，并获取需要被拦截的方法集合。</p>
<p>代码@3：如果需被拦截的方法集合包含当前执行的方法，则执行拦截器的interceptor方法。</p>
<p>代码@4：如果不是，则直接调用目标方法的Invoke方法。</p>
<p>从该方法可以看出Interceptor接口的intercept方法就是拦截器自身需要实现的逻辑，其参数为Invocation，在该方法的结束，需要调用invocation#proceed()方法，进行拦截器链的传播。</p>
<p>从目前的学习中，我们已经了解了Plugin.wrap方法就是生成带来带来类的唯一入口，那该方法在什么地方调用呢？从代码类库中没有找到该方法的调用链，说明该方法是供用户调用的。</p>
<p>再看InterceptorChain方法的pluginAll方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">pluginAll</span><span class="params">(Object target)</span> </span>&#123;   <span class="comment">// @1</span></span><br><span class="line">  <span class="keyword">for</span> (Interceptor interceptor : interceptors) &#123;   <span class="comment">// @2</span></span><br><span class="line">    target = interceptor.plugin(target);           <span class="comment">// @3</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> target;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法会遍历用户定义的插件实现类（Interceptor），并调用Interceptor的plugin方法，对target进行拆件化处理，即我们在实现自定义的Interceptor方法时，在plugin中需要根据自己的逻辑，对目标对象进行包装（代理），创建代理对象，那我们就可以在该方法中使用Plugin#wrap来创建代理类。</p>
<p>接下来我们再来用序列图来对上述源码分析做一个总结：<br><img src="https://img-blog.csdnimg.cn/2019053021182314.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>看到这里，大家是否对上面提出的3个问题都已经有了自己的答案了。</p>
<p>问题1：InterceptorChain中的interceptors是从什么时候初始化的呢，即拦截链中的拦截器从何而来。<br>答：在初始化SqlSesstionFactory的时候，会解析属性plugins属性，会加载所有的拦截器到InterceptorChain中。</p>
<p>问题2：从前面也得知，无论是创建Executor，还是创建StatementHandler等，都是调用InterceptorChain#pluginAll方法，那是不是拦截器中的拦截器都会作用与目标对象，这应该是有问题的，该如何处理？</p>
<p>答案是在各自订阅的Interceptor#plugin方法中，我们可以根据传入的目标对象，是否是该拦截器关注的，如果不关注，则直接返回目标对象，如果关注，则使用Plugin#wrap方法创建代理对象。</p>
<p>问题3：代理对象是如何创建的？<br>代理对象是使用JDK的动态代理机制创建，使用Plugin#wrap方法创建。</p>
<h2 id="5、实践"><a href="#5、实践" class="headerlink" title="5、实践"></a>5、实践</h2><p>实践是检验真理的唯一标准，那到底如何使用Mybatis的插件机制呢？<br>创建自定义的拦截器Interceptor,实现Interceptor接口。<br>1）实现plugin方法，在该方法中决定是否需要创建代理对象，如果创建，使用Plugin#wrap方法创建。<br>2）实现interceptor方法，该方法中定义拦截器的逻辑，并且在最后请调用invocation.proceed()方法传递拦截器链。<br>3）使用Intercepts注解，定义需要拦截目标对象的方法签名，支持多个。<br>将实现的Interceptor在定义SqlSessionFactory的配置中，放入plugins属性。</p>
<p>最后给出一个Mybatis Plugin插件机制使用案例：基于Mycat+Mybatis的多租户方案：<a href="https://blog.csdn.net/prestigeding/article/details/52662426">基于Mybatis与Mycat的多租户方式，通过Mybatis的插件机制，动态改写SQL语句来实现多租户</a></p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
        <tag>实战</tag>
        <tag>Plugin</tag>
      </tags>
  </entry>
  <entry>
    <title>源码阅读技巧篇：RocketMQ DLedger 多副本即主从切换专栏回顾</title>
    <url>/posts/12736650.html</url>
    <content><![CDATA[<div id="vip-container"><p>RocketMQ DLedger 多副本即主从切换专栏总共包含9篇文章，时间跨度大概为2个月的时间，笔者觉得授人以鱼不如授人以渔，借以这个系列来展示该系列的创作始末，展示笔者阅读源码的技巧。</p>
<p>首先在下决心研读  RocketMQ DLedger 多副本(主从切换)的源码之前，首先还是要通过官方的分享、百度等途径对该功能进行一些基本的了解。</p>
<p>我们了解到 RocketMQ 在 4.5.0 之前提供了主从同步功能，即当主节点宕机后，消费端可以继续从从节点上消费消息，但无法继续向该复制组发送消息。RocketMQ 4.5.0版本引入了多副本机制，即 DLedger，支持主从切换，即当一个复制组内的主节点宕机后，会在该复制组内触发重新选主，选主完成后即可继续提供消息写功能。同时还了解到 rocketmq 主从切换是基于 raft 协议的。</p>
<p>raft 协议是何许人也，我猜想大部分读者对这个名词并不陌生，但像笔者一样只是听过其大体作用但并未详细学习的应该也不在少数，故我觉得看 RocketMQ DLedger 多副本即主从切换之前应该重点了解 raft 协议。</p>
<p>1、<a href="https://blog.csdn.net/prestigeding/article/details/99101912">RocketMQ 多副本前置篇：初探raft协议</a></p>
<p>本文主要根据 raft 官方提供的动画来学习了解 raft 协议，从本文基本得知了 raft 协议主要包含两个重要部分：选主 以及 日志复制。在了解了 raft 协议的选主、日志复制的基本实现后，然后就可以步入到 RocketMQ DLedger 多副本即主从切换的源码研究了，以探究大神是如何实现 raft 协议的。同时在了解到了 raft 协议的选主部分内容后，自己也可以简单的思考，如果自己去实现 raft 协议，应该要实现哪些关键点，当时我的思考如下：<br><img src="https://img-blog.csdnimg.cn/20191020212502611.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>这样在看源码时更加有针对性，不至于在阅读源码过程中“迷失”。</p>
<p>2、<a href="https://blog.csdn.net/prestigeding/article/details/99697323">源码分析 RocketMQ DLedger 多副本之 Leader 选主</a></p>
<p>本文按照上一篇的思路，重点对 DLedgerLeaderElector 的实现进行了详细分析，特别是其内部的状态机流转，最后也给出一张流程图对选主过程进行一个简单的梳理与总结。</p>
<a id="more"></a>

<blockquote>
<p>温馨提示：如果在阅读源码的过程中一时无法理解，可以允许其提供的单元测试，DEBUG一下，可以起到拨云见雾之效。</p>
</blockquote>
<p>3、<a href="https://blog.csdn.net/prestigeding/article/details/100177780">源码分析 RocketMQ DLedger 多副本存储实现</a></p>
<p>在学习完 DLedger 选主实现后，接下来将重点突破 raft 协议的另外一个部分：日志复制。因为日志复制将涉及到存储，故在学习日志复制之前，先来看一下 DLedger 与存储相关的设计，例如 DLedger 日志条目的存储协议、日志在服务器的组织等关系，这部分类比 RocketMQ commitlog 等的存储。</p>
<p>4、<a href="https://blog.csdn.net/prestigeding/article/details/100835869">源码分析 RocketMQ DLedger(多副本) 之日志追加流程</a></p>
<p>在学习完DLedger 多副本即主从切换 日志存储后，我们将正式进入到日志复制部分，从上图我们可以简单了解，日志复制其实包含两个比较大的阶段，第一阶段是指主节点(Leader)接受客户端请求后，将数据先存储到主服务器中，然后再将数据转发到它的所有从节点。故本篇文章中的关注第一阶段：日志追加。</p>
<p>5、<a href="https://blog.csdn.net/prestigeding/article/details/100836389">源码分析 RocketMQ DLedger(多副本) 之日志复制(传播)</a><br>本文继续关注日志复制的第二个阶段，包含主节点日志转发、从节点接收日志、主节点对日志转发进行仲裁，即需要实现只有超过集群半数节点都存储成功才认为该消息已成功提交，才会对客户端承偌消息发送成功。</p>
<p>6、<a href="https://blog.csdn.net/prestigeding/article/details/101629440">基于 raft 协议的 RocketMQ DLedger 多副本日志复制设计原理</a></p>
<p>源码解读 raft 协议的日志复制部分毕竟比较枯燥，故本文梳理了3张流程图，并对日志的实现要点做一个总结，以此来介绍 rocketmq Dledger 多副本即主从切换部分的 raft 协议的解读。</p>
<p>7、<a href="https://blog.csdn.net/prestigeding/article/details/101984216">RocketMQ 整合 DLedger(多副本)即主从切换实现平滑升级的设计技巧</a></p>
<p>前面6篇文章都聚焦在 raft 协议的选主与日志复制。从本节开始将介绍 rocketmq 主从切换的实现细节，基于 raft 协议已经可以实现主节点的选主与日志复制，主从切换的另外一个核心就是主从切换后元数据的同步，例如topic、消费组订阅信息、消息消费进度等。另外主从切换是rocketmq 4.5.0 版本才引入的，如果从老版本升级到 4.5.0，直接兼容原先的消息是重中之中，故本文将详细剖析其设计要点。</p>
<p>8、<a href="https://blog.csdn.net/prestigeding/article/details/102239892">源码分析 RocketMQ DLedger 多副本即主从切换实现原理</a></p>
<p>从设计上理解了平滑升级的技巧，本篇就从源码角度剖析主从切换的实现要点，即重点关注元数据的同步（特别是消息消费进度的同步）。</p>
<p>9、<a href="https://blog.csdn.net/prestigeding/article/details/102532485">RocketMQ DLedger 多副本即主从切换实战</a></p>
<p>经过前面8篇文章的铺垫，我相信大家对 DLedger 的实现原理有了一个全新的认识，本篇作为该系列的收官之作，介绍如何从主从同步集群平滑升级到DLedger，即主从切换版本，并对功能进行验证。</p>
<p>整体总结一下就是首先从整体上认识其核心要点，然后逐步展开，逐步分解形成一篇一篇的文章，在遇到看不懂的时候，可以 debug  官方提供的单元测试用例。</p>
<p>如果本文对大家有所帮助的话，麻烦帮忙点个【在看】，谢谢。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>多副本</tag>
        <tag>主从切换</tag>
        <tag>DLedger</tag>
      </tags>
  </entry>
  <entry>
    <title>结合 Sentinel 专栏谈谈我的源码阅读技巧</title>
    <url>/posts/b9d8cad7.html</url>
    <content><![CDATA[<div id="vip-container"><blockquote>
<p>本文行文思路：先抛出源码阅读方法，然后结合Sentinel创作过程谈谈具体是如何运用这些技巧，最后解答几个源码阅读的误区。</p>
</blockquote>
<p>Sentinel 系列共包含15篇文章，主要以源码分析为手段，图文并茂的方式对 Sentinel 的架构设计理念、核心实现要点进行了一一剖析，并加以实战分析与思考。</p>
<p><strong>很多朋友都在询我是如何阅读源码的。对此可归纳为如下几个要点，然后结合 Sentienl 源码分析专栏对各个要点进行拆解，对源码阅读方法进行一次“实战”。</strong></p>
<ul>
<li>阅读官方文档，从全局了解待学习框架能解决什么样的问题，整体架构设计与思想是什么，主要包含哪些要点。</li>
<li>从官方提供的 Demo 程序开始，学习基本的使用方法，进一步加深其理解，并伺机寻找入口（突破口）。</li>
<li>寻找突破口，逐一突破，先主干再旁支，适度分解，各个击破。</li>
</ul>
<p>接下来将展示我是如何使用这套方法论来学习 Sentinel 的。</p>
<p>在准备深入学习 Sentinel 之前，首先认真看了一遍 Sentinel 的官方文档，从而形成了对 Sentinel 的基本认识，我们可以从官方文档了解到 Sentinel 主要涉及的核心内容，正如下图所示：<br><img src="https://img-blog.csdnimg.cn/2020053015083815.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">这些内容可以简单的当成一个学习的提纲，可以从里面挑选自己感兴趣的进行重点学习。</p>
<p>在看完官方文档后，我就踏上创作 Sentinel 系列的征途。</p>
<blockquote>
<p>本文不会再详细介绍每一个知识点的细节，有关各个知识点的具体讲解，大家可以点击感兴趣的链接中进行深入研究，本文主要是点到为止，重在介绍笔者是如何学习源码的。</p>
</blockquote>
<p>1、<a href="https://blog.csdn.net/prestigeding/article/details/103544443">Alibaba Sentinel 限流与熔断初探</a><br>该文章主要从如下几个点进行展开：</p>
<ul>
<li>Sentinel 是什么 ？主要能解决什么问题？</li>
<li>限流与熔断的使用场景</li>
<li>Sentinel 源码结构</li>
<li>在 IntelliJ IDEA 中运行 Sentine Demo</li>
</ul>
<p>其实第三点并不是特别必须，不过要得出这些结论也并不难，因为对 Sentinel 有了全局的认识后并根据各个模块的命名很容易能得出该模块的作用。这里第四点非常关键，通常一个优秀的开源框架都会提供完备的演示 Demo，大家可以看到 Sentinel 的演示 demo 非常丰富，在本文中我特意选择了 Dubbo 来做示例，主要是我们公司大量使用 dubbo 来实现公司的微服务，这样会更加贴近实战，更有利于寻找突破口。</p>
<p>通过跑通 Demo 的主要目的有三个：</p>
<ul>
<li>通过运行 Demo，了解框架的基本使用方法。</li>
<li>搭建一个可 Debug 的环境，为后续看不懂代码的情况下进行调试，根据运行时数据，可加快代码的理解速度，但千万不要一开始就 debug。</li>
<li>寻找源码阅读的入口。</li>
</ul>
<p>2、<a href="https://blog.csdn.net/prestigeding/article/details/103654590">源码分析 Sentinel 之 Dubbo 适配原理</a><br>紧跟第一篇文章，既然使用的是 Dubbo 作为其示例代码，自然而然的思考 Sentinel 是如何做到对 Dubbo 的适配并对业务无侵入性。</p>
<p>通过该篇文章的学习我们了解到可以通过 Dubbo 的扩展机制实现对 Dubbo 的适配，在 Dubbo Filter 中我们能看到了与 Sentinel 相关的核心 API SphU.entry，从而找到深入学习 Sentinel 的核心入口，也就是后续文章会通过对该方法的研究，从而打开进入 Sentinel 内核世界的大门。</p>
<blockquote>
<p>备注：在阅读这篇文章的时候，我觉得 Dubbo 的适配感觉非常简单，但随着我对这个系列的深入学习，发现了该方法没有那么简单，当时很多点都没有理解到位，这个在后续会有重点阐述，这也是不断学习、不断思考带来的好处。</p>
</blockquote>
<a id="more"></a>

<p>3、<a href="https://blog.csdn.net/prestigeding/article/details/103842382">寻找一把进入 Alibaba Sentinel 的钥匙</a><br>本文主要是详细跟踪 SphU.entry 方法的执行流程，从而揭晓其实现的关键点，果不其然，通过跟踪该方法的流程，找到了 Sentinel 的核心运作机制：Slot 处理链。<br><img src="https://img-blog.csdnimg.cn/20200530151308395.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>就问大家激不激动，开不开心，从这些 Slot 的名字基本就能得出其含义，后续的研究重点就是逐一解开这些 Slot 的实现原理即可。</p>
<p>4、<a href="https://blog.csdn.net/prestigeding/article/details/103943070">Sentinel 调用上下文环境实现原理</a><br>按照上述 Slot 的链，开始了 NodeSelectorSlot 的研究，通过学习了解到该 NodeSelectorSlot 主要是构建 Sentinel 的调用链，即调用上下文环境管理,准确的说是构建调用链的入口节点。在 Sentinel 中每进入一个资源都会有对应的节点实时存储该资源的调用信息。</p>
<p>5、Sentinel 实时数据采集原理<br>这个议题共两篇文章，其相关链接如下：</p>
<ul>
<li><a href="https://blog.csdn.net/prestigeding/article/details/104045216">实时采集数据详解</a></li>
<li><a href="https://blog.csdn.net/prestigeding/article/details/103753595">Sentinel 滑动窗口实现原理</a></li>
</ul>
<p>如果按照 Slot 链的执行顺序，下一个执行的 ClusterBuilderSlot，从名字就可以看出与集群限流相关的，但秉承着先简后难的学习策略，在当前先跳过该类的学习，先重点突破单机版限流，后续再回过头来学习集群限流相关的知识。</p>
<p>要实现限流、熔断等功能，首先要解决的问题是如何实时采集服务(资源)调用信息。例如将某一个接口设置的限流阔值 1W/tps，那首先如何判断当前的 TPS 是多少？Alibaba Sentinel 采用滑动窗口来实现实时数据的统计，实现类：StatisticSlot。</p>
<p>6、Sentinel 限流实现原理<br>在弄懂了 Sentinel 的实时数据采集原理后，限流实现就非常简单了，就是基于采集的调用信息，然后与限流规则进行比较，判断是否需要限流，Sentinel 在触发限流后还提供了多种处理策略，例如快速失败、匀速排队、预热等机制。</p>
<p>但我在学习限流的时候，我将限流核心逻辑与触发限流后的处理策略进行了分解，在学习限流的时候挑选了最简单处理策略(匀速排队)，将比较难的预热机制分解，再单起一篇文章进行学习，这样的拆解有利于保证学习单篇文章的用时，并提高自己的“产量”，提高自己的成就感。</p>
<p>这块主要包含如下4篇文章：</p>
<ul>
<li><a href="https://blog.csdn.net/prestigeding/article/details/104884255">Sentinel FlowSlot 限流实现原理</a></li>
<li><a href="https://blog.csdn.net/prestigeding/article/details/105027563"> RateLimiter SmoothBursty 实现原理</a></li>
<li><a href="https://blog.csdn.net/prestigeding/article/details/105180419">RateLimiter SmoothWarmingUp 实现原理</a></li>
<li><a href="https://blog.csdn.net/prestigeding/article/details/105341098">Sentinel 匀速排队与预热实现原理与实战建议</a></li>
</ul>
<p>这里还要重点阐述一下限流领域最核心的算法：漏桶算法、漏斗算法等，并且 Sentinel 的预热机制主要是参考 Guava 的实现，故这里花了点精力认真学习了 Guava 的 RateLimite 的实现原理。</p>
<p>7、<a href="https://blog.csdn.net/prestigeding/article/details/105470516">Sentinel DegradeSlot 熔断实现原理</a><br>限流部分学习完后，我就迫不及待的去探究熔断的实现，其实熔断本身并不复杂，和限流一样，无非就是根据当前的实时调用信息与熔断规则进行对比即可，如果满足熔断规则就抛出异常。如果只是熔断自身的实现本质确实简单，但要结合实际，其实有更多的问题需要思考，这个在后面的实战篇又是反复思考，从而发现 Sentinel 在熔断的实现上其实比较粗糙。</p>
<p>8、<a href="https://blog.csdn.net/prestigeding/article/details/105756877">Sentienl 动态数据源架构设计理念与改造实践</a><br>经过前面的文章，Sentinel 的单机限流与熔断已经基本学习了，这个时候就要开始思考如何使用 Sentinel 了，但 Sentinel 官方提供的后台运维管理系统的熔断、限流规则只能存储在内存，显然不能直接用于生产环境，故需要提出解决方案，本篇文章详细介绍了笔者是如何根据官方资料进行动态数据源配置的方法调研的，完成是按照工作中架构设计方案的标准来思考的，强烈推荐。</p>
<p>9、<a href="https://blog.csdn.net/prestigeding/article/details/106041456">Sentinel Dubbo 适配器看限流与熔断(实战思考篇)</a><br>支持了动态数据源，就继续进行思考，在微服务领域是如何思考引入熔断机制的，进行一番思考后发现官方提供的 Dubbo 适配器的粒度是服务级别的，无法控制机器级别，例如下图所示：<br><img src="https://img-blog.csdnimg.cn/2020053015244341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>例如当前的 Sentinel Dubbo 适配器目前不支持一个服务其中一台服务提供者变慢，发往这台机器上的请求被熔断，当前的实现版本会调用该服务的所有请求都会被熔断，故官方的 Dubbo 适配器还需要更加完善，有了自己的思考才会对知识理解更多，故通过学习源码，一定不能“尽信书”，要有自己的思考与怀疑能力，这样才能对开源社区做出一定的贡献，共同进步与成长。</p>
<p>以上就是我学习源码的方法，希望对大家真正有所帮助与感触。</p>
<p><strong>最后我再来谈一下回答关于源码阅读方面误区的几个问题。</strong></p>
<p><strong>1、看源码会忘记吗？为什么我们看源码的时候感觉看懂了，但很容易就忘记？</strong></p>
<p>我们要始终明白看<strong>源码只是手段</strong>，目的是要思考框架的设计原理、并通过源码了解实现细节并指导实践。重在思考。当然实现细节看过后容易忘记，但只要理解了思想，在需要使用时可以看自己写过的文章，一下子就能拾起来。</p>
<p><strong>2、看源码的时候是不是可以直接使用 Debug 进行调试学习</strong></p>
<p>我是<strong>强烈不建议</strong>这样做，这样会迷失在细节中无可自拔。正确的姿势是寻找入口，带上自己的思考去梳理，当遇到看不懂源码或是无法理解其思想时，这个时候可以借助 Debug，可以通过运行时可视化的数据，帮助我们更快的了解。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>源码阅读技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>KafkaProducer Sender 线程详解（含详细的执行流程图）</title>
    <url>/posts/80780dfa.html</url>
    <content><![CDATA[<div id="vip-container"><p>上文 <a href="https://blog.csdn.net/prestigeding/article/details/102994716">《源码分析 Kafka 消息发送流程》</a> 已经详细介绍了 KafkaProducer send 方法的流程，该方法只是将消息追加到 KafKaProducer 的缓存中，并未真正的向 broker 发送消息，本文将来探讨 Kafka 的 Sender 线程。</p>
<p>在 KafkaProducer 中会启动一个单独的线程，其名称为 “kafka-producer-network-thread | clientID”，其中 clientID 为生产者的 id 。</p>
<h2 id="1、Sender-线程详解"><a href="#1、Sender-线程详解" class="headerlink" title="1、Sender 线程详解"></a>1、Sender 线程详解</h2><h4 id="1-1-类图"><a href="#1-1-类图" class="headerlink" title="1.1 类图"></a>1.1 类图</h4><p><img src="https://img-blog.csdnimg.cn/20191117174420482.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们先来看一下其各个属性的含义：</p>
<ul>
<li>KafkaClient client<br>kafka 网络通信客户端，主要封装与 broker 的网络通信。</li>
<li>RecordAccumulator accumulator<br>消息记录累积器，消息追加的入口(RecordAccumulator 的 append 方法)。</li>
<li>Metadata metadata<br>元数据管理器，即 topic 的路由分区信息。</li>
<li>boolean guaranteeMessageOrder<br>是否需要保证消息的顺序性。</li>
<li>int maxRequestSize<br>调用 send 方法发送的最大请求大小，包括 key、消息体序列化后的消息总大小不能超过该值。通过参数 max.request.size 来设置。</li>
<li>short acks<br>用来定义消息“已提交”的条件(标准)，就是 Broker 端向客户端承偌已提交的条件，可选值如下0、-1、1.</li>
<li>int retries<br>重试次数。</li>
<li>Time time<br>时间工具类。</li>
<li>boolean running<br>该线程状态，为 true 表示运行中。</li>
<li>boolean forceClose<br>是否强制关闭，此时会忽略正在发送中的消息。</li>
<li>SenderMetrics sensors<br>消息发送相关的统计指标收集器。</li>
<li>int requestTimeoutMs<br>请求的超时时间。</li>
<li>long retryBackoffMs<br>请求失败之在重试之前等待的时间。</li>
<li>ApiVersions apiVersions<br>API版本信息。</li>
<li>TransactionManager transactionManager<br>事务处理器。</li>
<li>Map&lt; TopicPartition, List&lt; ProducerBatch&gt;&gt; inFlightBatches<br>正在执行发送相关的消息批次。</li>
</ul>
<a id="more"></a>

<h4 id="1-2-run-方法详解"><a href="#1-2-run-方法详解" class="headerlink" title="1.2 run 方法详解"></a>1.2 run 方法详解</h4><p>Sender#run</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    log.debug(<span class="string">&quot;Starting Kafka producer I/O thread.&quot;</span>);</span><br><span class="line">    <span class="keyword">while</span> (running) &#123;   </span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            runOnce();    <span class="comment">// @1</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;Uncaught error in kafka producer I/O thread: &quot;</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    log.debug(<span class="string">&quot;Beginning shutdown of Kafka producer I/O thread, sending remaining records.&quot;</span>);</span><br><span class="line">    <span class="keyword">while</span> (!forceClose &amp;&amp; (<span class="keyword">this</span>.accumulator.hasUndrained() || <span class="keyword">this</span>.client.inFlightRequestCount() &gt; <span class="number">0</span>)) &#123;    <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            runOnce();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;Uncaught error in kafka producer I/O thread: &quot;</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (forceClose) &#123;                                                                                                                                     <span class="comment">// @3</span></span><br><span class="line">        log.debug(<span class="string">&quot;Aborting incomplete batches due to forced shutdown&quot;</span>);</span><br><span class="line">        <span class="keyword">this</span>.accumulator.abortIncompleteBatches();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.client.close();                                                                                                                               <span class="comment">// @4</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        log.error(<span class="string">&quot;Failed to close network client&quot;</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">    log.debug(<span class="string">&quot;Shutdown of Kafka producer I/O thread has completed.&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：Sender 线程在运行状态下主要的业务处理方法，将消息缓存区中的消息向 broker 发送。<br>代码@2：如果主动关闭 Sender 线程，如果不是强制关闭，则如果缓存区还有消息待发送，再次调用 runOnce 方法将剩余的消息发送完毕后再退出。<br>代码@3：如果强制关闭 Sender 线程，则拒绝未完成提交的消息。<br>代码@4：关闭 Kafka Client 即网络通信对象。</p>
<p>接下来将分别探讨其上述方法的实现细节。</p>
<h5 id="1-2-1-runOnce-详解"><a href="#1-2-1-runOnce-详解" class="headerlink" title="1.2.1 runOnce 详解"></a>1.2.1 runOnce 详解</h5><p>Sender#runOnce</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">runOnce</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 此处省略与事务消息相关的逻辑</span></span><br><span class="line">    <span class="keyword">long</span> currentTimeMs = time.milliseconds();</span><br><span class="line">    <span class="keyword">long</span> pollTimeout = sendProducerData(currentTimeMs);   <span class="comment">// @1</span></span><br><span class="line">    client.poll(pollTimeout, currentTimeMs);                            <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>本文不关注事务消息的实现原理，故省略了该部分的代码。<br>代码@1：调用 sendProducerData 方法发送消息。<br>代码@2：调用这个方法的作用？</p>
<p>接下来分别对上述两个方法进行深入探究。</p>
<h6 id="1-1-2-1-sendProducerData"><a href="#1-1-2-1-sendProducerData" class="headerlink" title="1.1.2.1 sendProducerData"></a>1.1.2.1 sendProducerData</h6><p>接下来将详细分析其实现步骤。<br>Sender#sendProducerData</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Cluster cluster = metadata.fetch();</span><br><span class="line"><span class="comment">// get the list of partitions with data ready to send</span></span><br><span class="line">RecordAccumulator.ReadyCheckResult result = <span class="keyword">this</span>.accumulator.ready(cluster, now);</span><br></pre></td></tr></table></figure>
<p>Step1：首先根据当前时间，根据缓存队列中的数据判断哪些 topic 的 哪些分区已经达到发送条件。达到可发送的条件将在 2.1.1.1 节详细分析。</p>
<p>Sender#sendProducerData</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!result.unknownLeaderTopics.isEmpty()) &#123;</span><br><span class="line">    <span class="keyword">for</span> (String topic : result.unknownLeaderTopics)</span><br><span class="line">        <span class="keyword">this</span>.metadata.add(topic);</span><br><span class="line">    </span><br><span class="line">    log.debug(<span class="string">&quot;Requesting metadata update due to unknown leader topics from the batched records: &#123;&#125;&quot;</span>,</span><br><span class="line">                result.unknownLeaderTopics);</span><br><span class="line">    <span class="keyword">this</span>.metadata.requestUpdate();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：如果在待发送的消息未找到其路由信息，则需要首先去 broker 服务器拉取对应的路由信息(分区的 leader 节点信息)。</p>
<p>Sender#sendProducerData</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> notReadyTimeout = Long.MAX_VALUE;</span><br><span class="line"><span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">    Node node = iter.next();</span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">this</span>.client.ready(node, now)) &#123;</span><br><span class="line">        iter.remove();</span><br><span class="line">        notReadyTimeout = Math.min(notReadyTimeout, <span class="keyword">this</span>.client.pollDelayMs(node, now));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step3：移除在网络层面没有准备好的分区，并且计算在接下来多久的时间间隔内，该分区都将处于未准备状态。<br>1、在网络环节没有准备好的标准如下：</p>
<ul>
<li>分区没有未完成的更新元素数据请求(metadata)。</li>
<li>当前生产者与对端 broker 已建立连接并完成了 TCP 的三次握手。</li>
<li>如果启用 SSL、ACL 等机制，相关状态都已就绪。</li>
<li>该分区对应的连接正在处理中的请求数时是否超过设定值，默认为 5，可通过属性 max.in.flight.requests.per.connection 来设置。</li>
</ul>
<p>2、client pollDelayMs 预估分区在接下来多久的时间间隔内都将处于未转变好状态(not ready)，其标准如下：</p>
<ul>
<li>如果已与对端的 TCP 连接已创建好，并处于已连接状态，此时如果没有触发限流，则返回0，如果有触发限流，则返回限流等待时间。</li>
<li>如果还位于对端建立 TCP 连接，则返回 Long.MAX_VALUE，因为连接建立好后，会唤醒发送线程的。</li>
</ul>
<p>Sender#sendProducerData</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// create produce requests</span></span><br><span class="line">Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = <span class="keyword">this</span>.accumulator.drain(cluster, result.readyNodes, <span class="keyword">this</span>.maxRequestSize, now);</span><br></pre></td></tr></table></figure>
<p>Step4：根据已准备的分区，从缓存区中抽取待发送的消息批次(ProducerBatch)，并且按照 nodeId:List<ProducerBatch> 组织，注意，抽取后的 ProducerBatch 将不能再追加消息了，就算还有剩余空间可用，具体抽取将在下文在详细介绍。</p>
<p>Sender#sendProducerData</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">addToInflightBatches(batches);</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addToInflightBatches</span><span class="params">(Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (List&lt;ProducerBatch&gt; batchList : batches.values()) &#123;</span><br><span class="line">        addToInflightBatches(batchList);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addToInflightBatches</span><span class="params">(List&lt;ProducerBatch&gt; batches)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (ProducerBatch batch : batches) &#123;</span><br><span class="line">        List&lt;ProducerBatch&gt; inflightBatchList = inFlightBatches.get(batch.topicPartition);</span><br><span class="line">        <span class="keyword">if</span> (inflightBatchList == <span class="keyword">null</span>) &#123;</span><br><span class="line">            inflightBatchList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            inFlightBatches.put(batch.topicPartition, inflightBatchList);</span><br><span class="line">        &#125;</span><br><span class="line">        inflightBatchList.add(batch);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step5：将抽取的 ProducerBatch 加入到 inFlightBatches 数据结构，该属性的声明如下：Map&lt;TopicPartition, List&lt; ProducerBatch &gt;&gt; inFlightBatches，即按照 topic-分区 为键，存放已抽取的 ProducerBatch，这个属性的含义就是存储待发送的消息批次。可以根据该数据结构得知在消息发送时以分区为维度反馈 Sender 线程的“积压情况”，max.in.flight.requests.per.connection 就是来控制积压的最大数量，如果积压达到这个数值，针对该队列的消息发送会限流。</p>
<p>Sender#sendProducerData</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">accumulator.resetNextBatchExpiryTime();</span><br><span class="line">List&lt;ProducerBatch&gt; expiredInflightBatches = getExpiredInflightBatches(now);</span><br><span class="line">List&lt;ProducerBatch&gt; expiredBatches = <span class="keyword">this</span>.accumulator.expiredBatches(now);</span><br><span class="line">expiredBatches.addAll(expiredInflightBatches);</span><br></pre></td></tr></table></figure>
<p>Step6：从 inflightBatches 与 batches 中查找已过期的消息批次(ProducerBatch)，判断是否过期的标准是系统当前时间与 ProducerBatch 创建时间之差是否超过120s，过期时间可以通过参数 delivery.timeout.ms 设置。</p>
<p>Sender#sendProducerData</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!expiredBatches.isEmpty())</span><br><span class="line">    log.trace(<span class="string">&quot;Expired &#123;&#125; batches in accumulator&quot;</span>, expiredBatches.size());</span><br><span class="line"><span class="keyword">for</span> (ProducerBatch expiredBatch : expiredBatches) &#123;</span><br><span class="line">    String errorMessage = <span class="string">&quot;Expiring &quot;</span> + expiredBatch.recordCount + <span class="string">&quot; record(s) for &quot;</span> + expiredBatch.topicPartition</span><br><span class="line">                + <span class="string">&quot;:&quot;</span> + (now - expiredBatch.createdMs) + <span class="string">&quot; ms has passed since batch creation&quot;</span>;</span><br><span class="line">    failBatch(expiredBatch, -<span class="number">1</span>, NO_TIMESTAMP, <span class="keyword">new</span> TimeoutException(errorMessage), <span class="keyword">false</span>);</span><br><span class="line">    <span class="keyword">if</span> (transactionManager != <span class="keyword">null</span> &amp;&amp; expiredBatch.inRetry()) &#123;</span><br><span class="line">        <span class="comment">// This ensures that no new batches are drained until the current in flight batches are fully resolved.</span></span><br><span class="line">        transactionManager.markSequenceUnresolved(expiredBatch.topicPartition);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step7：处理已超时的消息批次，通知该批消息发送失败，即通过设置  KafkaProducer#send 方法返回的凭证中的 FutureRecordMetadata 中的 ProduceRequestResult result，使之调用其 get 方法不会阻塞。</p>
<p>Sender#sendProducerData</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">sensors.updateProduceRequestMetrics(batches);</span><br></pre></td></tr></table></figure>
<p>Step8：收集统计指标，本文不打算详细分析，但后续会专门对 Kafka 的 Metrics 设计进行一个深入的探讨与学习。</p>
<p>Sender#sendProducerData</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);</span><br><span class="line">pollTimeout = Math.min(pollTimeout, <span class="keyword">this</span>.accumulator.nextExpiryTimeMs() - now);</span><br><span class="line">pollTimeout = Math.max(pollTimeout, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">if</span> (!result.readyNodes.isEmpty()) &#123;</span><br><span class="line">    log.trace(<span class="string">&quot;Nodes with data ready to send: &#123;&#125;&quot;</span>, result.readyNodes);</span><br><span class="line">    pollTimeout = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step9：设置下一次的发送延时，待补充详细分析。</p>
<p>Sender#sendProducerData</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">sendProduceRequests(batches, now);</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sendProduceRequests</span><span class="params">(Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; collated, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;Integer, List&lt;ProducerBatch&gt;&gt; entry : collated.entrySet())</span><br><span class="line">        sendProduceRequest(now, entry.getKey(), acks, requestTimeoutMs, entry.getValue());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step10：该步骤按照 brokerId 分别构建发送请求，即每一个 broker 会将多个  ProducerBatch 一起封装成一个请求进行发送，同一时间，每一个 与 broker 连接只会只能发送一个请求，注意，这里只是构建请求，并最终会通过 NetworkClient#send 方法，将该批数据设置到 NetworkClient 的待发送数据中，此时并没有触发真正的网络调用。</p>
<p>sendProducerData 方法就介绍到这里了，既然这里还没有进行真正的网络请求，那在什么时候触发呢？</p>
<p>我们继续回到 runOnce 方法。</p>
<h6 id="1-2-1-2-NetworkClient-的-poll-方法"><a href="#1-2-1-2-NetworkClient-的-poll-方法" class="headerlink" title="1.2.1.2 NetworkClient 的 poll 方法"></a>1.2.1.2 NetworkClient 的 poll 方法</h6><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> <span class="function"><span class="keyword">public</span> List&lt;ClientResponse&gt; <span class="title">poll</span><span class="params">(<span class="keyword">long</span> timeout, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    ensureActive();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!abortedSends.isEmpty()) &#123;</span><br><span class="line">        <span class="comment">// If there are aborted sends because of unsupported version exceptions or disconnects,</span></span><br><span class="line">        <span class="comment">// handle them immediately without waiting for Selector#poll.</span></span><br><span class="line">        List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        handleAbortedSends(responses);</span><br><span class="line">        completeResponses(responses);</span><br><span class="line">        <span class="keyword">return</span> responses;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> metadataTimeout = metadataUpdater.maybeUpdate(now);   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.selector.poll(Utils.min(timeout, metadataTimeout, defaultRequestTimeoutMs));    <span class="comment">// @2</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        log.error(<span class="string">&quot;Unexpected error during I/O&quot;</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// process completed actions</span></span><br><span class="line">    <span class="keyword">long</span> updatedNow = <span class="keyword">this</span>.time.milliseconds();</span><br><span class="line">    List&lt;ClientResponse&gt; responses = <span class="keyword">new</span> ArrayList&lt;&gt;();            <span class="comment">// @3</span></span><br><span class="line">    handleCompletedSends(responses, updatedNow);</span><br><span class="line">    handleCompletedReceives(responses, updatedNow);</span><br><span class="line">    handleDisconnections(responses, updatedNow);</span><br><span class="line">    handleConnections();</span><br><span class="line">    handleInitiateApiVersionRequests(updatedNow);</span><br><span class="line">    handleTimedOutRequests(responses, updatedNow);</span><br><span class="line">    completeResponses(responses);                                               <span class="comment">// @4</span></span><br><span class="line">    <span class="keyword">return</span> responses;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>本文并不会详细深入探讨其网络实现部分，Kafka 的 网络通讯后续我会专门详细的介绍，在这里先点出其关键点。<br>代码@1：尝试更新云数据。<br>代码@2：触发真正的网络通讯，该方法中会通过收到调用 NIO 中的 Selector#select() 方法，对通道的读写就绪事件进行处理，当写事件就绪后，就会将通道中的消息发送到远端的 broker。<br>代码@3：然后会消息发送，消息接收、断开连接、API版本，超时等结果进行收集。<br>代码@4：并依次对结果进行唤醒，此时会将响应结果设置到  KafkaProducer#send 方法返回的凭证中，从而唤醒发送客户端，完成一次完整的消息发送流程。</p>
<p>Sender 发送线程的流程就介绍到这里了，接下来首先给出一张流程图，然后对上述流程中一些关键的方法再补充深入探讨一下。</p>
<h5 id="1-2-2-run-方法流程图"><a href="#1-2-2-run-方法流程图" class="headerlink" title="1.2.2 run 方法流程图"></a>1.2.2 run 方法流程图</h5><p><img src="https://img-blog.csdnimg.cn/20191117182748452.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>根据上面的源码分析得出上述流程图，图中对重点步骤也详细标注了其关键点。下面我们对上述流程图中 Sender 线程依赖的相关类的核心方法进行解读，以便加深 Sender 线程的理解。</p>
<p>由于在讲解 Sender 发送流程中，大部分都是调用 RecordAccumulator 方法来实现其特定逻辑，故接下来重点对上述涉及到RecordAccumulator 的方法进行一个详细剖析，加强对 Sender 流程的理解。</p>
<h2 id="2、RecordAccumulator-核心方法详解"><a href="#2、RecordAccumulator-核心方法详解" class="headerlink" title="2、RecordAccumulator 核心方法详解"></a>2、RecordAccumulator 核心方法详解</h2><h4 id="2-1-RecordAccumulator-的-ready-方法详解"><a href="#2-1-RecordAccumulator-的-ready-方法详解" class="headerlink" title="2.1 RecordAccumulator 的 ready 方法详解"></a>2.1 RecordAccumulator 的 ready 方法详解</h4><p>该方法主要就是根据缓存区中的消息，判断哪些分区已经达到发送条件。</p>
<p>RecordAccumulator#ready</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ReadyCheckResult <span class="title">ready</span><span class="params">(Cluster cluster, <span class="keyword">long</span> nowMs)</span> </span>&#123;</span><br><span class="line">    Set&lt;Node&gt; readyNodes = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">    <span class="keyword">long</span> nextReadyCheckDelayMs = Long.MAX_VALUE;</span><br><span class="line">    Set&lt;String&gt; unknownLeaderTopics = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">boolean</span> exhausted = <span class="keyword">this</span>.free.queued() &gt; <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt; entry : <span class="keyword">this</span>.batches.entrySet()) &#123;   <span class="comment">// @1</span></span><br><span class="line">        TopicPartition part = entry.getKey();</span><br><span class="line">        Deque&lt;ProducerBatch&gt; deque = entry.getValue();</span><br><span class="line"></span><br><span class="line">        Node leader = cluster.leaderFor(part);   <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">synchronized</span> (deque) &#123;</span><br><span class="line">            <span class="keyword">if</span> (leader == <span class="keyword">null</span> &amp;&amp; !deque.isEmpty()) &#123;   <span class="comment">// @3</span></span><br><span class="line">                <span class="comment">// This is a partition for which leader is not known, but messages are available to send.</span></span><br><span class="line">                <span class="comment">// Note that entries are currently not removed from batches when deque is empty.</span></span><br><span class="line">                unknownLeaderTopics.add(part.topic());</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!readyNodes.contains(leader) &amp;&amp; !isMuted(part, nowMs)) &#123;    <span class="comment">// @4</span></span><br><span class="line">                ProducerBatch batch = deque.peekFirst();</span><br><span class="line">                <span class="keyword">if</span> (batch != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">long</span> waitedTimeMs = batch.waitedTimeMs(nowMs);</span><br><span class="line">                    <span class="keyword">boolean</span> backingOff = batch.attempts() &gt; <span class="number">0</span> &amp;&amp; waitedTimeMs &lt; retryBackoffMs;</span><br><span class="line">                    <span class="keyword">long</span> timeToWaitMs = backingOff ? retryBackoffMs : lingerMs;</span><br><span class="line">                    <span class="keyword">boolean</span> full = deque.size() &gt; <span class="number">1</span> || batch.isFull();</span><br><span class="line">                    <span class="keyword">boolean</span> expired = waitedTimeMs &gt;= timeToWaitMs;</span><br><span class="line">                    <span class="keyword">boolean</span> sendable = full || expired || exhausted || closed || flushInProgress();</span><br><span class="line">                    <span class="keyword">if</span> (sendable &amp;&amp; !backingOff) &#123;   <span class="comment">// @5</span></span><br><span class="line">                        readyNodes.add(leader);</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="keyword">long</span> timeLeftMs = Math.max(timeToWaitMs - waitedTimeMs, <span class="number">0</span>);</span><br><span class="line">                        <span class="comment">// Note that this results in a conservative estimate since an un-sendable partition may have</span></span><br><span class="line">                        <span class="comment">// a leader that will later be found to have sendable data. However, this is good enough</span></span><br><span class="line">                        <span class="comment">// since we&#x27;ll just wake up and then sleep again for the remaining time.</span></span><br><span class="line">                        nextReadyCheckDelayMs = Math.min(timeLeftMs, nextReadyCheckDelayMs);   </span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ReadyCheckResult(readyNodes, nextReadyCheckDelayMs, unknownLeaderTopics);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：对生产者缓存区 ConcurrentHashMap&lt;TopicPartition, Deque&lt; ProducerBatch&gt;&gt; batches 遍历，从中挑选已准备好的消息批次。<br>代码@2：从生产者元数据缓存中尝试查找分区(TopicPartition) 的 leader 信息，如果不存在，当将该 topic 添加到 unknownLeaderTopics (代码@3)，稍后会发送元数据更新请求去 broker 端查找分区的路由信息。<br>代码@4：如果不在 readyNodes 中就需要判断是否满足条件，isMuted 与顺序消息有关，本文暂时不关注，在后面的顺序消息部分会重点探讨。<br>代码@5：这里就是判断是否准备好的条件，先一个一个来解读局部变量的含义。</p>
<ul>
<li>long waitedTimeMs<br>该 ProducerBatch 已等待的时长，等于当前时间戳 与 ProducerBatch 的 lastAttemptMs 之差，在 ProducerBatch 创建时或需要重试时会将当前的时间赋值给lastAttemptMs。</li>
<li>retryBackoffMs<br>当发生异常时发起重试之前的等待时间，默认为 100ms，可通过属性 retry.backoff.ms 配置。</li>
<li>batch.attempts()<br>该批次当前已重试的次数。</li>
<li>backingOff<br>后台发送是否关闭，即如果需要重试并且等待时间小于 retryBackoffMs ，则 backingOff = true，也意味着该批次未准备好。</li>
<li>timeToWaitMs<br>send 线程发送消息需要的等待时间，如果 backingOff  为 true，表示该批次是在重试，并且等待时间小于系统设置的需要等待时间，这种情况下 timeToWaitMs = retryBackoffMs 。否则需要等待的时间为 lingerMs。</li>
<li>boolean full<br>该批次是否已满，如果两个条件中的任意一个满足即为 true。<ul>
<li>Deque&lt; ProducerBatch&gt; 该队列的个数大于1，表示肯定有一个 ProducerBatch 已写满。 </li>
<li>ProducerBatch 已写满。</li>
</ul>
</li>
<li>boolean expired<br>是否过期，等于已经等待的时间是否大于需要等待的时间，如果把发送看成定时发送的话，expired 为 true 表示定时器已到达触发点，即需要执行。</li>
<li>boolean exhausted<br>当前生产者缓存已不够，创建新的 ProducerBatch 时阻塞在申请缓存空间的线程大于0，此时应立即将缓存区中的消息立即发送到服务器。</li>
<li>boolean sendable<br>是否可发送。其满足下面的任意一个条件即可：<ul>
<li>   该批次已写满。(full = true)。</li>
<li>   已等待系统规定的时长。（expired = true）</li>
<li>   发送者内部缓存区已耗尽并且有新的线程需要申请(exhausted = true)。</li>
<li>   该发送者的 close 方法被调用(close = true)。</li>
<li>   该发送者的 flush 方法被调用。</li>
</ul>
</li>
</ul>
<h4 id="2-2-RecordAccumulator-的-drain方法详解"><a href="#2-2-RecordAccumulator-的-drain方法详解" class="headerlink" title="2.2 RecordAccumulator 的 drain方法详解"></a>2.2 RecordAccumulator 的 drain方法详解</h4><p>RecordAccumulator#drain</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; drain(Cluster cluster, Set&lt;Node&gt; nodes, <span class="keyword">int</span> maxSize, <span class="keyword">long</span> now) &#123; <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (nodes.isEmpty())</span><br><span class="line">        <span class="keyword">return</span> Collections.emptyMap();</span><br><span class="line"></span><br><span class="line">    Map&lt;Integer, List&lt;ProducerBatch&gt;&gt; batches = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (Node node : nodes) &#123;                                                                                                                              </span><br><span class="line">        List&lt;ProducerBatch&gt; ready = drainBatchesForOneNode(cluster, node, maxSize, now);                      <span class="comment">// @2</span></span><br><span class="line">        batches.put(node.id(), ready);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> batches;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：我们首先来介绍该方法的参数：</p>
<ul>
<li>Cluster cluster<br>集群信息。</li>
<li>Set&lt; Node&gt; nodes<br>已准备好的节点集合。</li>
<li>int maxSize<br>一次请求最大的字节数。</li>
<li>long now<br>当前时间。</li>
</ul>
<p>代码@2：遍历所有节点，调用 drainBatchesForOneNode 方法抽取数据，组装成 Map&lt;Integer /** brokerId */, List&lt; ProducerBatch&gt;&gt; batches。</p>
<p>接下来重点来看一下 drainBatchesForOneNode。<br>RecordAccumulator#drainBatchesForOneNode</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> List&lt;ProducerBatch&gt; <span class="title">drainBatchesForOneNode</span><span class="params">(Cluster cluster, Node node, <span class="keyword">int</span> maxSize, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> size = <span class="number">0</span>;</span><br><span class="line">    List&lt;PartitionInfo&gt; parts = cluster.partitionsForNode(node.id());   <span class="comment">// @1</span></span><br><span class="line">    List&lt;ProducerBatch&gt; ready = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    <span class="keyword">int</span> start = drainIndex = drainIndex % parts.size();                        <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">do</span> &#123;                                                                                                <span class="comment">// @3 </span></span><br><span class="line">        PartitionInfo part = parts.get(drainIndex);</span><br><span class="line">        TopicPartition tp = <span class="keyword">new</span> TopicPartition(part.topic(), part.partition()); </span><br><span class="line">        <span class="keyword">this</span>.drainIndex = (<span class="keyword">this</span>.drainIndex + <span class="number">1</span>) % parts.size();                     </span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> (isMuted(tp, now))</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">        Deque&lt;ProducerBatch&gt; deque = getDeque(tp);                              <span class="comment">// @4</span></span><br><span class="line">        <span class="keyword">if</span> (deque == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">synchronized</span> (deque) &#123;</span><br><span class="line">            <span class="comment">// invariant: !isMuted(tp,now) &amp;&amp; deque != null</span></span><br><span class="line">            ProducerBatch first = deque.peekFirst();                                         <span class="comment">// @5</span></span><br><span class="line">            <span class="keyword">if</span> (first == <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// first != null</span></span><br><span class="line">            <span class="keyword">boolean</span> backoff = first.attempts() &gt; <span class="number">0</span> &amp;&amp; first.waitedTimeMs(now) &lt; retryBackoffMs;   <span class="comment">// @6</span></span><br><span class="line">            <span class="comment">// Only drain the batch if it is not during backoff period.</span></span><br><span class="line">            <span class="keyword">if</span> (backoff)                                                                                     </span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (size + first.estimatedSizeInBytes() &gt; maxSize &amp;&amp; !ready.isEmpty()) &#123;     <span class="comment">// @7</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (shouldStopDrainBatchesForPartition(first, tp))                                  </span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 这里省略与事务消息相关的代码，后续会重点学习。</span></span><br><span class="line">                batch.close();                                                                                            <span class="comment">// @8</span></span><br><span class="line">                size += batch.records().sizeInBytes();</span><br><span class="line">                ready.add(batch);                                                                            </span><br><span class="line"></span><br><span class="line">                batch.drained(now);                                                                             </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span> (start != drainIndex);</span><br><span class="line">    <span class="keyword">return</span> ready;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：根据 brokerId 获取该 broker 上的所有主分区。<br>代码@2：初始化 start。这里首先来阐述一下 start 与 drainIndex 。</p>
<ul>
<li>start 当前开始遍历的分区序号。</li>
<li>drainIndex 上次抽取的队列索引后，这里主要是为了每个队列都是从零号分区开始抽取。</li>
</ul>
<p>代码@3：循环从缓存区抽取对应分区中累积的数据。<br>代码@4：根据 topic + 分区号从生产者发送缓存区中获取已累积的双端Queue。<br>代码@5：从双端队列的头部获取一个元素。（消息追加时是追加到队列尾部）。<br>代码@6：如果当前批次是重试，并且还未到阻塞时间，则跳过该分区。<br>代码@7：如果当前已抽取的消息总大小 加上新的消息已超过 maxRequestSize，则结束抽取。<br>代码@8：将当前批次加入到已准备集合中，并关闭该批次，即不在允许向该批次中追加消息。</p>
<p>关于消息发送就介绍到这里，NetworkClient 的 poll 方法内部会调用 Selector 执行就绪事件的选择，并将抽取的消息通过网络发送到 Broker 服务器，关于网络后面的具体实现，将在后续文章中单独介绍。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>源码</tag>
        <tag>Sender</tag>
      </tags>
  </entry>
  <entry>
    <title>Lambda表达式语法与函数式编程接口</title>
    <url>/posts/26a08b7d.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、lambda语法初探"><a href="#1、lambda语法初探" class="headerlink" title="1、lambda语法初探"></a>1、lambda语法初探</h2><p>java8 lambda表达式语法的两种格式：</p>
<ul>
<li>(parameters)  -&gt;  expression</li>
<li>(parameters) -&gt; {statements;}</li>
</ul>
<p>语法解读：</p>
<ol>
<li>(parameters)，lambda表达式的参数列表，其定义方法为JAVA普通的方法相同，例如(Object a, Object b)。</li>
<li>-&gt; 箭头，是参数列表与lambda表达式主题部分的分隔符号。</li>
<li>expression 单表达式</li>
<li>{statements; } 语句。</li>
</ol>
<p>测试：如下语句是否是正确的lambda表达式。<br>(1)  () -&gt; {}<br>(2)  () -&gt; “Raoul”<br>(3)  () -&gt; {return “Mario”;}<br>(4)  (Integer i) -&gt; return “Alan” + i;<br>(5)  (String s) -&gt; {“IronMan”;}</p>
<p>正解：<br>(1) 正确。如果使用匿名类(接口名统一使用IDemoLambda)表示如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> new IDemoLambda() &#123;</span><br><span class="line">     public void test() &#123;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>(2)正确。如果使用匿名类(接口名统一使用IDemoLambda)表示如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> new IDemoLambda() &#123;</span><br><span class="line">     public String test() &#123;</span><br><span class="line">           return &quot;Raoul&quot;;  &#x2F;&#x2F; 如果直接接一个值，表示返回该值</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>(3)正确。如果使用匿名类(接口名统一使用IDemoLambda)表示如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> new IDemoLambda() &#123;</span><br><span class="line">     public String test() &#123;</span><br><span class="line">          return &quot;Mario&quot;;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>(4)错误。因为return是流程控制语句，表示返回，不是一个表达式，故不符合lambda语法，正确的表示方法应该是 (Integer i) -&gt;{ return “Alan” + i;}。如果使用匿名类(接口名统一使用IDemoLambda)表示如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> new IDemoLambda() &#123;</span><br><span class="line">     public String test(Integer i) &#123;</span><br><span class="line">          return &quot;Alan&quot; + i;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>(5)错误。因为”IronMan”是一个表达式，并不是一个语句，故不能使用{}修饰，应修改为 (String s) -&gt; “IronMan”。如果使用匿名类(接口名统一使用IDemoLambda)表示如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> new IDemoLambda() &#123;</span><br><span class="line">     public String test(String s) &#123;</span><br><span class="line">          return &quot;IronMan&quot;;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="2、初步接触函数式接口"><a href="#2、初步接触函数式接口" class="headerlink" title="2、初步接触函数式接口"></a>2、初步接触函数式接口</h2><p>在java8中，一个接口如果只定义了一个抽象方法，那这个接口就可以称为函数式接口，就可以使用lambda表达式来简化程序代码。Lambda表达式可以直接赋值给变量，也可以直接作为参数传递给函数，示例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void startThread(Runnable a) &#123;</span><br><span class="line">    (new Thread(a)).start();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">    &#x2F;&#x2F; lambda表达式可以直接赋值给变量，也可以直接以参数的形式传递给方法、</span><br><span class="line">    Runnable a &#x3D; () -&gt; &#123;</span><br><span class="line">        System.out.println(&quot;Hello World,Lambda...&quot;);</span><br><span class="line">    &#125;;</span><br><span class="line">    &#x2F;&#x2F; JDK8之前使用匿名类来实现</span><br><span class="line">    Runnable b &#x3D; new Runnable() &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public void run() &#123;</span><br><span class="line">            System.out.println(&quot;Hello World,Lambda...&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    startThread(a);</span><br><span class="line">    startThread(() -&gt; &#123;</span><br><span class="line">        System.out.println(&quot;Hello World,Lambda...&quot;);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那能将(int a) -&gt; {System.out.println(“Hello World, Lambda…”);}表达式赋值给Runnable a变量吗？答案是不能，因为该表达式不符合函数式编程接口(Runnable)唯一抽象方法的函数签名列表。<br>Runnable的函数式签名列表为public abstract void run();</p>
<blockquote>
<p>温馨提示：如果我们有留意JDK8的Runnable接口的定义，你会发现给接口相对JDK8之前的版本多了一个注解：@FunctionalInterface，该注解是一个标识注解，用来标识这个接口是一个函数式接口。如果我们人为在一个不满足函数式定义的接口上增加@FunctionalInterface，则会在编译时提示错误。</p>
</blockquote>
<a id="more"></a>

<h2 id="3、-Lambda表达式实战思考"><a href="#3、-Lambda表达式实战思考" class="headerlink" title="3、 Lambda表达式实战思考"></a>3、 Lambda表达式实战思考</h2><p>例如有如下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 处理文件：当前需求是处理文件的第一行数据</span><br><span class="line"> * @return</span><br><span class="line"> * @throws IOException</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static String processFile() throws IOException &#123;</span><br><span class="line">    try(BufferedReader br &#x3D; new BufferedReader(new FileReader(&quot;data.txt&quot;))) &#123;</span><br><span class="line">        return  br.readLine();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当前需求为处理文件的第一行数据，那问题来了，如果需求变化需要返回文件的第一行和第二行数据，那该如何进行改造呢？<br>在理想的情况下，需要重用执行设置和关闭流的代码，并告诉processFile()方法对文件执行不同的操作，换句话说就是要实现对processFile的行为进行参数化。</p>
<p>Step·1：行为参数化<br>要读取文件的头两行，用Lambda语法如何实现呢？思考一下，下面这条语句是否可以实现？</p>
<p>(BufferedReader bf) -&gt; br.readLine() + br.readLine()<br>答案是当然可以，接下来就要思考，定义一个什么样的方法，能接收上面这个参数。</p>
<p>Step2：使用函数式接口来传递行为<br>要使用(bufferedReader bf) -&gt; br.readLine() + br.readLine()，则需要定义一个接受参数为BufferedReader，并返回String类型的函数式接口。<br>定义如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@FunctionalInterface</span><br><span class="line">public interface BufferedReaderProcessor &#123;</span><br><span class="line">     public String process(BufferedReader b) throws IoException;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>那把processFile方法改造成如下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 处理文件：当前需求是处理文件的第一行数据</span><br><span class="line"> * @return</span><br><span class="line"> * @throws IOException</span><br><span class="line"> *&#x2F;</span><br><span class="line">public static String processFile(BufferedReaderProcess brp) throws IOException &#123;</span><br><span class="line">    try(BufferedReader br &#x3D; new BufferedReader(new FileReader(&quot;data.txt&quot;))) &#123;</span><br><span class="line">        return  brp.process(br);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step3：使用lambda表达式作为参数进行传递<br>将行为参数化后，并对方法进行改造，使方法接受一个函数式编程接口后，就可以将Lambda表达式直接传递给方法，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">processFile(  (BufferedReader br)  -&gt; br.readLine()  );</span><br><span class="line">processFile( (BufferedReader bf) -&gt; br.readLine() + br.readLine()); </span><br></pre></td></tr></table></figure>

<h2 id="4、Java8中自定义函数式接口"><a href="#4、Java8中自定义函数式接口" class="headerlink" title="4、Java8中自定义函数式接口"></a>4、Java8中自定义函数式接口</h2><p>从上面的讲解中我们已然能够得知，要能够将Lambda表达式当成方法参数进行参数行为化的一个前提条件是首先要在方法列表中使用一个函数式接口，例如上例中的BufferReaderProcess，那如果每次使用Labmbda表达式之前都要定义各自的函数式编程接口，那也够麻烦的，那有没有一种方式，或定义一种通用的函数式编程接口呢？答案是肯定的，Java8的设计者，利用泛型，定义了一整套函数式编程接口，下面将介绍java8中常用的函数式编程接口。</p>
<h4 id="4-1-Predicate"><a href="#4-1-Predicate" class="headerlink" title="4.1 Predicate"></a>4.1 Predicate</h4><p><img src="https://img-blog.csdnimg.cn/20190512222228610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>所谓函数式编程接口就是只能定义一个抽象方法，Predicate 函数接口中定义的抽象方法为 boolean test(T t)，对应的函数式行为为接收一类对象 t，返回 boolean 类型，其可用的 lambda 表达式为 (T t) -&gt; boolean 类型的表达式，例如(Sample a) -&gt; a.isEmpty() 。</p>
<p>该接口通常的应用场景为过滤。例如，要定义一个方法，从集合中进行刷选，具体的刷选逻辑（行为）由参数进行指定，那我们可以定义这样一个刷选的方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static &lt;T&gt; List&lt;T&gt; filter(List&lt;T&gt; list, Predicate&lt;T&gt; p) &#123;</span><br><span class="line">List&lt;T&gt; results &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">for(T s: list)&#123;</span><br><span class="line">if(p.test(s))&#123;</span><br><span class="line">results.add(s);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">return results;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述函数，我们可以这样进行调用：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Predicate&lt;String&gt; behaviorFilter &#x3D; (String s) -&gt; !s.isEmpty();  &#x2F;&#x2F; lambda表达式赋值给一个变量</span><br><span class="line">filter(behaviorFilter);  </span><br></pre></td></tr></table></figure>
<p>其它add等方法，将在下文介绍（复合lambda表达式）。</p>
<p>另外，为了避免java基本类型与包装类型的装箱与拆箱带来的性能损耗，JDK8的设计者们提供了如下函数式编程接口：IntPredicate、LongPredicate、DoublePredicate。我们选择LongPredicate看一下其函数接口的声明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boolean test(long value);</span><br></pre></td></tr></table></figure>

<h4 id="4-2-Consumer"><a href="#4-2-Consumer" class="headerlink" title="4.2 Consumer"></a>4.2 Consumer</h4><p><img src="https://img-blog.csdnimg.cn/20190512222420653.png" alt="在这里插入图片描述"><br>该函数式编程接口适合对对象进行处理，但没有返回值,对应的函数描述符：T -&gt; void</p>
<p>举例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static &lt;T&gt; void forEach(List&lt;T&gt; list, Consumer&lt;T&gt; c) &#123;</span><br><span class="line">    for(T t : list) &#123;</span><br><span class="line">        c.accept(t);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其调用示例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">forEach(  Arrays.asList(1,2,3,4,5),   (Integer i) -&gt; System.out.println(i) ); </span><br></pre></td></tr></table></figure>
<p>另外，为了避免java基本类型与包装类型的装箱与拆箱带来的性能损耗，JDK8的设计者们提供了如下函数式编程接口：IntConsumer、LongConsumer、DoubleConsumer。</p>
<h4 id="4-3-Function-lt-T-R-gt"><a href="#4-3-Function-lt-T-R-gt" class="headerlink" title="4.3 Function&lt;T,R&gt;"></a>4.3 Function&lt;T,R&gt;</h4><p><img src="https://img-blog.csdnimg.cn/20190512222646904.png" alt="在这里插入图片描述"><br>其适合的场景是，接收一个泛型T的对象，返回一个泛型为R的对象，其对应的函数描述符:  T -&gt; R。</p>
<p>示例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static &lt;T,R&gt; List&lt;R&gt; map(List&lt;T&gt; list, Function&lt;T,R&gt; f) &#123;</span><br><span class="line">          List&lt;R&gt; result &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">          for(T t : list) &#123;</span><br><span class="line">                result.add(  f.apply(t) );</span><br><span class="line">          &#125;</span><br><span class="line">          return result;</span><br><span class="line">&#125;</span><br><span class="line">List&lt;Integer&gt; l &#x3D; map(Arrays.asList(&quot;lambdas&quot;, &quot;in&quot;, &quot;action&quot;),  (String s)  -&gt; s.length  );</span><br></pre></td></tr></table></figure>
<p>另外，为了避免java基本类型与包装类型的装箱与拆箱带来的性能损耗，JDK8的设计者们提供了如下函数式编程接口：IntFunction&lt; R&gt;、LongFunction&lt; R&gt;、DoubleFunction&lt; R&gt;、IntToDoubleFunction、IntToLongFunction、LongToIntFunction、LongToDoubleFunction、ToIntFunction&lt; T&gt;、ToDoubleFunction&lt; T&gt;、ToLongFunction&lt; T&gt;。</p>
<h4 id="4-4-Supplier-lt-T-gt"><a href="#4-4-Supplier-lt-T-gt" class="headerlink" title="4.4 Supplier&lt; T&gt;"></a>4.4 Supplier&lt; T&gt;</h4><p><img src="https://img-blog.csdnimg.cn/20190512222740390.png" alt="在这里插入图片描述"><br>函数描述符：() -&gt; T。适合创建对象的场景，例如  () -&gt; new Object();</p>
<p>另外，为了避免java基本类型与包装类型的装箱与拆箱带来的性能损耗，JDK8的设计者们提供了如下函数式编程接口：BooleanSupplier、IntSupplier、LongSupplier、DoubleSupplier。</p>
<h4 id="4-5-UnaryOperator-lt-T-gt"><a href="#4-5-UnaryOperator-lt-T-gt" class="headerlink" title="4.5 UnaryOperator&lt; T &gt;"></a>4.5 UnaryOperator&lt; T &gt;</h4><p><img src="https://img-blog.csdnimg.cn/20190512222814465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>一元运算符函数式接口，接收一个泛型T的对象，同样返回一个泛型T的对象。<br>示例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static &lt;T&gt; List&lt;T&gt; map(List&lt;T&gt; list, UnaryOperator&lt;T&gt; f) &#123;</span><br><span class="line">          List&lt;R&gt; result &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">          for(T t : list) &#123;</span><br><span class="line">                result.add(  f.apply(t) );</span><br><span class="line">          &#125;</span><br><span class="line">          return result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">map(  list, (int i) -&gt; i ++ );</span><br></pre></td></tr></table></figure>

<p>另外，为了避免java基本类型与包装类型的装箱与拆箱带来的性能损耗，JDK8的设计者们提供了如下函数式编程接口：IntUnaryOperator、LongUnaryOperator、DoubleUnaryOperator。</p>
<h4 id="4-6-BiPredicate-lt-T-U-gt"><a href="#4-6-BiPredicate-lt-T-U-gt" class="headerlink" title="4.6 BiPredicate&lt;T,U&gt;"></a>4.6 BiPredicate&lt;T,U&gt;</h4><p><img src="https://img-blog.csdnimg.cn/20190512222852671.png" alt="在这里插入图片描述"><br>接收两个参数，返回boolean类型。其对应的函数描述符：(T,U) -&gt; boolean。</p>
<h4 id="4-7-BiConsumer-lt-T-U-gt"><a href="#4-7-BiConsumer-lt-T-U-gt" class="headerlink" title="4.7 BiConsumer&lt;T,U&gt;"></a>4.7 BiConsumer&lt;T,U&gt;</h4><p><img src="https://img-blog.csdnimg.cn/20190512222914785.png" alt="在这里插入图片描述"><br>与Consume函数式接口类似，只是该接口接收两个参数，对应的函数描述符(T,U)  -&gt; void。</p>
<p>另外，为了避免java基本类型与包装类型的装箱与拆箱带来的性能损耗，JDK8的设计者们提供了如下函数式编程接口：ObjIntConsumer、ObjLongConsumer、ObjDoubleConsumer。</p>
<h4 id="4-8-BiFunction-lt-T-U-R-gt"><a href="#4-8-BiFunction-lt-T-U-R-gt" class="headerlink" title="4.8 BiFunction&lt;T,U,R&gt;"></a>4.8 BiFunction&lt;T,U,R&gt;</h4><p><img src="https://img-blog.csdnimg.cn/20190512222939113.png" alt="在这里插入图片描述"><br>与Function函数式接口类似，其对应的函数描述符：(T,U) -&gt; R。</p>
<p>另外，为了避免java基本类型与包装类型的装箱与拆箱带来的性能损耗，JDK8的设计者们提供了如下函数式编程接口：ToIntBiFunction(T,U)、ToLongBiFunction(T,U)、ToDoubleBiFunction(T,U)。</p>
<h4 id="4-9-BinaryOperator-lt-T-gt"><a href="#4-9-BinaryOperator-lt-T-gt" class="headerlink" title="4.9 BinaryOperator&lt; T &gt;"></a>4.9 BinaryOperator&lt; T &gt;</h4><p><img src="https://img-blog.csdnimg.cn/20190512223009303.png" alt="在这里插入图片描述"><br>二维运算符，接收两个T类型的对象，返回一个T类型的对象。</p>
<p>另外，为了避免java基本类型与包装类型的装箱与拆箱带来的性能损耗，JDK8的设计者们提供了如下函数式编程接口：IntBinaryOperator、LongBinaryOperator、DoubleBinaryOperator。</p>
<p>上述就是JDK8定义在java.util.function中的函数式编程接口。重点关注的是其定义的函数式编程接口，其复合操作相关的API将在下文中详细介绍。</p>
<h2 id="5、类型检查、类型推断以及限制"><a href="#5、类型检查、类型推断以及限制" class="headerlink" title="5、类型检查、类型推断以及限制"></a>5、类型检查、类型推断以及限制</h2><h4 id="5-1-类型检查"><a href="#5-1-类型检查" class="headerlink" title="5.1 类型检查"></a>5.1 类型检查</h4><p>java8是如何检查传入的Lambda表示式是否符合约定的类型呢？<br>例如</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static &lt;T&gt; List&lt;T&gt; filter(List&lt;T&gt; list, Predicate&lt;T&gt; p) &#123;</span><br><span class="line">    List&lt;T&gt; results &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">    for(T s: list)&#123;</span><br><span class="line">        if(p.test(s))&#123;</span><br><span class="line">            results.add(s);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   return results;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">List&lt;Apple&gt; heavierThan150g &#x3D; filter(inventory, (Apple a) -&gt; a.getWeight() &gt; 150);</span><br></pre></td></tr></table></figure>
<p>其类型检测的步骤：<br>1）首先查看filter函数的参数列表，得出Lambda对应的参数类型为Predicate&lt; T &gt;。<br>2）函数式接口Predicate中定义的抽象接口为  boolean test(T t),对应的函数描述符(  T  -&gt;  boolean)。<br>3）验证Lambda表达式是否符合函数描述符。</p>
<p>注意：如果一个Lambda的主体式一个语句表达式，它就和一个返回void的函数描述符兼容（当然参数列表也必须兼容）。例如，以下两行都是合法的，尽管List的add方法返回一个boolean，而不式Consumer上下文(T -&gt; void)所要求的void：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; Predicate返回了一个boolean</span><br><span class="line">Predicate&lt;String&gt; p &#x3D; s -&gt; list.add(s);</span><br><span class="line">&#x2F;&#x2F; Consumer返回了一个void</span><br><span class="line">Consumer&lt;String&gt; b &#x3D; s -&gt; list.add(s);</span><br></pre></td></tr></table></figure>
<p>思考题：如下表达式是否正确？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Object o &#x3D; () -&gt; &#123;System.out.println(&quot;Tricky example&quot;); &#125;;</span><br></pre></td></tr></table></figure>
<p>答案是错误的，该语句的含义就是把lambda表达式复制给目标对象(Object o)，lambda对应的函数描述符为() -&gt; void，期望目标对象拥有一个唯一的抽象方法，参数列表为空，返回值为void的方法，显然目标对象Object不满足该条件，如果换成如下示例，则能编译通过：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Runnable r &#x3D; () &#123;System.out.println(&quot;Tricky example&quot;); &#125;;</span><br></pre></td></tr></table></figure>
<p>因为Runnable的定义如下：<br><img src="https://img-blog.csdnimg.cn/20190512223153712.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h4 id="5-2-类型推断"><a href="#5-2-类型推断" class="headerlink" title="5.2 类型推断"></a>5.2 类型推断</h4><p>所谓的类型推断，指的式java编译器能根据目标类型来推断出用什么函数式接口来配合Lambda表达式，这也意味着它也可以推断出适合Lambda的签名，因为函数描述符可以通过目标类型得到。</p>
<p>例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">List&lt;Apple&gt; greenApples &#x3D;  filter(inventory, （Apple a） -&gt; &quot;green&quot;.equals(a.getColor()));</span><br><span class="line">也可以写成</span><br><span class="line">List&lt;Apple&gt; greenApples &#x3D;  filter(inventory, a  -&gt; &quot;green&quot;.equals(a.getColor()));</span><br><span class="line"></span><br><span class="line">Lambda表达式有多个参数，代码可读性的好处就更为明显。例如，你可以这样来创建一个Comparator 对象：</span><br><span class="line">Comparator&lt;Apple&gt; c &#x3D;  (Apple a1, Apple a2) -&gt; a1.getWeight().compareTo(a2.getWeight());</span><br><span class="line">Comparator&lt;Apple&gt; c &#x3D; (a1, a2) -&gt; a1.getWeight().compareTo(a2.getWeight());</span><br></pre></td></tr></table></figure>
<p>由于java编译器能根据目标类型来推导出Lambda的函数签名，故lambda的函数签名列表时，可以去掉参数的类型。</p>
<h4 id="5-3-局部变量"><a href="#5-3-局部变量" class="headerlink" title="5.3 局部变量"></a>5.3 局部变量</h4><p>Lambda表达式主体部分也能引入外部的变量，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int portNumber &#x3D; 1337;</span><br><span class="line">Runnable r &#x3D; () -&gt; System.out.println(portNumber);</span><br></pre></td></tr></table></figure>
<p>其中portNumber参数并不是方法签名参数，但这样有一个限制条件，引入的局部变量必须是常量（实际意义上的常量，可以不用final来定义，但不能改变其值。例如如下示例是错误的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int portNumber &#x3D; 1337;</span><br><span class="line">Runnable r &#x3D; () -&gt; System.out.println(portNumber);</span><br><span class="line">portNumber &#x3D; 1228;  &#x2F;&#x2F; 因为portNumber的值已改变，不符合局部变量的捕获条件，上述代码无法编译通过。</span><br></pre></td></tr></table></figure>
<h4 id="5-4-方法引用"><a href="#5-4-方法引用" class="headerlink" title="5.4 方法引用"></a>5.4 方法引用</h4><h5 id="5-4-1-方法引用常用的构造方法"><a href="#5-4-1-方法引用常用的构造方法" class="headerlink" title="5.4.1 方法引用常用的构造方法"></a>5.4.1 方法引用常用的构造方法</h5><p>JDK8中有3中方法引用：</p>
<ol>
<li>指向静态方法的方法引用<br>Integer.parseInt  对应的方法引用可以写成： Integer::parseInt。</li>
<li>指向任意类型的实例方法的引用<br>  (Strng str ) -&gt; str.length  对应的方法引用：String::length。(注意这里的属性为方法列表)</li>
<li>lambda捕获外部的实例对象<br>例如如下代码：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Apple a &#x3D; new Apple();</span><br><span class="line">process(  () -&gt; a.getColor()  );  &#x2F;&#x2F; 则可以写成  process ( a::getColor ); </span><br></pre></td></tr></table></figure>
<h5 id="5-4-2-构造函数引用"><a href="#5-4-2-构造函数引用" class="headerlink" title="5.4.2 构造函数引用"></a>5.4.2 构造函数引用</h5><p>大家可以回想一下，jdk8中定义了一个创建对象的函数式编程接口Supplier,函数描述符：() -&gt; T。适合创建对象的场景，例如  () -&gt; new Object();<br>对于没有构造函数的，我们可以这样来创建对象：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Supplier&lt;Apple&gt; c1 &#x3D; Apple:new;</span><br><span class="line">Apple a1 &#x3D; c1.get();</span><br></pre></td></tr></table></figure>
<p>如果有1个参数的构造方法呢？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Function&lt;Integer, Apple&gt; c2 &#x3D; Apple::new;</span><br><span class="line">Apple a2 &#x3D; c2.apply(weight);</span><br></pre></td></tr></table></figure>
<p>Lambda语法的基础知识就介绍到这里，本文详细介绍了Lambda表达式的语法格式、函数式编程接口、lambda与函数式编程接口的关系、方法引用。</p>
<p>下一节主要介绍复合Lambda表达式使用。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>java8</category>
      </categories>
      <tags>
        <tag>java8</tag>
        <tag>Lambda</tag>
        <tag>函数式编程</tag>
      </tags>
  </entry>
  <entry>
    <title>Mybatis一二级缓存实现原理与使用指南</title>
    <url>/posts/36b32da.html</url>
    <content><![CDATA[<div id="vip-container"><p>Mybatis 与 Hibernate 一样，支持一二级缓存。一级缓存指的是 Session 级别的缓存，即在一个会话中多次执行同一条 SQL 语句并且参数相同，则后面的查询将不会发送到数据库，直接从 Session 缓存中获取。二级缓存，指的是 SessionFactory 级别的缓存，即不同的会话可以共享。</p>
<p>缓存，通常涉及到缓存的写、读、过期(更新缓存)等几个方面，请带着这些问题一起来探究Mybatis关于缓存的实现原理吧。</p>
<blockquote>
<p>提出问题：缓存的查询顺序，是先查一级缓存还是二级缓存？</p>
</blockquote>
<p>本文以SQL查询与更新两个流程来揭开Mybatis缓存实现的细节。</p>
<h2 id="1、从-SQL-查询流程看一二级缓存"><a href="#1、从-SQL-查询流程看一二级缓存" class="headerlink" title="1、从 SQL 查询流程看一二级缓存"></a>1、从 SQL 查询流程看一二级缓存</h2><blockquote>
<p>温馨提示，本文不会详细介绍详细的 SQL 执行流程，如果对其感兴趣，可以查阅笔者的另外一篇文章：<a href="https://blog.csdn.net/prestigeding/article/details/90647674">源码分析Mybatis SQL执行流程</a></p>
</blockquote>
<h3 id="1-1-创建Executor"><a href="#1-1-创建Executor" class="headerlink" title="1.1 创建Executor"></a>1.1 创建Executor</h3><p>Configuration#newExecutor</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Executor <span class="title">newExecutor</span><span class="params">(Transaction transaction, ExecutorType executorType)</span> </span>&#123;</span><br><span class="line">	executorType = executorType == <span class="keyword">null</span> ? defaultExecutorType : executorType;</span><br><span class="line">    executorType = executorType == <span class="keyword">null</span> ? ExecutorType.SIMPLE : executorType;</span><br><span class="line">    Executor executor;</span><br><span class="line">    <span class="keyword">if</span> (ExecutorType.BATCH == executorType) &#123;</span><br><span class="line">      executor = <span class="keyword">new</span> BatchExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ExecutorType.REUSE == executorType) &#123;</span><br><span class="line">      executor = <span class="keyword">new</span> ReuseExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      executor = <span class="keyword">new</span> SimpleExecutor(<span class="keyword">this</span>, transaction);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (cacheEnabled) &#123;                                                           <span class="comment">// @1</span></span><br><span class="line">      executor = <span class="keyword">new</span> CachingExecutor(executor);                 <span class="comment">// @2</span></span><br><span class="line">    &#125;</span><br><span class="line">    executor = (Executor) interceptorChain.pluginAll(executor);</span><br><span class="line">    <span class="keyword">return</span> executor;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果 cacheEnabled 为 true，表示开启缓存机制，缓存的实现类为 CachingExecutor，这里使用了经典的装饰模式，处理了缓存的相关逻辑后，委托给的具体的 Executor 执行。</p>
<p>cacheEnable 在实际的使用中通过在 mybatis-config.xml 文件中指定，例如：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">settings</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">setting</span> <span class="attr">name</span>=<span class="string">&quot;cacheEnabled&quot;</span> <span class="attr">value</span>=<span class="string">&quot;true&quot;</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">settings</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>该值默认为true。</p>
<h3 id="1-2-CachingExecutor-query"><a href="#1-2-CachingExecutor-query" class="headerlink" title="1.2 CachingExecutor#query"></a>1.2 CachingExecutor#query</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">query</span><span class="params">(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    BoundSql boundSql = ms.getBoundSql(parameterObject);  <span class="comment">// @1</span></span><br><span class="line">    CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql);   <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">return</span> query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);       <span class="comment">// @3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：根据参数生成SQL语句。</p>
<p>代码@2：根据 MappedStatement、参数、分页参数、SQL 生成缓存 Key。</p>
<p>代码@3：调用6个参数的 query 方法。</p>
<p>缓存 Key 的创建比较简单，本文就只贴出代码，大家一目了然,大家重点关注组成缓存Key的要素。<br>BaseExecute#createCacheKey</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CacheKey <span class="title">createCacheKey</span><span class="params">(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (closed) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> ExecutorException(<span class="string">&quot;Executor was closed.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  CacheKey cacheKey = <span class="keyword">new</span> CacheKey();</span><br><span class="line">  cacheKey.update(ms.getId());</span><br><span class="line">  cacheKey.update(rowBounds.getOffset());</span><br><span class="line">  cacheKey.update(rowBounds.getLimit());</span><br><span class="line">  cacheKey.update(boundSql.getSql());</span><br><span class="line">  List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings();</span><br><span class="line">  TypeHandlerRegistry typeHandlerRegistry = ms.getConfiguration().getTypeHandlerRegistry();</span><br><span class="line">  <span class="comment">// mimic DefaultParameterHandler logic</span></span><br><span class="line">  <span class="keyword">for</span> (ParameterMapping parameterMapping : parameterMappings) &#123;</span><br><span class="line">    <span class="keyword">if</span> (parameterMapping.getMode() != ParameterMode.OUT) &#123;</span><br><span class="line">      Object value;</span><br><span class="line">      String propertyName = parameterMapping.getProperty();</span><br><span class="line">      <span class="keyword">if</span> (boundSql.hasAdditionalParameter(propertyName)) &#123;</span><br><span class="line">        value = boundSql.getAdditionalParameter(propertyName);</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (parameterObject == <span class="keyword">null</span>) &#123;</span><br><span class="line">        value = <span class="keyword">null</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123;</span><br><span class="line">        value = parameterObject;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        MetaObject metaObject = configuration.newMetaObject(parameterObject);</span><br><span class="line">        value = metaObject.getValue(propertyName);</span><br><span class="line">      &#125;</span><br><span class="line">      cacheKey.update(value);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (configuration.getEnvironment() != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// issue #176</span></span><br><span class="line">    cacheKey.update(configuration.getEnvironment().getId());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> cacheKey;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来重点看CachingExecutor的另外一个query方法。</p>
<p>CachingExecutor#query</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">query</span><span class="params">(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)</span></span></span><br><span class="line"><span class="function">      <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    Cache cache = ms.getCache();    <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (cache != <span class="keyword">null</span>) &#123;</span><br><span class="line">      flushCacheIfRequired(ms);        <span class="comment">// @2</span></span><br><span class="line">      <span class="keyword">if</span> (ms.isUseCache() &amp;&amp; resultHandler == <span class="keyword">null</span>) &#123;</span><br><span class="line">        ensureNoOutParams(ms, boundSql);</span><br><span class="line">        <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">        List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key);      <span class="comment">// @3</span></span><br><span class="line">        <span class="keyword">if</span> (list == <span class="keyword">null</span>) &#123;                                                              <span class="comment">// @4</span></span><br><span class="line">          list = delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);    <span class="comment">//@5</span></span><br><span class="line">          tcm.putObject(cache, key, list); <span class="comment">// issue #578 and #116                                                               // @6</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> list;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);  <span class="comment">//@7</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：获取 MappedStatement 中的 Cache cache 属性。<br>代码@2：如果不为空，则尝试从缓存中获取，否则直接委托给具体的执行器执行，例如 SimpleExecutor (@7)。<br>代码@3：尝试从缓存中根据缓存 Key 查找。<br>代码@4：如果从缓存中获取的值不为空，则直接返回缓存中的值，否则先从数据库查询@5，将查询结果更新到缓存中。</p>
<p>这里的缓存即 MappedStatement 中的 Cache 对象是一级缓存还是二级缓存？通常在 ORM 类框架中，Session 级别的缓存为一级缓存，即会话结束后就会失效，显然这里不会随着 Session 的失效而失效，因为 Cache 对象是存储在于 MappedStatement 对象中的，每一个 MappedStatement 对象代表一个 Dao(Mapper) 中的一个方法，即代表一条对应的 SQL 语句，是一个全局的概念。</p>
<p>相信大家也会觉得，想继续深入了解 CachingExecutor 中使用的 Cache 是一级缓存还是二级缓存，了解 Cache 对象的创建至关重要。关于 MappedStatement 的创建流程，建议查阅笔者的另外一篇博文：<a href="https://blog.csdn.net/prestigeding/article/details/90488395">源码分析Mybatis MappedStatement的创建流程</a>。</p>
<p>本文只会关注 MappedStatement 对象流程中关于于缓存相关的部分。</p>
<p>接下来将按照先二级缓存，再一级缓存的思路进行讲解。</p>
<h4 id="1-2-1-二级缓存"><a href="#1-2-1-二级缓存" class="headerlink" title="1.2.1 二级缓存"></a>1.2.1 二级缓存</h4><h5 id="1-2-1-1-MappedStatement-cache属性创建机制"><a href="#1-2-1-1-MappedStatement-cache属性创建机制" class="headerlink" title="1.2.1.1 MappedStatement#cache属性创建机制"></a>1.2.1.1 MappedStatement#cache属性创建机制</h5><p>从上面看，如果 cacheEnable 为 true 并且 MappedStatement 对象的 cache 属性不为空，则能使用二级缓存。</p>
<p>我们可以看到 MappedStatement 对象的 cache 属性赋值的地方为：MapperBuilderAssistant#addMappedStatement，从该方法的调用链可以得知是在解析 Mapper 定义的时候就会创建。<br><img src="https://img-blog.csdnimg.cn/20190826205429651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>使用的 cache 属性为 MapperBuilderAssistant 的 currentCache,我们跟踪一下该属性的赋值方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Cache <span class="title">useCacheRef</span><span class="params">(String namespace)</span></span></span><br></pre></td></tr></table></figure>
<p>其调用链如下：<br><img src="https://img-blog.csdnimg.cn/2019082620552683.png" alt="在这里插入图片描述"><br>可以看出是在解析 cacheRef 标签，即在解析 Mapper.xml 文件中的 cacheRef 标签时，即二级缓存的使用和 cacheRef 标签离不开关系，并且特别注意一点，其参数为 namespace，即每一个 namespace 对应一个 Cache 对象，在 Mybatis 的方法中，通常namespace 对一个 Mapper.java 对象，对应对数据库一张表的更新、新增操作。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> Cache useNewCache</span><br></pre></td></tr></table></figure>
<p>其调用链如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190826205659301.png" alt="在这里插入图片描述">在解析 Mapper.xml 文件中的 cache 标签时被调用。</p>
<h5 id="1-2-1-2-cache标签解析"><a href="#1-2-1-2-cache标签解析" class="headerlink" title="1.2.1.2 cache标签解析"></a>1.2.1.2 cache标签解析</h5><p>接下来我们根据 cache 标签简单看一下 cache 标签的解析，下面以 xml 配置方式为例展开，基于注解的解析，其原理类似，其代码 XMLMapperBuilder 的 cacheElement 方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">cacheElement</span><span class="params">(XNode context)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (context != <span class="keyword">null</span>) &#123;</span><br><span class="line">      String type = context.getStringAttribute(<span class="string">&quot;type&quot;</span>, <span class="string">&quot;PERPETUAL&quot;</span>);                                                      </span><br><span class="line">      Class&lt;? extends Cache&gt; typeClass = typeAliasRegistry.resolveAlias(type);</span><br><span class="line">      String eviction = context.getStringAttribute(<span class="string">&quot;eviction&quot;</span>, <span class="string">&quot;LRU&quot;</span>);</span><br><span class="line">      Class&lt;? extends Cache&gt; evictionClass = typeAliasRegistry.resolveAlias(eviction);</span><br><span class="line">      Long flushInterval = context.getLongAttribute(<span class="string">&quot;flushInterval&quot;</span>);</span><br><span class="line">      Integer size = context.getIntAttribute(<span class="string">&quot;size&quot;</span>);</span><br><span class="line">      <span class="keyword">boolean</span> readWrite = !context.getBooleanAttribute(<span class="string">&quot;readOnly&quot;</span>, <span class="keyword">false</span>);</span><br><span class="line">      <span class="keyword">boolean</span> blocking = context.getBooleanAttribute(<span class="string">&quot;blocking&quot;</span>, <span class="keyword">false</span>);</span><br><span class="line">      Properties props = context.getChildrenAsProperties();</span><br><span class="line">      builderAssistant.useNewCache(typeClass, evictionClass, flushInterval, size, readWrite, blocking, props);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>从上面 cache 标签的核心属性如下：</p>
<ul>
<li>type<br>缓存实现类，可选择值：PERPETUAL、LRU 等，Mybatis 中所有的缓存实现类如下：<br><img src="https://img-blog.csdnimg.cn/2019082620593518.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li>
<li>eviction<br>移除算法，默认为 LRU。</li>
<li>flushInterval<br>缓存过期时间。</li>
<li>size<br>缓存在内存中的缓存个数。</li>
<li>readOnly<br>是否是只读。</li>
<li>blocking<br>是否阻塞，具体实现请看 BlockingCache。</li>
</ul>
<h5 id="1-2-1-3-cacheRef"><a href="#1-2-1-3-cacheRef" class="headerlink" title="1.2.1.3 cacheRef"></a>1.2.1.3 cacheRef</h5><p><img src="https://img-blog.csdnimg.cn/20190826210042752.png" alt="在这里插入图片描述"><br>cacheRef 只有一个属性，就是 namespace，就是引用其他 namespace 中的 cache。</p>
<p>Cache 的创建流程就讲解到这里，同一个 Namespace 只会定义一个 Cache。二级缓存的创建是在 *Mapper.xml 文件中使用了&lt; cache/&gt;、&lt; cacheRef/&gt;标签时创建，并且会按 NameSpace 为维度，为各个 MapperStatement 传入它所属的 Namespace 的二级缓存对象。</p>
<p>二级缓存的查询逻辑就介绍到这里了，我们再次回成 CacheingExecutor 的查询方法：<br>CachingExecutor#query</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">query</span><span class="params">(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)</span></span></span><br><span class="line"><span class="function">      <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    Cache cache = ms.getCache();    <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (cache != <span class="keyword">null</span>) &#123;</span><br><span class="line">      flushCacheIfRequired(ms);        <span class="comment">// @2</span></span><br><span class="line">      <span class="keyword">if</span> (ms.isUseCache() &amp;&amp; resultHandler == <span class="keyword">null</span>) &#123;</span><br><span class="line">        ensureNoOutParams(ms, boundSql);</span><br><span class="line">        <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">        List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key);      <span class="comment">// @3</span></span><br><span class="line">        <span class="keyword">if</span> (list == <span class="keyword">null</span>) &#123;                                                              <span class="comment">// @4</span></span><br><span class="line">          list = delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);    <span class="comment">//@5</span></span><br><span class="line">          tcm.putObject(cache, key, list); <span class="comment">// issue #578 and #116                                                               // @6</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> list;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);  <span class="comment">//@7</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果 MappedStatement 的 cache 属性为空，则直接调用内部的 Executor 的查询方法。也就时如果在 *.Mapper.xm l文件中未定义&lt; cache/&gt;或&lt; cacheRef/&gt;，则 cache 属性会为空。</p>
<h4 id="1-2-2-一级缓存"><a href="#1-2-2-一级缓存" class="headerlink" title="1.2.2 一级缓存"></a>1.2.2 一级缓存</h4><p>Mybatis 根据 SQL 的类型共有如下3种 Executor类型，分别是 SIMPLE,  REUSE, BATCH，本文将以 SimpleExecutor为 例来对一级缓存的介绍。</p>
<p>BaseExecutor#query</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">query</span><span class="params">(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    ErrorContext.instance().resource(ms.getResource()).activity(<span class="string">&quot;executing a query&quot;</span>).object(ms.getId());</span><br><span class="line">    <span class="keyword">if</span> (closed) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> ExecutorException(<span class="string">&quot;Executor was closed.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (queryStack == <span class="number">0</span> &amp;&amp; ms.isFlushCacheRequired()) &#123;   <span class="comment">// @1</span></span><br><span class="line">      clearLocalCache();</span><br><span class="line">    &#125;</span><br><span class="line">    List&lt;E&gt; list;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      queryStack++;                                                              </span><br><span class="line">      list = resultHandler == <span class="keyword">null</span> ? (List&lt;E&gt;) localCache.getObject(key) : <span class="keyword">null</span>;     <span class="comment">// @2</span></span><br><span class="line">      <span class="keyword">if</span> (list != <span class="keyword">null</span>) &#123;</span><br><span class="line">        handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);   <span class="comment">// @3</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      queryStack--;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (queryStack == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (DeferredLoad deferredLoad : deferredLoads) &#123;</span><br><span class="line">        deferredLoad.load();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// issue #601</span></span><br><span class="line">      deferredLoads.clear();</span><br><span class="line">      <span class="keyword">if</span> (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123;</span><br><span class="line">        <span class="comment">// issue #482</span></span><br><span class="line">        clearLocalCache();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> list;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：queryStack：查询栈，每次查询之前，加一，查询返回结果后减一，如果为1，表示整个会会话中没有执行的查询语句，并根据 MappedStatement 是否需要执行清除缓存，如果是查询类的请求，无需清除缓存，如果是更新类操作的MappedStatemt，每次执行之前都需要清除缓存。<br>代码@2：如果缓存中存在，直接返回缓存中的数据。<br>代码@3：如果缓存未命中，则调用 queryFromDatabase 从数据中查询。</p>
<p>我们顺便看一下 queryFromDatabase 方法，再来看一下一级缓存的实现类。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">queryFromDatabase</span><span class="params">(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">   List&lt;E&gt; list;</span><br><span class="line">   localCache.putObject(key, EXECUTION_PLACEHOLDER);   <span class="comment">//@!</span></span><br><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">     list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql);   <span class="comment">// @2</span></span><br><span class="line">   &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">     localCache.removeObject(key);                                                            <span class="comment">// @3</span></span><br><span class="line">   &#125;</span><br><span class="line">   localCache.putObject(key, list);                                                              <span class="comment">// @4</span></span><br><span class="line">   <span class="keyword">if</span> (ms.getStatementType() == StatementType.CALLABLE) &#123;</span><br><span class="line">     localOutputParameterCache.putObject(key, parameter);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> list;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：先往本地遍历存储一个厂里，表示正在执行中。<br>代码@2：从数据中查询数据。<br>代码@3：先移除正在执行中的标记。<br>代码@4：将数据库中的值存储到一级缓存中。</p>
<p>可以看出一级缓存的属性为 localCache，为 Executor 的属性。如果大家看过笔者发布的这个 Mybatis 系列就能轻易得出一个结论，每一个 SQL 会话对应一个 SqlSession 对象，每一个 SqlSession 会对应一个 Executor 对象，故 Executor 级别的缓存即为Session 级别的缓存，即为 Mybatis 的一级缓存。</p>
<p>上面已经介绍了一二级缓存的查找与添加，在查询的时候，首先查询缓存，如果缓存未命中，则查询数据库，然后将查询到的结果存入缓存中。</p>
<p>下面我们来简单看看缓存的更新。</p>
<h2 id="2、从SQL更新流程看一二级缓存"><a href="#2、从SQL更新流程看一二级缓存" class="headerlink" title="2、从SQL更新流程看一二级缓存"></a>2、从SQL更新流程看一二级缓存</h2><p>从更新的角度，更加的是关注缓存的更新，即当数据发生变化后，如果清除对应的缓存。</p>
<a id="more"></a>

<h3 id="2-1-二级缓存"><a href="#2-1-二级缓存" class="headerlink" title="2.1 二级缓存"></a>2.1 二级缓存</h3><p>CachingExecutor#update</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">update</span><span class="params">(MappedStatement ms, Object parameterObject)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    flushCacheIfRequired(ms);    <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span> delegate.update(ms, parameterObject);  <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果有必要则刷新缓存。<br>代码@2：调用内部的 Executor，例如 SimpleExecutor。</p>
<p>接下来重点看一下 flushCacheIfRequired 方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">flushCacheIfRequired</span><span class="params">(MappedStatement ms)</span> </span>&#123;</span><br><span class="line">    Cache cache = ms.getCache();</span><br><span class="line">    <span class="keyword">if</span> (cache != <span class="keyword">null</span> &amp;&amp; ms.isFlushCacheRequired()) &#123;      </span><br><span class="line">      tcm.clear(cache);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TransactionalCacheManager#clear</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">(Cache cache)</span> </span>&#123;</span><br><span class="line">    getTransactionalCache(cache).clear();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>TransactionalCacheManager 事务缓存管理器，其实就是对 MappedStatement 的 cache 属性进行装饰，最终调用的还是MappedStatement 的 getCache 方法得到其缓存对象然后调用 clear 方法，清空所有的缓存，即缓存的更新策略是只要namespace 的任何一条插入或更新语句执行，整个 namespace 的缓存数据将全部清空。</p>
<h3 id="2-2-一级缓存的更新"><a href="#2-2-一级缓存的更新" class="headerlink" title="2.2 一级缓存的更新"></a>2.2 一级缓存的更新</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">update</span><span class="params">(MappedStatement ms, Object parameter)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">  ErrorContext.instance().resource(ms.getResource()).activity(<span class="string">&quot;executing an update&quot;</span>).object(ms.getId());</span><br><span class="line">  <span class="keyword">if</span> (closed) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> ExecutorException(<span class="string">&quot;Executor was closed.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  clearLocalCache();</span><br><span class="line">  <span class="keyword">return</span> doUpdate(ms, parameter);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其更新策略与二级缓存维护的一样。</p>
<p>一二级缓存的的新增、查询、更新就介绍到这里了，接下来对其进行一个总结。</p>
<h2 id="3、总结"><a href="#3、总结" class="headerlink" title="3、总结"></a>3、总结</h2><h3 id="3-1-一二级缓存作用序列图"><a href="#3-1-一二级缓存作用序列图" class="headerlink" title="3.1 一二级缓存作用序列图"></a>3.1 一二级缓存作用序列图</h3><p>Mybatis 一二级缓存时序图如下：<br><img src="https://img-blog.csdnimg.cn/20190826210834511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="3-2-如何使用二级缓存"><a href="#3-2-如何使用二级缓存" class="headerlink" title="3.2 如何使用二级缓存"></a>3.2 如何使用二级缓存</h3><p>1、在mybatis-config.xml中将cacheEnable设置为true。例如：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">settings</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">setting</span> <span class="attr">name</span>=<span class="string">&quot;cacheEnabled&quot;</span> <span class="attr">value</span>=<span class="string">&quot;true&quot;</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">settings</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>不过该值默认为true。</p>
<p>2、在需要缓存的表操作，对应的 Dao 的配置文件中，例如 *Mapper.xml 文件中使用 cache、或 cacheRef 标签来定义缓存。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">mapper</span> <span class="meta-keyword">PUBLIC</span> <span class="meta-string">&quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;</span> <span class="meta-string">&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;</span> &gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mapper</span> <span class="attr">namespace</span>=<span class="string">&quot;com.winterchen.dao.UserDao&quot;</span> &gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">insert</span> <span class="attr">id</span>=<span class="string">&quot;insert&quot;</span> <span class="attr">parameterType</span>=<span class="string">&quot;com.winterchen.model.UserDomain&quot;</span>&gt;</span></span><br><span class="line">    //省略</span><br><span class="line">  <span class="tag">&lt;/<span class="name">insert</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;selectUsers&quot;</span> <span class="attr">resultType</span>=<span class="string">&quot;com.winterchen.model.UserDomain&quot;</span>&gt;</span></span><br><span class="line">      //省略</span><br><span class="line">  <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">cache</span> <span class="attr">type</span>=<span class="string">&quot;lru&quot;</span> <span class="attr">readOnly</span>=<span class="string">&quot;true&quot;</span> <span class="attr">flushInterval</span>=<span class="string">&quot;3600000&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">cache</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mapper</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>这样就定义了一个 Cache，其 namespace 为 com.winterchen.dao.UserDao。其中 flushInterval 定义该 cache 定时清除的时间间隔，单位为 ms。</p>
<p>如果一个表的更新操作、新增操作位于不同的 Mapper.xml 文件中，如果对一个表的操作的 Cache 定义在不同的文件，则缓存数据则会出现不一致的情况，因为 Cache 的更新逻辑是，在一个 Namespace 中，如果有更新、插入语句的执行，则会清除该 namespace 对应的 cache 里面的所有缓存。那怎么来处理这种场景呢？cacheRef 闪亮登场。</p>
<p>如果一个 Mapper.xml 文件需要引入定义在别的 Mapper.xml 文件中定义的 cache,则使用 cacheRef，示例如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">cacheRef</span> &quot;<span class="attr">namespace</span>&quot; = <span class="string">&quot;com.winterchen.dao.UserDao&quot;</span>/&gt;</span></span><br></pre></td></tr></table></figure>

<p>一级缓存默认是开启的，也无法关闭。</p>
<p>缓存的介绍就介绍到这里。如果本文对您有所帮助，麻烦点一下赞，谢谢。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
        <tag>一级缓存</tag>
        <tag>二级缓存</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ 消息发送system busy、broker busy原因分析与解决方案</title>
    <url>/posts/be0ab616.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、现象"><a href="#1、现象" class="headerlink" title="1、现象"></a>1、现象</h2><p>最近收到很多RocketMQ使用者，反馈生产环境中在消息发送过程中偶尔会出现如下4个错误信息之一：<br>1）[REJECTREQUEST]system busy, start flow control for a while<br>2）too many requests and system thread pool busy, RejectedExecutionException<br>3）[PC_SYNCHRONIZED]broker busy, start flow control for a while<br>4）[PCBUSY_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: %sms, size of queue: %d</p>
<h2 id="2、原理解读"><a href="#2、原理解读" class="headerlink" title="2、原理解读"></a>2、原理解读</h2><p>在进行消息中间件的选型时，如果待选中间件在功能上、性能上都能满足业务的情况下，建议把中间件的实现语言这个因素也考虑进去，毕竟选择一门用自己擅长的语言实现的中间件会更具掌控性。在出现异常的情况下，我们可以根据自己的经验提取错误信息关键字system busy，在RocketMQ源码中直接搜索，得到抛出上述错误信息的代码如下：<br><img src="https://img-blog.csdnimg.cn/20190618213541816.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其代码入口为：org.apache.rocketmq.remoting.netty.NettyRemotingAbstract#processRequestCommand。从图中可以看出，抛出上述错误的关键原因是：pair.getObject1().rejectRequest()和抛出RejectedExecutionException异常。</p>
<blockquote>
<p>备注：本文偏实战，源码只是作为分析的重点证据，故本文只会点出关键源码，并不会详细跟踪其整个实现流程，如果想详细了解其实现，可以查阅笔者编著的《RocketMQ技术内幕》。</p>
</blockquote>
<h3 id="2-1-RocketMQ-网络处理机制概述"><a href="#2-1-RocketMQ-网络处理机制概述" class="headerlink" title="2.1 RocketMQ 网络处理机制概述"></a>2.1 RocketMQ 网络处理机制概述</h3><p>RocketMQ的网络设计非常值得我们学习与借鉴，首先在客户端端将不同的请求定义不同的请求命令CODE，服务端会将客户端请求进行分类，每个命令或每类请求命令定义一个处理器(NettyRequestProcessor)，然后每一个NettyRequestProcessor绑定到一个单独的线程池，进行命令处理，不同类型的请求将使用不同的线程池进行处理，实现线程隔离。</p>
<a id="more"></a>

<p>为了方便下文的描述，我们先简单的认识一下NettyRequestProcessor、Pair、RequestCode。其核心关键点如下：<br><img src="https://img-blog.csdnimg.cn/20190618213801293.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ol>
<li>NettyRequestProcessor<br>RocketMQ 服务端请求处理器，例如SendMessageProcessor是消息发送处理器、PullMessageProcessor是消息拉取命令处理器。</li>
<li>RequestCode<br>请求CODE，用来区分请求的类型，例如SEND_MESSAGE：表示该请求为消息发送，PULL_MESSAGE:消息拉取请求。</li>
<li>Pair<br>用来封装NettyRequestProcessor与ExecuteService的绑定关系。在RocketMQ的网络处理模型中，会为每一个NettyRequestProcessor与特定的线程池绑定，所有该NettyRequestProcessor的处理逻辑都在该线程池中运行。</li>
</ol>
<h3 id="2-2-pair-getObject1-rejectRequest"><a href="#2-2-pair-getObject1-rejectRequest" class="headerlink" title="2.2 pair.getObject1().rejectRequest()"></a>2.2 pair.getObject1().rejectRequest()</h3><p>由于读者朋友提出的问题，都是发生在消息发送过程中，故本文重点关注SendMessageProcessor#rejectRequest方法。<br>SendMessageProcessor#rejectRequest</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">rejectRequest</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.brokerController.getMessageStore().isOSPageCacheBusy() ||               <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">this</span>.brokerController.getMessageStore().isTransientStorePoolDeficient();        <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>拒绝请求的条件有两个，只要其中任意一个满足，则返回true。</p>
<p>代码@1：Os PageCache busy，判断操作系统PageCache是否繁忙，如果忙，则返回true。想必看到这里大家肯定与我一样好奇，RocketMQ是如何判断pageCache是否繁忙呢？下面会重点分析。</p>
<p>代码@2：transientStorePool是否不足。</p>
<h4 id="2-2-1-isOSPageCacheBusy"><a href="#2-2-1-isOSPageCacheBusy" class="headerlink" title="2.2.1 isOSPageCacheBusy()"></a>2.2.1 isOSPageCacheBusy()</h4><p>DefaultMessageStore#isOSPageCacheBusy()</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isOSPageCacheBusy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> begin = <span class="keyword">this</span>.getCommitLog().getBeginTimeInLock();  <span class="comment">// @1 start</span></span><br><span class="line">    <span class="keyword">long</span> diff = <span class="keyword">this</span>.systemClock.now() - begin;                         <span class="comment">// @1  end</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> diff &lt; <span class="number">10000000</span></span><br><span class="line">                &amp;&amp; diff &gt; <span class="keyword">this</span>.messageStoreConfig.getOsPageCacheBusyTimeOutMills();     <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：先重点解释begin、diff两个局部变量的含义：</p>
<ul>
<li>begin<br>通俗的一点讲，就是将消息写入Commitlog文件所持有锁的时间，精确说是将消息体追加到内存映射文件(DirectByteBuffer)或pageCache(FileChannel#map)该过程中开始持有锁的时间戳，具体的代码请参考：CommitLog#putMessage。</li>
<li>diff<br>一次消息追加过程中持有锁的总时长，即往内存映射文件或pageCache追加一条消息所耗时间。</li>
</ul>
<p>代码@2：如果一次消息追加过程的时间超过了Broker配置文件osPageCacheBusyTimeOutMills，则认为pageCache繁忙，osPageCacheBusyTimeOutMills默认值为1000，表示1s。</p>
<h4 id="2-2-2-isTransientStorePoolDeficient"><a href="#2-2-2-isTransientStorePoolDeficient" class="headerlink" title="2.2.2 isTransientStorePoolDeficient()"></a>2.2.2 isTransientStorePoolDeficient()</h4><p>DefaultMessageStore#isTransientStorePoolDeficient</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isTransientStorePoolDeficient</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> remainTransientStoreBufferNumbs() == <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">remainTransientStoreBufferNumbs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.transientStorePool.remainBufferNumbs();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终调用TransientStorePool#remainBufferNumbs方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">remainBufferNumbs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (storeConfig.isTransientStorePoolEnable()) &#123;</span><br><span class="line">            <span class="keyword">return</span> availableBuffers.size();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Integer.MAX_VALUE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果启用transientStorePoolEnable机制，返回当前可用的ByteBuffer个数，即整个isTransientStorePoolDeficient方法的用意是是否还存在可用的ByteBuffer，如果不存在，即表示pageCache繁忙。那什么是transientStorePoolEnable机制呢？</p>
<h3 id="2-3-漫谈transientStorePoolEnable机制"><a href="#2-3-漫谈transientStorePoolEnable机制" class="headerlink" title="2.3 漫谈transientStorePoolEnable机制"></a>2.3 漫谈transientStorePoolEnable机制</h3><p>Java NIO的内存映射机制，提供了将文件系统中的文件映射到内存机制，实现对文件的操作转换对内存地址的操作，极大的提高了IO特性，但这部分内存并不是常驻内存，可以被置换到交换内存(虚拟内存)，RocketMQ为了提高消息发送的性能，引入了内存锁定机制，即将最近需要操作的commitlog文件映射到内存，并提供内存锁定功能，确保这些文件始终存在内存中，该机制的控制参数就是transientStorePoolEnable。</p>
<h3 id="2-3-1-MappedFile"><a href="#2-3-1-MappedFile" class="headerlink" title="2.3.1 MappedFile"></a>2.3.1 MappedFile</h3><p>重点关注MappedFile的ByteBuffer writeBuffer、MappedByteBuffer mappedByteBuffer这两个属性的初始化，因为这两个方法是写消息与查消息操作的直接数据结构。<br><img src="https://img-blog.csdnimg.cn/20190618214230830.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>两个关键点如下：</p>
<ul>
<li>ByteBuffer writeBuffer<br>如果开启了transientStorePoolEnable,则使用ByteBuffer.allocateDirect(fileSize),创建(java.nio的内存映射机制)。如果未开启，则为空。</li>
<li>MappedByteBuffer mappedByteBuffer<br>使用FileChannel#map方法创建，即真正意义上的PageCache。</li>
</ul>
<p>消息写入时：<br>MappedFile#appendMessagesInner<br><img src="https://img-blog.csdnimg.cn/20190618214320459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>从中可见，在消息写入时，如果writerBuffer不为空，说明开启了transientStorePoolEnable机制，则消息首先写入writerBuffer中，如果其为空，则写入mappedByteBuffer中。</p>
<p>消息拉取(读消息)：<br>MappedFile#selectMappedBuffer<br><img src="https://img-blog.csdnimg.cn/2019061821440272.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>消息读取时，是从mappedByteBuffer中读(pageCache)。</p>
<p>大家是不是发现了一个有趣的点，如果开启transientStorePoolEnable机制，是不是有了读写分离的效果，先写入writerBuffer中，读却是从mappedByteBuffer中读取。</p>
<p>为了对transientStorePoolEnable引入意图阐述的更加明白，这里我引入Rocketmq社区贡献者胡宗棠关于此问题的见解。</p>
<p>通常有如下两种方式进行读写：</p>
<ol>
<li>第一种，Mmap+PageCache的方式，读写消息都走的是pageCache，这样子读写都在pagecache里面不可避免会有锁的问题，在并发的读写操作情况下，会出现缺页中断降低，内存加锁，污染页的回写。</li>
<li>第二种，DirectByteBuffer(堆外内存)+PageCache的两层架构方式，这样子可以实现读写消息分离，写入消息时候写到的是DirectByteBuffer——堆外内存中,读消息走的是PageCache(对于,DirectByteBuffer是两步刷盘，一步是刷到PageCache，还有一步是刷到磁盘文件中)，带来的好处就是，避免了内存操作的很多容易堵的地方，降低了时延，比如说缺页中断降低，内存加锁，污染页的回写。</li>
</ol>
<blockquote>
<p>温馨提示：如果想与胡宗棠大神进一步沟通交流，可以关注他的github账号：<a href="https://github.com/zongtanghu">https://github.com/zongtanghu</a></p>
</blockquote>
<p>不知道大家会不会有另外一个担忧，如果开启了transientStorePoolEnable，内存锁定机制，那是不是随着commitlog文件的不断增加，最终导致内存溢出？</p>
<h3 id="2-3-2-TransientStorePool初始化"><a href="#2-3-2-TransientStorePool初始化" class="headerlink" title="2.3.2 TransientStorePool初始化"></a>2.3.2 TransientStorePool初始化</h3><p><img src="https://img-blog.csdnimg.cn/20190618214632249.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>从这里可以看出，TransientStorePool默认会初始化5个DirectByteBuffer(对外内存)，并提供内存锁定功能，即这部分内存不会被置换，可以通过transientStorePoolSize参数控制。</p>
<p>在消息写入消息时，首先从池子中获取一个DirectByteBuffer进行消息的追加。当5个DirectByteBuffer全部写满消息后，该如何处理呢？从RocketMQ的设计中来看，同一时间，只会对一个commitlog文件进行顺序写，写完一个后，继续创建一个新的commitlog文件。故TransientStorePool的设计思想是循环利用这5个DirectByteBuffer，只需要写入到DirectByteBuffer的内容被提交到PageCache后，即可重复利用。对应的代码如下：<br>TransientStorePool#returnBuffer</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">returnBuffer</span><span class="params">(ByteBuffer byteBuffer)</span> </span>&#123;</span><br><span class="line">    byteBuffer.position(<span class="number">0</span>);</span><br><span class="line">    byteBuffer.limit(fileSize);</span><br><span class="line">    <span class="keyword">this</span>.availableBuffers.offerFirst(byteBuffer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其调用栈如下：<br><img src="https://img-blog.csdnimg.cn/20190618214837186.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>从上面的分析看来，并不会随着消息的不断写入而导致内存溢出。</p>
<h2 id="3、现象解答"><a href="#3、现象解答" class="headerlink" title="3、现象解答"></a>3、现象解答</h2><h3 id="3-1-REJECTREQUEST-system-busy"><a href="#3-1-REJECTREQUEST-system-busy" class="headerlink" title="3.1 [REJECTREQUEST]system busy"></a>3.1 [REJECTREQUEST]system busy</h3><p><img src="https://img-blog.csdnimg.cn/20190618214915789.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其抛出的源码入口点：NettyRemotingAbstract#processRequestCommand，上面的原理分析部分已经详细介绍其实现原理，总结如下。</p>
<p>在不开启transientStorePoolEnable机制时，如果Broker PageCache繁忙时则抛出上述错误，判断PageCache繁忙的依据就是向PageCache追加消息时，如果持有锁的时间超过1s，则会抛出该错误；在开启transientStorePoolEnable机制时，其判断依据是如果TransientStorePool中不存在可用的堆外内存时抛出该错误。</p>
<h3 id="3-2-too-many-requests-and-system-thread-pool-busy-RejectedExecutionException"><a href="#3-2-too-many-requests-and-system-thread-pool-busy-RejectedExecutionException" class="headerlink" title="3.2 too many requests and system thread pool busy, RejectedExecutionException"></a>3.2 too many requests and system thread pool busy, RejectedExecutionException</h3><p><img src="https://img-blog.csdnimg.cn/20190618215005406.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其抛出的源码入口点：NettyRemotingAbstract#processRequestCommand，其调用地方紧跟3.1,是在向线程池执行任务时，被线程池拒绝执行时抛出的，我们可以顺便看看Broker消息处理发送的线程信息：<br>BrokerController#registerProcessor<br><img src="https://img-blog.csdnimg.cn/20190618215027611.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>该线程池的队列长度默认为10000，我们可以通过sendThreadPoolQueueCapacity来改变默认值。</p>
<h3 id="3-3-PC-SYNCHRONIZED-broker-busy"><a href="#3-3-PC-SYNCHRONIZED-broker-busy" class="headerlink" title="3.3 [PC_SYNCHRONIZED]broker busy"></a>3.3 [PC_SYNCHRONIZED]broker busy</h3><p><img src="https://img-blog.csdnimg.cn/20190618215119506.png" alt="在这里插入图片描述"><br>其抛出的源码入口点：DefaultMessageStore#putMessage，在进行消息追加时，再一次判断PageCache是否繁忙，如果繁忙，则抛出上述错误。</p>
<h3 id="3-4-broker-busy-period-in-queue-sms-size-of-queue-d"><a href="#3-4-broker-busy-period-in-queue-sms-size-of-queue-d" class="headerlink" title="3.4 broker busy,  period in queue: %sms, size of queue: %d"></a>3.4 broker busy,  period in queue: %sms, size of queue: %d</h3><p><img src="https://img-blog.csdnimg.cn/2019061821520312.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其抛出源码的入口点：BrokerFastFailure#cleanExpiredRequest。该方法的调用频率为每隔10s中执行一次，不过有一个执行前提条件就是Broker端要开启快速失败，默认为开启，可以通过参数brokerFastFailureEnable来设置。该方法的实现要点是每隔10s，检测一次，如果检测到PageCache繁忙，并且发送队列中还有排队的任务，则直接不再等待，直接抛出系统繁忙错误，使正在排队的线程快速失败，结束等待。</p>
<h2 id="4、实践建议"><a href="#4、实践建议" class="headerlink" title="4、实践建议"></a>4、实践建议</h2><p>经过上面的原理讲解与现象分析，消息发送时抛出system busy、broker busy的原因都是PageCache繁忙，那是不是可以通过调整上述提到的某些参数来避免抛出错误呢？.例如如下参数：</p>
<ul>
<li>osPageCacheBusyTimeOutMills<br>设置PageCache系统超时的时间，默认为1000，表示1s，那是不是可以把增加这个值，例如设置为2000或3000。作者观点：非常不可取。</li>
<li>sendThreadPoolQueueCapacity<br>Broker服务器处理的排队队列，默认为10000，如果队列中积压了10000个请求，则会抛出RejectExecutionException。作者观点：不可取。</li>
<li>brokerFastFailureEnable<br>是否启用快速失败，默认为true，表示当如果发现Broker服务器的PageCache繁忙，如果发现sendThreadPoolQueue队列中不为空，表示还有排队的发送请求在排队等待执行，则直接结束等待，返回broker busy。那如果不开启快速失败，则同样可以避免抛出这个错误。作者观点：非常不可取。</li>
</ul>
<p>修改上述参数，都不可取，原因是出现system busy、broker busy这个错误，其本质是系统的PageCache繁忙，通俗一点讲就是向PageCache追加消息时，单个消息发送占用的时间超过1s了，如果继续往该Broker服务器发送消息并等待，其TPS根本无法满足，哪还是高性能的消息中间了呀。故才会采用快速失败机制，直接给消息发送者返回错误，消息发送者默认情况会重试2次，将消息发往其他Broker，保证其高可用。</p>
<p>下面根据个人的见解，提出如下解决办法：</p>
<h3 id="4-1-开启transientStorePoolEnable"><a href="#4-1-开启transientStorePoolEnable" class="headerlink" title="4.1 开启transientStorePoolEnable"></a>4.1 开启transientStorePoolEnable</h3><p>在broker.config中将transientStorePoolEnable=true。</p>
<ul>
<li><p>方案依据：<br>启用“读写”分离，消息发送时消息先追加到DirectByteBuffer(堆外内存)中，然后在异步刷盘机制下，会将DirectByteBuffer中的内容提交到PageCache，然后刷写到磁盘。消息拉取时，直接从PageCache中拉取，实现了读写分离，减轻了PageCaceh的压力，能从根本上解决该问题。</p>
</li>
<li><p>方案缺点：<br>会增加数据丢失的可能性，如果Broker JVM进程异常退出，提交到PageCache中的消息是不会丢失的，但存在堆外内存(DirectByteBuffer)中但还未提交到PageCache中的这部分消息，将会丢失。但通常情况下，RocketMQ进程退出的可能性不大。</p>
</li>
</ul>
<h3 id="4-2-扩容Broker服务器"><a href="#4-2-扩容Broker服务器" class="headerlink" title="4.2 扩容Broker服务器"></a>4.2 扩容Broker服务器</h3><p>方案依据：</p>
<p>当Broker服务器自身比较忙的时候，快速失败，并且在接下来的一段时间内会规避该Broker，这样该Broker恢复提供了时间保证，Broker本身的架构是支持分布式水平扩容的，增加Topic的队列数，降低单台Broker服务器的负载，从而避免出现PageCache。</p>
<blockquote>
<p>温馨提示：在Broker扩容时候，可以复制集群中任意一台Broker服务下${ROCKETMQ_HOME}/store/config/topics.json到新Broker服务器指定目录，避免在新Broker服务器上为Broker创建队列，然后消息发送者、消息消费者都能动态获取Topic的路由信息。</p>
</blockquote>
<p>与之扩容对应的，也可以通过对原有Broker进行升配，例如增加内存、把机械盘换成SSD，但这种情况，通常需要重启Broekr服务器，没有扩容来的方便。</p>
<p>本文就介绍到这里了，如果大家觉得文章对自己有用的话，麻烦帮忙点赞、转发，谢谢。亲爱的读者朋友，还有更好的方案没？欢迎留言与作者互动，共同探讨。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>broker busy</tag>
        <tag>system busy</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ 整合 DLedger(多副本)即主从切换实现平滑升级的设计技巧</title>
    <url>/posts/ab1a7b9b.html</url>
    <content><![CDATA[<div id="vip-container"><p>源码分析 RocketMQ DLedger 多副本系列已经进行到第 8 篇了，前面的章节主要是介绍了基于 raft  协议的选主与日志复制，从本篇开始将开始关注如何将 DLedger 应用到 RocketMQ中。</p>
<p>摘要：详细分析了RocketMQ DLedger 多副本(主从切换) 是如何整合到 RocketMQ中，本文的行文思路首先结合已掌握的DLedger 多副本相关的知识初步思考其实现思路，然后从 Broker启动流程、DLedgerCommitlog 核心类的讲解，再从消息发送(追加)与消息查找来进一步探讨 DLedger 是如何支持平滑升级的。</p>
<h2 id="1、阅读源码之前的思考"><a href="#1、阅读源码之前的思考" class="headerlink" title="1、阅读源码之前的思考"></a>1、阅读源码之前的思考</h2><p>RocketMQ 的消息存储文件主要包括 commitlog 文件、consumequeue 文件与 Index 文件。commitlog 文件存储全量的消息，consumequeue、index 文件都是基于 commitlog 文件构建的。要使用 DLedger 来实现消息存储的一致性，应该关键是要实现 commitlog 文件的一致性，即  DLedger 要整合的对象应该是 commitlog 文件，即只需保证 raft 协议的复制组内各个节点的 commitlog 文件一致即可。</p>
<p>我们知道使用文件存储消息都会基于一定的存储格式，rocketmq 的 commitlog 一个条目就包含魔数、消息长度，消息属性、消息体等，而我们再来回顾一下 DLedger 日志的存储格式：<br><img src="https://img-blog.csdnimg.cn/20191003120527109.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>DLedger 要整合 commitlog 文件，是不是可以把 rocketmq  消息，即一个个  commitlog 条目整体当成 DLedger 的 body 字段即可。</p>
<p>还等什么，跟我一起来看源码吧！！！别急，再抛一个问题，DLedger 整合 RocketMQ commitlog，能不能做到平滑升级？</p>
<p>带着这些思考和问题，一起来探究 DLedger 是如何整合 RocketMQ 的。 </p>
<a id="more"></a>

<h2 id="2、从-Broker-启动流程看-DLedger"><a href="#2、从-Broker-启动流程看-DLedger" class="headerlink" title="2、从 Broker 启动流程看 DLedger"></a>2、从 Broker 启动流程看 DLedger</h2><blockquote>
<p>温馨提示：本文不会详细介绍 Broker 端的启动流程，只会点出在启动过程中与 DLedger 相关的代码，如想详细了解 Broker 的启动流程，建议关注笔者的《RocketMQ技术内幕》一书。</p>
</blockquote>
<p>Broker 涉及到 DLedger 相关关键点如下：<br><img src="https://img-blog.csdnimg.cn/20191003120628182.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="2-1-构建-DefaultMessageStore"><a href="#2-1-构建-DefaultMessageStore" class="headerlink" title="2.1 构建 DefaultMessageStore"></a>2.1 构建 DefaultMessageStore</h3><p>DefaultMessageStore 构造方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(messageStoreConfig.isEnableDLegerCommitLog()) &#123;  <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">this</span>.commitLog = <span class="keyword">new</span> DLedgerCommitLog(<span class="keyword">this</span>);</span><br><span class="line"> <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">this</span>.commitLog = <span class="keyword">new</span> CommitLog(<span class="keyword">this</span>);                    <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果开启 DLedger ，commitlog 的实现类为 DLedgerCommitLog，也是本文需要关注的关键所在。</p>
<p>代码@2：如果未开启 DLedger，则使用旧版的 Commitlog实现类。</p>
<h3 id="2-2-增加节点状态变更事件监听器"><a href="#2-2-增加节点状态变更事件监听器" class="headerlink" title="2.2 增加节点状态变更事件监听器"></a>2.2 增加节点状态变更事件监听器</h3><p>BrokerController#initialize</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (messageStoreConfig.isEnableDLegerCommitLog()) &#123;</span><br><span class="line">    DLedgerRoleChangeHandler roleChangeHandler = <span class="keyword">new</span> DLedgerRoleChangeHandler(<span class="keyword">this</span>, (DefaultMessageStore) messageStore);</span><br><span class="line">    ((DLedgerCommitLog)((DefaultMessageStore) messageStore).getCommitLog()).getdLedgerServer().getdLedgerLeaderElector().addRoleChangeHandler(roleChangeHandler);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>主要调用 LedgerLeaderElector 的 addRoleChanneHandler 方法增加 节点角色变更事件监听器，DLedgerRoleChangeHandler 是实现主从切换的另外一个关键点。</p>
<h3 id="2-3-调用-DefaultMessageStore-的-load-方法"><a href="#2-3-调用-DefaultMessageStore-的-load-方法" class="headerlink" title="2.3 调用 DefaultMessageStore 的 load 方法"></a>2.3 调用 DefaultMessageStore 的 load 方法</h3><p>DefaultMessageStore#load</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// load Commit Log</span></span><br><span class="line">result = result &amp;&amp; <span class="keyword">this</span>.commitLog.load();   <span class="comment">// @1</span></span><br><span class="line"><span class="comment">// load Consume Queue</span></span><br><span class="line">result = result &amp;&amp; <span class="keyword">this</span>.loadConsumeQueue();  </span><br><span class="line"><span class="keyword">if</span> (result) &#123;</span><br><span class="line">    <span class="keyword">this</span>.storeCheckpoint =  <span class="keyword">new</span> StoreCheckpoint(StorePathConfigHelper.getStoreCheckpoint(<span class="keyword">this</span>.messageStoreConfig.getStorePathRootDir()));</span><br><span class="line">    <span class="keyword">this</span>.indexService.load(lastExitOK);</span><br><span class="line">    <span class="keyword">this</span>.recover(lastExitOK);                         <span class="comment">// @2</span></span><br><span class="line">    log.info(<span class="string">&quot;load over, and the max phy offset = &#123;&#125;&quot;</span>, <span class="keyword">this</span>.getMaxPhyOffset());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1、@2 最终都是委托 commitlog 对象来执行，这里的关键又是如果开启了 DLedger，则最终调用的是 DLedgerCommitLog。</p>
<p>经过上面的铺垫，主角 DLedgerCommitLog “闪亮登场“了。</p>
<h2 id="3、DLedgerCommitLog-详解"><a href="#3、DLedgerCommitLog-详解" class="headerlink" title="3、DLedgerCommitLog 详解"></a>3、DLedgerCommitLog 详解</h2><p>温馨提示：由于 Commitlog 的绝大部分方法都已经在《RocketMQ技术内幕》一书中详细介绍了，并且 DLedgerCommitLog  的实现原理与 Commitlog 文件的实现原理类同，本文会一笔带过关于存储部分的实现细节。</p>
<h3 id="3-1-核心类图"><a href="#3-1-核心类图" class="headerlink" title="3.1 核心类图"></a>3.1 核心类图</h3><p><img src="https://img-blog.csdnimg.cn/20191003120747775.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>DLedgerCommitlog 继承自 Commitlog。让我们一一来看一下它的核心属性。</p>
<ul>
<li>DLedgerServer dLedgerServer<br>基于 raft 协议实现的集群内的一个节点，用 DLedgerServer 实例表示。</li>
<li>DLedgerConfig dLedgerConfig<br>DLedger 的配置信息。</li>
<li>DLedgerMmapFileStore dLedgerFileStore<br>DLedger 基于文件映射的存储实现。</li>
<li>MmapFileList dLedgerFileList<br>DLedger 所管理的存储文件集合，对比 RocketMQ 中的 MappedFileQueue。</li>
<li>int id<br>节点ID，0 表示主节点，非0表示从节点</li>
<li>MessageSerializer messageSerializer<br>消息序列器。</li>
<li>long beginTimeInDledgerLock = 0<br>用于记录 消息追加的时耗(日志追加所持有锁时间)。</li>
<li>long dividedCommitlogOffset = -1<br>记录的旧 commitlog 文件中的最大偏移量，如果访问的偏移量大于它，则访问 dledger 管理的文件。</li>
<li>boolean isInrecoveringOldCommitlog = false<br>是否正在恢复旧的 commitlog 文件。</li>
</ul>
<p>接下来我们将详细介绍 DLedgerCommitlog 各个核心方法及其实现要点。</p>
<h3 id="3-2-构造方法"><a href="#3-2-构造方法" class="headerlink" title="3.2 构造方法"></a>3.2 构造方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DLedgerCommitLog</span><span class="params">(<span class="keyword">final</span> DefaultMessageStore defaultMessageStore)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(defaultMessageStore);                   <span class="comment">// @1</span></span><br><span class="line">    dLedgerConfig =  <span class="keyword">new</span> DLedgerConfig();</span><br><span class="line">    dLedgerConfig.setEnableDiskForceClean(defaultMessageStore.getMessageStoreConfig().isCleanFileForciblyEnable());</span><br><span class="line">    dLedgerConfig.setStoreType(DLedgerConfig.FILE);</span><br><span class="line">    dLedgerConfig.setSelfId(defaultMessageStore.getMessageStoreConfig().getdLegerSelfId());</span><br><span class="line">    dLedgerConfig.setGroup(defaultMessageStore.getMessageStoreConfig().getdLegerGroup());</span><br><span class="line">    dLedgerConfig.setPeers(defaultMessageStore.getMessageStoreConfig().getdLegerPeers());</span><br><span class="line">    dLedgerConfig.setStoreBaseDir(defaultMessageStore.getMessageStoreConfig().getStorePathRootDir());</span><br><span class="line">    dLedgerConfig.setMappedFileSizeForEntryData(defaultMessageStore.getMessageStoreConfig().getMapedFileSizeCommitLog());</span><br><span class="line">    dLedgerConfig.setDeleteWhen(defaultMessageStore.getMessageStoreConfig().getDeleteWhen());</span><br><span class="line">    dLedgerConfig.setFileReservedHours(defaultMessageStore.getMessageStoreConfig().getFileReservedTime() + <span class="number">1</span>);  </span><br><span class="line">    id = Integer.valueOf(dLedgerConfig.getSelfId().substring(<span class="number">1</span>)) + <span class="number">1</span>;            <span class="comment">// @2</span></span><br><span class="line">    dLedgerServer = <span class="keyword">new</span> DLedgerServer(dLedgerConfig);                           <span class="comment">// @3</span></span><br><span class="line">    dLedgerFileStore = (DLedgerMmapFileStore) dLedgerServer.getdLedgerStore();</span><br><span class="line">    DLedgerMmapFileStore.AppendHook appendHook = (entry, buffer, bodyOffset) -&gt; &#123;</span><br><span class="line">            <span class="keyword">assert</span> bodyOffset == DLedgerEntry.BODY_OFFSET;</span><br><span class="line">            buffer.position(buffer.position() + bodyOffset + MessageDecoder.PHY_POS_POSITION);</span><br><span class="line">            buffer.putLong(entry.getPos() + bodyOffset);</span><br><span class="line">    &#125;;</span><br><span class="line">    dLedgerFileStore.addAppendHook(appendHook);   <span class="comment">// @4</span></span><br><span class="line">    dLedgerFileList = dLedgerFileStore.getDataFileList();</span><br><span class="line">    <span class="keyword">this</span>.messageSerializer = <span class="keyword">new</span> MessageSerializer(defaultMessageStore.getMessageStoreConfig().getMaxMessageSize());   <span class="comment">// @5</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：调用父类 即 CommitLog 的构造函数，加载 ${ROCKETMQ_HOME}/store/ comitlog 下的 commitlog 文件，以便兼容升级 DLedger 的消息。我们稍微看一下 CommitLog 的构造函数：<br><img src="https://img-blog.csdnimg.cn/20191003120936564.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>代码@2：构建 DLedgerConfig 相关配置属性，其主要属性如下：</p>
<ul>
<li>enableDiskForceClean<br>是否强制删除文件，取自 broker 配置属性 cleanFileForciblyEnable，默认为 true 。</li>
<li>storeType<br>DLedger 存储类型，固定为 基于文件的存储模式。</li>
<li>dLegerSelfId<br>leader 节点的 id 名称，示例配置：n0，其配置要求第二个字符后必须是数字。</li>
<li>dLegerGroup<br>DLeger group 的名称，建议与 broker 配置属性 brokerName 保持一致。</li>
<li>dLegerPeers<br>DLeger Group 中所有的节点信息，其配置示例 n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913。多个节点使用分号隔开。</li>
<li>storeBaseDir<br>设置 DLedger 的日志文件的根目录，取自 borker 配件文件中的 storePathRootDir ，即 RocketMQ 的数据存储根路径。</li>
<li>mappedFileSizeForEntryData<br>设置 DLedger 的单个日志文件的大小，取自 broker 配置文件中的 - mapedFileSizeCommitLog，即与 commitlog 文件的单个文件大小一致。</li>
<li>deleteWhen<br>DLedger 日志文件的删除时间，取自 broker 配置文件中的 deleteWhen，默认为凌晨 4点。</li>
<li>fileReservedHours<br>DLedger 日志文件保留时长，取自 broker 配置文件中的 fileReservedHours，默认为 72h。</li>
</ul>
<p>代码@3：根据 DLedger 配置信息创建 DLedgerServer，即创建 DLedger 集群节点，集群内各个节点启动后，就会触发选主。</p>
<p>代码@4：构建 appendHook 追加钩子函数，这是兼容 Commitlog 文件很关键的一步，后面会详细介绍其作用。</p>
<p>代码@5：构建消息序列化。</p>
<p>根据上述的流程图，构建好 DefaultMessageStore 实现后，就是调用其 load 方法，在启用 DLedger 机制后，会依次调用 DLedgerCommitlog 的 load、recover 方法。</p>
<h3 id="3-3-load"><a href="#3-3-load" class="headerlink" title="3.3 load"></a>3.3 load</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">load</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> result = <span class="keyword">super</span>.load();</span><br><span class="line">    <span class="keyword">if</span> (!result) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DLedgerCommitLog 的 laod 方法实现比较简单，就是调用 其父类 Commitlog 的 load 方法，即这里也是为了启用 DLedger 时能够兼容以前的消息。</p>
<h3 id="3-4-recover"><a href="#3-4-recover" class="headerlink" title="3.4 recover"></a>3.4 recover</h3><p>在 Broker 启动时会加载 commitlog、consumequeue等文件，需要恢复其相关是数据结构，特别是与写入、刷盘、提交等指针，其具体调用 recover 方法。<br>DLedgerCommitLog#recover</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">recoverNormally</span><span class="params">(<span class="keyword">long</span> maxPhyOffsetOfConsumeQueue)</span> </span>&#123;  <span class="comment">// @1</span></span><br><span class="line">    recover(maxPhyOffsetOfConsumeQueue);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先会先恢复 consumequeue，得出 consumequeue 中记录的最大有效物理偏移量，然后根据该物理偏移量进行恢复。<br>接下来看一下该方法的处理流程与关键点。</p>
<p>DLedgerCommitLog#recover</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">dLedgerFileStore.load();</span><br></pre></td></tr></table></figure>
<p>Step1：加载 DLedger  相关的存储文件，并一一构建对应的 MmapFile，其初始化三个重要的指针 wrotePosition、flushedPosition、committedPosition 三个指针为文件的大小。</p>
<p>DLedgerCommitLog#recover</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (dLedgerFileList.getMappedFiles().size() &gt; <span class="number">0</span>) &#123;   </span><br><span class="line">    dLedgerFileStore.recover();   <span class="comment">// @1</span></span><br><span class="line">    dividedCommitlogOffset = dLedgerFileList.getFirstMappedFile().getFileFromOffset();     <span class="comment">// @2</span></span><br><span class="line">    MappedFile mappedFile = <span class="keyword">this</span>.mappedFileQueue.getLastMappedFile();</span><br><span class="line">    <span class="keyword">if</span> (mappedFile != <span class="keyword">null</span>) &#123;                                                                                                       <span class="comment">// @3</span></span><br><span class="line">        disableDeleteDledger();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">long</span> maxPhyOffset = dLedgerFileList.getMaxWrotePosition();</span><br><span class="line">    <span class="comment">// Clear ConsumeQueue redundant data</span></span><br><span class="line">    <span class="keyword">if</span> (maxPhyOffsetOfConsumeQueue &gt;= maxPhyOffset) &#123;      <span class="comment">// @4</span></span><br><span class="line">        log.warn(<span class="string">&quot;[TruncateCQ]maxPhyOffsetOfConsumeQueue(&#123;&#125;) &gt;= processOffset(&#123;&#125;), truncate dirty logic files&quot;</span>, maxPhyOffsetOfConsumeQueue, maxPhyOffset);</span><br><span class="line">        <span class="keyword">this</span>.defaultMessageStore.truncateDirtyLogicFiles(maxPhyOffset);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：如果已存在  DLedger 的数据文件，则只需要恢复 DLedger 相关数据文建，因为在加载旧的 commitlog 文件时已经将其重要的数据指针设置为最大值。其关键实现点如下：</p>
<ul>
<li>首先调用 DLedger 文件存储实现类 DLedgerFileStore 的 recover 方法，恢复管辖的 MMapFile 对象(一个文件对应一个MMapFile实例)的相关指针，其实现方法与 RocketMQ 的 DefaultMessageStore 的恢复过程类似。</li>
<li>设置 dividedCommitlogOffset 的值为  DLedger 中所有物理文件的最小偏移量。操作消息的物理偏移量小于该值，则从 commitlog 文件中查找；物理偏移量大于等于该值的话则从 DLedger 相关的文件中查找消息。</li>
<li>如果存在旧的 commitlog 文件，则禁止删除 DLedger 文件，其具体做法就是禁止强制删除文件，并将文件的有效存储时间设置为 10 年。</li>
<li>如果 consumequeue 中存储的最大物理偏移量大于 DLedger 中最大的物理偏移量，则删除多余的 consumequeue 文件。</li>
</ul>
<blockquote>
<p>温馨提示：为什么当存在 commitlog 文件的情况下，不能删除 DLedger 相关的日志文件呢？</p>
<p>因为在此种情况下，如果 DLedger 中的物理文件有删除，则物理偏移量会断层。<br><img src="https://img-blog.csdnimg.cn/20191003143959204.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>正常情况下， maxCommitlogPhyOffset 与 dividedCommitlogOffset 是连续的，这样非常方便是访问 commitlog 还是 访问 DLedger ，但如果DLedger 部分文件删除后，这两个值就变的不连续，就会造成中间的文件空洞，无法被连续访问。</p>
</blockquote>
<p>DLedgerCommitLog#recover</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">isInrecoveringOldCommitlog = <span class="keyword">true</span>;</span><br><span class="line"><span class="keyword">super</span>.recoverNormally(maxPhyOffsetOfConsumeQueue);</span><br><span class="line">isInrecoveringOldCommitlog = <span class="keyword">false</span>;</span><br></pre></td></tr></table></figure>
<p>Step3：如果启用了 DLedger 并且是初次启动(还未生成 DLedger 相关的日志文件)，则需要恢复 旧的 commitlog 文件。</p>
<p>DLedgerCommitLog#recover</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">MappedFile mappedFile = <span class="keyword">this</span>.mappedFileQueue.getLastMappedFile();</span><br><span class="line"><span class="keyword">if</span> (mappedFile == <span class="keyword">null</span>) &#123;           <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line">ByteBuffer byteBuffer =  mappedFile.sliceByteBuffer();</span><br><span class="line">byteBuffer.position(mappedFile.getWrotePosition());</span><br><span class="line"><span class="keyword">boolean</span> needWriteMagicCode = <span class="keyword">true</span>;</span><br><span class="line"><span class="comment">// 1 TOTAL SIZE</span></span><br><span class="line">byteBuffer.getInt(); <span class="comment">//size</span></span><br><span class="line"><span class="keyword">int</span> magicCode = byteBuffer.getInt();</span><br><span class="line"><span class="keyword">if</span> (magicCode == CommitLog.BLANK_MAGIC_CODE) &#123;   <span class="comment">// @2</span></span><br><span class="line">    needWriteMagicCode = <span class="keyword">false</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    log.info(<span class="string">&quot;Recover old commitlog found a illegal magic code=&#123;&#125;&quot;</span>, magicCode);</span><br><span class="line">&#125;</span><br><span class="line">dLedgerConfig.setEnableDiskForceClean(<span class="keyword">false</span>);</span><br><span class="line">dividedCommitlogOffset = mappedFile.getFileFromOffset() + mappedFile.getFileSize();   <span class="comment">// @3</span></span><br><span class="line">log.info(<span class="string">&quot;Recover old commitlog needWriteMagicCode=&#123;&#125; pos=&#123;&#125; file=&#123;&#125; dividedCommitlogOffset=&#123;&#125;&quot;</span>, needWriteMagicCode, mappedFile.getFileFromOffset() + mappedFile.getWrotePosition(), mappedFile.getFileName(), dividedCommitlogOffset);</span><br><span class="line"><span class="keyword">if</span> (needWriteMagicCode) &#123;  <span class="comment">// @4</span></span><br><span class="line">    byteBuffer.position(mappedFile.getWrotePosition());</span><br><span class="line">    byteBuffer.putInt(mappedFile.getFileSize() - mappedFile.getWrotePosition());</span><br><span class="line">    byteBuffer.putInt(BLANK_MAGIC_CODE);</span><br><span class="line">    mappedFile.flush(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line">mappedFile.setWrotePosition(mappedFile.getFileSize());   <span class="comment">// @5</span></span><br><span class="line">mappedFile.setCommittedPosition(mappedFile.getFileSize());</span><br><span class="line">mappedFile.setFlushedPosition(mappedFile.getFileSize());</span><br><span class="line">dLedgerFileList.getLastMappedFile(dividedCommitlogOffset);</span><br><span class="line">log.info(<span class="string">&quot;Will set the initial commitlog offset=&#123;&#125; for dledger&quot;</span>, dividedCommitlogOffset);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step4：如果存在旧的 commitlog 文件，需要将最后的文件剩余部分全部填充，即不再接受新的数据写入，新的数据全部写入到 DLedger 的数据文件中。其关键实现点如下：</p>
<ul>
<li>尝试查找最后一个 commitlog 文件，如果未找到，则结束。</li>
<li>从最后一个文件的最后写入点(原 commitlog 文件的 待写入位点)尝试去查找写入的魔数，如果存在魔数并等于 CommitLog.BLANK_MAGIC_CODE，则无需再写入魔数，在升级 DLedger 第一次启动时，魔数为空，故需要写入魔数。</li>
<li>初始化 dividedCommitlogOffset ，等于最后一个文件的起始偏移量加上文件的大小，即该指针指向最后一个文件的结束位置。</li>
<li>将最后一个 commitlog 未写满的数据全部写入，其方法为 设置消息体的 size 与 魔数即可。</li>
<li>设置最后一个文件的 wrotePosition、flushedPosition、committedPosition  为文件的大小，同样有意味者最后一个文件已经写满，下一条消息将写入 DLedger 中。</li>
</ul>
<p>在启用 DLedger 机制时 Broker 的启动流程就介绍到这里了，相信大家已经了解 DLedger 在整合 RocketMQ 上做的努力，接下来我们从消息追加、消息读取两个方面再来探讨  DLedger 是如何无缝整合 RocketMQ 的，实现平滑升级的。</p>
<h2 id="4、从消息追加看-DLedger-整合-RocketMQ-如何实现无缝兼容"><a href="#4、从消息追加看-DLedger-整合-RocketMQ-如何实现无缝兼容" class="headerlink" title="4、从消息追加看 DLedger 整合 RocketMQ 如何实现无缝兼容"></a>4、从消息追加看 DLedger 整合 RocketMQ 如何实现无缝兼容</h2><blockquote>
<p>温馨提示：本节同样也不会详细介绍整个消息追加(存储流程)，只是要点出与 DLedger(多副本、主从切换)相关的核心关键点。如果想详细了解消息追加的流程，可以阅读笔者所著的《RocketMQ技术内幕》一书。</p>
</blockquote>
<p>DLedgerCommitLog#putMessage</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">AppendEntryRequest request = <span class="keyword">new</span> AppendEntryRequest();</span><br><span class="line">request.setGroup(dLedgerConfig.getGroup());</span><br><span class="line">request.setRemoteId(dLedgerServer.getMemberState().getSelfId());</span><br><span class="line">request.setBody(encodeResult.data);</span><br><span class="line">dledgerFuture = (AppendFuture&lt;AppendEntryResponse&gt;) dLedgerServer.handleAppend(request);</span><br><span class="line"><span class="keyword">if</span> (dledgerFuture.getPos() == -<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> PutMessageResult(PutMessageStatus.OS_PAGECACHE_BUSY, <span class="keyword">new</span> AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>关键点一：消息追加时，则不再写入到原先的 commitlog 文件中，而是调用 DLedgerServer 的 handleAppend 进行消息追加，该方法会有集群内的 Leader 节点负责消息追加以及在消息复制，只有超过集群内的半数节点成功写入消息后，才会返回写入成功。如果追加成功，将会返回本次追加成功后的起始偏移量，即 pos 属性，即类似于 rocketmq 中 commitlog 的偏移量，即物理偏移量。</p>
<p>DLedgerCommitLog#putMessage</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> wroteOffset =  dledgerFuture.getPos() + DLedgerEntry.BODY_OFFSET;</span><br><span class="line">ByteBuffer buffer = ByteBuffer.allocate(MessageDecoder.MSG_ID_LENGTH);</span><br><span class="line">String msgId = MessageDecoder.createMessageId(buffer, msg.getStoreHostBytes(), wroteOffset);</span><br><span class="line">eclipseTimeInLock = <span class="keyword">this</span>.defaultMessageStore.getSystemClock().now() - beginTimeInDledgerLock;</span><br><span class="line">appendResult = <span class="keyword">new</span> AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset, encodeResult.data.length, msgId, System.currentTimeMillis(), queueOffset, eclipseTimeInLock);</span><br></pre></td></tr></table></figure>
<p>关键点二：根据 DLedger 的起始偏移量计算真正的消息的物理偏移量，从开头部分得知，DLedger 自身有其存储协议，其 body 字段存储真实的消息，即 commitlog 条目的存储结构，返回给客户端的消息偏移量为  body  字段的开始偏移量，即通过 putMessage 返回的物理偏移量与不使用Dledger 方式返回的物理偏移量的含义是一样的，即从开偏移量开始，可以正确读取消息，这样 DLedger 完美的兼容了 RocketMQ Commitlog。关于 pos 以及 wroteOffset 的图解如下：<br><img src="https://img-blog.csdnimg.cn/20191003152522946.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="5、从消息读取看-DLedger-整合-RocketMQ-如何实现无缝兼容"><a href="#5、从消息读取看-DLedger-整合-RocketMQ-如何实现无缝兼容" class="headerlink" title="5、从消息读取看 DLedger 整合 RocketMQ 如何实现无缝兼容"></a>5、从消息读取看 DLedger 整合 RocketMQ 如何实现无缝兼容</h2><p>DLedgerCommitLog#getMessage</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> SelectMappedBufferResult <span class="title">getMessage</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> offset, <span class="keyword">final</span> <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (offset &lt; dividedCommitlogOffset) &#123;   <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">super</span>.getMessage(offset, size);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> mappedFileSize = <span class="keyword">this</span>.dLedgerServer.getdLedgerConfig().getMappedFileSizeForEntryData();</span><br><span class="line">    MmapFile mappedFile = <span class="keyword">this</span>.dLedgerFileList.findMappedFileByOffset(offset, offset == <span class="number">0</span>);   <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">if</span> (mappedFile != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> pos = (<span class="keyword">int</span>) (offset % mappedFileSize);</span><br><span class="line">        <span class="keyword">return</span>  convertSbr(mappedFile.selectMappedBuffer(pos, size));                                       <span class="comment">// @3</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>消息查找比较简单，因为返回给客户端消息，转发给 consumequeue 的消息物理偏移量并不是  DLedger 条目的偏移量，而是真实消息的起始偏移量。其实现关键点如下：</p>
<ul>
<li>如果查找的物理偏移量小于 dividedCommitlogOffset，则从原先的 commitlog 文件中查找。</li>
<li>然后根据物理偏移量按照二分方找到具体的物理文件。</li>
<li>对物理偏移量取模，得出在该物理文件中中的绝对偏移量，进行消息查找即可，因为只有知道其物理偏移量，从该处先将消息的长度读取出来，然后即可读出一条完整的消息。</li>
</ul>
<h2 id="5、总结"><a href="#5、总结" class="headerlink" title="5、总结"></a>5、总结</h2><p>根据上面详细的介绍，我想读者朋友们应该不难得出如下结论：</p>
<ul>
<li>DLedger 在整合时，使用 DLedger 条目包裹 RocketMQ 中的 commitlog 条目，即在  DLedger 条目的 body 字段来存储整条 commitlog 条目。</li>
<li>引入 dividedCommitlogOffset 变量，表示物理偏移量小于该值的消息存在于旧的 commitlog 文件中，实现 升级 DLedger 集群后能访问到旧的数据。</li>
<li>新 DLedger 集群启动后，会将最后一个 commitlog 填充，即新的数据不会再写入到 原先的 commitlog 文件。</li>
<li>消息追加到 DLedger 数据日志文件中，返回的偏移量不是 DLedger 条目的起始偏移量，而是DLedger 条目中 body 字段的起始偏移量，即真实消息的起始偏移量，保证消息物理偏移量的语义与 RocketMQ Commitlog一样。</li>
</ul>
<p>RocketMQ 整合 DLedger(多副本)实现平滑升级的设计技巧就介绍到这里了。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>主从同步</tag>
        <tag>多副本</tag>
        <tag>raft</tag>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ一个新的消费组初次启动时从何处开始消费呢？</title>
    <url>/posts/9502f6ef.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、抛出问题"><a href="#1、抛出问题" class="headerlink" title="1、抛出问题"></a>1、抛出问题</h2><p>一个新的消费组订阅一个已存在的Topic主题时，消费组是从该Topic的哪条消息开始消费呢？</p>
<p>首先翻阅DefaultMQPushConsumer的API时，setConsumeFromWhere(ConsumeFromWhere consumeFromWhere)API映入眼帘，从字面意思来看是设置消费者从哪里开始消费，正是解开该问题的”钥匙“。ConsumeFromWhere枚举类图如下：<br><img src="https://img-blog.csdnimg.cn/20190720120834686.png" alt="在这里插入图片描述"></p>
<ul>
<li>CONSUME_FROM_MAX_OFFSET<br>从消费队列最大的偏移量开始消费。</li>
<li>CONSUME_FROM_FIRST_OFFSET<br>从消费队列最小偏移量开始消费。</li>
<li>CONSUME_FROM_TIMESTAMP<br>从指定的时间戳开始消费，默认为消费者启动之前的30分钟处开始消费。可以通过DefaultMQPushConsumer#setConsumeTimestamp。</li>
</ul>
<p>是不是点小激动，还不快试试。</p>
<p>需求：新的消费组启动时，从队列最后开始消费，即只消费启动后发送到消息服务器后的最新消息。</p>
<h3 id="1-1-环境准备"><a href="#1-1-环境准备" class="headerlink" title="1.1 环境准备"></a>1.1 环境准备</h3><p>本示例所用到的Topic路由信息如下：<br><img src="https://img-blog.csdnimg.cn/20190720120920850.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p><strong>Broker的配置如下(broker.conf)</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brokerClusterName &#x3D; DefaultCluster</span><br><span class="line">brokerName &#x3D; broker-a</span><br><span class="line">brokerId &#x3D; 0</span><br><span class="line">deleteWhen &#x3D; 04</span><br><span class="line">fileReservedTime &#x3D; 48</span><br><span class="line">brokerRole &#x3D; ASYNC_MASTER</span><br><span class="line">flushDiskType &#x3D; ASYNC_FLUSH</span><br><span class="line"></span><br><span class="line">storePathRootDir&#x3D;E:&#x2F;SH2019&#x2F;tmp&#x2F;rocketmq_home&#x2F;rocketmq4.5_simple&#x2F;store</span><br><span class="line">storePathCommitLog&#x3D;E:&#x2F;SH2019&#x2F;tmp&#x2F;rocketmq_home&#x2F;rocketmq4.5_simple&#x2F;store&#x2F;commitlog</span><br><span class="line">namesrvAddr&#x3D;127.0.0.1:9876</span><br><span class="line">autoCreateTopicEnable&#x3D;false</span><br><span class="line">mapedFileSizeCommitLog&#x3D;10240</span><br><span class="line">mapedFileSizeConsumeQueue&#x3D;2000</span><br></pre></td></tr></table></figure>
<p>其中重点修改了如下两个参数：</p>
<ul>
<li>mapedFileSizeCommitLog<br>单个commitlog文件的大小，这里使用10M，方便测试用。</li>
<li>mapedFileSizeConsumeQueue<br>单个consumequeue队列长度，这里使用1000，表示一个consumequeue文件中包含1000个条目。</li>
</ul>
<h3 id="1-2-消息发送者代码"><a href="#1-2-消息发送者代码" class="headerlink" title="1.2 消息发送者代码"></a>1.2 消息发送者代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, InterruptedException </span>&#123;</span><br><span class="line">    DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;please_rename_unique_group_name&quot;</span>);</span><br><span class="line">    producer.setNamesrvAddr(<span class="string">&quot;127.0.0.1:9876&quot;</span>);</span><br><span class="line">    producer.start();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">300</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;TopicTest&quot;</span> ,<span class="string">&quot;TagA&quot;</span> , (<span class="string">&quot;Hello RocketMQ &quot;</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">            SendResult sendResult = producer.send(msg);</span><br><span class="line">            System.out.printf(<span class="string">&quot;%s%n&quot;</span>, sendResult);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    producer.shutdown();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过上述，往TopicTest发送300条消息，发送完毕后，RocketMQ Broker存储结构如下：<br><img src="https://img-blog.csdnimg.cn/20190720121132299.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="1-3-消费端验证代码"><a href="#1-3-消费端验证代码" class="headerlink" title="1.3 消费端验证代码"></a>1.3 消费端验证代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, MQClientException </span>&#123;</span><br><span class="line">    DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">&quot;my_consumer_01&quot;</span>);</span><br><span class="line">    consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);</span><br><span class="line">    consumer.subscribe(<span class="string">&quot;TopicTest&quot;</span>, <span class="string">&quot;*&quot;</span>);</span><br><span class="line">    consumer.setNamesrvAddr(<span class="string">&quot;127.0.0.1:9876&quot;</span>);</span><br><span class="line">    consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs,</span></span></span><br><span class="line"><span class="function"><span class="params">            ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">            System.out.printf(<span class="string">&quot;%s Receive New Messages: %s %n&quot;</span>, Thread.currentThread().getName(), msgs);</span><br><span class="line">            <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    consumer.start();</span><br><span class="line">    System.out.printf(<span class="string">&quot;Consumer Started.%n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行上述代码后，按照期望，应该是不会消费任何消息，只有等生产者再发送消息后，才会对消息进行消费，事实是这样吗？执行效果如图所示：<br><img src="https://img-blog.csdnimg.cn/20190720121225978.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>令人意外的是，竟然从队列的最小偏移量开始消费了</strong>，这就“尴尬”了。难不成是RocketMQ的Bug。带着这个疑问，从源码的角度尝试来解读该问题，并指导我们实践。</p>
<a id="more"></a>

<h2 id="2、探究CONSUME-FROM-MAX-OFFSET实现原理"><a href="#2、探究CONSUME-FROM-MAX-OFFSET实现原理" class="headerlink" title="2、探究CONSUME_FROM_MAX_OFFSET实现原理"></a>2、探究CONSUME_FROM_MAX_OFFSET实现原理</h2><p>对于一个新的消费组，无论是集群模式还是广播模式都不会存储该消费组的消费进度，可以理解为-1,此时就需要根据DefaultMQPushConsumer#consumeFromWhere属性来决定其从何处开始消费，首先我们需要找到其对应的处理入口。我们知道，消息消费者从Broker服务器拉取消息时，需要进行消费队列的负载，即RebalanceImpl。</p>
<blockquote>
<p>温馨提示：本文不会详细介绍RocketMQ消息队列负载、消息拉取、消息消费逻辑，只会展示出通往该问题的简短流程，如想详细了解消息消费具体细节，建议购买笔者出版的《RocketMQ技术内幕》书籍。</p>
</blockquote>
<p>RebalancePushImpl#computePullFromWhere</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">computePullFromWhere</span><span class="params">(MessageQueue mq)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> result = -<span class="number">1</span>;                                                                                                                                                                                                                  <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">final</span> ConsumeFromWhere consumeFromWhere = <span class="keyword">this</span>.defaultMQPushConsumerImpl.getDefaultMQPushConsumer().getConsumeFromWhere();    </span><br><span class="line">        <span class="keyword">final</span> OffsetStore offsetStore = <span class="keyword">this</span>.defaultMQPushConsumerImpl.getOffsetStore();</span><br><span class="line">        <span class="keyword">switch</span> (consumeFromWhere) &#123;</span><br><span class="line">            <span class="keyword">case</span> CONSUME_FROM_LAST_OFFSET_AND_FROM_MIN_WHEN_BOOT_FIRST:</span><br><span class="line">            <span class="keyword">case</span> CONSUME_FROM_MIN_OFFSET:</span><br><span class="line">            <span class="keyword">case</span> CONSUME_FROM_MAX_OFFSET:</span><br><span class="line">            <span class="keyword">case</span> CONSUME_FROM_LAST_OFFSET: &#123;                                                                                                                                                                <span class="comment">// @2</span></span><br><span class="line">               <span class="comment">// 省略部分代码</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">case</span> CONSUME_FROM_FIRST_OFFSET: &#123;                                                                                                                                                              <span class="comment">// @3</span></span><br><span class="line">                <span class="comment">// 省略部分代码</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">case</span> CONSUME_FROM_TIMESTAMP: &#123;                                                                                                                                                                  <span class="comment">//@4</span></span><br><span class="line">                <span class="comment">// 省略部分代码</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;                                                                                                                                                                                                                  <span class="comment">// @5</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：先解释几个局部变量。</p>
<ul>
<li>result<br>最终的返回结果，默认为-1。</li>
<li>consumeFromWhere<br>消息消费者开始消费的策略，即CONSUME_FROM_LAST_OFFSET等。</li>
<li>offsetStore<br>offset存储器，消费组消息偏移量存储实现器。</li>
</ul>
<p>代码@2：CONSUME_FROM_LAST_OFFSET(从队列的最大偏移量开始消费)的处理逻辑，下文会详细介绍。</p>
<p>代码@3：CONSUME_FROM_FIRST_OFFSET(从队列最小偏移量开始消费)的处理逻辑，下文会详细介绍。</p>
<p>代码@4：CONSUME_FROM_TIMESTAMP(从指定时间戳开始消费)的处理逻辑，下文会详细介绍。</p>
<p>代码@5：返回最后计算的偏移量，从该偏移量出开始消费。</p>
<h3 id="2-1-CONSUME-FROM-LAST-OFFSET计算逻辑"><a href="#2-1-CONSUME-FROM-LAST-OFFSET计算逻辑" class="headerlink" title="2.1 CONSUME_FROM_LAST_OFFSET计算逻辑"></a>2.1 CONSUME_FROM_LAST_OFFSET计算逻辑</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> CONSUME_FROM_LAST_OFFSET: &#123;</span><br><span class="line">    <span class="keyword">long</span> lastOffset = offsetStore.readOffset(mq, ReadOffsetType.READ_FROM_STORE);   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (lastOffset &gt;= <span class="number">0</span>) &#123;                                                                                                             <span class="comment">// @2</span></span><br><span class="line">        result = lastOffset;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// First start,no offset</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (-<span class="number">1</span> == lastOffset) &#123;                                                                                                  <span class="comment">// @3</span></span><br><span class="line">        <span class="keyword">if</span> (mq.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123;               </span><br><span class="line">            result = <span class="number">0L</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                result = <span class="keyword">this</span>.mQClientFactory.getMQAdminImpl().maxOffset(mq);                     </span><br><span class="line">            &#125; <span class="keyword">catch</span> (MQClientException e) &#123;                                                                              <span class="comment">// @4</span></span><br><span class="line">                result = -<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        result = -<span class="number">1</span>;    </span><br><span class="line">    &#125;</span><br><span class="line">	<span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：使用offsetStore从消息消费进度文件中读取消费消费进度，本文将以集群模式为例展开。稍后详细分析。</p>
<p>代码@2：如果返回的偏移量大于等于0，则直接使用该offset，这个也能理解，大于等于0，表示查询到有效的消息消费进度，从该有效进度开始消费，但我们要特别留意lastOffset为0是什么场景，因为返回0，并不会执行CONSUME_FROM_LAST_OFFSET(语义)。</p>
<p>代码@3：如果lastOffset为-1,表示当前并未存储其有效偏移量，可以理解为第一次消费，如果是消费组重试主题，从重试队列偏移量为0开始消费；如果是普通主题，则从队列当前的最大的有效偏移量开始消费，即CONSUME_FROM_LAST_OFFSET语义的实现。</p>
<p>代码@4：如果从远程服务拉取最大偏移量拉取异常或其他情况，则使用-1作为第一次拉取偏移量。</p>
<p><strong>分析，上述执行的现象，虽然设置的是CONSUME_FROM_LAST_OFFSET，但现象是从队列的第一条消息开始消费，根据上述源码的分析，只有从消费组消费进度存储文件中取到的消息偏移量为0时，才会从第一条消息开始消费，故接下来重点分析消息消费进度存储器(OffsetStore)在什么情况下会返回0。</strong></p>
<p>接下来我们将以集群模式来查看一下消息消费进度的查询逻辑，集群模式的消息进度存储管理器实现为：<br>RemoteBrokerOffsetStore,最终Broker端的命令处理类为：ConsumerManageProcessor。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ConsumerManageProcessor#queryConsumerOffset</span><br><span class="line"><span class="function"><span class="keyword">private</span> RemotingCommand <span class="title">queryConsumerOffset</span><span class="params">(ChannelHandlerContext ctx, RemotingCommand request)</span> <span class="keyword">throws</span> RemotingCommandException </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> RemotingCommand response =</span><br><span class="line">        RemotingCommand.createResponseCommand(QueryConsumerOffsetResponseHeader.class);</span><br><span class="line">    <span class="keyword">final</span> QueryConsumerOffsetResponseHeader responseHeader =</span><br><span class="line">        (QueryConsumerOffsetResponseHeader) response.readCustomHeader();</span><br><span class="line">    <span class="keyword">final</span> QueryConsumerOffsetRequestHeader requestHeader =</span><br><span class="line">        (QueryConsumerOffsetRequestHeader) request</span><br><span class="line">            .decodeCommandCustomHeader(QueryConsumerOffsetRequestHeader.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> offset =</span><br><span class="line">        <span class="keyword">this</span>.brokerController.getConsumerOffsetManager().queryOffset(</span><br><span class="line">            requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId());    <span class="comment">// @1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (offset &gt;= <span class="number">0</span>) &#123;                                                                                                                                          <span class="comment">// @2</span></span><br><span class="line">        responseHeader.setOffset(offset);</span><br><span class="line">        response.setCode(ResponseCode.SUCCESS);</span><br><span class="line">        response.setRemark(<span class="keyword">null</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;                                                                                                                                                       <span class="comment">// @3</span></span><br><span class="line">        <span class="keyword">long</span> minOffset =</span><br><span class="line">            <span class="keyword">this</span>.brokerController.getMessageStore().getMinOffsetInQueue(requestHeader.getTopic(),</span><br><span class="line">                requestHeader.getQueueId());                                                                                                     <span class="comment">// @4</span></span><br><span class="line">        <span class="keyword">if</span> (minOffset &lt;= <span class="number">0</span></span><br><span class="line">            &amp;&amp; !<span class="keyword">this</span>.brokerController.getMessageStore().checkInDiskByConsumeOffset(                                <span class="comment">// @5</span></span><br><span class="line">            requestHeader.getTopic(), requestHeader.getQueueId(), <span class="number">0</span>)) &#123;</span><br><span class="line">            responseHeader.setOffset(<span class="number">0L</span>);</span><br><span class="line">            response.setCode(ResponseCode.SUCCESS);</span><br><span class="line">            response.setRemark(<span class="keyword">null</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;                                                                                                                                                 <span class="comment">// @6</span></span><br><span class="line">            response.setCode(ResponseCode.QUERY_NOT_FOUND);</span><br><span class="line">            response.setRemark(<span class="string">&quot;Not found, V3_0_6_SNAPSHOT maybe this group consumer boot first&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> response;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：从消费消息进度文件中查询消息消费进度。</p>
<p>代码@2：如果消息消费进度文件中存储该队列的消息进度，其返回的offset必然会大于等于0，则直接返回该偏移量该客户端，客户端从该偏移量开始消费。</p>
<p>代码@3：如果未从消息消费进度文件中查询到其进度，offset为-1。则首先获取该主题、消息队列当前在Broker服务器中的最小偏移量(@4)。如果小于等于0(返回0则表示该队列的文件还未曾删除过)并且其最小偏移量对应的消息存储在内存中而不是存在磁盘中，则返回偏移量0，这就意味着ConsumeFromWhere中定义的三种枚举类型都不会生效，直接从0开始消费，到这里就能解开其谜团了(@5)。</p>
<p>代码@6：如果偏移量小于等于0，但其消息已经存储在磁盘中，此时返回未找到，最终RebalancePushImpl#computePullFromWhere中得到的偏移量为-1。</p>
<p>看到这里，大家应该能回答文章开头处提到的问题了吧？</p>
<p><strong>看到这里，大家应该明白了，为什么设置的CONSUME_FROM_LAST_OFFSET，但消费组是从消息队列的开始处消费了吧，原因就是消息消费进度文件中并没有找到其消息消费进度，并且该队列在Broker端的最小偏移量为0，说的更直白点，consumequeue/topicName/queueNum的第一个消息消费队列文件为00000000000000000000,并且消息其对应的消息缓存在Broker端的内存中(pageCache)，其返回给消费端的偏移量为0，故会从0开始消费，而不是从队列的最大偏移量处开始消费。</strong></p>
<p>为了知识体系的完备性，我们顺便来看一下其他两种策略的计算逻辑。</p>
<h3 id="2-2-CONSUME-FROM-FIRST-OFFSET"><a href="#2-2-CONSUME-FROM-FIRST-OFFSET" class="headerlink" title="2.2 CONSUME_FROM_FIRST_OFFSET"></a>2.2 CONSUME_FROM_FIRST_OFFSET</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> CONSUME_FROM_FIRST_OFFSET: &#123;</span><br><span class="line">    <span class="keyword">long</span> lastOffset = offsetStore.readOffset(mq, ReadOffsetType.READ_FROM_STORE);   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (lastOffset &gt;= <span class="number">0</span>) &#123;    <span class="comment">// @2</span></span><br><span class="line">        result = lastOffset;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (-<span class="number">1</span> == lastOffset) &#123;  <span class="comment">// @3</span></span><br><span class="line">        result = <span class="number">0L</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;                                  </span><br><span class="line">        result = -<span class="number">1</span>;                    <span class="comment">// @4</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从队列的开始偏移量开始消费，其计算逻辑如下：<br>代码@1：首先通过偏移量存储器查询消费队列的消费进度。</p>
<p>代码@2：如果大于等于0，则从当前该偏移量开始消费。</p>
<p>代码@3：如果远程返回-1，表示并没有存储该队列的消息消费进度，从0开始。</p>
<p>代码@4：否则从-1开始消费。</p>
<h3 id="2-4-CONSUME-FROM-TIMESTAMP"><a href="#2-4-CONSUME-FROM-TIMESTAMP" class="headerlink" title="2.4 CONSUME_FROM_TIMESTAMP"></a>2.4 CONSUME_FROM_TIMESTAMP</h3><p>从指定时戳后的消息开始消费。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> CONSUME_FROM_TIMESTAMP: &#123;</span><br><span class="line">    ong lastOffset = offsetStore.readOffset(mq, ReadOffsetType.READ_FROM_STORE);   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (lastOffset &gt;= <span class="number">0</span>) &#123;                                                                                                            <span class="comment">// @2</span></span><br><span class="line">        result = lastOffset;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (-<span class="number">1</span> == lastOffset) &#123;                                                                                                 <span class="comment">// @3</span></span><br><span class="line">        <span class="keyword">if</span> (mq.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                result = <span class="keyword">this</span>.mQClientFactory.getMQAdminImpl().maxOffset(mq);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (MQClientException e) &#123;</span><br><span class="line">                result = -<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">long</span> timestamp = UtilAll.parseDate(<span class="keyword">this</span>.defaultMQPushConsumerImpl.getDefaultMQPushConsumer().getConsumeTimestamp(),</span><br><span class="line">                    UtilAll.YYYYMMDDHHMMSS).getTime();</span><br><span class="line">                result = <span class="keyword">this</span>.mQClientFactory.getMQAdminImpl().searchOffset(mq, timestamp);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (MQClientException e) &#123;</span><br><span class="line">                result = -<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        result = -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其基本套路与CONSUME_FROM_LAST_OFFSET一样：<br>代码@1：首先通过偏移量存储器查询消费队列的消费进度。</p>
<p>代码@2：如果大于等于0，则从当前该偏移量开始消费。</p>
<p>代码@3：如果远程返回-1，表示并没有存储该队列的消息消费进度，如果是重试主题，则从当前队列的最大偏移量开始消费，如果是普通主题，则根据时间戳去Broker端查询，根据查询到的偏移量开始消费。</p>
<p>原理就介绍到这里，下面根据上述理论对其进行验证。</p>
<h2 id="3、猜想与验证"><a href="#3、猜想与验证" class="headerlink" title="3、猜想与验证"></a>3、猜想与验证</h2><p>根据上述理论分析我们得知设置CONSUME_FROM_LAST_OFFSET但并不是从消息队列的最大偏移量开始消费的“罪魁祸首”是因为消息消费队列的最小偏移量为0，如果不为0，则就会符合预期，我们来验证一下这个猜想。<br>首先我们删除commitlog目录下的文件，如图所示：<br><img src="https://img-blog.csdnimg.cn/20190720121720399.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其消费队列截图如下：<br><img src="https://img-blog.csdnimg.cn/20190720121738795.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>消费端的验证代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException, MQClientException </span>&#123;</span><br><span class="line">    DefaultMQPushConsumer consumer = <span class="keyword">new</span> DefaultMQPushConsumer(<span class="string">&quot;my_consumer_02&quot;</span>);</span><br><span class="line">    consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);</span><br><span class="line">    consumer.subscribe(<span class="string">&quot;TopicTest&quot;</span>, <span class="string">&quot;*&quot;</span>);</span><br><span class="line">    consumer.setNamesrvAddr(<span class="string">&quot;127.0.0.1:9876&quot;</span>);</span><br><span class="line">    consumer.registerMessageListener(<span class="keyword">new</span> MessageListenerConcurrently() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs,</span></span></span><br><span class="line"><span class="function"><span class="params">            ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class="line">            System.out.printf(<span class="string">&quot;%s Receive New Messages: %s %n&quot;</span>, Thread.currentThread().getName(), msgs);</span><br><span class="line">            <span class="keyword">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    consumer.start();</span><br><span class="line">    System.out.printf(<span class="string">&quot;Consumer Started.%n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果如下：<br><img src="https://img-blog.csdnimg.cn/20190720121811440.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>并没有消息存在的消息，符合预期。</p>
<h2 id="4、解决方案"><a href="#4、解决方案" class="headerlink" title="4、解决方案"></a>4、解决方案</h2><p>如果在生产环境下，一个新的消费组订阅一个已经存在比较久的topic，设置CONSUME_FROM_MAX_OFFSET是符合预期的，即该主题的consumequeue/{queueNum}/fileName，fileName通常不会是00000000000000000000，如是是上面文件名，想要实现从队列的最后开始消费，该如何做呢？那就走自动创建消费组的路子，执行如下命令：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">./mqadmin updateSubGroup -n 127.0.0.1:9876 -c DefaultCluster -g my_consumer_05</span><br><span class="line"></span><br><span class="line">//克隆一个订阅了该topic的消费组消费进度</span><br><span class="line">./mqadmin cloneGroupOffset -n 127.0.0.1:9876 -s my_consumer_01 -d my_consumer_05 -t TopicTest</span><br><span class="line"></span><br><span class="line">//重置消费进度到当前队列的最大值</span><br><span class="line">./mqadmin resetOffsetByTime -n 127.0.0.1:9876 -g my_consumer_05 -t TopicTest -s -1</span><br></pre></td></tr></table></figure>
<p>按照上上述命令后，即可实现其目的。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>CONSUME_FROM_TIMESTAMP</tag>
        <tag>ConsumeFromWhere</tag>
        <tag>CONSUME_FROM_MAX_OFFSET</tag>
        <tag>CONSUME_FROM_FIRST_OFFSET</tag>
      </tags>
  </entry>
  <entry>
    <title>Sentinel FlowSlot 限流实现原理(文末附流程图与总结)</title>
    <url>/posts/d83864c8.html</url>
    <content><![CDATA[<div id="vip-container"><p>Sentinel 触发限流的实现类为 FlowSlot。我们再来简单思考一下，要实现触发限流，至少需要完成如下几件事情：</p>
<ul>
<li>收集实时调用信息。</li>
<li>设置触发限流规则</li>
<li>根据限流规则与调用信息来决定是否对请求进行限流等。</li>
</ul>
<p>如何收集实时调用信息在前面的文章中已详细介绍，请带着上述问题开始本节的探讨。</p>
<h2 id="1、初始-FlowSlot"><a href="#1、初始-FlowSlot" class="headerlink" title="1、初始 FlowSlot"></a>1、初始 FlowSlot</h2><p>我们先从 FlotSlot 类的注释来简单认识一下流量控制相关的内容。</p>
<ul>
<li>根据已（NodeSelectorSlot、ClusterNodeBuilderSlot 和 StatisticSlot）收集的运行时统计信息，FlowSlot将使用预先设置的规则来决定是否应阻止传入请求。</li>
<li>SphU.entry(resourceName)调用时，如果有任意一条规则被触发则会抛出 FlowException 异常，应用程序可捕捉该异常对业务进行定制化处理。</li>
<li>每一条流控规则(FlowRule)都包含三个要素：流控类别、基于调用链的流控制策略、限流后的处理行为(参考FlowRule相关的注释)。<ul>
<li><pre><code>grade 流量控制的阈值类型</code></pre>
可选值：QPS(基于QPS限流策略)、并发线程数。</li>
<li>strategy 基于调用链的流控制策略<br>可选值：STRATEGY_DIRECT(根据调用方限流策略)、STRATEGY_RELATE(关联流量限<br>流策略)、STRATEGY_CHAIN(根据调用链入口限流策略)</li>
<li>controlBehavior 流量控制后的采取的行为<br>CONTROL_BEHAVIOR_DEFAULT(直接拒绝)、CONTROL_BEHAVIOR_WARM_UP(预热)、CONTROL_BEHAVIOR_RATE_LIMITER(匀速排队)、<br>CONTROL_BEHAVIOR_WARM_UP_RATE_LIMITER(预热与匀速排队)。</li>
</ul>
</li>
</ul>
<h2 id="2、FlowSlot-详解"><a href="#2、FlowSlot-详解" class="headerlink" title="2、FlowSlot 详解"></a>2、FlowSlot 详解</h2><h4 id="2-1-FlowSlot-类图"><a href="#2-1-FlowSlot-类图" class="headerlink" title="2.1 FlowSlot 类图"></a>2.1 FlowSlot 类图</h4><p><img src="https://img-blog.csdnimg.cn/20200315193331252.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>FlowSlot 的类图非常简单，内部持有一个成员变量，FlowRuleChecker，用来判断是否满足流控触发条件。</p>
<p>在继续探讨 Sentinel 限流之前，我们先来了解一下 FlowRule，即认识一下 Sentienl 流控规则主要包含哪些配置项，为后续的流程做一个消息的准备。</p>
<h4 id="2-2-FlowRule-配置项"><a href="#2-2-FlowRule-配置项" class="headerlink" title="2.2 FlowRule 配置项"></a>2.2 FlowRule 配置项</h4><p>FlowRule 的类体系如图所示：<br><img src="https://img-blog.csdnimg.cn/20200315193402645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其属性的含义如下：</p>
<ul>
<li>String resource<br>资源的名称。</li>
<li>String limitApp<br>需要限制的调用来源，对应【新增流控规则界面】的针对来源。</li>
<li>int grade<br>流量控制的阈值类型，目前支持 QPS 与 并发线程数，对应 【新增流控规则界面】的阔值类型。</li>
<li>int strategy<br>基于调用链的流量控制策略，对应【新增流控规则界面】的流控模式，其可选取值在本文开头部分有详细介绍。</li>
<li>String refResource<br>关联资源或入口资源，当流控模式为关联或链路时配置的关联资源或入口资源，对应【新增流控规则界面】的【入口资源】</li>
<li>int controlBehavior<br>流量控制后的采取的行为，其可选取值在本文开头部分有详细介绍，对应【新增流控规则界面】的流控效果。</li>
<li>int warmUpPeriodSec<br>预热时间，如果 controlBehavior 设置为预热(warm up)时，可以配置其预热时间，在【新增流控规则界面】中选择 warm up 类型后，会增加一行，供用户配置，默认值 10s。</li>
<li>int maxQueueingTimeMs<br>最大超时时间，如果 controlBehavior 设置为排队等待时，等待的最大超时时间，默认为500ms。</li>
<li>boolean clusterMode<br>是否是集群限流模式，对应【新增流控规则界面】的是否集群。</li>
<li>ClusterFlowConfig clusterConfig<br>集群扩容相关配置，集群限流将在后续文章中重点介绍。</li>
</ul>
<p>在 sentinel-dashboard 的配置界面如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200315193551464.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h4 id="2-3-FlowSlot-entry-流程详解"><a href="#2-3-FlowSlot-entry-流程详解" class="headerlink" title="2.3 FlowSlot#entry 流程详解"></a>2.3 FlowSlot#entry 流程详解</h4><p>FlowSlot#entry</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">entry</span><span class="params">(Context context, ResourceWrapper resourceWrapper, DefaultNode node, <span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">                      <span class="keyword">boolean</span> prioritized, Object... args)</span> <span class="keyword">throws</span> Throwable </span>&#123;   <span class="comment">// @1</span></span><br><span class="line">    checkFlow(resourceWrapper, context, node, count, prioritized);       <span class="comment">// @2</span></span><br><span class="line">    fireEntry(context, resourceWrapper, node, count, prioritized, args);  <span class="comment">// @3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先来解释一下该方法的参数：</p>
<ul>
<li>Context context<br>当前 Sentinel 调用的上下文。</li>
<li>ResourceWrapper resourceWrapper<br>当前访问的资源。</li>
<li>DefaultNode node<br>当前上下文环境对应的节点。</li>
<li>int count<br>本次调用需要消耗的“令牌”个数</li>
<li>boolean prioritized<br>是否是高优先级。</li>
<li>Object… args<br>额外参数。</li>
</ul>
<p>代码@2：调用 checkFlow ，根据配置的限流规则，结合实时统计信息，判断是否满足流控条件，如果满足，则触发流控，稍后会详细探讨该方法的实现原理。</p>
<p>代码@3：调用 fireEntry 继续沿着 slot 链进行传播。</p>
<p>FlowSlot 的 checkFlow 方法在内部就是直接调用 FlowRuleChecker 的 checkFlow 方法，故我们将目光放到 FlowRuleChecker 中。</p>
<h4 id="2-4-FlowRuleChecker-checkFlow-方法详解"><a href="#2-4-FlowRuleChecker-checkFlow-方法详解" class="headerlink" title="2.4 FlowRuleChecker checkFlow 方法详解"></a>2.4 FlowRuleChecker checkFlow 方法详解</h4><p>FlowRuleChecker#checkFlow</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">checkFlow</span><span class="params">(Function&lt;String, Collection&lt;FlowRule&gt;&gt; ruleProvider, ResourceWrapper resource,</span></span></span><br><span class="line"><span class="function"><span class="params">                          Context context, DefaultNode node, <span class="keyword">int</span> count, <span class="keyword">boolean</span> prioritized)</span> <span class="keyword">throws</span> BlockException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (ruleProvider == <span class="keyword">null</span> || resource == <span class="keyword">null</span>) &#123; </span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    Collection&lt;FlowRule&gt; rules = ruleProvider.apply(resource.getName());   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (rules != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (FlowRule rule : rules) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!canPassCheck(rule, context, node, count, prioritized)) &#123;            <span class="comment">// @2</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> FlowException(rule.getLimitApp(), rule);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：通过限流规则提供器获取与该资源相关的流控规则列表。</p>
<p>代码@2：然后遍历流控规则列表，通过调用 canPassCheck 方法来判断是否满足该规则设置的条件，如果满足流控规则，则抛出 FlowException，即只需要满足一个即结束校验。</p>
<p>接下来继续查看 canPassCheck 方法。</p>
<h5 id="2-4-1-FlowRuleChecker-canPassCheck-详解"><a href="#2-4-1-FlowRuleChecker-canPassCheck-详解" class="headerlink" title="2.4.1 FlowRuleChecker canPassCheck 详解"></a>2.4.1 FlowRuleChecker canPassCheck 详解</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">canPassCheck</span><span class="params">(FlowRule rule, Context context, DefaultNode node, </span></span></span><br><span class="line"><span class="function"><span class="params">				<span class="keyword">int</span> acquireCount, <span class="keyword">boolean</span> prioritized)</span> </span>&#123;</span><br><span class="line">    String limitApp = rule.getLimitApp(); </span><br><span class="line">    <span class="keyword">if</span> (limitApp == <span class="keyword">null</span>) &#123;    <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (rule.isClusterMode()) &#123;  <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">return</span> passClusterCheck(rule, context, node, acquireCount, prioritized);  </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> passLocalCheck(rule, context, node, acquireCount, prioritized);     </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果限流规则没有配置针对来源，则直接默认通过，该值在配置时，默认为 default，即对所有调用发起方都生效。</p>
<p>代码@2：如果是集群限流模式，则调用 passClusterCheck，非集群限流模式则调用 passLocalCheck 方法，本文重点讲述单节点限流，集群限流模式将在后续文章中详细探讨。</p>
<p>FlowRuleChecker#passLocalCheck</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">passLocalCheck</span><span class="params">(FlowRule rule, Context context, DefaultNode node, <span class="keyword">int</span> acquireCount,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">boolean</span> prioritized)</span> </span>&#123;</span><br><span class="line">    Node selectedNode = selectNodeByRequesterAndStrategy(rule, context, node);    <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (selectedNode == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> rule.getRater().canPass(selectedNode, acquireCount, prioritized);    <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先根据流控模式(strategy)选择一个合适的 Node，看到这，大家可以思考一下，这一步骤的目的，如果为空，则直接返回 true，表示放行。</p>
<p>代码@2：调用 FlowRule 内部持有的流量控制器来判断是否符合流控规则，最终调用的是 TrafficShapingController canPass 方法。</p>
<p>那我们接下来分别对上述两个方法进行详细展开。</p>
<h6 id="2-4-1-1-selectNodeByRequesterAndStrategy"><a href="#2-4-1-1-selectNodeByRequesterAndStrategy" class="headerlink" title="2.4.1.1 selectNodeByRequesterAndStrategy"></a>2.4.1.1 selectNodeByRequesterAndStrategy</h6><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">FlowRuleChecker#selectNodeByRequesterAndStrategy</span><br><span class="line"><span class="function"><span class="keyword">static</span> Node <span class="title">selectNodeByRequesterAndStrategy</span><span class="params">(FlowRule rule, Context context, DefaultNode node)</span> </span>&#123;</span><br><span class="line">    String limitApp = rule.getLimitApp();</span><br><span class="line">    <span class="keyword">int</span> strategy = rule.getStrategy();</span><br><span class="line">    String origin = context.getOrigin();   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (limitApp.equals(origin) &amp;&amp; filterOrigin(origin)) &#123;    <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">if</span> (strategy == RuleConstant.STRATEGY_DIRECT) &#123;</span><br><span class="line">            <span class="comment">// Matches limit origin, return origin statistic node.</span></span><br><span class="line">            <span class="keyword">return</span> context.getOriginNode();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> selectReferenceNode(rule, context, node);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (RuleConstant.LIMIT_APP_DEFAULT.equals(limitApp)) &#123;  <span class="comment">// @3</span></span><br><span class="line">        <span class="keyword">if</span> (strategy == RuleConstant.STRATEGY_DIRECT) &#123;</span><br><span class="line">            <span class="comment">// Return the cluster node.</span></span><br><span class="line">            <span class="keyword">return</span> node.getClusterNode();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> selectReferenceNode(rule, context, node);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (RuleConstant.LIMIT_APP_OTHER.equals(limitApp)</span><br><span class="line">            &amp;&amp; FlowRuleManager.isOtherOrigin(origin, rule.getResource())) &#123;    <span class="comment">// @4</span></span><br><span class="line">        <span class="keyword">if</span> (strategy == RuleConstant.STRATEGY_DIRECT) &#123;</span><br><span class="line">            <span class="keyword">return</span> context.getOriginNode();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> selectReferenceNode(rule, context, node);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在介绍该方法之前，先回答上文提到一个问题，我们知道，要判断是否满足了限流规则所配置的条件，一个重要的点就是要拿到当前的实时统计信息，通过上面介绍限流规则时提到 Sentinel 目前支持3种流控模式（直接、关联、链路），针对模式的不同，选择的实时统计数据的逻辑就应该不同，即该方法主要是根据流控策略找到对应的实时统计信息(Node)。</p>
<p>代码@1：首先先介绍几个局部变量的含义：</p>
<ul>
<li>String limitApp<br>该条限流规则针对的调用方。</li>
<li>int strategy<br>该条限流规则的流控策略。</li>
<li>String origin<br>本次请求的调用方，从当前上下文环境中获取，例如 dubbo 服务提供者，原始调用方为 dubbo 服务提供者的 application。</li>
</ul>
<p>代码@2：如果限流规则配置的针对的调用方与当前请求实际调用来源匹配（并且不是 default、other)时的处理逻辑，其实现的要点：</p>
<ul>
<li>如果流控模式为 RuleConstant.STRATEGY_DIRECT(直接)，则从 context 中获取源调用方所代表的 Node。</li>
<li>如果流控模式为 RuleConstant.STRATEGY_RELATE(关联)，则从集群环境中获取对应关联资源所代表的 Node，通过(ClusterBuilderSlot会收集每一个资源的实时统计信息，子集群限流时详细介绍)</li>
<li>如果流控模式为 RuleConstant.STRATEGY_CHAIN(调用链)，则判断当前调用上下文的入口资源与规则配置的是否一样，如果是，则返回入口资源对应的 Node，否则返回 null，注意：返回空则该条流控规则直接通过。【这部分代码，对应代码中的 selectReferenceNode 方法】</li>
</ul>
<p>代码@3：如果流控规则针对的调用方(limitApp) 配置的为 default，表示对所有的调用源都生效，其获取实时统计节点(Node)的处理逻辑为：</p>
<ul>
<li>如果流控模式为 RuleConstant.STRATEGY_DIRECT，则直接获取本次调用上下文环境对应的节点的ClusterNode。</li>
<li>如果是其他流控模式，与代码@2的获取逻辑一样，都是调用 selectReferenceNode 进行获取。</li>
</ul>
<p>代码@4：如果流控规则针对的调用方为(other)，此时需要判断是否有针对当前的流控规则，只要存在，则这条规则对当前资源“失效”，如果针对该资源没有配置其他额外的流控规则，则获取实时统计节点(Node)的处理逻辑为：</p>
<ul>
<li>如果流控模式为 RuleConstant.STRATEGY_DIRECT(直接)，则从 context 中获取源调用方所代表的 Node。</li>
<li>如果是其他流控模式，与代码@2的获取逻辑一样，都是调用 selectReferenceNode 进行获取。</li>
</ul>
<p>从这里可以看出，流控规则针对调用方如果设置为 other，表示针对没有配置流控规则的资源。</p>
<p>根据流控策略选择合适的 Node 的逻辑就介绍到这里，如果没有选择到合适的 Node，则针对该流控规则，默认放行。</p>
<h6 id="2-4-1-2-TrafficShapingController-canPass"><a href="#2-4-1-2-TrafficShapingController-canPass" class="headerlink" title="2.4.1.2 TrafficShapingController canPass"></a>2.4.1.2 TrafficShapingController canPass</h6><p>经过上一个步骤获取到对应的实时统计数据，接下来就是根据数据与流控规则，是否匹配。Sentinel 中用于实现流控规则的匹配其类体系如图所示：<br><img src="https://img-blog.csdnimg.cn/20200315193943356.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>由于篇幅的关系，本节只会以 DefaultController 来介绍其实现原理，对应【流控模式：快速失败】，由于篇幅的关系，其他两种流控模式将在下文详细探讨。<br>DefaultController#canPass</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">canPass</span><span class="params">(Node node, <span class="keyword">int</span> acquireCount, <span class="keyword">boolean</span> prioritized)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> curCount = avgUsedTokens(node);     <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (curCount + acquireCount &gt; count) &#123;   <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">if</span> (prioritized &amp;&amp; grade == RuleConstant.FLOW_GRADE_QPS) &#123;   <span class="comment">// @3</span></span><br><span class="line">            <span class="keyword">long</span> currentTime;</span><br><span class="line">            <span class="keyword">long</span> waitInMs;</span><br><span class="line">            currentTime = TimeUtil.currentTimeMillis();</span><br><span class="line">            waitInMs = node.tryOccupyNext(currentTime, acquireCount, count);   <span class="comment">// @4</span></span><br><span class="line">            <span class="keyword">if</span> (waitInMs &lt; OccupyTimeoutProperty.getOccupyTimeout()) &#123;             <span class="comment">// @5</span></span><br><span class="line">                node.addWaitingRequest(currentTime + waitInMs, acquireCount);</span><br><span class="line">                node.addOccupiedPass(acquireCount);</span><br><span class="line">                sleep(waitInMs);                                                                                  <span class="comment">// @6</span></span><br><span class="line">                <span class="comment">// PriorityWaitException indicates that the request will pass after waiting for &#123;@link @waitInMs&#125;.</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> PriorityWaitException(waitInMs);   <span class="comment">// @7</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;     <span class="comment">// @8</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;       <span class="comment">// @9</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先先解释一下两个局部变量的含义：</p>
<ul>
<li>int curCount<br>当前已消耗的令牌数量，即当前时间窗口内已创建的线程数量(FLOW_GRADE_THREAD) 或已通过的请求个数(FLOW_GRADE_QPS)。</li>
<li>double count<br>流控规则中配置的阔值(即一个时间窗口中总的令牌个数)</li>
</ul>
<p>代码@2：如果当前请求的令牌数加上已消耗的令牌数之和小于总令牌数，则直接返回true，表示通过，见代码@9;如果当前时间窗口剩余令牌数小于需要申请的令牌数，则需要根据是否有优先级进行不同的处理。</p>
<ul>
<li>如果该请求存在优先级，即 prioritized 设置为 true，并且流控类型为基于QPS进行限流，则进入相关的处理逻辑，见代码@3~@8。</li>
<li>否则直接返回 false，最终会直接抛出 FlowException，即快速失败，应用方可以捕捉该异常，对其业务进行容错处理。</li>
</ul>
<p>代码@4：尝试抢占下一个滑动窗口的令牌，并返回该时间窗口所剩余的时间，如果获取失败，则返回 OccupyTimeoutProperty.getOccupyTimeout() 值，该返回值的作用就是当前申请资源的线程将 sleep(阻塞)的时间。</p>
<p>代码@5：如果 waitInMs 小于抢占的最大超时时间，则在下一个时间窗口中增加对应令牌数，并且线程将sleep，见代码@6。</p>
<p>代码@7：这里不是很明白为什么等待 waitMs 之后，还需要抛出 PriorityWaitException，那这个prioritized 机制、可抢占下一个时间窗口的令牌有什么意义呢？应该是一个BUG吧。</p>
<h2 id="3、总结"><a href="#3、总结" class="headerlink" title="3、总结"></a>3、总结</h2><p>整个 FlowSlot 限流规则就介绍到这里了，为了更加直观的认识其限流的流程，下面给出一张流程图来对上面的源码分析进行一个总结。<br><img src="https://img-blog.csdnimg.cn/20200315194109133.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>该篇注重理论与实践相结合，在进行源码解读之前先从流控规则配置界面入手，代入感比较强，文章再提供一张流程图。</p>
<p>整个限流部分目前还有所欠缺的两个部分：<br>1、流程规则的存储与加载。<br>2、其他几种流控后行为(预热、匀速排队等实现原理)</p>
<p>该部分内容将在后续文章中详细介绍，本文疑似发现一个BUG，也请大家一起交流、探讨。<br>在分析 DefaultController canPass 方法时，prioritized 为 true 时，执行 sleep 方法唤醒后不管三七二十一，直接抛出 PriorityWaitException 这是要起到一个什么作用呢？</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>sentinel</category>
      </categories>
      <tags>
        <tag>sentinel</tag>
        <tag>源码</tag>
        <tag>FlowSlot</tag>
      </tags>
  </entry>
  <entry>
    <title>初识Stream、流的基本操作（流计算）</title>
    <url>/posts/3f62c87c.html</url>
    <content><![CDATA[<div id="vip-container"><p>本文中的部分示例基于如下场景：餐厅点菜，Dish为餐厅中可提供的菜品，Dish的定义如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class Dish &#123;</span><br><span class="line">    &#x2F;** 菜品名称 *&#x2F;</span><br><span class="line">	private final String name;</span><br><span class="line">	&#x2F;** 是否是素食 *&#x2F;</span><br><span class="line">	private final boolean vegetarian;</span><br><span class="line">	&#x2F;** 含卡路里 *&#x2F;</span><br><span class="line">	private final int calories;</span><br><span class="line">	&#x2F;** 类型 *&#x2F;</span><br><span class="line">	private final Type type;</span><br><span class="line">	</span><br><span class="line">	public Dish(String name, boolean vegetarian, int calories, Type type) &#123;</span><br><span class="line">		this.name &#x3D; name;</span><br><span class="line">		this.vegetarian &#x3D; vegetarian;</span><br><span class="line">		this.calories &#x3D; calories;</span><br><span class="line">		this.type &#x3D; type;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public enum Type &#123; MEAT, FISH, OTHER &#125;</span><br><span class="line">	</span><br><span class="line">	&#x2F;&#x2F; 省略set get方法</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>菜单的数据如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">List&lt;Dish&gt; menu &#x3D; Arrays.asList(</span><br><span class="line">new Dish(&quot;pork&quot;, false, 800, Dish.Type.MEAT),</span><br><span class="line">new Dish(&quot;beef&quot;, false, 700, Dish.Type.MEAT),</span><br><span class="line">new Dish(&quot;chicken&quot;, false, 400, Dish.Type.MEAT),</span><br><span class="line">new Dish(&quot;french fries&quot;, true, 530, Dish.Type.OTHER),</span><br><span class="line">new Dish(&quot;rice&quot;, true, 350, Dish.Type.OTHER),</span><br><span class="line">new Dish(&quot;season fruit&quot;, true, 120, Dish.Type.OTHER),</span><br><span class="line">new Dish(&quot;pizza&quot;, true, 550, Dish.Type.OTHER),</span><br><span class="line">new Dish(&quot;prawns&quot;, false, 300, Dish.Type.FISH),</span><br><span class="line">new Dish(&quot;salmon&quot;, false, 450, Dish.Type.FISH) );</span><br></pre></td></tr></table></figure>
<p>我们以一个简单的示例来引入流：从菜单列表中，查找出是素食的菜品，并打印其菜品的名称。</p>
<p>在Java8之前，我们通常是这样实现该需求的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">List&lt;String&gt; dishNames &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">for(Dish d menu) &#123;</span><br><span class="line">    if(d.isVegetarian()) &#123;</span><br><span class="line">        dishNames.add(d.getName()); </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;输出帅选出来的菜品的名称：</span><br><span class="line">for(String n : dishNames) &#123;</span><br><span class="line">    System.out.println(n);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那在java8中，我们可以这样写：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">menu.streams() .filter( Dish::isVegetarian).map( Dish::getName) .forEach( a -&gt; System.out.println(a) );</span><br></pre></td></tr></table></figure>
<p>其运行输出的结果：<br><img src="https://img-blog.csdnimg.cn/20190518134242508.png" alt="在这里插入图片描述"><br>怎么样，神奇吧！！！</p>
<p>在解释上面的代码之前，我们先对流做一个理论上的介绍。</p>
<h2 id="1、流是什么？"><a href="#1、流是什么？" class="headerlink" title="1、流是什么？"></a>1、流是什么？</h2><p>流，就是数据流，是元素序列，在Java8中，流的接口定义在 java.util.stream.Stream包中，并且在Collection(集合)接口中新增一个方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">default Stream&lt;E&gt; stream() &#123;</span><br><span class="line">        return StreamSupport.stream(spliterator(), false);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>流的简短定义：从支持数据处理操作的源生成的元素序列。例如集合、数组都是支持数据操作的数据结构（容器），都可以做为流的创建源，该定义的核心要素如下：</p>
<ul>
<li>源<br>流是从一个源创建来而来，而且这个源是支持数据处理的，例如集合、数组等。</li>
<li>元素序列<br>流代表一个元素序列（流水线），因为是从根据一个数据处理源而创建得来的。</li>
<li>数据处理操作<br>流的侧重点并不在数据存储，而在于数据处理，例如示例中的filter、map、forEach等。</li>
<li>迭代方式<br>流的迭代方式为内部迭代，而集合的迭代方式为外部迭代。例如我们遍历Collection接口需要用户去做迭代，例如for-each，然后在循环体中写对应的处理代码，这叫外部迭代。相反，Stream库使用内部迭代，我们只需要对流传入对应的函数即可，表示要做什么就行。</li>
</ul>
<blockquote>
<p>注意：流和迭代器Iterator一样，只能遍历一次，如果要多次遍历，请创建多个流。</p>
</blockquote>
<p>接下来我们将重点先介绍流的常用操作方法。</p>
<h2 id="2、常用的流操作方法"><a href="#2、常用的流操作方法" class="headerlink" title="2、常用的流操作方法"></a>2、常用的流操作方法</h2><h4 id="2-1-filter"><a href="#2-1-filter" class="headerlink" title="2.1 filter"></a>2.1 filter</h4><p>filter函数的方法声明如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java.util.stream.Stream#filter</span><br><span class="line">Stream&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate);</span><br></pre></td></tr></table></figure>
<p>该方法接收一个谓词，返回一个流，即filter方法接收的lambda表达式需要满足 （  T  -&gt; Boolean ）。</p>
<p>示例：从菜单中选出所有是素食的菜品：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">List&lt;Dish&gt; vegetarianDishs &#x3D; menu.stream().filter(  Dish::isVegetarian )    &#x2F;&#x2F; 使用filter过滤流中的菜品。</span><br><span class="line">                                          .collect(toList())；              &#x2F;&#x2F; 将流转换成List，该方法将在后面介绍。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>温馨提示：流的操作可以分成中间件操作和终端操作。中间操作通常的返回结果还是流，并且在调用终端操作之前，并不会立即调用，等终端方法调用后，中间操作才会真正触发执行，该示例中的collect方法为终端方法。</p>
</blockquote>
<p>我们类比一下数据库查询操作，除了基本的筛选动作外，还有去重，分页等功能，那java8的流API能支持这些操作吗？<br>答案当然是肯定。</p>
<h4 id="2-1-1-distinct"><a href="#2-1-1-distinct" class="headerlink" title="2.1.1 distinct"></a>2.1.1 distinct</h4><p>distinct，类似于数据库中的排重函数，就是对结果集去重。<br>例如有一个数值numArr = [1,5,8,6,5,2,6]，现在要输出该数值中的所有奇数并且不能重复输出，那该如何实现呢？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Arrays.stream(numArr).filter(  a -&gt; a % 2 &#x3D;&#x3D; 0 ).distinict().forEach(System.out::println);</span><br></pre></td></tr></table></figure>
<h4 id="2-1-2-limit"><a href="#2-1-2-limit" class="headerlink" title="2.1.2 limit"></a>2.1.2 limit</h4><p>截断流，返回一个i不超过指定元素个数的流。<br>还是以上例举例，如果要输出的元素是偶数，不能重复输出，并且只输出1个元素，那又该如何实现呢？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Arrays.stream(numArr).filter(  a -&gt; a % 2 &#x3D;&#x3D; 0 ).distinict().limit(1).forEach(System.out::println);</span><br></pre></td></tr></table></figure>
<h4 id="2-1-3-skip"><a href="#2-1-3-skip" class="headerlink" title="2.1.3 skip"></a>2.1.3 skip</h4><p>跳过指定元素，返回剩余元素的流，与limit互补。</p>
<a id="more"></a>

<h4 id="2-2-Map"><a href="#2-2-Map" class="headerlink" title="2.2 Map"></a>2.2 Map</h4><p>还是类比数据库操作，我们通常可以只选择一个表中的某一列，java8流操作也提供了类似的方法。<br>例如，我们需要从菜单中提取所有菜品的名称，在java8中我们可以使用如下代码实现：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">版本1：List&lt;String&gt; dishNames &#x3D; menu.stream().map( (Dish d) -&gt; d.getName() ).collect(Collectors.toList());</span><br><span class="line">版本2：List&lt;String&gt; dishNames &#x3D; menu.stream().map( d -&gt; d.getName() ).collect(Collectors.toList());</span><br><span class="line">版本3：List&lt;String&gt; dishNames &#x3D; menu.stream().map(Dish::getName).collect(Collectors.toList());</span><br></pre></td></tr></table></figure>
<blockquote>
<p>文章的后续部分尽量使用最简洁的lambda表达式。</p>
</blockquote>
<p>我们来看一下Stream关于map方法的声明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;R&gt; Stream&lt;R&gt; map(Function&lt;? super T, ? extends R&gt; mapper)</span><br></pre></td></tr></table></figure>
<p>接受一个函数Function，其函数声明为：T -&gt; R，接收一个T类型的对象，返回一个R类型的对象。</p>
<p>当然，java为了高效的处理基础数据类型（避免装箱、拆箱带来性能损耗）也定义了如下方法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">IntStream mapToInt(ToIntFunction&lt;? super T&gt; mapper)</span><br><span class="line">LongStream mapToLong(ToLongFunction&lt;? super T&gt; mapper)</span><br><span class="line">DoubleStream mapToDouble(ToDoubleFunction&lt;? super T&gt; mapper)</span><br></pre></td></tr></table></figure>

<p>思考题：对于字符数值[“Hello”,”World”] ，输出字符序列，并且去重。<br>第一次尝试：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void test_flat_map() &#123;</span><br><span class="line">    String[] strArr &#x3D; new String[] &#123;&quot;hello&quot;, &quot;world&quot;&#125;;</span><br><span class="line">    List&lt;String&gt; strList &#x3D; Arrays.asList(strArr);</span><br><span class="line">    strList.stream().map( s -&gt; s.split(&quot;&quot;))</span><br><span class="line">                    .distinct().forEach(System.out::println);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><img src="https://img-blog.csdnimg.cn/20190518134853228.png" alt="在这里插入图片描述"><br>为什么会返回两个String[]元素呢？因为map(s -&gt; s.split()) 此时返回的流为Stream&lt;String[]&gt;，那我们是不是可以继续对该Steam[String[]],把String[]转换为字符流，其代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void test_flat_map() &#123;</span><br><span class="line">    String[] strArr &#x3D; new String[] &#123;&quot;hello&quot;, &quot;world&quot;&#125;;</span><br><span class="line">    List&lt;String&gt; strList &#x3D; Arrays.asList(strArr);</span><br><span class="line">    strList.stream().map( s -&gt; s.split(&quot;&quot;))</span><br><span class="line">                    .map(Arrays::stream)</span><br><span class="line">                    .distinct().forEach(System.out::println);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其返回结果：<br><img src="https://img-blog.csdnimg.cn/20190518134944653.png" alt="在这里插入图片描述"><br>还是不符合预期，其实原因也很好理解，再次经过map(Arrays:stream)后，返回的结果为 Stream&lt;Stream&lt; String&gt;&gt;，即包含两个元素，每一个元素为一个字符流，可以通过如下代码验证：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void test_flat_map() &#123;</span><br><span class="line">    String[] strArr &#x3D; new String[] &#123;&quot;hello&quot;, &quot;world&quot;&#125;;</span><br><span class="line">    List&lt;String&gt; strList &#x3D; Arrays.asList(strArr);</span><br><span class="line">    strList.stream().map( s -&gt; s.split(&quot;&quot;))</span><br><span class="line">                    .map(Arrays::stream)</span><br><span class="line">                    .forEach(  (Stream&lt;String&gt; s) -&gt; &#123;</span><br><span class="line">                        System.out.println(&quot;\n --start---&quot;);</span><br><span class="line">                        s.forEach(a -&gt; System.out.print(a + &quot; &quot;));</span><br><span class="line">                        System.out.println(&quot;\n --end---&quot;);</span><br><span class="line">                    &#125; );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>综合上述分析，之所以不符合预期，主要是原数组中的两个字符，经过map后返回的是两个独立的流，那有什么方法将这两个流合并成一个流，然后再进行disinic去重呢？</p>
<p>答案当然是可以的，flatMap方法闪亮登场：先看代码和显示结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void test_flat_map() &#123;</span><br><span class="line">    String[] strArr &#x3D; new String[] &#123;&quot;hello&quot;, &quot;world&quot;&#125;;</span><br><span class="line">    List&lt;String&gt; strList &#x3D; Arrays.asList(strArr);</span><br><span class="line">    strList.stream().map( s -&gt; s.split(&quot;&quot;))</span><br><span class="line">                    .flatMap(Arrays::stream)</span><br><span class="line">                    .distinct().forEach( a -&gt; System.out.print(a +&quot; &quot;));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其输出结果：<br><img src="https://img-blog.csdnimg.cn/20190518135118267.png" alt="在这里插入图片描述"><br>符合预期。一言以蔽之，flatMap可以把两个流合并成一个流进行操作。</p>
<h4 id="2-3-查找和匹配"><a href="#2-3-查找和匹配" class="headerlink" title="2.3 查找和匹配"></a>2.3 查找和匹配</h4><p>Stream API提供了allMatch、anyMatch、noneMatch、findFirst和findAny方法来实现对流中数据的匹配与查找。</p>
<h5 id="2-3-1-allMatch"><a href="#2-3-1-allMatch" class="headerlink" title="2.3.1 allMatch"></a>2.3.1 allMatch</h5><p>我们先看一下该方法的声明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boolean allMatch(Predicate&lt;? super T&gt; predicate);</span><br></pre></td></tr></table></figure>
<p>接收一个谓词函数(T-&gt;boolean)，返回一个boolean值，是一个终端操作，用于判断流中的所有元素是否与Predicate相匹配，只要其中一个元素不复合，该表达式将返回false。<br>示例如下：例如存在这样一个List a,其中元素为 1,2,4,6,8。判断流中的元素是否都是偶数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boolean result &#x3D; a.stream().allMatch(  a -&gt; a % 2 &#x3D;&#x3D; 0 )；  &#x2F;&#x2F; 将返回false。</span><br></pre></td></tr></table></figure>

<h5 id="2-3-2-anyMatch"><a href="#2-3-2-anyMatch" class="headerlink" title="2.3.2 anyMatch"></a>2.3.2 anyMatch</h5><p>该方法的函数声明如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boolean anyMatch(Predicate&lt;? super T&gt; predicate)</span><br></pre></td></tr></table></figure>
<p>同样接收一个谓词Predicate( T -&gt; boolean )，表示只要流中的元素至少一个匹配谓词，即返回真。</p>
<p>示例如下：例如存在这样一个List a,其中元素为 1,2,4,6,8。判断流中的元素是否包含偶数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boolean result &#x3D; a.stream().anyMatch(  a -&gt; a % 2 &#x3D;&#x3D; 0 )；  &#x2F;&#x2F; 将返回true。</span><br></pre></td></tr></table></figure>

<h5 id="2-3-3-noneMatch"><a href="#2-3-3-noneMatch" class="headerlink" title="2.3.3 noneMatch"></a>2.3.3 noneMatch</h5><p>该方法的函数声明如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boolean noneMatch(Predicate&lt;? super T&gt; predicate);</span><br></pre></td></tr></table></figure>
<p>同样接收一个谓词Predicate( T -&gt; boolean )，表示只要流中的元素全部不匹配谓词表达式，则返回true。</p>
<p>示例如下：例如存在这样一个List a,其中元素为 2,4,6,8。判断流中的所有元素都不式奇数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">boolean result &#x3D; a.stream().noneMatch(  a -&gt; a % 2 &#x3D;&#x3D; 1 )；  &#x2F;&#x2F; 将返回true。</span><br></pre></td></tr></table></figure>

<h5 id="2-3-4-findFirst"><a href="#2-3-4-findFirst" class="headerlink" title="2.3.4 findFirst"></a>2.3.4 findFirst</h5><p>查找流中的一个元素，其函数声明如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Optional&lt;T&gt; findFirst();</span><br></pre></td></tr></table></figure>
<p>返回流中的一个元素。其返回值为Optional<T>，这是jdk8中引入的一个类，俗称值容器类，其主要左右是用来避免值空指针，一种更加优雅的方式来处理null。该类的具体使用将在下一篇详细介绍。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void test_find_first(List&lt;Dish&gt; menu) &#123;</span><br><span class="line">    Optional&lt;Dish&gt; dish &#x3D; menu.stream().findFirst();</span><br><span class="line">    &#x2F;&#x2F; 这个方法表示，Optional中包含Dish对象，则执行里面的代码，否则什么事不干，是不是比判断是否为null更友好</span><br><span class="line">    dish.ifPresent(a -&gt; System.out.println(a.getName()));  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-3-5-findAny"><a href="#2-3-5-findAny" class="headerlink" title="2.3.5 findAny"></a>2.3.5 findAny</h5><p>返回流中任意一个元素，其函数声明如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Optional&lt;T&gt; findAny();</span><br></pre></td></tr></table></figure>
<h4 id="2-4-reduce"><a href="#2-4-reduce" class="headerlink" title="2.4 reduce"></a>2.4 reduce</h4><p>reduce归约，看过大数据的人用过会非常敏感，目前的java8的流操作是不是有点map-reduce的味道，归约，就是对流中所有的元素进行统计分析，归约成一个数值。<br>首先我们看一下reduce的函数说明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">T reduce(T identity, BinaryOperator&lt;T&gt; accumulator)</span><br></pre></td></tr></table></figure>
<ul>
<li>T identity：累积器的初始值。</li>
<li>BinaryOperator&lt; T&gt; accumulator：累积函数。BinaryOperator&lt; T&gt; extend BiFunction&lt;T, U, R&gt;。BinaryOperator<T>的函数式表示，接受两个T类型的入参，返回T类型的返回值。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Optional&lt;T&gt; reduce(BinaryOperator&lt;T&gt; accumulator);</span><br></pre></td></tr></table></figure>
可以理解为没有初始值的归约，如果流为空，则会返回空，故其返回值使用了Optional类来优雅处理null值。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;U&gt; U reduce(U identity, BiFunction&lt;U, ? super T, U&gt; accumulator, BinaryOperator&lt;U&gt; combiner);</span><br></pre></td></tr></table></figure>
<p>首先，最后的返回值类型为U。</p>
<ul>
<li>U identity：累积函数的初始值。</li>
<li>BiFunction&lt;U, ? super T, U&gt; accumulator：累积器函数，对流中的元素使用该累积器进行归约，在具体执行时accumulator.apply(  identity,  第二个参数的类型不做限制 )，只要最终返回U即可。</li>
<li>BinaryOperator&lt; U&gt; combiner：组合器。对累积器的结果进行组合，因为归约reduce，java流计算内部使用了fork-join框架，会对流的中的元素使用并行累积，每个线程处理流中一部分数据，最后对结果进行组合，得出最终的值。</li>
</ul>
<blockquote>
<p>温馨提示：对流API的学习，一个最最重点的就是要掌握这些函数式编程接口，然后掌握如何使用Lambda表达式进行行为参数化（lambda表达当成参数传入到函数中）。</p>
</blockquote>
<p>接下来我们举例来展示如何使用reduce。<br>示例1：对集合中的元素求和</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; goodsNumber &#x3D; Arrays.asList(   3, 5, 8, 4, 2, 13 );</span><br><span class="line">java7之前的示例：</span><br><span class="line">int sum &#x3D; 0;</span><br><span class="line">for(Integer i : goodsNumber) &#123;</span><br><span class="line">sum +&#x3D; i;&#x2F;&#x2F;  sum &#x3D; sum + i;</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(&quot;sum:&quot; + sum);</span><br></pre></td></tr></table></figure>
<p>求和运算符： c = a + b，也就是接受2个参数，返回一个值，并且这三个值的类型一致。</p>
<p>故我们可以使用T reduce(T identity, BinaryOperator&lt; T&gt; accumulator)来实现我们的需求：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static void test_reduce() &#123;</span><br><span class="line">    List&lt;Integer&gt; goodsNumber &#x3D; Arrays.asList(   3, 5, 8, 4, 2, 13 );</span><br><span class="line">    int sum &#x3D; goodsNumber.stream().reduce(0, (a,b) -&gt; a + b);</span><br><span class="line">    &#x2F;&#x2F;这里也可以写成这样：</span><br><span class="line">    &#x2F;&#x2F; int sum &#x3D; goodsNumber.stream().reduce(0, Integer::sum);</span><br><span class="line">    System.out.println(sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>不知大家是否只读(a,b)这两个参数的来源，其实第一个参数为初始值T identity，第二个参数为流中的元素。</p>
<p>那三个参数的reduce函数主要用在什么场景下呢？接下来还是用求和的例子来展示其使用场景。在java多线程编程模型中，引入了fork-join框架，就是对一个大的任务进行先拆解，用多线程分别并行执行，最终再两两进行合并，得出最终的结果。reduce函数的第三个函数，就是组合这个动作，下面给出并行执行的流式处理示例代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> public static void test_reduce_combiner() &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;** 初始化待操作的流 *&#x2F;</span><br><span class="line">    List&lt;Integer&gt; nums &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">    int s &#x3D; 0;</span><br><span class="line">    for(int i &#x3D; 0; i &lt; 200; i ++) &#123;</span><br><span class="line">        nums.add(i);</span><br><span class="line">        s &#x3D; s + i;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 对流进行归并，求和,这里使用了流的并行执行版本 parallelStream，内部使用Fork-Join框架多线程并行执行，</span><br><span class="line">    &#x2F;&#x2F; 关于流的内部高级特性，后续再进行深入，目前先以掌握其用法为主。</span><br><span class="line">    int sum2 &#x3D; nums.parallelStream().reduce(0,Integer::sum, Integer::sum);</span><br><span class="line">    System.out.println(&quot;和为：&quot; + sum2);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 下面给出上述版本的debug版本。</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 累积器执行的次数</span><br><span class="line">    AtomicInteger accumulatorCount &#x3D; new AtomicInteger(0);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 组合器执行的次数（其实就是内部并行度）</span><br><span class="line">    AtomicInteger combinerCount &#x3D; new AtomicInteger(0);</span><br><span class="line"></span><br><span class="line">    int sum &#x3D; nums.parallelStream().reduce(0,(a,b) -&gt; &#123;</span><br><span class="line">                accumulatorCount.incrementAndGet();</span><br><span class="line">                return a + b;</span><br><span class="line">           &#125;, (c,d) -&gt; &#123;</span><br><span class="line">                combinerCount.incrementAndGet();</span><br><span class="line">                return  c+d;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">    System.out.println(&quot;accumulatorCount:&quot; + accumulatorCount.get());</span><br><span class="line">    System.out.println(&quot;combinerCountCount:&quot; + combinerCount.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从结果上可以看出，执行了100次累积动作，但只进行了15次合并。</p>
<p>流的基本操作就介绍到这里，在此总结一下，目前接触到的流操作：<br>1、filter</p>
<ul>
<li>函数功能：过滤</li>
<li>操作类型：中间操作</li>
<li>返回类型：Stream<T></li>
<li>函数式接口：Predicate<T></li>
<li>函数描述符：T -&gt; boolean</li>
</ul>
<p>2、distinct</p>
<ul>
<li>函数功能：去重</li>
<li>操作类型：中间操作</li>
<li>返回类型：Stream<T></li>
</ul>
<p>3、skip</p>
<ul>
<li>函数功能：跳过n个元素</li>
<li>操作类型：中间操作</li>
<li>返回类型：Stream<T></li>
<li>接受参数：long</li>
</ul>
<p>4、limit</p>
<ul>
<li>函数功能：截断流，值返回前n个元素的流</li>
<li>操作类型：中间操作</li>
<li>返回类型：Stream<T></li>
<li>接受参数：long</li>
</ul>
<p>5、map</p>
<ul>
<li>函数功能：映射</li>
<li>操作类型：中间操作</li>
<li>返回类型：Stream<R></li>
<li>函数式接口：Function&lt;T,R&gt;</li>
<li>函数描述符：T -&gt; R<br>6、flatMap</li>
<li>函数功能：扁平化流，将多个流合并成一个流</li>
<li>操作类型：中间操作</li>
<li>返回类型：Stream<R></li>
<li>函数式接口：Function&lt;T, Stream<R>&gt;</li>
<li>函数描述符：T -&gt; Stream<R><br>7、sorted</li>
<li>函数功能：排序</li>
<li>操作类型：中间操作</li>
<li>返回类型：Stream<T></li>
<li>函数式接口：Comparator<T></li>
<li>函数描述符：(T,T) -&gt; int<br>8、anyMatch</li>
<li>函数功能：流中任意一个匹配则返回true</li>
<li>操作类型：终端操作</li>
<li>返回类型：boolean</li>
<li>函数式接口：Predicate<T></li>
<li>函数描述符：T -&gt; boolean<br>9、allMatch</li>
<li>函数功能：流中全部元素匹配则返回true</li>
<li>操作类型：终端操作</li>
<li>返回类型：boolean</li>
<li>函数式接口：Predicate<T></li>
<li>函数描述符：T -&gt; boolean<br>10、 noneMatch</li>
<li>函数功能：流中所有元素都不匹配则返回true</li>
<li>操作类型：终端操作</li>
<li>返回类型：boolean</li>
<li>函数式接口：Predicate<T></li>
<li>函数描述符：T -&gt; boolean<br>11、findAny</li>
<li>函数功能：从流中任意返回一个元素</li>
<li>操作类型：终端操作</li>
<li>返回类型：Optional<T><br>12、findFirst</li>
<li>函数功能：返回流中第一个元素</li>
<li>操作类型：终端操作</li>
<li>返回类型：Optional<T><br>13、forEach</li>
<li>函数功能：遍历流</li>
<li>操作类型：终端操作</li>
<li>返回类型：void</li>
<li>函数式接口：Consumer<T></li>
<li>函数描述符：T -&gt; void<br>14、collect</li>
<li>函数功能：将流进行转换</li>
<li>操作类型：终端操作</li>
<li>返回类型：R</li>
<li>函数式接口：Collector&lt;T,A,R&gt;</li>
</ul>
<p>15、reduce</p>
<ul>
<li><p>函数功能：规约流</p>
</li>
<li><p>操作类型：终端操作 </p>
</li>
<li><p>返回类型：Optional<T></p>
</li>
<li><p>函数式接口：BinaryOperator<T></p>
</li>
<li><p>函数描述符：(T,T) -&gt; T</p>
<p>16、count</p>
</li>
<li><p>函数功能：返回流中总元素个数</p>
</li>
<li><p>操作类型：终端操作</p>
</li>
<li><p>返回类型：long</p>
</li>
</ul>
<p>由于篇幅的原因，流的基本计算就介绍到这里了，下文还将重点介绍流的创建，数值流与Optional类的使用。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>java8</category>
      </categories>
      <tags>
        <tag>java8</tag>
        <tag>Lambda</tag>
        <tag>流计算</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析 Kafka 消息发送流程(文末附流程图)</title>
    <url>/posts/f81e58bb.html</url>
    <content><![CDATA[<div id="vip-container"><blockquote>
<p>温馨提示：本文基于 Kafka 2.2.1 版本。本文主要是以源码的手段一步一步探究消息发送流程，如果对源码不感兴趣，可以直接跳到文末查看消息发送流程图与消息发送本地缓存存储结构。</p>
</blockquote>
<p>从上文 <a href="https://blog.csdn.net/prestigeding/article/details/102881472">初识 Kafka Producer 生产者</a>，可以通过 KafkaProducer 的 send 方法发送消息，send 方法的声明如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record)</span></span></span><br><span class="line"><span class="function">Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span></span></span><br></pre></td></tr></table></figure>
<p>从上面的 API 可以得知，用户在使用 KafkaProducer 发送消息时，首先需要将待发送的消息封装成 ProducerRecord，返回的是一个 Future 对象，典型的 Future 设计模式。在发送时也可以指定一个 Callable 接口用来执行消息发送的回调。</p>
<p>我们在学习消息发送流程之前先来看一下用于封装一条消息的 ProducerRecord 的类图，先来认识一下 kafka 是如何对一条消息进行抽象的。</p>
<h2 id="1、ProducerRecord-类图"><a href="#1、ProducerRecord-类图" class="headerlink" title="1、ProducerRecord 类图"></a>1、ProducerRecord 类图</h2><p><img src="https://img-blog.csdnimg.cn/201911100956254.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们首先来看一下 ProducerRecord 的核心属性，即构成 消息的6大核心要素：</p>
<ul>
<li>String topic<br>消息所属的主题。</li>
<li>Integer partition<br>消息所在主题的队列数，可以人为指定，如果指定了 key 的话，会使用 key 的 hashCode 与队列总数进行取模来选择分区，如果前面两者都未指定，则会轮询主题下的所有分区。</li>
<li>Headers headers<br>该消息的额外属性对，与消息体分开存储.</li>
<li>K key<br>消息键，如果指定该值，则会使用该值的 hashcode 与 队列数进行取模来选择分区。</li>
<li>V value<br>消息体。</li>
<li>Long timestamp<br>消息时间戳，根据 topic 的配置信息 message.timestamp.type 的值来赋予不同的值。<ul>
<li>CreateTime<br>发送客户端发送消息时的时间戳。</li>
<li>LogAppendTime<br>消息在 broker 追加时的时间戳。</li>
</ul>
</li>
</ul>
<p>其中Headers是一系列的 key-value 键值对。</p>
<p>在了解 ProducerRecord 后我们开始来探讨 Kafka 的消息发送流程。</p>
<a id="more"></a>

<h2 id="2、Kafka-消息追加流程"><a href="#2、Kafka-消息追加流程" class="headerlink" title="2、Kafka 消息追加流程"></a>2、Kafka 消息追加流程</h2><p>KafkaProducer 的 send 方法，并不会直接向 broker 发送消息，kafka 将消息发送异步化，即分解成两个步骤，send 方法的职责是将消息追加到内存中(分区的缓存队列中)，然后会由专门的 Send 线程异步将缓存中的消息批量发送到 Kafka Broker 中。</p>
<p>消息追加入口为 KafkaProducer#send</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;  </span><br><span class="line">    <span class="comment">// intercept the record, which can be potentially modified; this method does not throw exceptions</span></span><br><span class="line">    ProducerRecord&lt;K, V&gt; interceptedRecord = <span class="keyword">this</span>.interceptors.onSend(record);                <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span> doSend(interceptedRecord, callback);                                                                     <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先执行消息发送拦截器，拦截器通过 interceptor.classes 指定，类型为 List&lt; String &gt;，每一个元素为拦截器的全类路径限定名。<br>代码@2：执行 doSend 方法，后续我们需要留意一下 Callback  的调用时机。</p>
<p>接下来我们来看 doSend 方法。</p>
<h3 id="2-1-doSend"><a href="#2-1-doSend" class="headerlink" title="2.1 doSend"></a>2.1 doSend</h3><p>KafkaProducer#doSend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ClusterAndWaitTime clusterAndWaitTime;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);</span><br><span class="line">&#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">    <span class="keyword">if</span> (metadata.isClosed())</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">&quot;Producer closed while send in progress&quot;</span>, e);</span><br><span class="line">	<span class="keyword">throw</span> e;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">long</span> remainingWaitMs = Math.max(<span class="number">0</span>, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);</span><br></pre></td></tr></table></figure>
<p>Step1：获取 topic 的分区列表，如果本地没有该topic的分区信息，则需要向远端 broker 获取，该方法会返回拉取元数据所耗费的时间。在消息发送时的最大等待时间时会扣除该部分损耗的时间。</p>
<blockquote>
<p>温馨提示：本文不打算对该方法进行深入学习，后续会有专门的文章来分析 Kafka 元数据的同步机制，类似于专门介绍 RocketMQ 的 Nameserver 类似。</p>
</blockquote>
<p>KafkaProducer#doSend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">byte</span>[] serializedKey;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key());</span><br><span class="line">&#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">&quot;Can&#x27;t convert key of class &quot;</span> + record.key().getClass().getName() +</span><br><span class="line">                        <span class="string">&quot; to class &quot;</span> + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                        <span class="string">&quot; specified in key.serializer&quot;</span>, cce);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：序列化 key。注意：序列化方法虽然有传入 topic、Headers 这两个属性，但参与序列化的只是 key 。</p>
<p>KafkaProducer#doSend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">byte</span>[] serializedValue;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value());</span><br><span class="line">&#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">&quot;Can&#x27;t convert value of class &quot;</span> + record.value().getClass().getName() +</span><br><span class="line">                        <span class="string">&quot; to class &quot;</span> + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                        <span class="string">&quot; specified in value.serializer&quot;</span>, cce);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step3：对消息体内容进行序列化。</p>
<p>KafkaProducer#doSend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, cluster);</span><br><span class="line">tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</span><br></pre></td></tr></table></figure>
<p>Step4：根据分区负载算法计算本次消息发送该发往的分区。其默认实现类为 DefaultPartitioner，路由算法如下：</p>
<ul>
<li>如果指定了 key ，则使用 key 的 hashcode 与分区数取模。</li>
<li>如果未指定 key，则轮询所有的分区。</li>
</ul>
<p>KafkaProducer#doSend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">setReadOnly(record.headers());</span><br><span class="line">Header[] headers = record.headers().toArray();</span><br></pre></td></tr></table></figure>
<p>Step5：如果是消息头信息(RecordHeaders)，则设置为只读。</p>
<p>KafkaProducer#doSend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> serializedSize = AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(),</span><br><span class="line">                    compressionType, serializedKey, serializedValue, headers);</span><br><span class="line">ensureValidRecordSize(serializedSize);</span><br></pre></td></tr></table></figure>
<p>Step5：根据使用的版本号，按照消息协议来计算消息的长度，并是否超过指定长度，如果超过则抛出异常。</p>
<p>KafkaProducer#doSend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> timestamp = record.timestamp() == <span class="keyword">null</span> ? time.milliseconds() : record.timestamp();</span><br><span class="line">log.trace(<span class="string">&quot;Sending record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;&quot;</span>, record, callback, record.topic(), partition);</span><br><span class="line">Callback interceptCallback = <span class="keyword">new</span> InterceptorCallback&lt;&gt;(callback, <span class="keyword">this</span>.interceptors, tp);</span><br></pre></td></tr></table></figure>
<p>Step6：先初始化消息时间戳，并对传入的 Callable(回调函数) 加入到拦截器链中。</p>
<p>KafkaProducer#doSend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (transactionManager != <span class="keyword">null</span> &amp;&amp; transactionManager.isTransactional())</span><br><span class="line">    transactionManager.maybeAddPartitionToTransaction(tp);</span><br></pre></td></tr></table></figure>
<p>Step7：如果事务处理器不为空，执行事务管理相关的，本节不考虑事务消息相关的实现细节，后续估计会有对应的文章进行解析。</p>
<p>KafkaProducer#doSend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptCallback, remainingWaitMs);</span><br><span class="line"><span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">    log.trace(<span class="string">&quot;Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch&quot;</span>, record.topic(), partition);</span><br><span class="line">                <span class="keyword">this</span>.sender.wakeup();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> result.future;</span><br></pre></td></tr></table></figure>
<p>Step8：将消息追加到缓存区，这将是本文重点需要探讨的。如果当前缓存区已写满或创建了一个新的缓存区，则唤醒 Sender(消息发送线程)，将缓存区中的消息发送到 broker 服务器，最终返回 future。这里是经典的 Future 设计模式，从这里也能得知，doSend 方法执行完成后，此时消息还不一定成功发送到 broker。</p>
<p>KafkaProducer#doSend</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#125; catch (ApiException e) &#123;</span><br><span class="line">    log.debug(&quot;Exception occurred during message send:&quot;, e);</span><br><span class="line">    if (callback !&#x3D; null)</span><br><span class="line">        callback.onCompletion(null, e);</span><br><span class="line">        </span><br><span class="line">	this.errors.record();</span><br><span class="line">    this.interceptors.onSendError(record, tp, e);</span><br><span class="line">        return new FutureFailure(e);</span><br><span class="line">&#125; catch (InterruptedException e) &#123;</span><br><span class="line">    this.errors.record();</span><br><span class="line">    this.interceptors.onSendError(record, tp, e);</span><br><span class="line">    throw new InterruptException(e);</span><br><span class="line">&#125; catch (BufferExhaustedException e) &#123;</span><br><span class="line">    this.errors.record();</span><br><span class="line">    this.metrics.sensor(&quot;buffer-exhausted-records&quot;).record();</span><br><span class="line">    this.interceptors.onSendError(record, tp, e);</span><br><span class="line">    throw e;</span><br><span class="line">&#125; catch (KafkaException e) &#123;</span><br><span class="line">    this.errors.record();</span><br><span class="line">    this.interceptors.onSendError(record, tp, e);</span><br><span class="line">    throw e;</span><br><span class="line">&#125; catch (Exception e) &#123;</span><br><span class="line">    &#x2F;&#x2F; we notify interceptor about all exceptions, since onSend is called before anything else in this method</span><br><span class="line">    this.interceptors.onSendError(record, tp, e);</span><br><span class="line">    throw e;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step9：针对各种异常，进行相关信息的收集。</p>
<p>接下来将重点介绍如何将消息追加到生产者的发送缓存区，其实现类为：RecordAccumulator。</p>
<h3 id="2-2-RecordAccumulator-append-方法详解"><a href="#2-2-RecordAccumulator-append-方法详解" class="headerlink" title="2.2 RecordAccumulator append 方法详解"></a>2.2 RecordAccumulator append 方法详解</h3><p>RecordAccumulator#append</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> RecordAppendResult <span class="title">append</span><span class="params">(TopicPartition tp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">byte</span>[] key,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">byte</span>[] value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     Header[] headers,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     Callback callback,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">long</span> maxTimeToBlock)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br></pre></td></tr></table></figure>
<p>在介绍该方法之前，我们首先来看一下该方法的参数。</p>
<ul>
<li>TopicPartition tp<br>topic 与分区信息，即发送到哪个 topic 的那个分区。</li>
<li>long timestamp<br>客户端发送时的时间戳。</li>
<li>byte[] key<br>消息的 key。</li>
<li>byte[] value<br>消息体。</li>
<li>Header[] headers<br>消息头，可以理解为额外消息属性。</li>
<li>Callback callback<br>回调方法。</li>
<li>long maxTimeToBlock<br>消息追加超时时间。</li>
</ul>
<p>RecordAccumulator#append</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Deque&lt;ProducerBatch&gt; dq = getOrCreateDeque(tp);</span><br><span class="line"><span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">    <span class="keyword">if</span> (closed)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">&quot;Producer closed while send in progress&quot;</span>);</span><br><span class="line">    RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callback, dq);</span><br><span class="line">    <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> appendResult;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step1：尝试根据 topic与分区在 kafka 中获取一个双端队列，如果不存在，则创建一个，然后调用 tryAppend 方法将消息追加到缓存中。Kafka 会为每一个 topic 的每一个分区创建一个消息缓存区，消息先追加到缓存中，然后消息发送 API 立即返回，然后由单独的线程 Sender 将缓存区中的消息定时发送到 broker 。这里的缓存区的实现使用的是 ArrayQeque。然后调用 tryAppend 方法尝试将消息追加到其缓存区，如果追加成功，则返回结果。</p>
<p>在讲解下一个流程之前，我们先来看一下 Kafka 双端队列的存储结构：<br><img src="https://img-blog.csdnimg.cn/20191110101227257.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>RecordAccumulator#append</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> size = Math.max(<span class="keyword">this</span>.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers));</span><br><span class="line">log.trace(<span class="string">&quot;Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;&quot;</span>, size, tp.topic(), tp.partition());</span><br><span class="line">buffer = free.allocate(size, maxTimeToBlock);</span><br></pre></td></tr></table></figure>
<p>Step2：如果第一步未追加成功，说明当前没有可用的 ProducerBatch，则需要创建一个 ProducerBatch，故先从 BufferPool 中申请 batch.size 的内存空间，为创建 ProducerBatch 做准备，如果由于 BufferPool 中未有剩余内存，则最多等待 maxTimeToBlock ，如果在指定时间内未申请到内存，则抛出异常。</p>
<p>RecordAccumulator#append</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">    <span class="comment">// Need to check if producer is closed again after grabbing the dequeue lock.</span></span><br><span class="line">    <span class="keyword">if</span> (closed)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">&quot;Producer closed while send in progress&quot;</span>);</span><br><span class="line">    <span class="comment">// 省略部分代码</span></span><br><span class="line">    MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, maxUsableMagic);</span><br><span class="line">    ProducerBatch batch = <span class="keyword">new</span> ProducerBatch(tp, recordsBuilder, time.milliseconds());</span><br><span class="line">    FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, headers, callback, time.milliseconds()));</span><br><span class="line">    dq.addLast(batch);</span><br><span class="line">    incomplete.add(batch);</span><br><span class="line">    <span class="comment">// Don&#x27;t deallocate this buffer in the finally block as it&#x27;s being used in the record batch</span></span><br><span class="line">    buffer = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="number">1</span> || batch.isFull(), <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step3：创建一个新的批次 ProducerBatch，并将消息写入到该批次中，并返回追加结果，这里有如下几个关键点：</p>
<ul>
<li>创建 ProducerBatch ，其内部持有一个 MemoryRecordsBuilder对象，该对象负责将消息写入到内存中，即写入到 ProducerBatch 内部持有的内存，大小等于 batch.size。</li>
<li>将消息追加到 ProducerBatch 中。</li>
<li>将新创建的 ProducerBatch  添加到双端队列的末尾。</li>
<li>将该批次加入到 incomplete 容器中，该容器存放未完成发送到 broker 服务器中的消息批次，当 Sender 线程将消息发送到 broker 服务端后，会将其移除并释放所占内存。</li>
<li>返回追加结果。</li>
</ul>
<p>纵观 RecordAccumulator  append 的流程，基本上就是从双端队列获取一个未填充完毕的 ProducerBatch（消息批次），然后尝试将其写入到该批次中（缓存、内存中），如果追加失败，则尝试创建一个新的 ProducerBatch 然后继续追加。</p>
<p>接下来我们继续探究如何向 ProducerBatch 中写入消息。</p>
<h3 id="2-3-ProducerBatch-tryAppend方法详解"><a href="#2-3-ProducerBatch-tryAppend方法详解" class="headerlink" title="2.3 ProducerBatch  tryAppend方法详解"></a>2.3 ProducerBatch  tryAppend方法详解</h3><p>ProducerBatch #tryAppend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> FutureRecordMetadata <span class="title">tryAppend</span><span class="params">(<span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Header[] headers, Callback callback, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!recordsBuilder.hasRoomFor(timestamp, key, value, headers)) &#123;  <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        Long checksum = <span class="keyword">this</span>.recordsBuilder.append(timestamp, key, value, headers);                    <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">this</span>.maxRecordSize = Math.max(<span class="keyword">this</span>.maxRecordSize, AbstractRecords.estimateSizeInBytesUpperBound(magic(),</span><br><span class="line">                    recordsBuilder.compressionType(), key, value, headers));               <span class="comment">// @3</span></span><br><span class="line">        <span class="keyword">this</span>.lastAppendTime = now;                                                                          <span class="comment">//                                                     </span></span><br><span class="line">        FutureRecordMetadata future = <span class="keyword">new</span> FutureRecordMetadata(<span class="keyword">this</span>.produceFuture, <span class="keyword">this</span>.recordCount,</span><br><span class="line">                                                                   timestamp, checksum,</span><br><span class="line">                                                                   key == <span class="keyword">null</span> ? -<span class="number">1</span> : key.length,</span><br><span class="line">                                                                   value == <span class="keyword">null</span> ? -<span class="number">1</span> : value.length,</span><br><span class="line">                                                                   Time.SYSTEM);                                        <span class="comment">// @4</span></span><br><span class="line">        <span class="comment">// we have to keep every future returned to the users in case the batch needs to be</span></span><br><span class="line">        <span class="comment">// split to several new batches and resent.</span></span><br><span class="line">        thunks.add(<span class="keyword">new</span> Thunk(callback, future));                                                           <span class="comment">// @5</span></span><br><span class="line">        <span class="keyword">this</span>.recordCount++;</span><br><span class="line">        <span class="keyword">return</span> future;                                                                            </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先判断 ProducerBatch  是否还能容纳当前消息，如果剩余内存不足，将直接返回 null。如果返回 null ，会尝试再创建一个新的ProducerBatch。</p>
<p>代码@2：通过 MemoryRecordsBuilder 将消息写入按照 Kafka 消息格式写入到内存中，即写入到 在创建 ProducerBatch  时申请的 ByteBuffer 中。本文先不详细介绍 Kafka 各个版本的消息格式，后续会专门写一篇文章介绍 Kafka 各个版本的消息格式。</p>
<p>代码@3：更新 ProducerBatch  的 maxRecordSize、lastAppendTime 属性，分别表示该批次中最大的消息长度与最后一次追加消息的时间。</p>
<p>代码@4：构建 FutureRecordMetadata 对象，这里是典型的 Future模式，里面主要包含了该条消息对应的批次的 produceFuture、消息在该批消息的下标，key 的长度、消息体的长度以及当前的系统时间。</p>
<p>代码@5：将 callback 、本条消息的凭证(Future) 加入到该批次的 thunks 中，该集合存储了 一个批次中所有消息的发送回执。</p>
<p>流程执行到这里，KafkaProducer 的 send 方法就执行完毕了，返回给调用方的就是一个 FutureRecordMetadata 对象。</p>
<p>源码的阅读比较枯燥，接下来用一个流程图简单的阐述一下消息追加的关键要素，重点关注一下各个 Future。</p>
<h3 id="2-4-Kafka-消息追加流程图与总结"><a href="#2-4-Kafka-消息追加流程图与总结" class="headerlink" title="2.4 Kafka 消息追加流程图与总结"></a>2.4 Kafka 消息追加流程图与总结</h3><p><img src="https://img-blog.csdnimg.cn/201911101014500.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>上面的消息发送，其实用消息追加来表达更加贴切，因为 Kafka 的 send 方法，并不会直接向 broker 发送消息，而是首先先追加到生产者的内存缓存中，其内存存储结构如下：ConcurrentMap&lt; TopicPartition, Deque&lt; ProducerBatch&gt;&gt; batches，那我们自然而然的可以得知，Kafka 的生产者为会每一个 topic 的每一个 分区单独维护一个队列，即 ArrayDeque，内部存放的元素为 ProducerBatch，即代表一个批次，即 Kafka 消息发送是按批发送的。其缓存结果图如下：<br><img src="https://img-blog.csdnimg.cn/20191110101523210.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>KafkaProducer 的 send 方法最终返回的 FutureRecordMetadata ，是 Future 的子类，即 Future 模式。那 kafka 的消息发送怎么实现异步发送、同步发送的呢？</p>
<p>其实答案也就蕴含在 send 方法的返回值，如果项目方需要使用同步发送的方式，只需要拿到 send 方法的返回结果后，调用其 get() 方法，此时如果消息还未发送到 Broker 上，该方法会被阻塞，等到 broker 返回消息发送结果后该方法会被唤醒并得到消息发送结果。如果需要异步发送，则建议使用 send(ProducerRecord&lt; K, V &gt; record, Callback callback),但不能调用 get 方法即可。Callback 会在收到 broker 的响应结果后被调用，并且支持拦截器。</p>
<p>消息追加流程就介绍到这里了，消息被追加到缓存区后，什么是会被发送到 broker 端呢？将在下一篇文章中详细介绍。</p>
<p>如果文章对您有所帮助的话，麻烦帮忙点个赞，谢谢您的认可与支持。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>源码</tag>
        <tag>ProducerRecord</tag>
        <tag>双端队列</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析 RocketMQ DLedger 多副本即主从切换实现原理</title>
    <url>/posts/433e34a1.html</url>
    <content><![CDATA[<div id="vip-container"><p>DLedger 基于 raft 协议，故天然支持主从切换，即主节点(Leader)发生故障，会重新触发选主，在集群内再选举出新的主节点。</p>
<p>RocketMQ 中主从同步，从节点不仅会从主节点同步数据，也会同步元数据，包含 topic 路由信息、消费进度、延迟队列处理队列、消费组订阅配置等信息。那主从切换后元数据如何同步呢？特别是主从切换过程中，对消息消费有多大的影响，会丢失消息吗？</p>
<blockquote>
<p>温馨提示：本文假设大家已经对 RocketMQ4.5 版本之前的主从同步实现有一定的了解，这部分内容在《RocketMQ技术内幕》一书中有详细的介绍，大家也可以参考如下两篇文章：<br>1、 <a href="https://blog.csdn.net/prestigeding/article/details/93672079">RocketMQ HA机制(主从同步)</a> 。<br>2、<a href="https://blog.csdn.net/prestigeding/article/details/101629440">RocketMQ 整合 DLedger(多副本)即主从切换实现平滑升级的设计技巧</a></p>
</blockquote>
<h2 id="1、BrokerController-中与主从相关的方法详解"><a href="#1、BrokerController-中与主从相关的方法详解" class="headerlink" title="1、BrokerController 中与主从相关的方法详解"></a>1、BrokerController 中与主从相关的方法详解</h2><p>本节先对 BrokerController 中与主从切换相关的方法。</p>
<h3 id="1-1-startProcessorByHa"><a href="#1-1-startProcessorByHa" class="headerlink" title="1.1 startProcessorByHa"></a>1.1 startProcessorByHa</h3><p>BrokerController#startProcessorByHa</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startProcessorByHa</span><span class="params">(BrokerRole role)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (BrokerRole.SLAVE != role) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.transactionalMessageCheckService != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.transactionalMessageCheckService.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>感觉该方法的取名较为随意，该方法的作用是开启事务状态回查处理器，即当节点为主节点时，开启对应的事务状态回查处理器，对PREPARE状态的消息发起事务状态回查请求。</p>
<h3 id="1-2-shutdownProcessorByHa"><a href="#1-2-shutdownProcessorByHa" class="headerlink" title="1.2 shutdownProcessorByHa"></a>1.2 shutdownProcessorByHa</h3><p>BrokerController#shutdownProcessorByHa</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">shutdownProcessorByHa</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.transactionalMessageCheckService != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">this</span>.transactionalMessageCheckService.shutdown(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>关闭事务状态回查处理器，当节点从主节点变更为从节点后，该方法被调用。</p>
<h3 id="1-3-handleSlaveSynchronize"><a href="#1-3-handleSlaveSynchronize" class="headerlink" title="1.3 handleSlaveSynchronize"></a>1.3 handleSlaveSynchronize</h3><p>BrokerController#handleSlaveSynchronize</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleSlaveSynchronize</span><span class="params">(BrokerRole role)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (role == BrokerRole.SLAVE) &#123;   <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != slaveSyncFuture) &#123;   </span><br><span class="line">            slaveSyncFuture.cancel(<span class="keyword">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.slaveSynchronize.setMasterAddr(<span class="keyword">null</span>);   <span class="comment">// </span></span><br><span class="line">        slaveSyncFuture = <span class="keyword">this</span>.scheduledExecutorService.scheduleAtFixedRate(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    BrokerController.<span class="keyword">this</span>.slaveSynchronize.syncAll();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">                    log.error(<span class="string">&quot;ScheduledTask SlaveSynchronize syncAll error.&quot;</span>, e);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="number">1000</span> * <span class="number">3</span>, <span class="number">1000</span> * <span class="number">10</span>, TimeUnit.MILLISECONDS);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  <span class="comment">// @2</span></span><br><span class="line">        <span class="comment">//handle the slave synchronise</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != slaveSyncFuture) &#123;</span><br><span class="line">            slaveSyncFuture.cancel(<span class="keyword">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.slaveSynchronize.setMasterAddr(<span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法的主要作用是处理从节点的元数据同步，即从节点向主节点主动同步 topic 的路由信息、消费进度、延迟队列处理队列、消费组订阅配置等信息。</p>
<p>代码@1：如果当前节点的角色为从节点：</p>
<ul>
<li>如果上次同步的 future 不为空，则首先先取消。</li>
<li>然后设置 slaveSynchronize 的 master 地址为空。不知大家是否与笔者一样，有一个疑问，从节点的时候，如果将 master 地址设置为空，那如何同步元数据，那这个值会在什么时候设置呢？</li>
<li>开启定时同步任务，每 10s 从主节点同步一次元数据。 </li>
</ul>
<p>代码@2：如果当前节点的角色为主节点，则取消定时同步任务并设置 master 的地址为空。</p>
<h3 id="1-4-changeToSlave"><a href="#1-4-changeToSlave" class="headerlink" title="1.4 changeToSlave"></a>1.4 changeToSlave</h3><p>BrokerController#changeToSlave</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">changeToSlave</span><span class="params">(<span class="keyword">int</span> brokerId)</span> </span>&#123;</span><br><span class="line">    log.info(<span class="string">&quot;Begin to change to slave brokerName=&#123;&#125; brokerId=&#123;&#125;&quot;</span>, brokerConfig.getBrokerName(), brokerId);</span><br><span class="line">    <span class="comment">//change the role</span></span><br><span class="line">    brokerConfig.setBrokerId(brokerId == <span class="number">0</span> ? <span class="number">1</span> : brokerId); <span class="comment">//TO DO check       // @1</span></span><br><span class="line">    messageStoreConfig.setBrokerRole(BrokerRole.SLAVE);                            <span class="comment">// @2</span></span><br><span class="line">    <span class="comment">//handle the scheduled service</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.messageStore.handleScheduleMessageService(BrokerRole.SLAVE);    <span class="comment">//  @3</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        log.error(<span class="string">&quot;[MONITOR] handleScheduleMessageService failed when changing to slave&quot;</span>, t);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//handle the transactional service</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.shutdownProcessorByHa();                                                                    <span class="comment">//  @4</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        log.error(<span class="string">&quot;[MONITOR] shutdownProcessorByHa failed when changing to slave&quot;</span>, t);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//handle the slave synchronise</span></span><br><span class="line">    handleSlaveSynchronize(BrokerRole.SLAVE);                                               <span class="comment">// @5</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.registerBrokerAll(<span class="keyword">true</span>, <span class="keyword">true</span>, brokerConfig.isForceRegister());              <span class="comment">// @6</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable ignored) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    log.info(<span class="string">&quot;Finish to change to slave brokerName=&#123;&#125; brokerId=&#123;&#125;&quot;</span>, brokerConfig.getBrokerName(), brokerId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Broker 状态变更为从节点。其关键实现如下：</p>
<ul>
<li>设置 brokerId，如果broker的id为0，则设置为1，这里在使用的时候，注意规划好集群内节点的 brokerId。</li>
<li>设置 broker  的状态为 BrokerRole.SLAVE。</li>
<li>如果是从节点，则关闭定时调度线程(处理 RocketMQ 延迟队列)，如果是主节点，则启动该线程。</li>
<li>关闭事务状态回查处理器。</li>
<li>从节点需要启动元数据同步处理器，即启动 SlaveSynchronize 定时从主服务器同步元数据。</li>
<li>立即向集群内所有的 nameserver 告知 broker  信息状态的变更。</li>
</ul>
<h3 id="1-5-changeToMaster"><a href="#1-5-changeToMaster" class="headerlink" title="1.5 changeToMaster"></a>1.5 changeToMaster</h3><p>BrokerController#changeToMaster</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">changeToMaster</span><span class="params">(BrokerRole role)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (role == BrokerRole.SLAVE) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    log.info(<span class="string">&quot;Begin to change to master brokerName=&#123;&#125;&quot;</span>, brokerConfig.getBrokerName());</span><br><span class="line">    <span class="comment">//handle the slave synchronise</span></span><br><span class="line">    handleSlaveSynchronize(role);   <span class="comment">// @1</span></span><br><span class="line">    <span class="comment">//handle the scheduled service</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.messageStore.handleScheduleMessageService(role);      <span class="comment">// @2</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        log.error(<span class="string">&quot;[MONITOR] handleScheduleMessageService failed when changing to master&quot;</span>, t);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//handle the transactional service</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.startProcessorByHa(BrokerRole.SYNC_MASTER);         <span class="comment">// @3</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        log.error(<span class="string">&quot;[MONITOR] startProcessorByHa failed when changing to master&quot;</span>, t);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//if the operations above are totally successful, we change to master</span></span><br><span class="line">    brokerConfig.setBrokerId(<span class="number">0</span>); <span class="comment">//TO DO check                              // @4</span></span><br><span class="line">    messageStoreConfig.setBrokerRole(role);                               </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.registerBrokerAll(<span class="keyword">true</span>, <span class="keyword">true</span>, brokerConfig.isForceRegister()); <span class="comment">// @5</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable ignored) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    log.info(<span class="string">&quot;Finish to change to master brokerName=&#123;&#125;&quot;</span>, brokerConfig.getBrokerName());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法是 Broker 角色从从节点变更为主节点的处理逻辑，其实现要点如下：</p>
<ul>
<li>关闭元数据同步器，因为主节点无需同步。</li>
<li>开启定时任务处理线程。</li>
<li>开启事务状态回查处理线程。</li>
<li>设置 brokerId 为 0。</li>
<li>向 nameserver 立即发送心跳包以便告知 broker 服务器当前最新的状态。</li>
</ul>
<p>主从节点状态变更的核心方法就介绍到这里了，接下来看看如何触发主从切换。</p>
<h2 id="2、如何触发主从切换"><a href="#2、如何触发主从切换" class="headerlink" title="2、如何触发主从切换"></a>2、如何触发主从切换</h2><p>从前面的文章我们可以得知，RocketMQ DLedger 是基于 raft 协议实现的，在该协议中就实现了主节点的选举与主节点失效后集群会自动进行重新选举，经过协商投票产生新的主节点，从而实现高可用。</p>
<p>BrokerController#initialize</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (messageStoreConfig.isEnableDLegerCommitLog()) &#123;</span><br><span class="line">    DLedgerRoleChangeHandler roleChangeHandler = <span class="keyword">new</span> DLedgerRoleChangeHandler(<span class="keyword">this</span>, (DefaultMessageStore) messageStore);</span><br><span class="line">    ((DLedgerCommitLog)((DefaultMessageStore) messageStore).getCommitLog()).getdLedgerServer().getdLedgerLeaderElector().addRoleChangeHandler(roleChangeHandler);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述代码片段截取自 BrokerController 的 initialize 方法，我们可以得知在 Broker 启动时，如果开启了 多副本机制，即 enableDLedgerCommitLog 参数设置为 true，会为 集群节点选主器添加 roleChangeHandler 事件处理器，即节点发送变更后的事件处理器。</p>
<a id="more"></a>

<p>接下来我们将重点探讨 DLedgerRoleChangeHandler 。</p>
<h3 id="2-1-类图"><a href="#2-1-类图" class="headerlink" title="2.1 类图"></a>2.1 类图</h3><p><img src="https://img-blog.csdnimg.cn/20191006174148582.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>DLedgerRoleChangeHandler 继承自 RoleChangeHandler，即节点状态发生变更后的事件处理器。上述的属性都很简单，在这里就重点介绍一下 ExecutorService executorService，事件处理线程池，但只会开启一个线程，故事件将一个一个按顺序执行。</p>
<p>接下来我们来重点看一下 handle 方法的执行。</p>
<h3 id="2-2-handle-主从状态切换处理逻辑"><a href="#2-2-handle-主从状态切换处理逻辑" class="headerlink" title="2.2 handle 主从状态切换处理逻辑"></a>2.2 handle 主从状态切换处理逻辑</h3><p>DLedgerRoleChangeHandler#handle</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(<span class="keyword">long</span> term, MemberState.Role role)</span> </span>&#123;</span><br><span class="line">    Runnable runnable = <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">boolean</span> succ = <span class="keyword">true</span>;</span><br><span class="line">                log.info(<span class="string">&quot;Begin handling broker role change term=&#123;&#125; role=&#123;&#125; currStoreRole=&#123;&#125;&quot;</span>, term, role, messageStore.getMessageStoreConfig().getBrokerRole());</span><br><span class="line">                <span class="keyword">switch</span> (role) &#123;</span><br><span class="line">                    <span class="keyword">case</span> CANDIDATE:    <span class="comment">// @1</span></span><br><span class="line">                        <span class="keyword">if</span> (messageStore.getMessageStoreConfig().getBrokerRole() != BrokerRole.SLAVE) &#123;</span><br><span class="line">                            brokerController.changeToSlave(dLedgerCommitLog.getId());</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> FOLLOWER:         <span class="comment">// @2</span></span><br><span class="line">                        brokerController.changeToSlave(dLedgerCommitLog.getId());</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> LEADER:           <span class="comment">// @3</span></span><br><span class="line">                        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                            <span class="keyword">if</span> (!dLegerServer.getMemberState().isLeader()) &#123;</span><br><span class="line">                                succ = <span class="keyword">false</span>;</span><br><span class="line">                                <span class="keyword">break</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">if</span> (dLegerServer.getdLedgerStore().getLedgerEndIndex() == -<span class="number">1</span>) &#123;</span><br><span class="line">                                <span class="keyword">break</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">if</span> (dLegerServer.getdLedgerStore().getLedgerEndIndex() == dLegerServer.getdLedgerStore().getCommittedIndex()</span><br><span class="line">                                &amp;&amp; messageStore.dispatchBehindBytes() == <span class="number">0</span>) &#123;</span><br><span class="line">                                <span class="keyword">break</span>;</span><br><span class="line">                            &#125;</span><br><span class="line">                            Thread.sleep(<span class="number">100</span>);</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">if</span> (succ) &#123;</span><br><span class="line">                            messageStore.recoverTopicQueueTable();</span><br><span class="line">                            brokerController.changeToMaster(BrokerRole.SYNC_MASTER);</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">default</span>:</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                log.info(<span class="string">&quot;Finish handling broker role change succ=&#123;&#125; term=&#123;&#125; role=&#123;&#125; currStoreRole=&#123;&#125; cost=&#123;&#125;&quot;</span>, succ, term, role, messageStore.getMessageStoreConfig().getBrokerRole(), DLedgerUtils.elapsed(start));</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">                log.info(<span class="string">&quot;[MONITOR]Failed handling broker role change term=&#123;&#125; role=&#123;&#125; currStoreRole=&#123;&#125; cost=&#123;&#125;&quot;</span>, term, role, messageStore.getMessageStoreConfig().getBrokerRole(), DLedgerUtils.elapsed(start), t);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    executorService.submit(runnable);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果当前节点状态机状态为 CANDIDATE，表示正在发起 Leader 节点，如果该服务器的角色不是 SLAVE 的话，需要将状态切换为 SLAVE。</p>
<p>代码@2：如果当前节点状态机状态为 FOLLOWER，broker 节点将转换为 从节点。</p>
<p>代码@3：如果当前节点状态机状态为 Leader，说明该节点被选举为 Leader，在切换到 Master 节点之前，首先需要等待当前节点追加的数据都已经被提交后才可以将状态变更为 Master，其关键实现如下：</p>
<ul>
<li>如果 ledgerEndIndex 为 -1，表示当前节点还未又数据转发，直接跳出循环，无需等待。</li>
<li>如果 ledgerEndIndex 不为 -1 ，则必须等待数据都已提交，即 ledgerEndIndex 与 committedIndex 相等。</li>
<li>并且需要等待  commitlog 日志全部已转发到 consumequeue中，即 ReputMessageService 中的 reputFromOffset 与 commitlog 的 maxOffset 相等。</li>
</ul>
<p>等待上述条件满足后，即可以进行状态的变更，需要恢复 ConsumeQueue，维护每一个 queue 对应的 maxOffset，然后将 broker 角色转变为 master。</p>
<p>经过上面的步骤，就能实时完成 broker 主节点的自动切换。由于单从代码的角度来看主从切换不够直观，下面我将给出主从切换的流程图。</p>
<h3 id="2-3-主从切换流程图"><a href="#2-3-主从切换流程图" class="headerlink" title="2.3 主从切换流程图"></a>2.3 主从切换流程图</h3><p>由于从源码的角度或许不够直观，故本节给出其流程图。</p>
<blockquote>
<p>温馨提示：该流程图的前半部分在 源码分析 RocketMQ 整合 DLedger(多副本)实现平滑升级的设计技巧 该文中有所阐述。</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/20191006174334194.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="3、主从切换若干问题思考"><a href="#3、主从切换若干问题思考" class="headerlink" title="3、主从切换若干问题思考"></a>3、主从切换若干问题思考</h2><p>我相信经过上面的讲解，大家应该对主从切换的实现原理有了一个比较清晰的理解，我更相信读者朋友们会抛出一个疑问，主从切换会不会丢失消息，消息消费进度是否会丢失而导致重复消费呢？</p>
<h3 id="3-1-消息消费进度是否存在丢失风险"><a href="#3-1-消息消费进度是否存在丢失风险" class="headerlink" title="3.1 消息消费进度是否存在丢失风险"></a>3.1 消息消费进度是否存在丢失风险</h3><p>首先，由于 RocketMQ 元数据，当然也包含消息消费进度的同步是采用的从服务器定时向主服务器拉取进行更新，存在时延，引入 DLedger 机制，也并不保证其一致性，DLedger 只保证 commitlog 文件的一致性。</p>
<p>当主节点宕机后，各个从节点并不会完成同步了消息消费进度，于此同时，消息消费继续，此时消费者会继续从从节点拉取消息进行消费，但汇报的从节点并不一定会成为新的主节点，故消费进度在 broker 端存在丢失的可能性。当然并不是一定会丢失，因为消息消费端只要不重启，消息消费进度会存储在内存中。</p>
<p>综合所述，消息消费进度在 broker  端会有丢失的可能性，存在重复消费的可能性，不过问题不大，因为 RocketMQ 本身也不承若不会重复消费。</p>
<h3 id="3-2-消息是否存在丢失风险"><a href="#3-2-消息是否存在丢失风险" class="headerlink" title="3.2 消息是否存在丢失风险"></a>3.2 消息是否存在丢失风险</h3><p>消息会不会丢失的关键在于，日志复制进度较慢的从节点是否可以被选举为主节点，如果在一个集群中，从节点的复制进度落后与从主节点，但当主节点宕机后，如果该从节点被选举成为新的主节点，那这将是一个灾难，将会丢失数据。关于一个节点是否给另外一个节点投赞成票的逻辑在 <a href="https://blog.csdn.net/prestigeding/article/details/99697323">源码分析 RocketMQ DLedger 多副本之 Leader 选主</a> 的 2.4.2 handleVote 方法中已详细介绍，在这里我以截图的方式再展示其核心点：<br><img src="https://img-blog.csdnimg.cn/20191006175156723.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191006175216215.png" alt="在这里插入图片描述"><br>从上面可以得知，如果发起投票节点的复制进度比自己小的话，会投拒绝票。其<br><img src="https://img-blog.csdnimg.cn/20191006175250767.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191006175310688.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>必须得到集群内超过半数节点认可，即最终选举出来的主节点的当前复制进度一定是比绝大多数的从节点要大，并且也会等于承偌给客户端的已提交偏移量。故得出的结论是不会丢消息。</p>
<p>本文的介绍就到此为止了，最后抛出一个思考题与大家相互交流学习，也算是对 DLedger 多副本即主从切换一个总结回顾。答案我会以留言的方式或在下一篇文章中给出。</p>
<h2 id="4、思考题"><a href="#4、思考题" class="headerlink" title="4、思考题"></a>4、思考题</h2><p>例如一个集群内有5个节点的 DLedgr 集群。<br>Leader Node:  n0-broker-a<br>folloer Node:   n1-broker-a,n2-broker-a,n3-broker-a,n4-broker-a</p>
<p>从节点的复制进度可能不一致，例如：<br>n1-broker-a复制进度为 100<br>n2-broker-a复制进度为 120<br>n3-broker-a复制进度为 90<br>n4-broker-a负载进度为 90</p>
<p>如果此时 n0-broker-a 节点宕机，触发选主，如果  n1率先发起投票，由于 n1,的复制进度大于 n3,n4，再加上自己一票，是有可能成为leader的，此时消息会丢失吗？为什么？</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>多副本</tag>
        <tag>主从切换</tag>
        <tag>DLedger</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析 RocketMQ DLedger(多副本) 之日志追加流程</title>
    <url>/posts/d35cbb14.html</url>
    <content><![CDATA[<div id="vip-container"><p>根据 raft 协议可知，当整个集群完成 Leader 选主后，集群中的主节点就可以接受客户端的请求，而集群中的从节点只负责从主节点同步数据，而不会处理读写请求，与M-S结构的读写分离有着巨大的区别。</p>
<p>有了前篇文章的基础，本文将直接从 Leader 处理客户端请求入口开始，其入口为：DLedgerServer 的 handleAppend 方法开始讲起。</p>
<h2 id="1、日志复制基本流程"><a href="#1、日志复制基本流程" class="headerlink" title="1、日志复制基本流程"></a>1、日志复制基本流程</h2><p>在正式分析 RocketMQ DLedger 多副本复制之前，我们首先来了解客户端发送日志的请求协议字段，其类图如下所示：<br><img src="https://img-blog.csdnimg.cn/20190914204415722.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们先一一介绍各个字段的含义：</p>
<ul>
<li>String group<br>该集群所属组名。</li>
<li>String remoteId<br>请求目的节点ID。</li>
<li>String localId<br>节点ID。</li>
<li>int code<br>请求响应字段，表示返回响应码。</li>
<li>String leaderId = null<br>集群中的Leader Id。</li>
<li>long term<br>集群当前的选举轮次。</li>
<li>byte[] body<br>待发送的数据。</li>
</ul>
<p>日志的请求处理处理入口为 DLedgerServer 的 handleAppend 方法。</p>
<p>DLedgerServer#handleAppend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PreConditions.check(memberState.getSelfId().equals(request.getRemoteId()), DLedgerResponseCode.UNKNOWN_MEMBER, <span class="string">&quot;%s != %s&quot;</span>, request.getRemoteId(), memberState.getSelfId());</span><br><span class="line">reConditions.check(memberState.getGroup().equals(request.getGroup()), DLedgerResponseCode.UNKNOWN_GROUP, <span class="string">&quot;%s != %s&quot;</span>, request.getGroup(), memberState.getGroup());</span><br><span class="line">PreConditions.check(memberState.isLeader(), DLedgerResponseCode.NOT_LEADER);</span><br></pre></td></tr></table></figure>
<p>Step1：首先验证请求的合理性：</p>
<ul>
<li>如果请求的节点ID不是当前处理节点，则抛出异常。</li>
<li>如果请求的集群不是当前节点所在的集群，则抛出异常。</li>
<li>如果当前节点不是主节点，则抛出异常。</li>
</ul>
<p>DLedgerServer#handleAppend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> currTerm = memberState.currTerm();</span><br><span class="line"><span class="keyword">if</span> (dLedgerEntryPusher.isPendingFull(currTerm)) &#123;  <span class="comment">// @1</span></span><br><span class="line">    AppendEntryResponse appendEntryResponse = <span class="keyword">new</span> AppendEntryResponse();</span><br><span class="line">    appendEntryResponse.setGroup(memberState.getGroup());</span><br><span class="line">    appendEntryResponse.setCode(DLedgerResponseCode.LEADER_PENDING_FULL.getCode());</span><br><span class="line">    appendEntryResponse.setTerm(currTerm);</span><br><span class="line">    appendEntryResponse.setLeaderId(memberState.getSelfId());</span><br><span class="line">    <span class="keyword">return</span> AppendFuture.newCompletedFuture(-<span class="number">1</span>, appendEntryResponse);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;   <span class="comment">// @2</span></span><br><span class="line">    DLedgerEntry dLedgerEntry = <span class="keyword">new</span> DLedgerEntry();</span><br><span class="line">    dLedgerEntry.setBody(request.getBody());</span><br><span class="line">    DLedgerEntry resEntry = dLedgerStore.appendAsLeader(dLedgerEntry);</span><br><span class="line">    <span class="keyword">return</span> dLedgerEntryPusher.waitAck(resEntry);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：如果预处理队列已经满了，则拒绝客户端请求，返回 LEADER_PENDING_FULL 错误码；如果未满，将请求封装成 DledgerEntry，则调用 dLedgerStore 方法追加日志，并且通过使用 dLedgerEntryPusher 的 waitAck 方法同步等待副本节点的复制响应，并最终将结果返回给调用方法。</p>
<ul>
<li>代码@1：如果 dLedgerEntryPusher 的 push 队列已满，则返回追加一次，其错误码为 LEADER_PENDING_FULL。</li>
<li>代码@2：追加消息到 Leader 服务器，并向从节点广播，在指定时间内如果未收到从节点的确认，则认为追加失败。</li>
</ul>
<p>接下来就按照上述三个要点进行展开：</p>
<ul>
<li>判断 Push 队列是否已满</li>
<li>Leader 节点存储消息</li>
<li>主节点等待从节点复制 ACK</li>
</ul>
<h3 id="1-1-如何判断-Push-队列是否已满"><a href="#1-1-如何判断-Push-队列是否已满" class="headerlink" title="1.1  如何判断 Push 队列是否已满"></a>1.1  如何判断 Push 队列是否已满</h3><p>DLedgerEntryPusher#isPendingFull</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isPendingFull</span><span class="params">(<span class="keyword">long</span> currTerm)</span> </span>&#123;</span><br><span class="line">    checkTermForPendingMap(currTerm, <span class="string">&quot;isPendingFull&quot;</span>);     <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span> pendingAppendResponsesByTerm.get(currTerm).size() &gt; dLedgerConfig.getMaxPendingRequestsNum(); <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>主要分两个步骤：<br>代码@1：检查当前投票轮次是否在 PendingMap 中，如果不在，则初始化，其结构为：Map&lt; Long/* 投票轮次*/, ConcurrentMap&lt;Long, TimeoutFuture&lt; AppendEntryResponse&gt;&gt;&gt;。</p>
<p>代码@2：检测当前等待从节点返回结果的个数是否超过其最大请求数量，可通过maxPendingRequests<br>Num 配置，该值默认为：10000。</p>
<p>上述逻辑比较简单，但疑问随着而来，ConcurrentMap&lt;Long, TimeoutFuture&lt; AppendEntryResponse&gt;&gt; 中的数据是从何而来的呢？我们不妨接着往下看。</p>
<a id="more"></a>

<h3 id="1-2-Leader-节点存储数据"><a href="#1-2-Leader-节点存储数据" class="headerlink" title="1.2  Leader 节点存储数据"></a>1.2  Leader 节点存储数据</h3><p>Leader 节点的数据存储主要由 DLedgerStore 的 appendAsLeader 方法实现。DLedger 分别实现了基于内存、基于文件的存储实现，本文重点关注基于文件的存储实现，其实现类为：DLedgerMmapFileStore。</p>
<p>下面重点来分析一下数据存储流程，其入口为DLedgerMmapFileStore 的 appendAsLeader 方法。</p>
<p>DLedgerMmapFileStore#appendAsLeader</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PreConditions.check(memberState.isLeader(), DLedgerResponseCode.NOT_LEADER);</span><br><span class="line">PreConditions.check(!isDiskFull, DLedgerResponseCode.DISK_FULL);</span><br></pre></td></tr></table></figure>
<p>Step1：首先判断是否可以追加数据，其判断依据主要是如下两点：</p>
<ul>
<li>当前节点的状态是否是 Leader，如果不是，则抛出异常。</li>
<li>当前磁盘是否已满，其判断依据是 DLedger 的根目录或数据文件目录的使用率超过了允许使用的最大值，默认值为85%。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ByteBuffer dataBuffer = localEntryBuffer.get();</span><br><span class="line">ByteBuffer indexBuffer = localIndexBuffer.get();</span><br></pre></td></tr></table></figure>
<p>Step2：从本地线程变量获取一个数据与索引 buffer。其中用于存储数据的 ByteBuffer，其容量固定为 4M ，索引的 ByteBuffer 为两个索引条目的长度，固定为64个字节。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DLedgerEntryCoder.encode(entry, dataBuffer);</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">encode</span><span class="params">(DLedgerEntry entry, ByteBuffer byteBuffer)</span> </span>&#123;</span><br><span class="line">    byteBuffer.clear();</span><br><span class="line">    <span class="keyword">int</span> size = entry.computSizeInBytes();</span><br><span class="line">    <span class="comment">//always put magic on the first position</span></span><br><span class="line">    byteBuffer.putInt(entry.getMagic());</span><br><span class="line">    byteBuffer.putInt(size);</span><br><span class="line">    byteBuffer.putLong(entry.getIndex());</span><br><span class="line">    byteBuffer.putLong(entry.getTerm());</span><br><span class="line">    byteBuffer.putLong(entry.getPos());</span><br><span class="line">    byteBuffer.putInt(entry.getChannel());</span><br><span class="line">    byteBuffer.putInt(entry.getChainCrc());</span><br><span class="line">    byteBuffer.putInt(entry.getBodyCrc());</span><br><span class="line">    byteBuffer.putInt(entry.getBody().length);</span><br><span class="line">    byteBuffer.put(entry.getBody());</span><br><span class="line">    byteBuffer.flip();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step3：将 DLedgerEntry，即将数据写入到 ByteBuffer中，从这里看出，每一次写入会调用 ByteBuffer 的 clear 方法，将数据清空，从这里可以看出，每一次数据追加，只能存储4M的数据。</p>
<p>DLedgerMmapFileStore#appendAsLeader</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">synchronized</span> (memberState) &#123;</span><br><span class="line">    PreConditions.check(memberState.isLeader(), DLedgerResponseCode.NOT_LEADER, <span class="keyword">null</span>);</span><br><span class="line">	<span class="comment">// ... 省略代码</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step4：锁定状态机，并再一次检测节点的状态是否是 Leader 节点。</p>
<p>DLedgerMmapFileStore#appendAsLeader</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> nextIndex = ledgerEndIndex + <span class="number">1</span>;</span><br><span class="line">entry.setIndex(nextIndex);</span><br><span class="line">entry.setTerm(memberState.currTerm());</span><br><span class="line">entry.setMagic(CURRENT_MAGIC);</span><br><span class="line">DLedgerEntryCoder.setIndexTerm(dataBuffer, nextIndex, memberState.currTerm(), CURRENT_MAGIC);</span><br></pre></td></tr></table></figure>
<p>Step5：为当前日志条目设置序号，即 entryIndex 与 entryTerm (投票轮次)。并将魔数、entryIndex、entryTerm 等写入到 bytebuffer 中。</p>
<p>DLedgerMmapFileStore#appendAsLeader</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> prePos = dataFileList.preAppend(dataBuffer.remaining());</span><br><span class="line">entry.setPos(prePos);</span><br><span class="line">PreConditions.check(prePos != -<span class="number">1</span>, DLedgerResponseCode.DISK_ERROR, <span class="keyword">null</span>);</span><br><span class="line">DLedgerEntryCoder.setPos(dataBuffer, prePos);</span><br></pre></td></tr></table></figure>
<p>Step6：计算新的消息的起始偏移量，关于 dataFileList 的 preAppend 后续详细介绍其实现，然后将该偏移量写入日志的 bytebuffer 中。</p>
<p>DLedgerMmapFileStore#appendAsLeader</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (AppendHook writeHook : appendHooks) &#123;</span><br><span class="line">    writeHook.doHook(entry, dataBuffer.slice(), DLedgerEntry.BODY_OFFSET);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step7：执行钩子函数。</p>
<p>DLedgerMmapFileStore#appendAsLeader</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> dataPos = dataFileList.append(dataBuffer.array(), <span class="number">0</span>, dataBuffer.remaining());</span><br><span class="line">PreConditions.check(dataPos != -<span class="number">1</span>, DLedgerResponseCode.DISK_ERROR, <span class="keyword">null</span>);</span><br><span class="line">PreConditions.check(dataPos == prePos, DLedgerResponseCode.DISK_ERROR, <span class="keyword">null</span>);</span><br></pre></td></tr></table></figure>
<p>Step8：将数据追加到 pagecache 中。该方法稍后详细介绍。</p>
<p>DLedgerMmapFileStore#appendAsLeader</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DLedgerEntryCoder.encodeIndex(dataPos, entrySize, CURRENT_MAGIC, nextIndex, memberState.currTerm(), indexBuffer);</span><br><span class="line"><span class="keyword">long</span> indexPos = indexFileList.append(indexBuffer.array(), <span class="number">0</span>, indexBuffer.remaining(), <span class="keyword">false</span>);</span><br><span class="line">PreConditions.check(indexPos == entry.getIndex() * INDEX_UNIT_SIZE, DLedgerResponseCode.DISK_ERROR, <span class="keyword">null</span>);</span><br></pre></td></tr></table></figure>
<p>Step9：构建条目索引并将索引数据追加到 pagecache。</p>
<p>DLedgerMmapFileStore#appendAsLeader</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ledgerEndIndex++;</span><br><span class="line">ledgerEndTerm = memberState.currTerm();</span><br><span class="line"><span class="keyword">if</span> (ledgerBeginIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">    ledgerBeginIndex = ledgerEndIndex;</span><br><span class="line">&#125;</span><br><span class="line">updateLedgerEndIndexAndTerm();</span><br></pre></td></tr></table></figure>
<p>Step10：ledgerEndeIndex 加一（下一个条目）的序号。并设置 leader 节点的状态机的 ledgerEndIndex 与 ledgerEndTerm。</p>
<p>Leader 节点数据追加就介绍到这里，稍后会重点介绍与存储相关方法的实现细节。</p>
<h3 id="1-3-主节点等待从节点复制-ACK"><a href="#1-3-主节点等待从节点复制-ACK" class="headerlink" title="1.3 主节点等待从节点复制 ACK"></a>1.3 主节点等待从节点复制 ACK</h3><p>其实现入口为 dLedgerEntryPusher 的 waitAck 方法。</p>
<p>DLedgerEntryPusher#waitAck</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;AppendEntryResponse&gt; <span class="title">waitAck</span><span class="params">(DLedgerEntry entry)</span> </span>&#123;</span><br><span class="line">    updatePeerWaterMark(entry.getTerm(), memberState.getSelfId(), entry.getIndex());    <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (memberState.getPeerMap().size() == <span class="number">1</span>) &#123;                                                                  <span class="comment">// @2</span></span><br><span class="line">        AppendEntryResponse response = <span class="keyword">new</span> AppendEntryResponse();</span><br><span class="line">        response.setGroup(memberState.getGroup());</span><br><span class="line">        response.setLeaderId(memberState.getSelfId());</span><br><span class="line">        response.setIndex(entry.getIndex());</span><br><span class="line">        response.setTerm(entry.getTerm());</span><br><span class="line">        response.setPos(entry.getPos());</span><br><span class="line">        <span class="keyword">return</span> AppendFuture.newCompletedFuture(entry.getPos(), response);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        checkTermForPendingMap(entry.getTerm(), <span class="string">&quot;waitAck&quot;</span>);                                            </span><br><span class="line">        AppendFuture&lt;AppendEntryResponse&gt; future = <span class="keyword">new</span> AppendFuture&lt;&gt;(dLedgerConfig.getMaxWaitAckTimeMs()); <span class="comment">// @3</span></span><br><span class="line">        future.setPos(entry.getPos());</span><br><span class="line">        CompletableFuture&lt;AppendEntryResponse&gt; old = pendingAppendResponsesByTerm.get(entry.getTerm()).put(entry.getIndex(), future);     <span class="comment">// @4</span></span><br><span class="line">        <span class="keyword">if</span> (old != <span class="keyword">null</span>) &#123;</span><br><span class="line">            logger.warn(<span class="string">&quot;[MONITOR] get old wait at index=&#123;&#125;&quot;</span>, entry.getIndex());</span><br><span class="line">        &#125;</span><br><span class="line">        wakeUpDispatchers();                                       <span class="comment">// @5</span></span><br><span class="line">        <span class="keyword">return</span> future;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：更新当前节点的 push 水位线。<br>代码@2：如果集群的节点个数为1，无需转发，直接返回成功结果。<br>代码@3：构建 append 响应 Future 并设置超时时间，默认值为：2500 ms，可以通过 maxWaitAckTimeMs 配置改变其默认值。<br>代码@4：将构建的 Future 放入等待结果集合中。<br>代码@5：唤醒 Entry 转发线程，即将主节点中的数据 push 到各个从节点。</p>
<p>接下来分别对上述几个关键点进行解读。</p>
<h4 id="1-3-1-updatePeerWaterMark-方法"><a href="#1-3-1-updatePeerWaterMark-方法" class="headerlink" title="1.3.1 updatePeerWaterMark 方法"></a>1.3.1 updatePeerWaterMark 方法</h4><p>DLedgerEntryPusher#updatePeerWaterMark</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">updatePeerWaterMark</span><span class="params">(<span class="keyword">long</span> term, String peerId, <span class="keyword">long</span> index)</span> </span>&#123;    <span class="comment">// 代码@1</span></span><br><span class="line">    <span class="keyword">synchronized</span> (peerWaterMarksByTerm) &#123; </span><br><span class="line">       checkTermForWaterMark(term, <span class="string">&quot;updatePeerWaterMark&quot;</span>);                     <span class="comment">// 代码@2</span></span><br><span class="line">        <span class="keyword">if</span> (peerWaterMarksByTerm.get(term).get(peerId) &lt; index) &#123;                   <span class="comment">// 代码@3</span></span><br><span class="line">            peerWaterMarksByTerm.get(term).put(peerId, index);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：先来简单介绍该方法的两个参数：</p>
<ul>
<li>long term<br>当前的投票轮次。</li>
<li>String peerId<br>当前节点的ID。</li>
<li>long index<br>当前追加数据的序号。</li>
</ul>
<p>代码@2：初始化 peerWaterMarksByTerm 数据结构，其结果为 &lt; Long /** term  */, Map&lt; String /** peerId */, Long /** entry index*/&gt;。</p>
<p>代码@3：如果 peerWaterMarksByTerm 存储的 index 小于当前数据的 index，则更新。</p>
<h4 id="1-3-2-wakeUpDispatchers-详解"><a href="#1-3-2-wakeUpDispatchers-详解" class="headerlink" title="1.3.2  wakeUpDispatchers 详解"></a>1.3.2  wakeUpDispatchers 详解</h4><p>DLedgerEntryPusher#updatePeerWaterMark</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">wakeUpDispatchers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (EntryDispatcher dispatcher : dispatcherMap.values()) &#123;</span><br><span class="line">        dispatcher.wakeup();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法主要就是遍历转发器并唤醒。本方法的核心关键就是 EntryDispatcher，在详细介绍它之前我们先来看一下该集合的初始化。</p>
<p>DLedgerEntryPusher 构造方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (String peer : memberState.getPeerMap().keySet()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!peer.equals(memberState.getSelfId())) &#123;</span><br><span class="line">        dispatcherMap.put(peer, <span class="keyword">new</span> EntryDispatcher(peer, logger));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>原来在构建 DLedgerEntryPusher 时会为每一个从节点创建一个 EntryDispatcher 对象。</p>
<p>显然，日志的复制由 DLedgerEntryPusher 来实现。由于篇幅的原因，该部分内容将在下篇文章中继续。</p>
<p>上面在讲解 Leader 追加日志时并没有详细分析存储相关的实现，为了知识体系的完备，接下来我们来分析一下其核心实现。</p>
<h2 id="2、日志存储实现详情"><a href="#2、日志存储实现详情" class="headerlink" title="2、日志存储实现详情"></a>2、日志存储实现详情</h2><p>本节主要对 MmapFileList 的 preAppend 与 append 方法进行详细讲解。</p>
<blockquote>
<p>存储部分的设计请查阅笔者的博客：<a href="https://blog.csdn.net/prestigeding/article/details/100177780">源码分析 RocketMQ DLedger 多副本存储实现</a>，MmapFileList 对标 RocketMQ 的MappedFileQueue。</p>
</blockquote>
<h3 id="2-1-MmapFileList-的-preAppend-详解"><a href="#2-1-MmapFileList-的-preAppend-详解" class="headerlink" title="2.1 MmapFileList 的 preAppend 详解"></a>2.1 MmapFileList 的 preAppend 详解</h3><p>该方法最终会调用两个参数的 preAppend方法，故我们直接来看两个参数的 preAppend 方法。</p>
<p>MmapFileList#preAppend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">preAppend</span><span class="params">(<span class="keyword">int</span> len, <span class="keyword">boolean</span> useBlank)</span> </span>&#123;                <span class="comment">// @1</span></span><br><span class="line">    MmapFile mappedFile = getLastMappedFile();                   <span class="comment">// @2 start</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == mappedFile || mappedFile.isFull()) &#123;</span><br><span class="line">        mappedFile = getLastMappedFile(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == mappedFile) &#123;</span><br><span class="line">        logger.error(<span class="string">&quot;Create mapped file for &#123;&#125;&quot;</span>, storePath);</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;                                                                                            <span class="comment">// @2 end</span></span><br><span class="line">    <span class="keyword">int</span> blank = useBlank ? MIN_BLANK_LEN : <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (len + blank &gt; mappedFile.getFileSize() - mappedFile.getWrotePosition()) &#123;   <span class="comment">// @3</span></span><br><span class="line">        <span class="keyword">if</span> (blank &lt; MIN_BLANK_LEN) &#123;</span><br><span class="line">            logger.error(<span class="string">&quot;Blank &#123;&#125; should ge &#123;&#125;&quot;</span>, blank, MIN_BLANK_LEN);</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            ByteBuffer byteBuffer = ByteBuffer.allocate(mappedFile.getFileSize() - mappedFile.getWrotePosition());     <span class="comment">// @4</span></span><br><span class="line">            byteBuffer.putInt(BLANK_MAGIC_CODE);                                                                                                      <span class="comment">// @5</span></span><br><span class="line">            byteBuffer.putInt(mappedFile.getFileSize() - mappedFile.getWrotePosition());                                               <span class="comment">// @6</span></span><br><span class="line">            <span class="keyword">if</span> (mappedFile.appendMessage(byteBuffer.array())) &#123;                                                                                     <span class="comment">// @7</span></span><br><span class="line">                <span class="comment">//need to set the wrote position</span></span><br><span class="line">                mappedFile.setWrotePosition(mappedFile.getFileSize());</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                logger.error(<span class="string">&quot;Append blank error for &#123;&#125;&quot;</span>, storePath);</span><br><span class="line">                <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            mappedFile = getLastMappedFile(<span class="number">0</span>);</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">null</span> == mappedFile) &#123;</span><br><span class="line">                logger.error(<span class="string">&quot;Create mapped file for &#123;&#125;&quot;</span>, storePath);</span><br><span class="line">                <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> mappedFile.getFileFromOffset() + mappedFile.getWrotePosition();<span class="comment">// @8</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先介绍其参数的含义：</p>
<ul>
<li>int len 需要申请的长度。</li>
<li>boolean useBlank 是否需要填充，默认为true。</li>
</ul>
<p>代码@2：获取最后一个文件，即获取当前正在写的文件。</p>
<p>代码@3：如果需要申请的资源超过了当前文件可写字节时，需要处理的逻辑。代码@4-@7都是其处理逻辑。</p>
<p>代码@4：申请一个当前文件剩余字节的大小的bytebuffer。</p>
<p>代码@5：先写入魔数。</p>
<p>代码@6：写入字节长度，等于当前文件剩余的总大小。</p>
<p>代码@7：写入空字节，代码@4-@7的用意就是写一条空Entry，填入魔数与 size，方便解析。</p>
<p>代码@8：如果当前文件足以容纳待写入的日志，则直接返回其物理偏移量。</p>
<p>经过上述代码解读，我们很容易得出该方法的作用，就是返回待写入日志的起始物理偏移量。</p>
<h3 id="2-2-MmapFileList-的-append-详解"><a href="#2-2-MmapFileList-的-append-详解" class="headerlink" title="2.2 MmapFileList 的 append 详解"></a>2.2 MmapFileList 的 append 详解</h3><p>最终会调用4个参数的 append 方法，其代码如下：<br>MmapFileList#append</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">append</span><span class="params">(<span class="keyword">byte</span>[] data, <span class="keyword">int</span> pos, <span class="keyword">int</span> len, <span class="keyword">boolean</span> useBlank)</span> </span>&#123;  <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (preAppend(len, useBlank) == -<span class="number">1</span>) &#123;</span><br><span class="line">		<span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    MmapFile mappedFile = getLastMappedFile();                               <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">long</span> currPosition = mappedFile.getFileFromOffset() + mappedFile.getWrotePosition();   <span class="comment">// @3</span></span><br><span class="line">    <span class="keyword">if</span> (!mappedFile.appendMessage(data, pos, len)) &#123;            <span class="comment">// @4</span></span><br><span class="line">        logger.error(<span class="string">&quot;Append error for &#123;&#125;&quot;</span>, storePath);</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> currPosition;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先介绍一下各个参数：</p>
<ul>
<li>byte[] data<br>待写入的数据，即待追加的日志。</li>
<li>int pos<br>从 data 字节数组哪个位置开始读取。</li>
<li>int len<br>待写入的字节数量。</li>
<li>boolean useBlank<br>是否使用填充，默认为 true。</li>
</ul>
<p>代码@2：获取最后一个文件，即当前可写的文件。</p>
<p>代码@3：获取当前写入指针。</p>
<p>代码@4：追加消息。</p>
<p>最后我们再来看一下 appendMessage，具体的消息追加实现逻辑。</p>
<p>DefaultMmapFile#appendMessage</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">appendMessage</span><span class="params">(<span class="keyword">final</span> <span class="keyword">byte</span>[] data, <span class="keyword">final</span> <span class="keyword">int</span> offset, <span class="keyword">final</span> <span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> currentPos = <span class="keyword">this</span>.wrotePosition.get();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ((currentPos + length) &lt;= <span class="keyword">this</span>.fileSize) &#123;</span><br><span class="line">        ByteBuffer byteBuffer = <span class="keyword">this</span>.mappedByteBuffer.slice(); <span class="comment">// @1</span></span><br><span class="line">        byteBuffer.position(currentPos);</span><br><span class="line">        byteBuffer.put(data, offset, length);</span><br><span class="line">        <span class="keyword">this</span>.wrotePosition.addAndGet(length);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法我主要是想突出一下写入的方式是 mappedByteBuffer，是通过 FileChannel 的 map 方法创建，即我们常说的 PageCache，即消息追加首先是写入到 pageCache 中。</p>
<p><strong>本文详细介绍了 Leader 节点处理客户端消息追加请求的前面两个步骤，即 判断 Push 队列是否已满 与 Leader 节点存储消息。考虑到篇幅的问题，各个节点的数据同步将在下一篇文章中详细介绍。</strong></p>
<p>在进入下一篇的文章学习之前，我们不妨思考一下如下问题：</p>
<ol>
<li>如果主节点追加成功（写入到 PageCache)，但同步到从节点过程失败或此时主节点宕机，集群中的数据如何保证一致性？</li>
</ol>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>多副本</tag>
        <tag>主从切换</tag>
        <tag>DLedger</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析RocketMQ ACL实现机制</title>
    <url>/posts/a6ee7996.html</url>
    <content><![CDATA[<div id="vip-container"><p>有关RocketMQ ACL的使用请查看上一篇<a href="https://blog.csdn.net/prestigeding/article/details/94317946">《RocketMQ ACL使用指南》</a>，本文从源码的角度，分析一下RocketMQ ACL的实现原理。</p>
<blockquote>
<p>备注：RocketMQ在4.4.0时引入了ACL机制，本文代码基于RocketMQ4.5.0版本。</p>
</blockquote>
<p>@<a href="%E6%9C%AC%E8%8A%82%E7%9B%AE%E5%BD%95">TOC</a><br>根据RocketMQ ACL使用手册，我们应该首先看一下Broker服务器在开启ACL机制时如何加载配置文件，并如何工作的。</p>
<h2 id="1、BrokerController-initialAcl"><a href="#1、BrokerController-initialAcl" class="headerlink" title="1、BrokerController#initialAcl"></a>1、BrokerController#initialAcl</h2><p>Broker端ACL的入口代码为：BrokerController#initialAcl</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initialAcl</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">this</span>.brokerConfig.isAclEnable()) &#123;                           <span class="comment">// @1</span></span><br><span class="line">        log.info(<span class="string">&quot;The broker dose not enable acl&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    List&lt;AccessValidator&gt; accessValidators = ServiceProvider.load(ServiceProvider.ACL_VALIDATOR_ID, AccessValidator.class);   <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">if</span> (accessValidators == <span class="keyword">null</span> || accessValidators.isEmpty()) &#123;</span><br><span class="line">        log.info(<span class="string">&quot;The broker dose not load the AccessValidator&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (AccessValidator accessValidator: accessValidators) &#123;                       <span class="comment">// @3</span></span><br><span class="line">        <span class="keyword">final</span> AccessValidator validator = accessValidator;</span><br><span class="line">        <span class="keyword">this</span>.registerServerRPCHook(<span class="keyword">new</span> RPCHook() &#123;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doBeforeRequest</span><span class="params">(String remoteAddr, RemotingCommand request)</span> </span>&#123;</span><br><span class="line">                <span class="comment">//Do not catch the exception</span></span><br><span class="line">                validator.validate(validator.parse(request, remoteAddr));                         <span class="comment">// @4</span></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doAfterResponse</span><span class="params">(String remoteAddr, RemotingCommand request, RemotingCommand response)</span> </span>&#123;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>本方法的实现共4个关键点。<br>代码@1：首先判断Broker是否开启了acl，通过配置参数aclEnable指定，默认为false。</p>
<p>代码@2：使用类似SPI机制，加载配置的AccessValidator,该方法返回一个列表，其实现逻辑时读取META-INF/service/org.apache.rocketmq.acl.AccessValidator文件中配置的访问验证器，默认配置内容如下：<br><img src="https://img-blog.csdnimg.cn/20190707120439720.png" alt="在这里插入图片描述"><br>代码@3：遍历配置的访问验证器(AccessValidator),并向Broker处理服务器注册钩子函数，RPCHook的doBeforeRequest方法会在服务端接收到请求，将其请求解码后，执行处理请求之前被调用;RPCHook的doAfterResponse方法会在处理完请求后，将结果返回之前被调用，其调用如图所示：<br><img src="https://img-blog.csdnimg.cn/20190707120505807.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>代码@4：在RPCHook#doBeforeRequest方法中调用AccessValidator#validate, 在真实处理命令之前，先执行ACL的验证逻辑，如果拥有该操作的执行权限，则放行，否则抛出AclException。</p>
<p>接下来，我们将重点放到Broker默认实现的访问验证器：PlainAccessValidator。</p>
<h2 id="2、PlainAccessValidator"><a href="#2、PlainAccessValidator" class="headerlink" title="2、PlainAccessValidator"></a>2、PlainAccessValidator</h2><h3 id="2-1-类图"><a href="#2-1-类图" class="headerlink" title="2.1 类图"></a>2.1 类图</h3><p><img src="https://img-blog.csdnimg.cn/20190707120530560.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li>AccessValidator<br>访问验证器接口，主要定义两个接口。<br>1）AccessResource parse(RemotingCommand request, String remoteAddr)<br>从请求头中解析本次请求对应的访问资源，即本次请求需要的访问权限。<br>2）void validate(AccessResource accessResource)<br>根据本次需要访问的权限，与请求用户拥有的权限进行对比验证，判断是拥有权限，如果没有访问该操作的权限，则抛出异常，否则放行。</li>
<li>PlainAccessValidator<br>RocketMQ默认提供的基于yml配置格式的访问验证器。</li>
</ul>
<p>接下来我们重点看一下PlainAccessValidator的parse方法与validate方法的实现细节。在讲解该方法之前，我们首先认识一下RocketMQ封装访问资源的PlainAccessResource。</p>
<a id="more"></a>

<h4 id="2-1-2-PlainAccessResource类图"><a href="#2-1-2-PlainAccessResource类图" class="headerlink" title="2.1.2 PlainAccessResource类图"></a>2.1.2 PlainAccessResource类图</h4><p><img src="https://img-blog.csdnimg.cn/20190707120741119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们对其属性一一做个介绍：</p>
<ul>
<li>private String accessKey<br>访问Key，用户名。</li>
<li>private String secretKey<br>用户密码。</li>
<li>private String whiteRemoteAddress<br>远程IP地址白名单。</li>
<li>private boolean admin<br>是否是管理员角色。</li>
<li>private byte defaultTopicPerm = 1<br>默认topic访问权限，即如果没有配置topic的权限，则Topic默认的访问权限为1，表示为DENY。</li>
<li>private byte defaultGroupPerm = 1<br>默认的消费组访问权限，默认为DENY。</li>
<li>private Map&lt;String, Byte&gt; resourcePermMap<br>资源需要的访问权限映射表。</li>
<li>private RemoteAddressStrategy remoteAddressStrategy<br>远程IP地址验证策略。</li>
<li>private int requestCode<br>当前请求的requestCode。</li>
<li>private byte[] content<br>请求头与请求体的内容。</li>
<li>private String signature<br>签名字符串，这是通常的套路，在客户端时，首先将请求参数排序，然后使用secretKey生成签名字符串，服务端重复这个步骤，然后对比签名字符串，如果相同，则认为登录成功，否则失败。</li>
<li>private String secretToken<br>密钥token。</li>
<li>private String recognition<br>目前作用未知，代码中目前未被使用。</li>
</ul>
<h3 id="2-2-构造方法"><a href="#2-2-构造方法" class="headerlink" title="2.2 构造方法"></a>2.2 构造方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">PlainAccessValidator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    aclPlugEngine = <span class="keyword">new</span> PlainPermissionLoader();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>构造函数，直接创建PlainPermissionLoader对象，从命名上来看，应该是触发acl规则的加载，即解析plain_acl.yml，接下来会重点探讨，即acl启动流程之配置文件的解析。</p>
<h3 id="2-3-parse方法"><a href="#2-3-parse方法" class="headerlink" title="2.3 parse方法"></a>2.3 parse方法</h3><p>该方法的作用就是从请求命令中解析出本次访问所需要的访问权限，最终构建AccessResource对象，为后续的校验权限做准备。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PlainAccessResource accessResource = <span class="keyword">new</span> PlainAccessResource();</span><br><span class="line"><span class="keyword">if</span> (remoteAddr != <span class="keyword">null</span> &amp;&amp; remoteAddr.contains(<span class="string">&quot;:&quot;</span>)) &#123;</span><br><span class="line">    accessResource.setWhiteRemoteAddress(remoteAddr.split(<span class="string">&quot;:&quot;</span>)[<span class="number">0</span>]);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    accessResource.setWhiteRemoteAddress(remoteAddr);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step1：首先创建PlainAccessResource，从远程地址中提取出远程访问IP地址。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (request.getExtFields() == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> AclException(<span class="string">&quot;request&#x27;s extFields value is null&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">accessResource.setRequestCode(request.getCode());</span><br><span class="line">accessResource.setAccessKey(request.getExtFields().get(SessionCredentials.ACCESS_KEY));</span><br><span class="line">accessResource.setSignature(request.getExtFields().get(SessionCredentials.SIGNATURE));</span><br><span class="line">accessResource.setSecretToken(request.getExtFields().get(SessionCredentials.SECURITY_TOKEN));</span><br></pre></td></tr></table></figure>
<p>Step2：如果请求头中的扩展字段为空，则抛出异常，如果不为空，则从请求头中读取requestCode、accessKey(请求用户名)、签名字符串(signature)、secretToken。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">switch</span> (request.getCode()) &#123;</span><br><span class="line">                <span class="keyword">case</span> RequestCode.SEND_MESSAGE:</span><br><span class="line">                    accessResource.addResourceAndPerm(request.getExtFields().get(<span class="string">&quot;topic&quot;</span>), Permission.PUB);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> RequestCode.SEND_MESSAGE_V2:</span><br><span class="line">                    accessResource.addResourceAndPerm(request.getExtFields().get(<span class="string">&quot;b&quot;</span>), Permission.PUB);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> RequestCode.CONSUMER_SEND_MSG_BACK:</span><br><span class="line">                    accessResource.addResourceAndPerm(request.getExtFields().get(<span class="string">&quot;originTopic&quot;</span>), Permission.PUB);</span><br><span class="line">                    accessResource.addResourceAndPerm(getRetryTopic(request.getExtFields().get(<span class="string">&quot;group&quot;</span>)), Permission.SUB);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> RequestCode.PULL_MESSAGE:</span><br><span class="line">                    accessResource.addResourceAndPerm(request.getExtFields().get(<span class="string">&quot;topic&quot;</span>), Permission.SUB);</span><br><span class="line">                    accessResource.addResourceAndPerm(getRetryTopic(request.getExtFields().get(<span class="string">&quot;consumerGroup&quot;</span>)), Permission.SUB);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> RequestCode.QUERY_MESSAGE:</span><br><span class="line">                    accessResource.addResourceAndPerm(request.getExtFields().get(<span class="string">&quot;topic&quot;</span>), Permission.SUB);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> RequestCode.HEART_BEAT:</span><br><span class="line">                    HeartbeatData heartbeatData = HeartbeatData.decode(request.getBody(), HeartbeatData.class);</span><br><span class="line">                    <span class="keyword">for</span> (ConsumerData data : heartbeatData.getConsumerDataSet()) &#123;</span><br><span class="line">                        accessResource.addResourceAndPerm(getRetryTopic(data.getGroupName()), Permission.SUB);</span><br><span class="line">                        <span class="keyword">for</span> (SubscriptionData subscriptionData : data.getSubscriptionDataSet()) &#123;</span><br><span class="line">                            accessResource.addResourceAndPerm(subscriptionData.getTopic(), Permission.SUB);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> RequestCode.UNREGISTER_CLIENT:</span><br><span class="line">                    <span class="keyword">final</span> UnregisterClientRequestHeader unregisterClientRequestHeader =</span><br><span class="line">                        (UnregisterClientRequestHeader) request</span><br><span class="line">                            .decodeCommandCustomHeader(UnregisterClientRequestHeader.class);</span><br><span class="line">                    accessResource.addResourceAndPerm(getRetryTopic(unregisterClientRequestHeader.getConsumerGroup()), Permission.SUB);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> RequestCode.GET_CONSUMER_LIST_BY_GROUP:</span><br><span class="line">                    <span class="keyword">final</span> GetConsumerListByGroupRequestHeader getConsumerListByGroupRequestHeader =</span><br><span class="line">                        (GetConsumerListByGroupRequestHeader) request</span><br><span class="line">                            .decodeCommandCustomHeader(GetConsumerListByGroupRequestHeader.class);</span><br><span class="line">                    accessResource.addResourceAndPerm(getRetryTopic(getConsumerListByGroupRequestHeader.getConsumerGroup()), Permission.SUB);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> RequestCode.UPDATE_CONSUMER_OFFSET:</span><br><span class="line">                    <span class="keyword">final</span> UpdateConsumerOffsetRequestHeader updateConsumerOffsetRequestHeader =</span><br><span class="line">                        (UpdateConsumerOffsetRequestHeader) request</span><br><span class="line">                            .decodeCommandCustomHeader(UpdateConsumerOffsetRequestHeader.class);</span><br><span class="line">                    accessResource.addResourceAndPerm(getRetryTopic(updateConsumerOffsetRequestHeader.getConsumerGroup()), Permission.SUB);</span><br><span class="line">                    accessResource.addResourceAndPerm(updateConsumerOffsetRequestHeader.getTopic(), Permission.SUB);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">default</span>:</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> AclException(t.getMessage(), t);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>Step3：根据请求命令，设置本次请求需要拥有的权限，上述代码比较简单，就是从请求中得出本次操作的Topic、消息组名称，为了方便区分topic与消费组，消费组使用消费者对应的重试主题，当成资源的Key，从这里也可以看出，当前版本需要进行ACL权限验证的请求命令如下：</p>
<ul>
<li>SEND_MESSAGE</li>
<li>SEND_MESSAGE_V2</li>
<li>CONSUMER_SEND_MSG_BACK</li>
<li>PULL_MESSAGE</li>
<li>QUERY_MESSAGE</li>
<li>HEART_BEAT</li>
<li>UNREGISTER_CLIENT</li>
<li>GET_CONSUMER_LIST_BY_GROUP</li>
<li>UPDATE_CONSUMER_OFFSET</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Content</span></span><br><span class="line">SortedMap&lt;String, String&gt; map = <span class="keyword">new</span> TreeMap&lt;String, String&gt;();</span><br><span class="line"><span class="keyword">for</span> (Map.Entry&lt;String, String&gt; entry : request.getExtFields().entrySet()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!SessionCredentials.SIGNATURE.equals(entry.getKey())) &#123;</span><br><span class="line">        map.put(entry.getKey(), entry.getValue());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">accessResource.setContent(AclUtils.combineRequestContent(request, map));</span><br><span class="line"><span class="keyword">return</span> accessResource;</span><br></pre></td></tr></table></figure>
<p>Step4：对扩展字段进行排序，便于生成签名字符串，然后将扩展字段与请求体(body)写入content字段。完成从请求头中解析出本次请求需要验证的权限。</p>
<h3 id="2-4-validate-方法"><a href="#2-4-validate-方法" class="headerlink" title="2.4 validate 方法"></a>2.4 validate 方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">validate</span><span class="params">(AccessResource accessResource)</span> </span>&#123;</span><br><span class="line">    aclPlugEngine.validate((PlainAccessResource) accessResource);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>验证权限，即根据本次请求需要的权限与当前用户所拥有的权限进行对比，如果符合，则正常执行；否则抛出AclException。</p>
<p>为了揭开配置文件的解析与验证，我们将目光投入到PlainPermissionLoader。</p>
<h2 id="3、PlainPermissionLoader"><a href="#3、PlainPermissionLoader" class="headerlink" title="3、PlainPermissionLoader"></a>3、PlainPermissionLoader</h2><p>该类的主要职责：加载权限，即解析acl主要配置文件plain_acl.yml。</p>
<h3 id="3-1-类图"><a href="#3-1-类图" class="headerlink" title="3.1 类图"></a>3.1 类图</h3><p><img src="https://img-blog.csdnimg.cn/20190707121053922.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>下面对其核心属性与核心方法一一介绍：</p>
<ul>
<li>DEFAULT_PLAIN_ACL_FILE<br>默认acl配置文件名称，默认值为conf/plain_acl.yml。</li>
<li>String fileName<br>acl配置文件名称，默认为DEFAULT_PLAIN_ACL_FILE ,可以通过系统参数-Drocketmq.acl.plain.file=fileName指定。</li>
<li>Map&lt;String, PlainAccessResource&gt; plainAccessResourceMap<br>解析出来的权限配置映射表，以用户名为键。</li>
<li>RemoteAddressStrategyFactory remoteAddressStrategyFactory<br>远程IP解析策略工厂，用于解析白名单IP地址。</li>
<li>boolean isWatchStart<br>是否开启了文件监听，即自动监听plain_acl.yml文件，一旦该文件改变，可在不重启服务器的情况下自动生效。</li>
<li>public PlainPermissionLoader()<br>构造方法。</li>
<li>public void load()<br>加载配置文件。</li>
<li>public void validate(PlainAccessResource plainAccessResource)<br>验证是否有权限访问待访问资源。</li>
</ul>
<h3 id="3-2-PlainPermissionLoader构造方法"><a href="#3-2-PlainPermissionLoader构造方法" class="headerlink" title="3.2 PlainPermissionLoader构造方法"></a>3.2 PlainPermissionLoader构造方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">PlainPermissionLoader</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    load();</span><br><span class="line">    watch();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在构造方法中调用load与watch方法。</p>
<h3 id="3-3-load"><a href="#3-3-load" class="headerlink" title="3.3 load"></a>3.3 load</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Map&lt;String, PlainAccessResource&gt; plainAccessResourceMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">List&lt;RemoteAddressStrategy&gt; globalWhiteRemoteAddressStrategy = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">String path = fileHome + File.separator + fileName;</span><br><span class="line">JSONObject plainAclConfData = AclUtils.getYamlDataObject(path,JSONObject.class);</span><br></pre></td></tr></table></figure>
<p>Step1：初始化plainAccessResourceMap(用户配置的访问资源，即权限容器)、globalWhiteRemoteAddressStrategy：全局IP白名单访问策略。配置文件，默认为${ROCKETMQ_HOME}/conf/plain_acl.yml。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JSONArray globalWhiteRemoteAddressesList = plainAclConfData.getJSONArray(<span class="string">&quot;globalWhiteRemoteAddresses&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (globalWhiteRemoteAddressesList != <span class="keyword">null</span> &amp;&amp; !globalWhiteRemoteAddressesList.isEmpty()) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; globalWhiteRemoteAddressesList.size(); i++) &#123;</span><br><span class="line">        globalWhiteRemoteAddressStrategy.add(remoteAddressStrategyFactory.</span><br><span class="line">        getRemoteAddressStrategy(globalWhiteRemoteAddressesList.getString(i)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：globalWhiteRemoteAddresses：全局白名单，类型为数组。根据配置的规则，使用remoteAddressStrategyFactory获取一个访问策略，下文会重点介绍其配置规则。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JSONArray accounts = plainAclConfData.getJSONArray(<span class="string">&quot;accounts&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (accounts != <span class="keyword">null</span> &amp;&amp; !accounts.isEmpty()) &#123;</span><br><span class="line">    List&lt;PlainAccessConfig&gt; plainAccessConfigList = accounts.toJavaList(PlainAccessConfig.class);</span><br><span class="line">    <span class="keyword">for</span> (PlainAccessConfig plainAccessConfig : plainAccessConfigList) &#123;</span><br><span class="line">        PlainAccessResource plainAccessResource = buildPlainAccessResource(plainAccessConfig);</span><br><span class="line">        plainAccessResourceMap.put(plainAccessResource.getAccessKey(),plainAccessResource);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">this</span>.globalWhiteRemoteAddressStrategy = globalWhiteRemoteAddressStrategy;</span><br><span class="line"><span class="keyword">this</span>.plainAccessResourceMap = plainAccessResourceMap;</span><br></pre></td></tr></table></figure>
<p>Step3：解析plain_acl.yml文件中的另外一个根元素accounts，用户定义的权限信息。从PlainAccessConfig的定义来看，accounts标签下支持如下标签：</p>
<ul>
<li>accessKey</li>
<li>secretKey</li>
<li>whiteRemoteAddress</li>
<li>admin</li>
<li>defaultTopicPerm</li>
<li>defaultGroupPerm</li>
<li>topicPerms</li>
<li>groupPerms<br>上述标签的说明，请参考：:<a href="https://blog.csdn.net/prestigeding/article/details/94317946">《RocketMQ ACL使用指南》</a> 。具体的解析过程比较容易，就不再细说。</li>
</ul>
<p>load方法主要完成acl配置文件的解析，将用户定义的权限加载到内存中。</p>
<h3 id="3-4-watch"><a href="#3-4-watch" class="headerlink" title="3.4 watch"></a>3.4 watch</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">watch</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        String watchFilePath = fileHome + fileName;</span><br><span class="line">        FileWatchService fileWatchService = <span class="keyword">new</span> FileWatchService(<span class="keyword">new</span> String[] &#123;watchFilePath&#125;, <span class="keyword">new</span> FileWatchService.Listener() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onChanged</span><span class="params">(String path)</span> </span>&#123;   </span><br><span class="line">                    log.info(<span class="string">&quot;The plain acl yml changed, reload the context&quot;</span>);</span><br><span class="line">                    load();</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        fileWatchService.start();</span><br><span class="line">        log.info(<span class="string">&quot;Succeed to start AclWatcherService&quot;</span>);</span><br><span class="line">        <span class="keyword">this</span>.isWatchStart = <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        log.error(<span class="string">&quot;Failed to start AclWatcherService&quot;</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>监听器，默认以500ms的频率判断文件的内容是否变化。在文件内容发生变化后调用load()方法，重新加载配置文件。那FileWatchService是如何判断两个文件的内容发生了变化呢？</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">FileWatchService#hash</span><br><span class="line"><span class="function"><span class="keyword">private</span> String <span class="title">hash</span><span class="params">(String filePath)</span> <span class="keyword">throws</span> IOException, NoSuchAlgorithmException </span>&#123;</span><br><span class="line">    Path path = Paths.get(filePath);</span><br><span class="line">    md.update(Files.readAllBytes(path));</span><br><span class="line">    <span class="keyword">byte</span>[] hash = md.digest();</span><br><span class="line">    <span class="keyword">return</span> UtilAll.bytes2string(hash);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>获取文件md5签名来做对比，这里为什么不在启动时先记录上一次文件的修改时间，然后先判断其修改时间是否变化，再判断其内容是否真正发生变化。</p>
<h3 id="3-5-validate"><a href="#3-5-validate" class="headerlink" title="3.5 validate"></a>3.5 validate</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Check the global white remote addr</span></span><br><span class="line"><span class="keyword">for</span> (RemoteAddressStrategy remoteAddressStrategy : globalWhiteRemoteAddressStrategy) &#123;</span><br><span class="line">    <span class="keyword">if</span> (remoteAddressStrategy.match(plainAccessResource)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step1：首先使用全局白名单对资源进行验证，只要一个规则匹配，则返回，表示认证成功。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (plainAccessResource.getAccessKey() == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> AclException(String.format(<span class="string">&quot;No accessKey is configured&quot;</span>));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (!plainAccessResourceMap.containsKey(plainAccessResource.getAccessKey())) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> AclException(String.format(<span class="string">&quot;No acl config for %s&quot;</span>, plainAccessResource.getAccessKey()));</span><br><span class="line">&#125;</span><br><span class="line">Step2：如果请求信息中，没有设置用户名，则抛出未配置AccessKey异常；如果Broker中并为配置该用户的配置信息，则抛出AclException。</span><br><span class="line"></span><br><span class="line"><span class="comment">// Check the white addr for accesskey</span></span><br><span class="line">PlainAccessResource ownedAccess = plainAccessResourceMap.get(plainAccessResource.getAccessKey());</span><br><span class="line"><span class="keyword">if</span> (ownedAccess.getRemoteAddressStrategy().match(plainAccessResource)) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step3：如果用户配置的白名单与待访问资源规则匹配的话，则直接发认证通过。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Check the signature</span></span><br><span class="line">String signature = AclUtils.calSignature(plainAccessResource.getContent(), ownedAccess.getSecretKey());</span><br><span class="line"><span class="keyword">if</span> (!signature.equals(plainAccessResource.getSignature())) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> AclException(String.format(<span class="string">&quot;Check signature failed for accessKey=%s&quot;</span>, plainAccessResource.getAccessKey()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step4：验证签名。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">checkPerm(plainAccessResource, ownedAccess);</span><br></pre></td></tr></table></figure>
<p>Step5：调用checkPerm方法，验证需要的权限与拥有的权限是否匹配。</p>
<h4 id="3-5-1-checkPerm"><a href="#3-5-1-checkPerm" class="headerlink" title="3.5.1 checkPerm"></a>3.5.1 checkPerm</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (Permission.needAdminPerm(needCheckedAccess.getRequestCode()) &amp;&amp; !ownedAccess.isAdmin()) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> AclException(String.format(<span class="string">&quot;Need admin permission for request code=%d, but accessKey=%s is not&quot;</span>, needCheckedAccess.getRequestCode(), ownedAccess.getAccessKey()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step6：如果当前的请求命令属于必须是Admin用户才能访问的权限，并且当前用户并不是管理员角色，则抛出异常，如下命令需要admin角色才能进行的操作：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Map&lt;String, Byte&gt; needCheckedPermMap = needCheckedAccess.getResourcePermMap();</span><br><span class="line">Map&lt;String, Byte&gt; ownedPermMap = ownedAccess.getResourcePermMap();</span><br><span class="line"><span class="keyword">if</span> (needCheckedPermMap == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// If the needCheckedPermMap is null,then return</span></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (ownedPermMap == <span class="keyword">null</span> &amp;&amp; ownedAccess.isAdmin()) &#123;</span><br><span class="line">    <span class="comment">// If the ownedPermMap is null and it is an admin user, then return</span></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step7：如果该请求不需要进行权限验证，则通过认证，如果当前用户的角色是管理员，并且没有配置用户权限，则认证通过，返回。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (Map.Entry&lt;String, Byte&gt; needCheckedEntry : needCheckedPermMap.entrySet()) &#123;</span><br><span class="line">    String resource = needCheckedEntry.getKey();</span><br><span class="line">    Byte neededPerm = needCheckedEntry.getValue();</span><br><span class="line">    <span class="keyword">boolean</span> isGroup = PlainAccessResource.isRetryTopic(resource);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (ownedPermMap == <span class="keyword">null</span> || !ownedPermMap.containsKey(resource)) &#123;</span><br><span class="line">        <span class="comment">// Check the default perm</span></span><br><span class="line">        <span class="keyword">byte</span> ownedPerm = isGroup ? ownedAccess.getDefaultGroupPerm() : ownedAccess.getDefaultTopicPerm();</span><br><span class="line">        <span class="keyword">if</span> (!Permission.checkPermission(neededPerm, ownedPerm)) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> AclException(String.format(<span class="string">&quot;No default permission for %s&quot;</span>, PlainAccessResource.printStr(resource, isGroup)));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!Permission.checkPermission(neededPerm, ownedPermMap.get(resource))) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> AclException(String.format(<span class="string">&quot;No default permission for %s&quot;</span>, PlainAccessResource.printStr(resource, isGroup)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step8：遍历需要权限与拥有的权限进行对比，如果配置对应的权限，则判断是否匹配；如果未配置权限，则判断默认权限时是否允许，不允许，则抛出AclException。</p>
<p>验证逻辑就介绍到这里了，下面给出其匹配流程图：<br><img src="https://img-blog.csdnimg.cn/20190707121507431.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>上述阐述了从Broker服务器启动、加载acl配置文件流程、动态监听配置文件、服务端权限验证流程，接下来我们看一下客户端关于ACL需要处理的事情。</p>
<h2 id="4、AclClientRPCHook"><a href="#4、AclClientRPCHook" class="headerlink" title="4、AclClientRPCHook"></a>4、AclClientRPCHook</h2><p>回顾一下，我们引入ACL机制后，客户端的代码示例如下：<br><img src="https://img-blog.csdnimg.cn/20190707121547164.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其在创建DefaultMQProducer时，注册AclClientRPCHook钩子，会在向服务端发送远程命令前后执行其钩子函数，接下来我们重点分析一下AclClientRPCHook。</p>
<h3 id="4-1-doBeforeRequest"><a href="#4-1-doBeforeRequest" class="headerlink" title="4.1 doBeforeRequest"></a>4.1 doBeforeRequest</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doBeforeRequest</span><span class="params">(String remoteAddr, RemotingCommand request)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">byte</span>[] total = AclUtils.combineRequestContent(request,</span><br><span class="line">           parseRequestContent(request, sessionCredentials.getAccessKey(), sessionCredentials.getSecurityToken()));   <span class="comment">// @1</span></span><br><span class="line">    String signature = AclUtils.calSignature(total, sessionCredentials.getSecretKey());                                                      <span class="comment">// @2</span></span><br><span class="line">    request.addExtField(SIGNATURE, signature);                                                                                                               <span class="comment">// @3</span></span><br><span class="line">    request.addExtField(ACCESS_KEY, sessionCredentials.getAccessKey());         </span><br><span class="line">    <span class="comment">// The SecurityToken value is unneccessary,user can choose this one.</span></span><br><span class="line">    <span class="keyword">if</span> (sessionCredentials.getSecurityToken() != <span class="keyword">null</span>) &#123;</span><br><span class="line">        request.addExtField(SECURITY_TOKEN, sessionCredentials.getSecurityToken());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：将Request请求参数进行排序，并加入accessKey。</p>
<p>代码@2：对排好序的请参数，使用用户配置的密码生成签名，并最近到扩展字段Signature，然后服务端也会按照相同的算法生成Signature，如果相同，则表示签名验证成功(类似于实现登录的效果)。</p>
<p>代码@3：将Signature、AccessKey等加入到请求头的扩展字段中，服务端拿到这些元数据，结合请求头中的信息，根据配置的权限，进行权限校验。</p>
<p>关于ACL客户端生成签名是一种通用套路，就不在细讲了。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>acl</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析RocketMQ消息轨迹</title>
    <url>/posts/e8f03b64.html</url>
    <content><![CDATA[<div id="vip-container"><p>本文沿着<a href="https://blog.csdn.net/prestigeding/article/details/95922489">《RocketMQ消息轨迹-设计篇》</a>的思路，从如下3个方面对其源码进行解读：</p>
<ol>
<li>发送消息轨迹</li>
<li>消息轨迹格式</li>
<li>存储消息轨迹数据</li>
</ol>
<h2 id="1、发送消息轨迹流程"><a href="#1、发送消息轨迹流程" class="headerlink" title="1、发送消息轨迹流程"></a>1、发送消息轨迹流程</h2><p>首先我们来看一下在消息发送端如何启用消息轨迹，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TraceProducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, InterruptedException </span>&#123;</span><br><span class="line">        DefaultMQProducer producer = <span class="keyword">new</span> DefaultMQProducer(<span class="string">&quot;ProducerGroupName&quot;</span>,<span class="keyword">true</span>);      <span class="comment">// @1</span></span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;127.0.0.1:9876&quot;</span>);</span><br><span class="line">        producer.start();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                &#123;</span><br><span class="line">                    Message msg = <span class="keyword">new</span> Message(<span class="string">&quot;TopicTest&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;TagA&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;OrderID188&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;Hello world&quot;</span>.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">                    SendResult sendResult = producer.send(msg);</span><br><span class="line">                    System.out.printf(<span class="string">&quot;%s%n&quot;</span>, sendResult);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上述代码可以看出其关键点是在创建DefaultMQProducer时指定开启消息轨迹跟踪。我们不妨浏览一下DefaultMQProducer与启用消息轨迹相关的构造函数：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DefaultMQProducer</span><span class="params">(<span class="keyword">final</span> String producerGroup, <span class="keyword">boolean</span> enableMsgTrace)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DefaultMQProducer</span><span class="params">(<span class="keyword">final</span> String producerGroup, <span class="keyword">boolean</span> enableMsgTrace, <span class="keyword">final</span> String customizedTraceTopic)</span></span></span><br></pre></td></tr></table></figure>
<p>参数如下：</p>
<ul>
<li>String producerGroup<br>生产者所属组名。</li>
<li>boolean enableMsgTrace<br>是否开启跟踪消息轨迹，默认为false。</li>
<li>String customizedTraceTopic<br>如果开启消息轨迹跟踪，用来存储消息轨迹数据所属的主题名称，默认为：RMQ_SYS_TRACE_TOPIC。</li>
</ul>
<h3 id="1-1-DefaultMQProducer构造函数"><a href="#1-1-DefaultMQProducer构造函数" class="headerlink" title="1.1 DefaultMQProducer构造函数"></a>1.1 DefaultMQProducer构造函数</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DefaultMQProducer</span><span class="params">(<span class="keyword">final</span> String producerGroup, RPCHook rpcHook, <span class="keyword">boolean</span> enableMsgTrace,<span class="keyword">final</span> String customizedTraceTopic)</span> </span>&#123;      <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">this</span>.producerGroup = producerGroup;</span><br><span class="line">    defaultMQProducerImpl = <span class="keyword">new</span> DefaultMQProducerImpl(<span class="keyword">this</span>, rpcHook);</span><br><span class="line">    <span class="comment">//if client open the message trace feature</span></span><br><span class="line">    <span class="keyword">if</span> (enableMsgTrace) &#123;                                                                                                                                                                                            <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            AsyncTraceDispatcher dispatcher = <span class="keyword">new</span> AsyncTraceDispatcher(customizedTraceTopic, rpcHook);                                                         </span><br><span class="line">            dispatcher.setHostProducer(<span class="keyword">this</span>.getDefaultMQProducerImpl());</span><br><span class="line">            traceDispatcher = dispatcher;</span><br><span class="line">            <span class="keyword">this</span>.getDefaultMQProducerImpl().registerSendMessageHook(</span><br><span class="line">                <span class="keyword">new</span> SendMessageTraceHookImpl(traceDispatcher));                                                                                                                             <span class="comment">// @3</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;system mqtrace hook init failed ,maybe can&#x27;t send msg trace data&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先介绍一下其局部变量。</p>
<ul>
<li>String producerGroup<br>生产者所属组。</li>
<li>RPCHook rpcHook<br>生产者发送钩子函数。</li>
<li>boolean enableMsgTrace<br>是否开启消息轨迹跟踪。</li>
<li>String customizedTraceTopic<br>定制用于存储消息轨迹的数据。</li>
</ul>
<p>代码@2：用来构建AsyncTraceDispatcher，看其名：异步转发消息轨迹数据，稍后重点关注。</p>
<p>代码@3：构建SendMessageTraceHookImpl对象，并使用AsyncTraceDispatcher用来异步转发。</p>
<h3 id="1-2-SendMessageTraceHookImpl钩子函数"><a href="#1-2-SendMessageTraceHookImpl钩子函数" class="headerlink" title="1.2 SendMessageTraceHookImpl钩子函数"></a>1.2 SendMessageTraceHookImpl钩子函数</h3><h4 id="1-2-1-SendMessageTraceHookImpl类图"><a href="#1-2-1-SendMessageTraceHookImpl类图" class="headerlink" title="1.2.1 SendMessageTraceHookImpl类图"></a>1.2.1 SendMessageTraceHookImpl类图</h4><p><img src="https://img-blog.csdnimg.cn/20190803203518449.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ol>
<li>SendMessageHook<br>消息发送钩子函数，用于在消息发送之前、发送之后执行一定的业务逻辑，是记录消息轨迹的最佳扩展点。</li>
<li>TraceDispatcher<br>消息轨迹转发处理器，其默认实现类AsyncTraceDispatcher，异步实现消息轨迹数据的发送。下面对其属性做一个简单的介绍：<ul>
<li>int queueSize<br>异步转发，队列长度，默认为2048，当前版本不能修改。</li>
<li>int batchSize<br>批量消息条数，消息轨迹一次消息发送请求包含的数据条数，默认为100，当前版本不能修改。</li>
<li>int maxMsgSize<br>消息轨迹一次发送的最大消息大小，默认为128K，当前版本不能修改。</li>
<li>DefaultMQProducer traceProducer<br>  用来发送消息轨迹的消息发送者。</li>
<li>ThreadPoolExecutor traceExecuter<br>线程池，用来异步执行消息发送。</li>
<li>AtomicLong discardCount<br>记录丢弃的消息个数。</li>
<li>Thread worker<br>woker线程，主要负责从追加队列中获取一批待发送的消息轨迹数据，提交到线程池中执行。</li>
<li>ArrayBlockingQueue&lt; TraceContext&gt; traceContextQueue<br>消息轨迹TraceContext队列，用来存放待发送到服务端的消息。</li>
<li>ArrayBlockingQueue&lt; Runnable&gt; appenderQueue<br>线程池内部队列，默认长度1024。</li>
<li>DefaultMQPushConsumerImpl hostConsumer<br>消费者信息，记录消息消费时的轨迹信息。</li>
<li>String traceTopicName<br>用于跟踪消息轨迹的topic名称。</li>
</ul>
</li>
</ol>
<a id="more"></a>

<h4 id="1-2-2-源码分析SendMessageTraceHookImpl"><a href="#1-2-2-源码分析SendMessageTraceHookImpl" class="headerlink" title="1.2.2 源码分析SendMessageTraceHookImpl"></a>1.2.2 源码分析SendMessageTraceHookImpl</h4><h5 id="1-2-2-1-sendMessageBefore"><a href="#1-2-2-1-sendMessageBefore" class="headerlink" title="1.2.2.1 sendMessageBefore"></a>1.2.2.1 sendMessageBefore</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendMessageBefore</span><span class="params">(SendMessageContext context)</span> </span>&#123; </span><br><span class="line">    <span class="comment">//if it is message trace data,then it doesn&#x27;t recorded</span></span><br><span class="line">    <span class="keyword">if</span> (context == <span class="keyword">null</span> || context.getMessage().getTopic().startsWith(((AsyncTraceDispatcher) localDispatcher).getTraceTopicName())) &#123;   <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//build the context content of TuxeTraceContext</span></span><br><span class="line">    TraceContext tuxeContext = <span class="keyword">new</span> TraceContext();</span><br><span class="line">    tuxeContext.setTraceBeans(<span class="keyword">new</span> ArrayList&lt;TraceBean&gt;(<span class="number">1</span>));</span><br><span class="line">    context.setMqTraceContext(tuxeContext);</span><br><span class="line">    tuxeContext.setTraceType(TraceType.Pub);</span><br><span class="line">    tuxeContext.setGroupName(context.getProducerGroup());                                                                                                                       <span class="comment">// @2</span></span><br><span class="line">    <span class="comment">//build the data bean object of message trace</span></span><br><span class="line">    TraceBean traceBean = <span class="keyword">new</span> TraceBean();                                                                                                                                                <span class="comment">// @3</span></span><br><span class="line">    traceBean.setTopic(context.getMessage().getTopic());</span><br><span class="line">    traceBean.setTags(context.getMessage().getTags());</span><br><span class="line">    traceBean.setKeys(context.getMessage().getKeys());</span><br><span class="line">    traceBean.setStoreHost(context.getBrokerAddr());</span><br><span class="line">    traceBean.setBodyLength(context.getMessage().getBody().length);</span><br><span class="line">    traceBean.setMsgType(context.getMsgType());</span><br><span class="line">    tuxeContext.getTraceBeans().add(traceBean);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果topic主题为消息轨迹的Topic，直接返回。</p>
<p>代码@2：在消息发送上下文中，设置用来跟踪消息轨迹的上下环境，里面主要包含一个TraceBean集合、追踪类型（TraceType.Pub）与生产者所属的组。</p>
<p>代码@3：构建一条跟踪消息，用TraceBean来表示，记录原消息的topic、tags、keys、发送到broker地址、消息体长度等消息。</p>
<p>从上文看出，sendMessageBefore主要的用途就是在消息发送的时候，先准备一部分消息跟踪日志，存储在发送上下文环境中，此时并不会发送消息轨迹数据。</p>
<h5 id="1-2-2-2-sendMessageAfter"><a href="#1-2-2-2-sendMessageAfter" class="headerlink" title="1.2.2.2 sendMessageAfter"></a>1.2.2.2 sendMessageAfter</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendMessageAfter</span><span class="params">(SendMessageContext context)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//if it is message trace data,then it doesn&#x27;t recorded</span></span><br><span class="line">    <span class="keyword">if</span> (context == <span class="keyword">null</span> || context.getMessage().getTopic().startsWith(((AsyncTraceDispatcher) localDispatcher).getTraceTopicName())     <span class="comment">// @1</span></span><br><span class="line">        || context.getMqTraceContext() == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (context.getSendResult() == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (context.getSendResult().getRegionId() == <span class="keyword">null</span></span><br><span class="line">        || !context.getSendResult().isTraceOn()) &#123;</span><br><span class="line">        <span class="comment">// if switch is false,skip it</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    TraceContext tuxeContext = (TraceContext) context.getMqTraceContext();</span><br><span class="line">    TraceBean traceBean = tuxeContext.getTraceBeans().get(<span class="number">0</span>);                                                                                                <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">int</span> costTime = (<span class="keyword">int</span>) ((System.currentTimeMillis() - tuxeContext.getTimeStamp()) / tuxeContext.getTraceBeans().size());     <span class="comment">// @3</span></span><br><span class="line">    tuxeContext.setCostTime(costTime);                                                                                                                                      <span class="comment">// @4</span></span><br><span class="line">    <span class="keyword">if</span> (context.getSendResult().getSendStatus().equals(SendStatus.SEND_OK)) &#123;                                                                    </span><br><span class="line">        tuxeContext.setSuccess(<span class="keyword">true</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        tuxeContext.setSuccess(<span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    tuxeContext.setRegionId(context.getSendResult().getRegionId());                                                                                      </span><br><span class="line">    traceBean.setMsgId(context.getSendResult().getMsgId());</span><br><span class="line">    traceBean.setOffsetMsgId(context.getSendResult().getOffsetMsgId());</span><br><span class="line">    traceBean.setStoreTime(tuxeContext.getTimeStamp() + costTime / <span class="number">2</span>);</span><br><span class="line">    localDispatcher.append(tuxeContext);                                                                                                                                   <span class="comment">// @5</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果topic主题为消息轨迹的Topic，直接返回。</p>
<p>代码@2：从MqTraceContext中获取跟踪的TraceBean，虽然设计成List结构体，但在消息发送场景，这里的数据永远只有一条，及时是批量发送也不例外。</p>
<p>代码@3：获取消息发送到收到响应结果的耗时。</p>
<p>代码@4：设置costTime(耗时)、success(是否发送成功)、regionId(发送到broker所在的分区)、msgId(消息ID，全局唯一)、offsetMsgId(消息物理偏移量，如果是批量消息，则是最后一条消息的物理偏移量)、storeTime，这里使用的是(客户端发送时间 + 二分之一的耗时)来表示消息的存储时间，这里是一个估值。</p>
<p>代码@5：将需要跟踪的信息通过TraceDispatcher转发到Broker服务器。其代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">append</span><span class="params">(<span class="keyword">final</span> Object ctx)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> result = traceContextQueue.offer((TraceContext) ctx);</span><br><span class="line">    <span class="keyword">if</span> (!result) &#123;</span><br><span class="line">        log.info(<span class="string">&quot;buffer full&quot;</span> + discardCount.incrementAndGet() + <span class="string">&quot; ,context is &quot;</span> + ctx);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里一个非常关键的点是offer方法的使用，当队列无法容纳新的元素时会立即返回false，并不会阻塞。</p>
<p>接下来将目光转向TraceDispatcher的实现。</p>
<h3 id="1-3-TraceDispatcher实现原理"><a href="#1-3-TraceDispatcher实现原理" class="headerlink" title="1.3 TraceDispatcher实现原理"></a>1.3 TraceDispatcher实现原理</h3><p>TraceDispatcher，用于客户端消息轨迹数据转发到Broker，其默认实现类：AsyncTraceDispatcher。</p>
<h4 id="1-3-1-TraceDispatcher构造函数"><a href="#1-3-1-TraceDispatcher构造函数" class="headerlink" title="1.3.1 TraceDispatcher构造函数"></a>1.3.1 TraceDispatcher构造函数</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">AsyncTraceDispatcher</span><span class="params">(String traceTopicName, RPCHook rpcHook)</span> <span class="keyword">throws</span> MQClientException </span>&#123;    </span><br><span class="line">    <span class="comment">// queueSize is greater than or equal to the n power of 2 of value</span></span><br><span class="line">    <span class="keyword">this</span>.queueSize = <span class="number">2048</span>;</span><br><span class="line">    <span class="keyword">this</span>.batchSize = <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">this</span>.maxMsgSize = <span class="number">128000</span>;                                        </span><br><span class="line">    <span class="keyword">this</span>.discardCount = <span class="keyword">new</span> AtomicLong(<span class="number">0L</span>);         </span><br><span class="line">    <span class="keyword">this</span>.traceContextQueue = <span class="keyword">new</span> ArrayBlockingQueue&lt;TraceContext&gt;(<span class="number">1024</span>);</span><br><span class="line">    <span class="keyword">this</span>.appenderQueue = <span class="keyword">new</span> ArrayBlockingQueue&lt;Runnable&gt;(queueSize);</span><br><span class="line">    <span class="keyword">if</span> (!UtilAll.isBlank(traceTopicName)) &#123;</span><br><span class="line">        <span class="keyword">this</span>.traceTopicName = traceTopicName;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.traceTopicName = MixAll.RMQ_SYS_TRACE_TOPIC;</span><br><span class="line">    &#125;                   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">this</span>.traceExecuter = <span class="keyword">new</span> ThreadPoolExecutor(<span class="comment">// :</span></span><br><span class="line">        <span class="number">10</span>, <span class="comment">//</span></span><br><span class="line">        <span class="number">20</span>, <span class="comment">//</span></span><br><span class="line">        <span class="number">1000</span> * <span class="number">60</span>, <span class="comment">//</span></span><br><span class="line">        TimeUnit.MILLISECONDS, <span class="comment">//</span></span><br><span class="line">        <span class="keyword">this</span>.appenderQueue, <span class="comment">//</span></span><br><span class="line">        <span class="keyword">new</span> ThreadFactoryImpl(<span class="string">&quot;MQTraceSendThread_&quot;</span>));</span><br><span class="line">    traceProducer = getAndCreateTraceProducer(rpcHook);      <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：初始化核心属性，该版本这些值都是“固化”的，用户无法修改。</p>
<ul>
<li>queueSize<br>队列长度，默认为2048，异步线程池能够积压的消息轨迹数量。</li>
<li>batchSize<br>一次向Broker批量发送的消息条数，默认为100.</li>
<li>maxMsgSize<br>向Broker汇报消息轨迹时，消息体的总大小不能超过该值，默认为128k。</li>
<li>discardCount<br>整个运行过程中，丢弃的消息轨迹数据，这里要说明一点的是，如果消息TPS发送过大，异步转发线程处理不过来时，会主动丢弃消息轨迹数据。</li>
<li>traceContextQueue<br>traceContext积压队列，客户端(消息发送、消息消费者)在收到处理结果后，将消息轨迹提交到噶队列中，则会立即返回。</li>
<li>appenderQueue<br>提交到Broker线程池中队列。</li>
<li>traceTopicName<br>用于接收消息轨迹的Topic，默认为RMQ_SYS_TRANS_HALF_TOPIC。</li>
<li>traceExecuter<br>用于发送到Broker服务的异步线程池，核心线程数默认为10，最大线程池为20，队列堆积长度2048，线程名称：MQTraceSendThread_。、</li>
<li>traceProducer<br>发送消息轨迹的Producer。</li>
</ul>
<p>代码@2：调用getAndCreateTraceProducer方法创建用于发送消息轨迹的Producer(消息发送者)，下面详细介绍一下其实现。</p>
<h4 id="1-3-2-getAndCreateTraceProducer详解"><a href="#1-3-2-getAndCreateTraceProducer详解" class="headerlink" title="1.3.2 getAndCreateTraceProducer详解"></a>1.3.2 getAndCreateTraceProducer详解</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> DefaultMQProducer <span class="title">getAndCreateTraceProducer</span><span class="params">(RPCHook rpcHook)</span> </span>&#123;</span><br><span class="line">        DefaultMQProducer traceProducerInstance = <span class="keyword">this</span>.traceProducer;</span><br><span class="line">        <span class="keyword">if</span> (traceProducerInstance == <span class="keyword">null</span>) &#123;  <span class="comment">//@1</span></span><br><span class="line">            traceProducerInstance = <span class="keyword">new</span> DefaultMQProducer(rpcHook);</span><br><span class="line">            traceProducerInstance.setProducerGroup(TraceConstants.GROUP_NAME);</span><br><span class="line">            traceProducerInstance.setSendMsgTimeout(<span class="number">5000</span>);</span><br><span class="line">            traceProducerInstance.setVipChannelEnabled(<span class="keyword">false</span>);</span><br><span class="line">            <span class="comment">// The max size of message is 128K</span></span><br><span class="line">            traceProducerInstance.setMaxMessageSize(maxMsgSize - <span class="number">10</span> * <span class="number">1000</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> traceProducerInstance;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果还未建立发送者，则创建用于发送消息轨迹的消息发送者，其GroupName为：_INNER_TRACE_PRODUCER，消息发送超时时间5s，最大允许发送消息大小118K。</p>
<h4 id="1-3-3-start"><a href="#1-3-3-start" class="headerlink" title="1.3.3 start"></a>1.3.3 start</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">(String nameSrvAddr)</span> <span class="keyword">throws</span> MQClientException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (isStarted.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>)) &#123;     <span class="comment">// @1</span></span><br><span class="line">        traceProducer.setNamesrvAddr(nameSrvAddr);</span><br><span class="line">        traceProducer.setInstanceName(TRACE_INSTANCE_NAME + <span class="string">&quot;_&quot;</span> + nameSrvAddr);</span><br><span class="line">        traceProducer.start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.worker = <span class="keyword">new</span> Thread(<span class="keyword">new</span> AsyncRunnable(), <span class="string">&quot;MQ-AsyncTraceDispatcher-Thread-&quot;</span> + dispatcherId);   <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">this</span>.worker.setDaemon(<span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">this</span>.worker.start();                                                                                   </span><br><span class="line">    <span class="keyword">this</span>.registerShutDownHook();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>开始启动，其调用的时机为启动DefaultMQProducer时，如果启用跟踪消息轨迹，则调用之。</p>
<p>代码@1：如果用于发送消息轨迹的发送者没有启动，则设置nameserver地址，并启动着。</p>
<p>代码@2：启动一个线程，用于执行AsyncRunnable任务，接下来将重点介绍。</p>
<h4 id="1-3-4-AsyncRunnable"><a href="#1-3-4-AsyncRunnable" class="headerlink" title="1.3.4 AsyncRunnable"></a>1.3.4 AsyncRunnable</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AsyncRunnable</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">         <span class="keyword">private</span> <span class="keyword">boolean</span> stopped;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (!stopped) &#123;</span><br><span class="line">            List&lt;TraceContext&gt; contexts = <span class="keyword">new</span> ArrayList&lt;TraceContext&gt;(batchSize);     <span class="comment">// @1</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; batchSize; i++) &#123;</span><br><span class="line">                TraceContext context = <span class="keyword">null</span>;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">//get trace data element from blocking Queue — traceContextQueue</span></span><br><span class="line">                    context = traceContextQueue.poll(<span class="number">5</span>, TimeUnit.MILLISECONDS);        <span class="comment">// @2</span></span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (context != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    contexts.add(context);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (contexts.size() &gt; <span class="number">0</span>) &#123;                                                                               :</span><br><span class="line">                AsyncAppenderRequest request = <span class="keyword">new</span> AsyncAppenderRequest(contexts);  <span class="comment">// @3</span></span><br><span class="line">                traceExecuter.submit(request);                                                               </span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (AsyncTraceDispatcher.<span class="keyword">this</span>.stopped) &#123;</span><br><span class="line">                <span class="keyword">this</span>.stopped = <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：构建待提交消息跟踪Bean，每次最多发送batchSize，默认为100条。</p>
<p>代码@2：从traceContextQueue中取出一个待提交的TraceContext，设置超时时间为5s，即如何该队列中没有待提交的TraceContext，则最多等待5s。</p>
<p>代码@3：向线程池中提交任务AsyncAppenderRequest。</p>
<h4 id="1-3-5-AsyncAppenderRequest-sendTraceData"><a href="#1-3-5-AsyncAppenderRequest-sendTraceData" class="headerlink" title="1.3.5 AsyncAppenderRequest#sendTraceData"></a>1.3.5 AsyncAppenderRequest#sendTraceData</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendTraceData</span><span class="params">(List&lt;TraceContext&gt; contextList)</span> </span>&#123;</span><br><span class="line">    Map&lt;String, List&lt;TraceTransferBean&gt;&gt; transBeanMap = <span class="keyword">new</span> HashMap&lt;String, List&lt;TraceTransferBean&gt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (TraceContext context : contextList) &#123;        <span class="comment">//@1</span></span><br><span class="line">        <span class="keyword">if</span> (context.getTraceBeans().isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Topic value corresponding to original message entity content</span></span><br><span class="line">        String topic = context.getTraceBeans().get(<span class="number">0</span>).getTopic();     <span class="comment">// @2</span></span><br><span class="line">        <span class="comment">// Use  original message entity&#x27;s topic as key</span></span><br><span class="line">        String key = topic;</span><br><span class="line">        List&lt;TraceTransferBean&gt; transBeanList = transBeanMap.get(key);</span><br><span class="line">        <span class="keyword">if</span> (transBeanList == <span class="keyword">null</span>) &#123;</span><br><span class="line">            transBeanList = <span class="keyword">new</span> ArrayList&lt;TraceTransferBean&gt;();</span><br><span class="line">            transBeanMap.put(key, transBeanList);</span><br><span class="line">        &#125;</span><br><span class="line">        TraceTransferBean traceData = TraceDataEncoder.encoderFromContextBean(context);    <span class="comment">// @3</span></span><br><span class="line">        transBeanList.add(traceData);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;String, List&lt;TraceTransferBean&gt;&gt; entry : transBeanMap.entrySet()) &#123;       <span class="comment">// @4</span></span><br><span class="line">        flushData(entry.getValue());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：遍历收集的消息轨迹数据。</p>
<p>代码@2：获取存储消息轨迹的Topic。</p>
<p>代码@3：对TraceContext进行编码，这里是消息轨迹的传输数据，稍后对其详细看一下，了解其上传的格式。</p>
<p>代码@4：将编码后的数据发送到Broker服务器。</p>
<h4 id="1-3-6-TraceDataEncoder-encoderFromContextBean"><a href="#1-3-6-TraceDataEncoder-encoderFromContextBean" class="headerlink" title="1.3.6 TraceDataEncoder#encoderFromContextBean"></a>1.3.6 TraceDataEncoder#encoderFromContextBean</h4><p>根据消息轨迹跟踪类型，其格式会有一些不一样，下面分别来介绍其合适。</p>
<h5 id="1-3-6-1-PUB-消息发送"><a href="#1-3-6-1-PUB-消息发送" class="headerlink" title="1.3.6.1 PUB(消息发送)"></a>1.3.6.1 PUB(消息发送)</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> Pub: &#123;</span><br><span class="line">    TraceBean bean = ctx.getTraceBeans().get(<span class="number">0</span>);</span><br><span class="line">    <span class="comment">//append the content of context and traceBean to transferBean&#x27;s TransData</span></span><br><span class="line">    sb.append(ctx.getTraceType()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(ctx.getTimeStamp()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(ctx.getRegionId()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(ctx.getGroupName()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(bean.getTopic()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(bean.getMsgId()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(bean.getTags()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(bean.getKeys()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(bean.getStoreHost()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(bean.getBodyLength()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(ctx.getCostTime()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(bean.getMsgType().ordinal()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(bean.getOffsetMsgId()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">     .append(ctx.isSuccess()).append(TraceConstants.FIELD_SPLITOR);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>消息轨迹数据的协议使用字符串拼接，字段的分隔符号为1，整个数据以2结尾，感觉这个设计还是有点“不可思议”，为什么不直接使用json协议呢？</p>
<h5 id="1-3-6-2-SubBefore-消息消费之前"><a href="#1-3-6-2-SubBefore-消息消费之前" class="headerlink" title="1.3.6.2 SubBefore(消息消费之前)"></a>1.3.6.2 SubBefore(消息消费之前)</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (TraceBean bean : ctx.getTraceBeans()) &#123;</span><br><span class="line">    sb.append(ctx.getTraceType()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(ctx.getTimeStamp()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(ctx.getRegionId()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(ctx.getGroupName()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(ctx.getRequestId()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(bean.getMsgId()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(bean.getRetryTimes()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">      .append(bean.getKeys()).append(TraceConstants.FIELD_SPLITOR);<span class="comment">//</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>轨迹就是按照上述顺序拼接而成，各个字段使用1分隔，每一条记录使用2结尾。</p>
<h5 id="1-3-2-3-SubAfter（消息消费后）"><a href="#1-3-2-3-SubAfter（消息消费后）" class="headerlink" title="1.3.2.3 SubAfter（消息消费后）"></a>1.3.2.3 SubAfter（消息消费后）</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> SubAfter: &#123;</span><br><span class="line">    <span class="keyword">for</span> (TraceBean bean : ctx.getTraceBeans()) &#123;</span><br><span class="line">        sb.append(ctx.getTraceType()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">          .append(ctx.getRequestId()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">          .append(bean.getMsgId()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">          .append(ctx.getCostTime()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">          .append(ctx.isSuccess()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">          .append(bean.getKeys()).append(TraceConstants.CONTENT_SPLITOR)<span class="comment">//</span></span><br><span class="line">          .append(ctx.getContextCode()).append(TraceConstants.FIELD_SPLITOR);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>格式编码一样，就不重复多说。</p>
<p>经过上面的源码跟踪，消息发送端的消息轨迹跟踪流程、消息轨迹数据编码协议就清晰了，接下来我们使用一张序列图来结束本部分的讲解。<br><img src="https://img-blog.csdnimg.cn/20190803204514547.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其实行文至此，只关注了消息发送的消息轨迹跟踪，消息消费的轨迹跟踪又是如何呢？其实现原理其实是一样的，就是在消息消费前后执行特定的钩子函数，其实现类为ConsumeMessageTraceHookImpl，由于其实现与消息发送的思路类似，故就不详细介绍了。</p>
<h2 id="2、-消息轨迹数据如何存储"><a href="#2、-消息轨迹数据如何存储" class="headerlink" title="2、 消息轨迹数据如何存储"></a>2、 消息轨迹数据如何存储</h2><p>其实从上面的分析，我们已经得知，RocketMQ的消息轨迹数据存储在到Broker上，那消息轨迹的主题名如何指定？其路由信息又怎么分配才好呢？是每台Broker上都创建还是只在其中某台上创建呢？RocketMQ支持系统默认与自定义消息轨迹的主题。</p>
<h3 id="2-1-使用系统默认的主题名称"><a href="#2-1-使用系统默认的主题名称" class="headerlink" title="2.1 使用系统默认的主题名称"></a>2.1 使用系统默认的主题名称</h3><p>RocketMQ默认的消息轨迹主题为：RMQ_SYS_TRACE_TOPIC，那该Topic需要手工创建吗？其路由信息呢？</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.brokerController.getBrokerConfig().isTraceTopicEnable()) &#123;    <span class="comment">// @1</span></span><br><span class="line">        String topic = <span class="keyword">this</span>.brokerController.getBrokerConfig().getMsgTraceTopicName();</span><br><span class="line">        TopicConfig topicConfig = <span class="keyword">new</span> TopicConfig(topic);</span><br><span class="line">        <span class="keyword">this</span>.systemTopicList.add(topic);</span><br><span class="line">        topicConfig.setReadQueueNums(<span class="number">1</span>);                                              <span class="comment">// @2</span></span><br><span class="line">        topicConfig.setWriteQueueNums(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">this</span>.topicConfigTable.put(topicConfig.getTopicName(), topicConfig);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述代码出自TopicConfigManager的构造函数，在Broker启动的时候会创建topicConfigManager对象，用来管理topic的路由信息。</p>
<p>代码@1：如果Broker开启了消息轨迹跟踪(traceTopicEnable=true)时，会自动创建默认消息轨迹的topic路由信息，注意其读写队列数为1。</p>
<h3 id="2-2-用户自定义消息轨迹主题"><a href="#2-2-用户自定义消息轨迹主题" class="headerlink" title="2.2 用户自定义消息轨迹主题"></a>2.2 用户自定义消息轨迹主题</h3><p>在创建消息发送者、消息消费者时，可以显示的指定消息轨迹的Topic，例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DefaultMQProducer</span><span class="params">(<span class="keyword">final</span> String producerGroup, RPCHook rpcHook, <span class="keyword">boolean</span> enableMsgTrace,<span class="keyword">final</span> String customizedTraceTopic)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DefaultMQPushConsumer</span><span class="params">(<span class="keyword">final</span> String consumerGroup, RPCHook rpcHook,</span></span></span><br><span class="line"><span class="function"><span class="params">        AllocateMessageQueueStrategy allocateMessageQueueStrategy, <span class="keyword">boolean</span> enableMsgTrace, <span class="keyword">final</span> String customizedTraceTopic)</span></span></span><br></pre></td></tr></table></figure>
<p>通过customizedTraceTopic来指定消息轨迹Topic。</p>
<blockquote>
<p>温馨提示：通常在生产环境上，将不会开启自动创建主题，故需要RocketMQ运维管理人员提前创建好Topic。</p>
</blockquote>
<p>好了，本文就介绍到这里了，本文详细介绍了RocktMQ消息轨迹的实现原理，下一篇，我们将进入到多副本的学习中。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>消息轨迹</tag>
      </tags>
  </entry>
  <entry>
    <title>源码解析MyBatis Sharding-Jdbc SQL语句执行流程详解</title>
    <url>/posts/6620f9ec.html</url>
    <content><![CDATA[<div id="vip-container"><p>本文将详细介绍Mybatis SQL语句执行的全流程，本文与上篇具有一定的关联性，建议先阅读该系列中的前面3篇文章，重点掌握Mybatis Mapper类的初始化过程，因为在Mybatis中，Mapper是执行SQL语句的入口，类似下面这段代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> UserService implements IUserService &#123;</span><br><span class="line"> 	<span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> UserMapper userMapper;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> User <span class="title">findUser</span><span class="params">(Integer id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> userMapper.find(id);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>开始进入本文的主题，以源码为手段，分析Mybatis执行SQL语句的流行，并且使用了数据库分库分表中间件sharding-jdbc,其版本为sharding-jdbc1.4.1。</p>
<p>为了方便大家对本文的源码分析，先给出Mybatis层面核心类的方法调用序列图。</p>
<h2 id="1、SQL执行序列图"><a href="#1、SQL执行序列图" class="headerlink" title="1、SQL执行序列图"></a>1、SQL执行序列图</h2><p><img src="https://img-blog.csdnimg.cn/20190528210928807.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="2、源码解析SQL执行流程"><a href="#2、源码解析SQL执行流程" class="headerlink" title="2、源码解析SQL执行流程"></a>2、源码解析SQL执行流程</h2><p>接下来从从源码的角度对其进行剖析。</p>
<blockquote>
<p>温馨提示：在本文的末尾，还会给出一张详细的Mybatis Shardingjdbc语句执行流程图。（请勿错过哦）。</p>
</blockquote>
<h3 id="2-1-MapperProxy-invoker"><a href="#2-1-MapperProxy-invoker" class="headerlink" title="2.1 MapperProxy#invoker"></a>2.1 MapperProxy#invoker</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (Object.class.equals(method.getDeclaringClass())) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> method.invoke(<span class="keyword">this</span>, args);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        <span class="keyword">throw</span> ExceptionUtil.unwrapThrowable(t);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">final</span> MapperMethod mapperMethod = cachedMapperMethod(method);   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span> mapperMethod.execute(sqlSession, args);                                     <span class="comment">// @2</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：创建并缓存MapperMethod对象。</p>
<p>代码@2：调用MapperMethod对象的execute方法，即mapperInterface中定义的每一个方法最终会对应一个MapperMethod。</p>
<h3 id="2-2-MapperMethod-execute"><a href="#2-2-MapperMethod-execute" class="headerlink" title="2.2 MapperMethod#execute"></a>2.2 MapperMethod#execute</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">execute</span><span class="params">(SqlSession sqlSession, Object[] args)</span> </span>&#123;</span><br><span class="line">    Object result;</span><br><span class="line">    <span class="keyword">if</span> (SqlCommandType.INSERT == command.getType()) &#123; </span><br><span class="line">      Object param = method.convertArgsToSqlCommandParam(args);</span><br><span class="line">      result = rowCountResult(sqlSession.insert(command.getName(), param));</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (SqlCommandType.UPDATE == command.getType()) &#123;</span><br><span class="line">      Object param = method.convertArgsToSqlCommandParam(args);</span><br><span class="line">      result = rowCountResult(sqlSession.update(command.getName(), param));</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (SqlCommandType.DELETE == command.getType()) &#123;</span><br><span class="line">      Object param = method.convertArgsToSqlCommandParam(args);</span><br><span class="line">      result = rowCountResult(sqlSession.delete(command.getName(), param));</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (SqlCommandType.SELECT == command.getType()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123;</span><br><span class="line">        executeWithResultHandler(sqlSession, args);</span><br><span class="line">        result = <span class="keyword">null</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (method.returnsMany()) &#123;</span><br><span class="line">        result = executeForMany(sqlSession, args);</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (method.returnsMap()) &#123;</span><br><span class="line">        result = executeForMap(sqlSession, args);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        Object param = method.convertArgsToSqlCommandParam(args);</span><br><span class="line">        result = sqlSession.selectOne(command.getName(), param);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> BindingException(<span class="string">&quot;Unknown execution method for: &quot;</span> + command.getName());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (result == <span class="keyword">null</span> &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> BindingException(<span class="string">&quot;Mapper method &#x27;&quot;</span> + command.getName() </span><br><span class="line">          + <span class="string">&quot; attempted to return null from a method with a primitive return type (&quot;</span> + method.getReturnType() + <span class="string">&quot;).&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>该方法主要是根据SQL类型，insert、update、select等操作，执行对应的逻辑，本文我们以查询语句，进行跟踪，进入executeForMany(sqlSession, args)方法。</p>
<h3 id="2-3-MapperMethod-executeForMany"><a href="#2-3-MapperMethod-executeForMany" class="headerlink" title="2.3 MapperMethod#executeForMany"></a>2.3 MapperMethod#executeForMany</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;E&gt; <span class="function">Object <span class="title">executeForMany</span><span class="params">(SqlSession sqlSession, Object[] args)</span> </span>&#123;</span><br><span class="line">    List&lt;E&gt; result;</span><br><span class="line">    Object param = method.convertArgsToSqlCommandParam(args);</span><br><span class="line">    <span class="keyword">if</span> (method.hasRowBounds()) &#123;</span><br><span class="line">      RowBounds rowBounds = method.extractRowBounds(args);</span><br><span class="line">      result = sqlSession.&lt;E&gt;selectList(command.getName(), param, rowBounds);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      result = sqlSession.&lt;E&gt;selectList(command.getName(), param);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// issue #510 Collections &amp; arrays support</span></span><br><span class="line">    <span class="keyword">if</span> (!method.getReturnType().isAssignableFrom(result.getClass())) &#123;</span><br><span class="line">      <span class="keyword">if</span> (method.getReturnType().isArray()) &#123;</span><br><span class="line">        <span class="keyword">return</span> convertToArray(result);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> convertToDeclaredCollection(sqlSession.getConfiguration(), result);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>该方法也比较简单，最终通过SqlSession调用selectList方法。</p>
<h3 id="2-4-DefaultSqlSession-selectList"><a href="#2-4-DefaultSqlSession-selectList" class="headerlink" title="2.4 DefaultSqlSession#selectList"></a>2.4 DefaultSqlSession#selectList</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">selectList</span><span class="params">(String statement, Object parameter, RowBounds rowBounds)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      MappedStatement ms = configuration.getMappedStatement(statement);   <span class="comment">// @1</span></span><br><span class="line">      List&lt;E&gt; result = executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);   <span class="comment">// @2</span></span><br><span class="line">      <span class="keyword">return</span> result;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      <span class="keyword">throw</span> ExceptionFactory.wrapException(<span class="string">&quot;Error querying database.  Cause: &quot;</span> + e, e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      ErrorContext.instance().reset();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：根据资源名称获取对应的MappedStatement对象，此时的statement为资源名称，例如com.demo.UserMapper.findUser。至于MappedStatement对象的生成在上一节初始化时已详细介绍过，此处不再重复介绍。</p>
<p>代码@2：调用Executor的query方法。这里说明一下，其实一开始会进入到CachingExecutor#query方法，由于CachingExecutor的Executor delegate属性默认是SimpleExecutor，故最终还是会进入到SimpleExecutor#query中。</p>
<p>接下来我们进入到SimpleExecutor的父类BaseExecutor的query方法中。</p>
<h3 id="2-5-BaseExecutor-query"><a href="#2-5-BaseExecutor-query" class="headerlink" title="2.5 BaseExecutor#query"></a>2.5 BaseExecutor#query</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">query</span><span class="params">(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql)</span> <span class="keyword">throws</span> SQLException </span>&#123;   <span class="comment">// @1</span></span><br><span class="line">    ErrorContext.instance().resource(ms.getResource()).activity(<span class="string">&quot;executing a query&quot;</span>).object(ms.getId());</span><br><span class="line">    <span class="keyword">if</span> (closed) <span class="keyword">throw</span> <span class="keyword">new</span> ExecutorException(<span class="string">&quot;Executor was closed.&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (queryStack == <span class="number">0</span> &amp;&amp; ms.isFlushCacheRequired()) &#123;</span><br><span class="line">      clearLocalCache();</span><br><span class="line">    &#125;</span><br><span class="line">    List&lt;E&gt; list;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      queryStack++;</span><br><span class="line">      list = resultHandler == <span class="keyword">null</span> ? (List&lt;E&gt;) localCache.getObject(key) : <span class="keyword">null</span>;                                            <span class="comment">// @2</span></span><br><span class="line">      <span class="keyword">if</span> (list != <span class="keyword">null</span>) &#123;</span><br><span class="line">        handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);                   <span class="comment">// @3</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      queryStack--;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (queryStack == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (DeferredLoad deferredLoad : deferredLoads) &#123;</span><br><span class="line">        deferredLoad.load();</span><br><span class="line">      &#125;</span><br><span class="line">      deferredLoads.clear(); <span class="comment">// issue #601</span></span><br><span class="line">      <span class="keyword">if</span> (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123;                         <span class="comment">// @4</span></span><br><span class="line">        clearLocalCache(); <span class="comment">// issue #482</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> list;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先介绍一下该方法的入参，这些类都是Mybatis的重要类：</p>
<ul>
<li>MappedStatement ms<br>映射语句，一个MappedStatemnet对象代表一个Mapper中的一个方法，是映射的最基本对象。</li>
<li>Object parameter<br>SQL语句的参数列表。</li>
<li>RowBounds rowBounds<br>行边界对象，其实就是分页参数limit与size。</li>
<li>ResultHandler resultHandler<br>结果处理Handler。</li>
<li>CacheKey key<br>Mybatis缓存Key</li>
<li>BoundSql boundSql<br>SQL与参数绑定信息，从该对象可以获取在映射文件中的SQL语句。</li>
</ul>
<p>代码@2：首先从缓存中获取，Mybatis支持一级缓存（SqlSession）与二级缓存（多个SqlSession共享）。</p>
<p>代码@3：从数据库查询结果，然后进入到doQuery方法，执行真正的查询动作。</p>
<p>代码@4：如果一级缓存是语句级别的，则语句执行完毕后，删除缓存。</p>
<h3 id="2-6-SimpleExecutor-doQuery"><a href="#2-6-SimpleExecutor-doQuery" class="headerlink" title="2.6 SimpleExecutor#doQuery"></a>2.6 SimpleExecutor#doQuery</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">doQuery</span><span class="params">(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    Statement stmt = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      Configuration configuration = ms.getConfiguration();</span><br><span class="line">      StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql);   <span class="comment">// @1</span></span><br><span class="line">      stmt = prepareStatement(handler, ms.getStatementLog());                                                                                                                   <span class="comment">// @2</span></span><br><span class="line">      <span class="keyword">return</span> handler.&lt;E&gt;query(stmt, resultHandler);                                                                                                                                        <span class="comment">// @3</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      closeStatement(stmt);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：创建StatementHandler，这里会加入Mybatis的插件扩展机制(将在下篇详细介绍)，如图所示：<br><img src="https://img-blog.csdnimg.cn/20190528211610596.png" alt="在这里插入图片描述"><br>代码@2：创建Statement对象，注意，这里就是JDBC协议的java.sql.Statement对象了。</p>
<p>代码@3：使用Statment对象执行SQL语句。</p>
<p>接下来详细介绍Statement对象的创建过程与执行过程，即分布详细跟踪代码@2与代码@3。</p>
<h2 id="3、Statement对象创建流程"><a href="#3、Statement对象创建流程" class="headerlink" title="3、Statement对象创建流程"></a>3、Statement对象创建流程</h2><h3 id="3-1-java-sql-Connection对象创建"><a href="#3-1-java-sql-Connection对象创建" class="headerlink" title="3.1 java.sql.Connection对象创建"></a>3.1 java.sql.Connection对象创建</h3><h4 id="3-1-1-SimpleExecutor-prepareStatement"><a href="#3-1-1-SimpleExecutor-prepareStatement" class="headerlink" title="3.1.1 SimpleExecutor#prepareStatement"></a>3.1.1 SimpleExecutor#prepareStatement</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Statement <span class="title">prepareStatement</span><span class="params">(StatementHandler handler, Log statementLog)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    Statement stmt;</span><br><span class="line">    Connection connection = getConnection(statementLog);  <span class="comment">// @1</span></span><br><span class="line">    stmt = handler.prepare(connection);                                  <span class="comment">// @2</span></span><br><span class="line">    handler.parameterize(stmt);                                               <span class="comment">// @3</span></span><br><span class="line">    <span class="keyword">return</span> stmt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>创建Statement对象，分成三步：<br>代码@1：创建java.sql.Connection对象。</p>
<p>代码@2：使用Connection对象创建Statment对象。</p>
<p>代码@3：对Statement进行额外处理，特别是PrepareStatement的参数设置(ParameterHandler)。</p>
<h4 id="3-1-2-SimpleExecutor-getConnection"><a href="#3-1-2-SimpleExecutor-getConnection" class="headerlink" title="3.1.2 SimpleExecutor#getConnection"></a>3.1.2 SimpleExecutor#getConnection</h4><p>getConnection方法，根据上面流程图所示，先是进入到org.mybatis.spring.transaction.SpringManagedTransaction，再通过spring-jdbc框架，利用DataSourceUtils获取连接，其代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Connection <span class="title">doGetConnection</span><span class="params">(DataSource dataSource)</span> <span class="keyword">throws</span> SQLException </span>&#123;  </span><br><span class="line">		Assert.notNull(dataSource, <span class="string">&quot;No DataSource specified&quot;</span>);</span><br><span class="line">		ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(dataSource); </span><br><span class="line">		<span class="keyword">if</span> (conHolder != <span class="keyword">null</span> &amp;&amp; (conHolder.hasConnection() || conHolder.isSynchronizedWithTransaction())) &#123;</span><br><span class="line">			conHolder.requested();</span><br><span class="line">			<span class="keyword">if</span> (!conHolder.hasConnection()) &#123;</span><br><span class="line">				conHolder.setConnection(dataSource.getConnection());</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> conHolder.getConnection();</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// Else we either got no holder or an empty thread-bound holder here.</span></span><br><span class="line"></span><br><span class="line">		logger.debug(<span class="string">&quot;Fetching JDBC Connection from DataSource&quot;</span>);</span><br><span class="line">		Connection con = dataSource.getConnection();      <span class="comment">// @1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 这里省略与事务处理相关的代码</span></span><br><span class="line">		<span class="keyword">return</span> con;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：通过DataSource获取connection，那此处的DataSource是“谁”呢？看一下我们工程的配置：<br><img src="https://img-blog.csdnimg.cn/20190528212019407.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20190528212039288.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>故最终dataSouce.getConnection获取的连接，是从SpringShardingDataSource中获取连接。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">com.dangdang.ddframe.rdb.sharding.jdbc.ShardingDataSource#getConnection</span><br><span class="line"><span class="function"><span class="keyword">public</span> ShardingConnection <span class="title">getConnection</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        MetricsContext.init(shardingProperties);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ShardingConnection(shardingContext);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>返回的结果如下：<br><img src="https://img-blog.csdnimg.cn/20190528212138293.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>备注：这里只是返回了一个ShardingConnection对象，该对象包含了分库分表上下文，但此时并没有执行具体的分库操作（切换数据源）。</p>
<p>Connection的获取流程清楚后，我们继续来看一下Statemnet对象的创建。</p>
<h3 id="3-2-java-sql-Statement对象创建"><a href="#3-2-java-sql-Statement对象创建" class="headerlink" title="3.2 java.sql.Statement对象创建"></a>3.2 java.sql.Statement对象创建</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">stmt = prepareStatement(handler, ms.getStatementLog());            </span><br></pre></td></tr></table></figure>
<p>上面语句的调用链：RoutingStatementHandler -》BaseStatementHandler</p>
<h4 id="3-2-1-BaseStatementHandler-prepare"><a href="#3-2-1-BaseStatementHandler-prepare" class="headerlink" title="3.2.1 BaseStatementHandler#prepare"></a>3.2.1 BaseStatementHandler#prepare</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Statement <span class="title">prepare</span><span class="params">(Connection connection)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    ErrorContext.instance().sql(boundSql.getSql());</span><br><span class="line">    Statement statement = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      statement = instantiateStatement(connection);    <span class="comment">// @1</span></span><br><span class="line">      setStatementTimeout(statement);                         <span class="comment">// @2</span></span><br><span class="line">      setFetchSize(statement);                                      <span class="comment">// @3</span></span><br><span class="line">      <span class="keyword">return</span> statement;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">      closeStatement(statement);</span><br><span class="line">      <span class="keyword">throw</span> e;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      closeStatement(statement);</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> ExecutorException(<span class="string">&quot;Error preparing statement.  Cause: &quot;</span> + e, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：根据Connection对象（本文中是ShardingConnection)来创建Statement对象，其默认实现类：PreparedStatementHandler#instantiateStatement方法。</p>
<p>代码@2：为Statement设置超时时间。</p>
<p>代码@3：设置fetchSize。</p>
<h4 id="3-2-2-PreparedStatementHandler-instantiateStatement"><a href="#3-2-2-PreparedStatementHandler-instantiateStatement" class="headerlink" title="3.2.2 PreparedStatementHandler#instantiateStatement"></a>3.2.2 PreparedStatementHandler#instantiateStatement</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Statement <span class="title">instantiateStatement</span><span class="params">(Connection connection)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    String sql = boundSql.getSql();</span><br><span class="line">    <span class="keyword">if</span> (mappedStatement.getKeyGenerator() <span class="keyword">instanceof</span> Jdbc3KeyGenerator) &#123;</span><br><span class="line">      String[] keyColumnNames = mappedStatement.getKeyColumns();</span><br><span class="line">      <span class="keyword">if</span> (keyColumnNames == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> connection.prepareStatement(sql, PreparedStatement.RETURN_GENERATED_KEYS);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> connection.prepareStatement(sql, keyColumnNames);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (mappedStatement.getResultSetType() != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> connection.prepareStatement(sql, mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> connection.prepareStatement(sql);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>其实Statement对象的创建，就比较简单了，既然Connection是ShardingConnection，那就看一下其对应的prepareStatement方法即可。</p>
<h4 id="3-2-2-ShardingConnection-prepareStatement"><a href="#3-2-2-ShardingConnection-prepareStatement" class="headerlink" title="3.2.2 ShardingConnection#prepareStatement"></a>3.2.2 ShardingConnection#prepareStatement</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> PreparedStatement <span class="title">prepareStatement</span><span class="params">(<span class="keyword">final</span> String sql)</span> <span class="keyword">throws</span> SQLException </span>&#123;   <span class="comment">// sql，为配置在mybatis xml文件中的sql语句</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ShardingPreparedStatement(<span class="keyword">this</span>, sql);</span><br><span class="line">&#125;</span><br><span class="line">ShardingPreparedStatement(<span class="keyword">final</span> ShardingConnection shardingConnection, </span><br><span class="line">            <span class="keyword">final</span> String sql, <span class="keyword">final</span> <span class="keyword">int</span> resultSetType, <span class="keyword">final</span> <span class="keyword">int</span> resultSetConcurrency, <span class="keyword">final</span> <span class="keyword">int</span> resultSetHoldability) &#123;</span><br><span class="line">        <span class="keyword">super</span>(shardingConnection, resultSetType, resultSetConcurrency, resultSetHoldability);</span><br><span class="line">        preparedSQLRouter = shardingConnection.getShardingContext().getSqlRouteEngine().prepareSQL(sql);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在构建ShardingPreparedStatement对象的时候，会根据SQL语句创建解析SQL路由的解析器对象，但此时并不会执行相关的路由计算，PreparedStatement对象创建完成后，就开始进入SQL执行流程中。</p>
<h2 id="4、SQL执行流程"><a href="#4、SQL执行流程" class="headerlink" title="4、SQL执行流程"></a>4、SQL执行流程</h2><p>接下来我们继续看SimpleExecutor#doQuery方法的第3步，执行SQL语句：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">handler.&lt;E&gt;query(stmt, resultHandler)。</span><br></pre></td></tr></table></figure>
<p>首先会进入RoutingStatementHandler这个类中，进行Mybatis层面的路由（主要是根据Statement类型）<br><img src="https://img-blog.csdnimg.cn/20190528212729690.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>然后进入到PreparedStatementHandler#query中。</p>
<h3 id="4-1-PreparedStatementHandler-query"><a href="#4-1-PreparedStatementHandler-query" class="headerlink" title="4.1 PreparedStatementHandler#query"></a>4.1 PreparedStatementHandler#query</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;E&gt; <span class="function">List&lt;E&gt; <span class="title">query</span><span class="params">(Statement statement, ResultHandler resultHandler)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    PreparedStatement ps = (PreparedStatement) statement;</span><br><span class="line">    ps.execute();  <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span> resultSetHandler.&lt;E&gt; handleResultSets(ps);  <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：调用PreparedStatement的execute方法，由于本例是使用了Sharding-jdbc分库分表，此时调用的具体实现为：ShardingPreparedStatement。</p>
<p>代码@2：处理结果。</p>
<p>我们接下来分别来跟进execute与结果处理方法。</p>
<h3 id="4-2-ShardingPreparedStatement-execute"><a href="#4-2-ShardingPreparedStatement-execute" class="headerlink" title="4.2 ShardingPreparedStatement#execute"></a>4.2 ShardingPreparedStatement#execute</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">execute</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> PreparedStatementExecutor(getShardingConnection().getShardingContext().getExecutorEngine(), routeSQL()).execute(); <span class="comment">// @1</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        clearRouteContext();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里奥妙无穷，其关键点如下：<br>1）创造PreparedStatementExecutor对象，其两个核心参数：</p>
<ul>
<li>ExecutorEngine executorEngine：shardingjdbc执行引擎。</li>
<li>Collection&lt; PreparedStatementExecutorWrapper&gt; preparedStatemenWrappers<br>一个集合，每一个集合是PreparedStatement的包装类，这个集合如何而来？</li>
</ul>
<p>2）preparedStatemenWrappers是通过routeSQL方法产生的。</p>
<p>3）最终调用PreparedStatementExecutor方法的execute来执行。</p>
<p>接下来分别看一下routeSQL与execute方法。</p>
<h3 id="4-3-ShardingPreparedStatement-routeSQL"><a href="#4-3-ShardingPreparedStatement-routeSQL" class="headerlink" title="4.3 ShardingPreparedStatement#routeSQL"></a>4.3 ShardingPreparedStatement#routeSQL</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> List&lt;PreparedStatementExecutorWrapper&gt; <span class="title">routeSQL</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        List&lt;PreparedStatementExecutorWrapper&gt; result = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        SQLRouteResult sqlRouteResult = preparedSQLRouter.route(getParameters());   <span class="comment">// @1</span></span><br><span class="line">        MergeContext mergeContext = sqlRouteResult.getMergeContext();                      </span><br><span class="line">        setMergeContext(mergeContext);</span><br><span class="line">        setGeneratedKeyContext(sqlRouteResult.getGeneratedKeyContext());</span><br><span class="line">        <span class="keyword">for</span> (SQLExecutionUnit each : sqlRouteResult.getExecutionUnits()) &#123;                      <span class="comment">// @2          </span></span><br><span class="line">            PreparedStatement preparedStatement = (PreparedStatement) getStatement(getShardingConnection().getConnection(each.getDataSource(), sqlRouteResult.getSqlStatementType()), each.getSql());     <span class="comment">// @3</span></span><br><span class="line">            replayMethodsInvocation(preparedStatement);</span><br><span class="line">            getParameters().replayMethodsInvocation(preparedStatement);</span><br><span class="line">            result.add(wrap(preparedStatement, each));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：根据SQL参数进行路由计算，本文暂不关注其具体实现细节，这些将在具体分析Sharding-jdbc时具体详解，在这里就直观看一下其结果：</p>
<p>代码@2、@3：对分库分表的结果进行遍历，然后使用底层Datasource来创建Connection，创建PreparedStatement 对象。</p>
<p>routeSQL就暂时讲到这，从这里我们得知，会在这里根据路由结果，使用底层的具体数据源创建对应的Connection与PreparedStatement 对象。</p>
<h3 id="4-4-PreparedStatementExecutor-execute"><a href="#4-4-PreparedStatementExecutor-execute" class="headerlink" title="4.4 PreparedStatementExecutor#execute"></a>4.4 PreparedStatementExecutor#execute</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">execute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Context context = MetricsContext.start(<span class="string">&quot;ShardingPreparedStatement-execute&quot;</span>);</span><br><span class="line">    eventPostman.postExecutionEvents();</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">boolean</span> isExceptionThrown = ExecutorExceptionHandler.isExceptionThrown();</span><br><span class="line">    <span class="keyword">final</span> Map&lt;String, Object&gt; dataMap = ExecutorDataMap.getDataMap();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="number">1</span> == preparedStatementExecutorWrappers.size()) &#123;     <span class="comment">// @1</span></span><br><span class="line">            PreparedStatementExecutorWrapper preparedStatementExecutorWrapper = preparedStatementExecutorWrappers.iterator().next();</span><br><span class="line">            <span class="keyword">return</span> executeInternal(preparedStatementExecutorWrapper, isExceptionThrown, dataMap);</span><br><span class="line">        &#125;</span><br><span class="line">        List&lt;Boolean&gt; result = executorEngine.execute(preparedStatementExecutorWrappers, <span class="keyword">new</span> ExecuteUnit&lt;PreparedStatementExecutorWrapper, Boolean&gt;() &#123;    <span class="comment">// @2</span></span><br><span class="line">        </span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Boolean <span class="title">execute</span><span class="params">(<span class="keyword">final</span> PreparedStatementExecutorWrapper input)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (input.getPreparedStatement().getConnection()) &#123;</span><br><span class="line">                    <span class="keyword">return</span> executeInternal(input, isExceptionThrown, dataMap);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">null</span> == result || result.isEmpty()) ? <span class="keyword">false</span> : result.get(<span class="number">0</span>);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        MetricsContext.stop(context);</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果计算出来的路由信息为1个，则同步执行。</p>
<p>代码@2：如果计算出来的路由信息有多个，则使用线程池异步执行。</p>
<p>那还有一个问题，通过PreparedStatement#execute方法执行后，如何返回结果呢？特别是异步执行的。</p>
<p>在上文其实已经谈到：</p>
<h3 id="4-4-DefaultResultSetHandler-handleResultSets"><a href="#4-4-DefaultResultSetHandler-handleResultSets" class="headerlink" title="4.4 DefaultResultSetHandler#handleResultSets"></a>4.4 DefaultResultSetHandler#handleResultSets</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> List&lt;Object&gt; <span class="title">handleResultSets</span><span class="params">(Statement stmt)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    ErrorContext.instance().activity(<span class="string">&quot;handling results&quot;</span>).object(mappedStatement.getId());</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">final</span> List&lt;Object&gt; multipleResults = <span class="keyword">new</span> ArrayList&lt;Object&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> resultSetCount = <span class="number">0</span>;</span><br><span class="line">    ResultSetWrapper rsw = getFirstResultSet(stmt);         <span class="comment">// @1</span></span><br><span class="line">    <span class="comment">//省略部分代码，完整代码可以查看DefaultResultSetHandler方法。</span></span><br><span class="line">    <span class="keyword">return</span> collapseSingleResultList(multipleResults);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> ResultSetWrapper <span class="title">getFirstResultSet</span><span class="params">(Statement stmt)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">    ResultSet rs = stmt.getResultSet();              <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">while</span> (rs == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">// move forward to get the first resultset in case the driver</span></span><br><span class="line">      <span class="comment">// doesn&#x27;t return the resultset as the first result (HSQLDB 2.1)</span></span><br><span class="line">      <span class="keyword">if</span> (stmt.getMoreResults()) &#123;</span><br><span class="line">        rs = stmt.getResultSet();</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (stmt.getUpdateCount() == -<span class="number">1</span>) &#123;</span><br><span class="line">          <span class="comment">// no more results. Must be no resultset</span></span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> rs != <span class="keyword">null</span> ? <span class="keyword">new</span> ResultSetWrapper(rs, configuration) : <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>我们看一下其关键代码如下：<br>代码@1：调用Statement#getResultSet()方法，如果使用shardingJdbc，则会调用ShardingStatement#getResultSet()，并会处理分库分表结果集的合并，在这里就不详细进行介绍，该部分会在shardingjdbc专栏详细分析。</p>
<p>代码@2：jdbc statement中获取结果集的通用写法，这里也不过多的介绍。</p>
<p>mybatis shardingjdbc SQL执行流程就介绍到这里了，为了方便大家对上述流程的理解，最后给出SQL执行的流程图：<br><img src="https://img-blog.csdnimg.cn/2019052821331476.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>Mybatis Sharding-Jdbc的SQL执行流程就介绍到这里了，从图中也能清晰看到Mybatis的拆件机制，将在下文详细介绍。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
        <tag>Sharding</tag>
        <tag>SQL执行流程</tag>
      </tags>
  </entry>
  <entry>
    <title>踩坑记：rocketmq-console 消费TPS为0，但消息积压数却在降低是个什么“鬼”</title>
    <url>/posts/9b5ea02.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="1、背景"><a href="#1、背景" class="headerlink" title="1、背景"></a>1、背景</h2><p>当消息出现大量挤压后，消费端将其代码优化后，重启消费端服务器，从 rocketmq-console 上发现 TPS 为 0，如图所示：<br><img src="https://img-blog.csdnimg.cn/20191130162947883.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>乍一看，第一时间得出应用还未恢复，就开始去查看相关的启动日志,通常查看的是应用服务器的 /home/baseuser/logs/rockemqlogs/rocketmq_client.logs，碰巧又看到如下的错误日志：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">RebalanceService - [BUG] ConsumerGroup: consumergourp-1 The consumerId: consumer-client-id-clusterA-192.168.x.x@21932 not in cidAll: [consumer-client-id-clusterA-192.168.x.x@22164]</span><br></pre></td></tr></table></figure>
<p>上面的日志显示在队列负载时候，当前节点竟然不属于 consumergourp-1 消费组的活跃连接，导致一大片的报错：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2019-11-02 19:29:17 WARN NettyClientPublicExecutor_1 - execute the pull request exception</span><br><span class="line">org.apache.rocketmq.client.exception.MQBrokerException: CODE: 25  DESC: the consumer&#39;s subscription not latest</span><br><span class="line">For more information, please visit the url, http:&#x2F;&#x2F;rocketmq.apache.org&#x2F;docs&#x2F;faq&#x2F;</span><br><span class="line">	at org.apache.rocketmq.client.impl.MQClientAPIImpl.processPullResponse(MQClientAPIImpl.java:639)</span><br><span class="line">	at org.apache.rocketmq.client.impl.MQClientAPIImpl.access$200(MQClientAPIImpl.java:156)</span><br><span class="line">	at org.apache.rocketmq.client.impl.MQClientAPIImpl$2.operationComplete(MQClientAPIImpl.java:592)</span><br><span class="line">	at org.apache.rocketmq.remoting.netty.ResponseFuture.executeInvokeCallback(ResponseFuture.java:51)</span><br><span class="line">	at org.apache.rocketmq.remoting.netty.NettyRemotingAbstract$2.run(NettyRemotingAbstract.java:275)</span><br><span class="line">	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</span><br><span class="line">	at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:745)</span><br></pre></td></tr></table></figure>
<p>乍一看确实是 rocketmq 相关的问题，导致上述 消费TPS 为0，经过半个小时的日志分析，发现这是RocketMQ 这是一种正常现象，最终会自动恢复，这里我留一个<strong>伏笔</strong>，将在我的<strong>知识星球</strong>中与广大星友讨论，<strong>经过日志分析得出 rocketmq 没问题，故后面去查看消息积压，发现消息积压明显在减少，那这就奇了怪了，咋消息积压在快速减少，但为啥消费TPS还是为0呢？</strong></p>
<p>接下来将该问题进行探讨。</p>
<blockquote>
<p>温馨提示：在问题分析部分，作者没有直接给出答案，而是一步一步探寻答案，因此会通过追踪源码来寻求答案，如果大家想急于答案，可以跳过问题分析，直接查看本文末尾的问题解答部分。<br>通过本文的阅读，您将获得如下信息：<br>1、RocketMQ 消费TPS的收集与计算逻辑。<br>2、RocketMQ 监控指标的设计思路。<br>3、RocketMQ 主从同步，消费者从主服务器拉取还是从从服务器拉取的判断逻辑。</p>
</blockquote>
<h2 id="2、问题分析"><a href="#2、问题分析" class="headerlink" title="2、问题分析"></a>2、问题分析</h2><h4 id="2-1-rocketmq-console-数据获获取逻辑探讨"><a href="#2-1-rocketmq-console-数据获获取逻辑探讨" class="headerlink" title="2.1 rocketmq-console 数据获获取逻辑探讨"></a>2.1 rocketmq-console 数据获获取逻辑探讨</h4><p>要解开消费TPS 显示为０的问题，我们首先要来看一下 rocketmq-console 这个页面的展示逻辑，即通过阅读 rocketmq-console的源码来解开其采集逻辑。<br><img src="https://img-blog.csdnimg.cn/20191130163430404.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>得知，【消费者】界面查询各个消费组的基本信息的接口为 /consumer/groupList.query，那接下来，我们首先从源码的角度来分析该接口的实现逻辑。其入口如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">org.apache.rocketmq.console.controller.ConsumerController#list</span><br><span class="line"><span class="meta">@RequestMapping(value = &quot;/groupList.query&quot;)</span></span><br><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">list</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> consumerService.queryGroupList();</span><br><span class="line">&#125;</span><br><span class="line">就是调用消费服务处理类的 queryGroupList 方法，其实现代码如下：</span><br><span class="line">ConsumerServiceImpl＃queryGroupList</span><br><span class="line"><span class="function"><span class="keyword">public</span> List&lt;GroupConsumeInfo&gt; <span class="title">queryGroupList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Set&lt;String&gt; consumerGroupSet = Sets.newHashSet();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        ClusterInfo clusterInfo = mqAdminExt.examineBrokerClusterInfo();　　<span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">for</span> (BrokerData brokerData : clusterInfo.getBrokerAddrTable().values()) &#123;   <span class="comment">// @2</span></span><br><span class="line">            SubscriptionGroupWrapper subscriptionGroupWrapper = mqAdminExt.getAllSubscriptionGroup(brokerData.selectBrokerAddr(), <span class="number">3000L</span>);  <span class="comment">// @3</span></span><br><span class="line">            consumerGroupSet.addAll(subscriptionGroupWrapper.getSubscriptionGroupTable().keySet());                                                                 </span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception err) &#123;</span><br><span class="line">        <span class="keyword">throw</span> Throwables.propagate(err);</span><br><span class="line">    &#125;</span><br><span class="line">    List&lt;GroupConsumeInfo&gt; groupConsumeInfoList = Lists.newArrayList();</span><br><span class="line">    <span class="keyword">for</span> (String consumerGroup : consumerGroupSet) &#123;                                                <span class="comment">// @4</span></span><br><span class="line">        groupConsumeInfoList.add(queryGroup(consumerGroup));                              </span><br><span class="line">    &#125;</span><br><span class="line">    Collections.sort(groupConsumeInfoList);</span><br><span class="line">    <span class="keyword">return</span> groupConsumeInfoList;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：获取集群的 broker 信息，主要是通过向 NameServer 发送 GET_BROKER_CLUSTER_INFO 请求，NameServer 返回集群包含的所有 broker 信息，包含从节点的信息，返回的格式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;clusterInfo&quot;: &#123;</span><br><span class="line">    &quot;brokerAddrTable&quot;: &#123;</span><br><span class="line">	   &quot;broker-a&quot;: &#123;</span><br><span class="line">	       &quot;cluster&quot;: &quot;DefaultCluster&quot;,</span><br><span class="line">			&quot;brokerName&quot;: &quot;broker-a&quot;,</span><br><span class="line">			&quot;brokerAddrs&quot;: &#123;</span><br><span class="line">				&quot;0&quot;: &quot;192.168.0.168:10911&quot;,</span><br><span class="line">				&quot;1&quot;: &quot;192.168.0.169:10911&quot;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;,</span><br><span class="line">        &quot;broker-b&quot;: &#123;</span><br><span class="line">	       &quot;cluster&quot;: &quot;DefaultCluster&quot;,</span><br><span class="line">			&quot;brokerName&quot;: &quot;broker-b&quot;,</span><br><span class="line">			&quot;brokerAddrs&quot;: &#123;</span><br><span class="line">				&quot;0&quot;: &quot;192.168.0.170:10911&quot;,</span><br><span class="line">				&quot;1&quot;: &quot;192.168.1.171:10911&quot;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;clusterAddrTable&quot;: &#123;</span><br><span class="line">		&quot;DefaultCluster&quot;: [&quot;broker-a&quot;,&quot;broker-b&quot;]</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@2：遍历集群中的 brokerAddrTable 数据结构，即存储了 broker 的地址信息的 Map 。</p>
<p>代码@3：分别向集群中的主节点(brokerData.selectBrokerAddr()) 获取所有的订阅关系（即消费组的订阅信息）。然后将所有的消费者组名称存入 consumerGroupSet。</p>
<p>代码@4：遍历代码@3收集到的消费组，调用 queryGroup 依次请求消费组的运行时信息，后面接下来详细分析。</p>
<p>接下来将重点分析 queryGroup方法的实现细节。</p>
<a id="more"></a>

<p>ConsumerServiceImpl#queryGroup</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> GroupConsumeInfo <span class="title">queryGroup</span><span class="params">(String consumerGroup)</span> </span>&#123;</span><br><span class="line">    GroupConsumeInfo groupConsumeInfo = <span class="keyword">new</span> GroupConsumeInfo();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        ConsumeStats consumeStats = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            consumeStats = mqAdminExt.examineConsumeStats(consumerGroup);  <span class="comment">// @1</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            logger.warn(<span class="string">&quot;examineConsumeStats exception, &quot;</span> + consumerGroup, e);</span><br><span class="line">        &#125;</span><br><span class="line">        ConsumerConnection consumerConnection = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            consumerConnection = mqAdminExt.examineConsumerConnectionInfo(consumerGroup); </span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            logger.warn(<span class="string">&quot;examineConsumerConnectionInfo exception, &quot;</span> + consumerGroup, e);</span><br><span class="line">        &#125;</span><br><span class="line">        groupConsumeInfo.setGroup(consumerGroup);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (consumeStats != <span class="keyword">null</span>) &#123;</span><br><span class="line">            groupConsumeInfo.setConsumeTps((<span class="keyword">int</span>)consumeStats.getConsumeTps());    <span class="comment">// @2</span></span><br><span class="line">            groupConsumeInfo.setDiffTotal(consumeStats.computeTotalDiff());                   <span class="comment">// @3</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (consumerConnection != <span class="keyword">null</span>) &#123;</span><br><span class="line">            groupConsumeInfo.setCount(consumerConnection.getConnectionSet().size());</span><br><span class="line">            groupConsumeInfo.setMessageModel(consumerConnection.getMessageModel());</span><br><span class="line">            groupConsumeInfo.setConsumeType(consumerConnection.getConsumeType());</span><br><span class="line">            groupConsumeInfo.setVersion(MQVersion.getVersionDesc(consumerConnection.computeMinVersion()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        logger.warn(<span class="string">&quot;examineConsumeStats or examineConsumerConnectionInfo exception, &quot;</span></span><br><span class="line">                + consumerGroup, e);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> groupConsumeInfo;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上面@1，@2，@3这三处代码可以得知，rocketmq-console 相关界面上的消费TPS主要来自 examineConsumeStats 方法，该方法我就不再继续深入，我们只需找到该方法向 broker 发送的请求编码，然后根据该请求编码找到 broker 的处理逻辑即可，最后跟踪发送的请求编码为：RequestCode.GET_CONSUME_STATS。</p>
<p>GET_CONSUME_STATS 命令在 broker 的处理逻辑如下：</p>
<p>AdminBrokerProcessor#getConsumeStats</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> RemotingCommand <span class="title">getConsumeStats</span><span class="params">(ChannelHandlerContext ctx, RemotingCommand request)</span> <span class="keyword">throws</span> RemotingCommandException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> RemotingCommand response = RemotingCommand.createResponseCommand(<span class="keyword">null</span>);</span><br><span class="line">        <span class="keyword">final</span> GetConsumeStatsRequestHeader requestHeader =</span><br><span class="line">            (GetConsumeStatsRequestHeader) request.decodeCommandCustomHeader(GetConsumeStatsRequestHeader.class);</span><br><span class="line">        ConsumeStats consumeStats = <span class="keyword">new</span> ConsumeStats();</span><br><span class="line">        Set&lt;String&gt; topics = <span class="keyword">new</span> HashSet&lt;String&gt;();</span><br><span class="line">        <span class="keyword">if</span> (UtilAll.isBlank(requestHeader.getTopic())) &#123;</span><br><span class="line">            topics = <span class="keyword">this</span>.brokerController.getConsumerOffsetManager().whichTopicByConsumer(requestHeader.getConsumerGroup());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            topics.add(requestHeader.getTopic());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (String topic : topics) &#123;   <span class="comment">// @1</span></span><br><span class="line">            TopicConfig topicConfig = <span class="keyword">this</span>.brokerController.getTopicConfigManager().selectTopicConfig(topic);</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">null</span> == topicConfig) &#123;  <span class="comment">// @2</span></span><br><span class="line">                log.warn(<span class="string">&quot;consumeStats, topic config not exist, &#123;&#125;&quot;</span>, topic);</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            &#123;                                </span><br><span class="line">                SubscriptionData findSubscriptionData =</span><br><span class="line">                    <span class="keyword">this</span>.brokerController.getConsumerManager().findSubscriptionData(requestHeader.getConsumerGroup(), topic);   <span class="comment">// @3</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">null</span> == findSubscriptionData <span class="comment">//</span></span><br><span class="line">                    &amp;&amp; <span class="keyword">this</span>.brokerController.getConsumerManager().findSubscriptionDataCount(requestHeader.getConsumerGroup()) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    log.warn(<span class="string">&quot;consumeStats, the consumer group[&#123;&#125;], topic[&#123;&#125;] not exist&quot;</span>, requestHeader.getConsumerGroup(), topic);</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; topicConfig.getReadQueueNums(); i++) &#123;   <span class="comment">// @4</span></span><br><span class="line">                MessageQueue mq = <span class="keyword">new</span> MessageQueue();</span><br><span class="line">                mq.setTopic(topic);</span><br><span class="line">                mq.setBrokerName(<span class="keyword">this</span>.brokerController.getBrokerConfig().getBrokerName());</span><br><span class="line">                mq.setQueueId(i);</span><br><span class="line">                OffsetWrapper offsetWrapper = <span class="keyword">new</span> OffsetWrapper();</span><br><span class="line">                <span class="keyword">long</span> brokerOffset = <span class="keyword">this</span>.brokerController.getMessageStore().getMaxOffsetInQueue(topic, i);</span><br><span class="line">                <span class="keyword">if</span> (brokerOffset &lt; <span class="number">0</span>)</span><br><span class="line">                    brokerOffset = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">long</span> consumerOffset = <span class="keyword">this</span>.brokerController.getConsumerOffsetManager().queryOffset(<span class="comment">//</span></span><br><span class="line">                    requestHeader.getConsumerGroup(), <span class="comment">//</span></span><br><span class="line">                    topic, <span class="comment">//</span></span><br><span class="line">                    i);</span><br><span class="line">                <span class="keyword">if</span> (consumerOffset &lt; <span class="number">0</span>)</span><br><span class="line">                    consumerOffset = <span class="number">0</span>;</span><br><span class="line">                offsetWrapper.setBrokerOffset(brokerOffset);                                   <span class="comment">// @5</span></span><br><span class="line">                offsetWrapper.setConsumerOffset(consumerOffset);                       <span class="comment">// @6</span></span><br><span class="line">                <span class="keyword">long</span> timeOffset = consumerOffset - <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">if</span> (timeOffset &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">long</span> lastTimestamp = <span class="keyword">this</span>.brokerController.getMessageStore().getMessageStoreTimeStamp(topic, i, timeOffset);</span><br><span class="line">                    <span class="keyword">if</span> (lastTimestamp &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                        offsetWrapper.setLastTimestamp(lastTimestamp);                 <span class="comment">// @7</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                consumeStats.getOffsetTable().put(mq, offsetWrapper);     <span class="comment">// @8</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">double</span> consumeTps = <span class="keyword">this</span>.brokerController.getBrokerStatsManager().tpsGroupGetNums(requestHeader.getConsumerGroup(), topic); <span class="comment">// @9</span></span><br><span class="line">            consumeTps += consumeStats.getConsumeTps(); <span class="comment">// @10</span></span><br><span class="line">            consumeStats.setConsumeTps(consumeTps);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">byte</span>[] body = consumeStats.encode();</span><br><span class="line">        response.setBody(body);</span><br><span class="line">        response.setCode(ResponseCode.SUCCESS);</span><br><span class="line">        response.setRemark(<span class="keyword">null</span>);</span><br><span class="line">        <span class="keyword">return</span> response;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法比较长，重点关注如下关键点：<br>代码@1：遍历该消费组订阅的所有主题。消费TPS将是所有主题消费TPS的总和，其他的信息按主题、队列信息单独存放。</p>
<p>代码@2：如果 topic 的元信息不存在，则跳过该主题。</p>
<p>代码@3：如果消费组的订阅信息不存在，则跳过该订阅关系。</p>
<p>代码@4：收集该主题所有的读队列，以messagequeue为键，OffsetWrapper为值存储在 consumeStats.getOffsetTable() ，见代码@8。</p>
<p>代码@5：设置该队列的最新偏移量。</p>
<p>代码@6：设置该消费组对该队列的消费进度，设置为consumeOffset。</p>
<p>代码@7：lastTimestamp 上一次消费的消息的存储时间，实现逻辑为：取消费组对于队列的消息消费进度 -1 的消息，存储在 broker 的时间，如果对应的消息已过期被删除，则在界面上显示的时间就会为1970-01-01 08:00:00。</p>
<p>代码@9：通过 BrokerStatsManager 的 tpsGroupGetNums 方法从统计数据中获取该消费组针对该队列的消费TPS。</p>
<p>代码@10：累积消费TPS，并最终作为该消费组的总TPS。</p>
<p><strong>上面这个方法非常关键，是返回给前段页面核心的数据组装逻辑，以队列、消费组为纬度给出 brokerOffset、consumeOffset、lastTimestamp。然后将数据返回给前段页面进行展示。</strong></p>
<p>接下将聚焦到消费组消费TPS的统计处理，其入口为 <strong>tpsGroupGetNums</strong> 。</p>
<h4 id="2-2-rocketmq-消费TPS统计实现原理"><a href="#2-2-rocketmq-消费TPS统计实现原理" class="headerlink" title="2.2 rocketmq 消费TPS统计实现原理"></a>2.2 rocketmq 消费TPS统计实现原理</h4><h5 id="2-2-1-消费TPS计算逻辑"><a href="#2-2-1-消费TPS计算逻辑" class="headerlink" title="2.2.1 消费TPS计算逻辑"></a>2.2.1 消费TPS计算逻辑</h5><p>首先我们还是从 tpsGroupGetNums 方法入手，探究一下 tps 的获取逻辑，然后再探究数据的采集原理（这也是 rocketmq 监控相关）。</p>
<p>BrokerStatsManager#tpsGroupGetNums</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">tpsGroupGetNums</span><span class="params">(<span class="keyword">final</span> String group, <span class="keyword">final</span> String topic)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> String statsKey = buildStatsKey(topic, group); <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.statsTable.get(GROUP_GET_NUMS).getStatsDataInMinute(statsKey).getTps(); <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：构建统计key，其逻辑为：其键为：topic@consumerGroup，即消息主题@消费组名。</p>
<p>要读懂 代码@2 的代码，先来看一下 rocketmq 监控指标的存储数据结构，如下图所示：<br><img src="https://img-blog.csdnimg.cn/20191130163718134.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>正如上图所示：RocketMQ  使用 HashMap&lt; String, StatusItemSet&gt; 来存储监控收集的数据，其中Key 为监控指标的类型，例如 topic 发送消息数量、topic 发送消息大小、消费组获取消息个数等信息，每一项使用 StatsItemSet 存储，该存储结构内部又维护一个HashMap：ConcurrentMap，key 代表某一个具体的统计目标，例如记录消费组拉取消息的数量监控指标，那其统计的对象即 topic@consumer_group，最终数据的载体是 StatsItem，使用如下几个关键字段来记录统计信息：</p>
<ul>
<li>AtomicLong value = new AtomicLong(0)<br>总数量，统计指标TOPIC_GET_NUMS 指标为例，记录的是消息拉取的总条数，例如一次消息拉取操作获取了32条消息，则该数量增加32。</li>
<li>AtomicLong times = new AtomicLong(0)<br>改变上述 value 的次数，还是以统计指标TOPIC_GET_NUMS 指标为例，记录的是增加 value 的次数。</li>
<li>LinkedList&lt; CallSnapshot&gt; csListMinute<br>一分钟的快照信息，该 List 只会存储6个元素，每10s记录一次调用快照，超过6条，则移除第一条，这个将在下文介绍。</li>
<li>LinkedList&lt; CallSnapshot&gt; csListHour<br>一小时的快照信息，该 List 只会存储6个元素，每10分钟记录一次快照，超过6条，则移除第一条。</li>
<li>LinkedList&lt; CallSnapshot&gt; csListDay<br>一天的快照新，该List 只会存储24个元素，每1小时记录一次快照，超过24条，则移除第一条。</li>
</ul>
<p>了解了上述存储结构后，代码@2，最终其实调用的就是 StatsItemSet 的 getStatsDataInMinute 方法。</p>
<p>StatsItemSet#getStatsDataInMinute</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> StatsSnapshot <span class="title">getStatsDataInMinute</span><span class="params">(<span class="keyword">final</span> String statsKey)</span> </span>&#123;</span><br><span class="line">    StatsItem statsItem = <span class="keyword">this</span>.statsItemTable.get(statsKey);</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> != statsItem) &#123;</span><br><span class="line">        <span class="keyword">return</span> statsItem.getStatsDataInMinute();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> StatsSnapshot();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从代码上最终调用 StatesItem 的 getStatsDataInMinute 方法。</p>
<p>StatesItem#getStatsDataInMinute</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> StatsSnapshot <span class="title">getStatsDataInMinute</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> computeStatsData(<span class="keyword">this</span>.csListMinute);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> StatsSnapshot <span class="title">computeStatsData</span><span class="params">(<span class="keyword">final</span> LinkedList&lt;CallSnapshot&gt; csList)</span> </span>&#123;</span><br><span class="line">    StatsSnapshot statsSnapshot = <span class="keyword">new</span> StatsSnapshot();</span><br><span class="line">    <span class="keyword">synchronized</span> (csList) &#123;</span><br><span class="line">        <span class="keyword">double</span> tps = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">double</span> avgpt = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">long</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (!csList.isEmpty()) &#123;</span><br><span class="line">            CallSnapshot first = csList.getFirst();   <span class="comment">// @1</span></span><br><span class="line">            CallSnapshot last = csList.getLast();    <span class="comment">// @2</span></span><br><span class="line">            sum = last.getValue() - first.getValue();  <span class="comment">// @3</span></span><br><span class="line">            tps = (sum * <span class="number">1000.0d</span>) / (last.getTimestamp() - first.getTimestamp());   <span class="comment">// @4</span></span><br><span class="line">            <span class="keyword">long</span> timesDiff = last.getTimes() - first.getTimes();</span><br><span class="line">            <span class="keyword">if</span> (timesDiff &gt; <span class="number">0</span>) &#123;                                                                                   <span class="comment">// @5</span></span><br><span class="line">                avgpt = (sum * <span class="number">1.0d</span>) / timesDiff;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        statsSnapshot.setSum(sum);</span><br><span class="line">        statsSnapshot.setTps(tps);</span><br><span class="line">        statsSnapshot.setAvgpt(avgpt);                                                          </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> statsSnapshot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先取快照中的第一条消息。</p>
<p>代码@2：取快照列表中的最后一条消息。</p>
<p>代码@3：计算这两个时间点 value 的差值，即这段时间内新增的总数。</p>
<p>代码@4：计算这段时间内的tps，即每秒处理的消息条数。</p>
<p>代码@5：计算 avgpt ，即平均一次操作新增的消息条数（即平均一次操作，value 新增的个数）。</p>
<p><strong>消费组的消费TPS的计算逻辑就介绍到这里了，那还有一个疑问，即 StatsItem 中 csListMinute 中的数据从哪来呢？</strong></p>
<h5 id="2-2-2-如何采集消费TPS原始数据"><a href="#2-2-2-如何采集消费TPS原始数据" class="headerlink" title="2.2.2 如何采集消费TPS原始数据"></a>2.2.2 如何采集消费TPS原始数据</h5><p>StatsItem#init</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.scheduledExecutorService.scheduleAtFixedRate(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    samplingInSeconds();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Throwable ignored) &#123;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="number">0</span>, <span class="number">10</span>, TimeUnit.SECONDS);</span><br><span class="line">   <span class="comment">// 省略其他代码</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>原来在创建一个新的StatsItem 的时候，就会启动一个定时任务，每隔 10s 调用 samplingInSeconds 方法进行抽样，那我们简单看一下这个方法：</p>
<p>StatsItem#samplingInSeconds</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">samplingInSeconds</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>.csListMinute) &#123;</span><br><span class="line">        <span class="keyword">this</span>.csListMinute.add(<span class="keyword">new</span> CallSnapshot(System.currentTimeMillis(), <span class="keyword">this</span>.times.get(), <span class="keyword">this</span>.value</span><br><span class="line">                .get()));</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.csListMinute.size() &gt; <span class="number">7</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.csListMinute.removeFirst();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>就是将当前StatsItem 中的 value 与 变更次数(time ) 存入封装成 CallSnapshot ，然后存储在快照列表中。这里的关键是times values 这些值在什么情况下会改变呢？ </p>
<p>接着往下看，源码在消息拉取的时候，会将本次拉取的信息加入到统计信息中，其入口为：</p>
<p>PullMessageProcessor#processRequest</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">switch</span> (response.getCode()) &#123;</span><br><span class="line">    <span class="keyword">case</span> ResponseCode.SUCCESS:</span><br><span class="line">        <span class="keyword">this</span>.brokerController.getBrokerStatsManager().incGroupGetNums(requestHeader.getConsumerGroup(), requestHeader.getTopic(),</span><br><span class="line">                        getMessageResult.getMessageCount());</span><br><span class="line">        <span class="keyword">this</span>.brokerController.getBrokerStatsManager().incGroupGetSize(requestHeader.getConsumerGroup(), requestHeader.getTopic(),</span><br><span class="line">                        getMessageResult.getBufferTotalSize());</span><br><span class="line">        <span class="keyword">this</span>.brokerController.getBrokerStatsManager().incBrokerGetNums(getMessageResult.getMessageCount());</span><br><span class="line">        </span><br><span class="line">    <span class="comment">// 省略其他代码</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法会最终更新 StatsItem 中的 values ，而 times 是 每调用一次，加1。</p>
<p>理论基础讲解完毕后，接下来我们来回答一下题目中的现象。</p>
<h2 id="3、问题解答"><a href="#3、问题解答" class="headerlink" title="3、问题解答"></a>3、问题解答</h2><p>按照上面的讲解，通过 rocketmq-console 发起查看消费组的TPS时，Broker 会根据过去一分钟内采集的快照数据进行计算。快照信息的采集机制是 broker 端会每10s 会记录一下消费组对应的拉取消息数量与拉取次数。</p>
<p><strong>那既然消息延迟(堆积数量在不断减少)，说明消费端正在消费，按道理来说，通过上述机制进行计算，TPS 不可能会是0？那又是什么原因呢？</strong></p>
<p><strong>如果TPS为0，可以说明消费端并没有向 broker 拉取消息，因为一旦从 broker 拉取消息，有关 StatsItem 的 拉取消息总数(value) 与 拉取次数(times) 再两次采集国产中肯定不会相等，只要两者有差距，其TPS就不可能为0，那消费组在消费消息，但又不从主节点上拉取消息，这种情况会出现吗？</strong></p>
<p><strong>答案是会的，在 RocketMQ 主从同步架构中，如果需要访问的消息偏移量与当前 commitlog 最大偏移的之间的差距超过了内存的40%，消息消费将由从节点接管，故此时消费的拉取不会去主节点拉取，故上面返回的TPS就会为0。这样就能完美解答了。</strong></p>
<p>经过上面的分析，我相信大家已经非常认可这个原因了，其实我们还有一个重要的论据，大家可以分别去查看 Rocketmq 主从节点 /home/{username}/logs/rocketmqlogs/stats.log，里面会每隔1分钟在日志中打印各个消费组的消费TPS.</p>
<p>从服务器(rocketmq-slave)对应的日志如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INFO - [GROUP_GET_NUMS] [t1@c1] Stats In One Minute, SUM: 785717 TPS: 15714.34 AVGPT: 8.14</span><br><span class="line">INFO - [GROUP_GET_NUMS] [t1@c1] Stats In One Minute, SUM: 940522 TPS: 15675.37 AVGPT: 8.06</span><br></pre></td></tr></table></figure>
<p>主服务器(rocketmq-master)对应的日志如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INFO - [GROUP_GET_NUMS] [t1@c1] Stats In One Minute, SUM: 0 TPS: 0.00 AVGPT: 0.00</span><br><span class="line">INFO - [GROUP_GET_NUMS] [t1@c1] Stats In One Minute, SUM: 0 TPS: 0.00 AVGPT: 0.00</span><br></pre></td></tr></table></figure>
<p><strong>主服务器上的TPS一定会0吗？不一定，其实也不一定。这里借着这波日志，再来总结一下 RocketMQ 主从同步时的切换逻辑。</strong></p>
<p>1、如果消费端请求的消息物理偏移量与 broker 当前最新的物理偏移量之间的差距查过内存的40%，下一次拉取会往从节点发送（当然前提是slaveReadEnable = true）。</p>
<p>2、当从节点开始接管消息消费时，下一次拉取请求一定会往从节点发送码？答案也是不一定：</p>
<ul>
<li>如果待拉取的消息偏移量与从节点最新的物理偏移量之间的差距超过内存的30%，下一次拉取请求还是会发往从节点。</li>
<li>如果待拉取的消息偏移量与从节点最新的物理偏移量之际的差距少于内存的30%，下一次拉取请求将发送到主节点。</li>
</ul>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>rocketmq-console</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析 RocketMQ DLedger 多副本之 Leader 选主</title>
    <url>/posts/8b1a2fc4.html</url>
    <content><![CDATA[<div id="vip-container"><p>本文将按照<a href="https://blog.csdn.net/prestigeding/article/details/99101912">《RocketMQ 多副本前置篇：初探raft协议》</a>的思路来学习RocketMQ选主逻辑。首先先回顾一下关于Leader的一些思考：</p>
<ol>
<li>节点状态<br> 需要引入3种节点状态：Follower(跟随者)、Candidate(候选者)，该状态下的节点会发起投票请求，Leader(主节点)。</li>
<li>选举计时器<br> Follower、Candidate两个状态时，需要维护一个定时器，每次定时时间从150ms-300ms直接进行随机，即每个节点的定时过期不一样，Follower状态时，定时器到点后，触发一轮投票。节点在收到投票请求、Leader的心跳请求并作出响应后，需要重置定时器。</li>
<li>投票轮次Team<br> Candidate状态的节点，每发起一轮投票，Team加一。</li>
<li>投票机制<br> 每一轮一个节点只能为一个节点投赞成票，例如节点A中维护的轮次为3，并且已经为节点B投了赞成票，如果收到其他节点，投票轮次为3，则会投反对票，如果收到轮次为4的节点，是又可以投赞成票的。</li>
<li>成为Leader的条件<br> 必须得到集群中初始数量的大多数，例如如果集群中有3台，则必须得到两票，如果其中一台服务器宕机，剩下的两个节点，还能进行选主吗？答案是可以的，因为可以得到2票，超过初始集群中3的一半，所以通常集群中的机器各位尽量为奇数，因为4台的可用性与3台的一样。</li>
</ol>
<blockquote>
<p>温馨提示：本文是从源码的角度分析 DLedger 选主实现原理，可能比较鼓噪，文末给出了选主流程图。</p>
</blockquote>
<p>@<a href="%E6%9C%AC%E8%8A%82%E7%9B%AE%E5%BD%95">TOC</a></p>
<h2 id="1、DLedger关于选主的核心类图"><a href="#1、DLedger关于选主的核心类图" class="headerlink" title="1、DLedger关于选主的核心类图"></a>1、DLedger关于选主的核心类图</h2><p><img src="https://img-blog.csdnimg.cn/20190817201207350.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="1-1-DLedgerConfig"><a href="#1-1-DLedgerConfig" class="headerlink" title="1.1 DLedgerConfig"></a>1.1 DLedgerConfig</h3><p>多副本模块相关的配置信息，例如集群节点信息。</p>
<h3 id="1-2-MemberState"><a href="#1-2-MemberState" class="headerlink" title="1.2 MemberState"></a>1.2 MemberState</h3><p>节点状态机，即raft协议中的follower、candidate、leader三种状态的状态机实现。</p>
<h3 id="1-3-raft协议相关"><a href="#1-3-raft协议相关" class="headerlink" title="1.3 raft协议相关"></a>1.3 raft协议相关</h3><h4 id="1-3-1-DLedgerClientProtocol"><a href="#1-3-1-DLedgerClientProtocol" class="headerlink" title="1.3.1 DLedgerClientProtocol"></a>1.3.1 DLedgerClientProtocol</h4><p>DLedger客户端协议，主要定义如下三个方法，在后面的日志复制部分会重点阐述。</p>
<ul>
<li>CompletableFuture&lt; GetEntriesResponse&gt; get(GetEntriesRequest request)<br>客户端从服务器获取日志条目（获取数据）</li>
<li>CompletableFuture&lt; AppendEntryResponse&gt; append(AppendEntryRequest request)<br>客户端向服务器追加日志（存储数据）</li>
<li>CompletableFuture&lt; MetadataResponse&gt; metadata(MetadataRequest request)<br>获取元数据。</li>
</ul>
<h4 id="1-3-2-DLedgerProtocol"><a href="#1-3-2-DLedgerProtocol" class="headerlink" title="1.3.2 DLedgerProtocol"></a>1.3.2 DLedgerProtocol</h4><p>DLedger服务端协议，主要定义如下三个方法。</p>
<ul>
<li>CompletableFuture&lt; VoteResponse&gt; vote(VoteRequest request)<br>发起投票请求。</li>
<li>CompletableFuture&lt; HeartBeatResponse&gt; heartBeat(HeartBeatRequest request)<br>Leader向从节点发送心跳包。</li>
<li>CompletableFuture&lt; PullEntriesResponse&gt; pull(PullEntriesRequest request)<br>拉取日志条目，在日志复制部分会详细介绍。</li>
<li>CompletableFuture&lt; PushEntryResponse&gt; push(PushEntryRequest request)<br>推送日志条件，在日志复制部分会详细介绍。</li>
</ul>
<h4 id="1-3-3-协议处理Handler"><a href="#1-3-3-协议处理Handler" class="headerlink" title="1.3.3 协议处理Handler"></a>1.3.3 协议处理Handler</h4><p>DLedgerClientProtocolHandler、DLedgerProtocolHander协议处理器。</p>
<h3 id="1-4-DLedgerRpcService"><a href="#1-4-DLedgerRpcService" class="headerlink" title="1.4 DLedgerRpcService"></a>1.4 DLedgerRpcService</h3><p>DLedger Server(节点)之间的网络通信，默认基于Netty实现，其实现类为：DLedgerRpcNettyService。</p>
<h3 id="1-5-DLedgerLeaderElector"><a href="#1-5-DLedgerLeaderElector" class="headerlink" title="1.5 DLedgerLeaderElector"></a>1.5 DLedgerLeaderElector</h3><p>Leader选举实现器。</p>
<h3 id="1-6-DLedgerServer"><a href="#1-6-DLedgerServer" class="headerlink" title="1.6 DLedgerServer"></a>1.6 DLedgerServer</h3><p>Dledger Server，Dledger节点的封装类。</p>
<p>接下来将从DLedgerLeaderElector开始剖析DLedger是如何实现Leader选举的。（基于raft协议）。</p>
<a id="more"></a>

<h2 id="2、源码分析Leader选举"><a href="#2、源码分析Leader选举" class="headerlink" title="2、源码分析Leader选举"></a>2、源码分析Leader选举</h2><h3 id="2-1-DLedgerLeaderElector-类图"><a href="#2-1-DLedgerLeaderElector-类图" class="headerlink" title="2.1 DLedgerLeaderElector 类图"></a>2.1 DLedgerLeaderElector 类图</h3><p><img src="https://img-blog.csdnimg.cn/20190817201557322.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们先一一来介绍其属性的含义：</p>
<ul>
<li>Random random<br>随机数生成器，对应raft协议中选举超时时间是一随机数。</li>
<li>DLedgerConfig dLedgerConfig<br>配置参数。</li>
<li>MemberState memberState<br>节点状态机。</li>
<li>DLedgerRpcService dLedgerRpcService<br>rpc服务，实现向集群内的节点发送心跳包、投票的RPC实现。<br>l- ong lastLeaderHeartBeatTime<br>上次收到心跳包的时间戳。</li>
<li>long lastSendHeartBeatTime<br>上次发送心跳包的时间戳。</li>
<li>long lastSuccHeartBeatTime<br>上次成功收到心跳包的时间戳。</li>
<li>int heartBeatTimeIntervalMs<br>一个心跳包的周期，默认为2s。</li>
<li>int maxHeartBeatLeak<br>允许最大的N个心跳周期内未收到心跳包，状态为Follower的节点只有超过 maxHeartBeatLeak * heartBeatTimeIntervalMs 的时间内未收到主节点的心跳包，才会重新进入 Candidate 状态，重新下一轮的选举。</li>
<li>long nextTimeToRequestVote<br>发送下一个心跳包的时间戳。</li>
<li>boolean needIncreaseTermImmediately<br>是否应该立即发起投票。</li>
<li>int minVoteIntervalMs<br>最小的发送投票间隔时间，默认为300ms。</li>
<li>int maxVoteIntervalMs<br>最大的发送投票的间隔，默认为1000ms。</li>
<li>List&lt; RoleChangeHandler&gt; roleChangeHandlers<br>注册的节点状态处理器，通过 addRoleChangeHandler 方法添加。</li>
<li>long lastVoteCost<br>上一次投票的开销。</li>
<li>StateMaintainer stateMaintainer<br>状态机管理器。</li>
</ul>
<h3 id="2-2-启动选举状态管理器"><a href="#2-2-启动选举状态管理器" class="headerlink" title="2.2 启动选举状态管理器"></a>2.2 启动选举状态管理器</h3><p>通过 DLedgerLeaderElector 的 startup 方法启动状态管理机，代码如下：<br>DLedgerLeaderElector#startup</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">startup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    stateMaintainer.start();   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">for</span> (RoleChangeHandler roleChangeHandler : roleChangeHandlers) &#123;   <span class="comment">// @2</span></span><br><span class="line">        roleChangeHandler.startup();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：启动状态维护管理器。</p>
<p>代码@2：遍历状态改变监听器并启动它，可通过DLedgerLeaderElector 的 addRoleChangeHandler 方法增加状态变化监听器。</p>
<p>其中的是启动状态管理器线程，其run方法实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (running.get()) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            doWork();    </span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">            <span class="keyword">if</span> (logger != <span class="keyword">null</span>) &#123;</span><br><span class="line">                logger.error(<span class="string">&quot;Unexpected Error in running &#123;&#125; &quot;</span>, getName(), t);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    latch.countDown();</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<p>从上面来看，主要是循环调用doWork方法，接下来重点看其doWork的实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWork</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (DLedgerLeaderElector.<span class="keyword">this</span>.dLedgerConfig.isEnableLeaderElector()) &#123;   <span class="comment">// @1</span></span><br><span class="line">            DLedgerLeaderElector.<span class="keyword">this</span>.refreshIntervals(dLedgerConfig);                 <span class="comment">// @2</span></span><br><span class="line">            DLedgerLeaderElector.<span class="keyword">this</span>.maintainState();                                           <span class="comment">// @3</span></span><br><span class="line">        &#125;</span><br><span class="line">        sleep(<span class="number">10</span>);                                                                                                    <span class="comment">// @4</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        DLedgerLeaderElector.logger.error(<span class="string">&quot;Error in heartbeat&quot;</span>, t);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果该节点参与Leader选举，则首先调用@2重置定时器，然后驱动状态机(@3)，是接下来重点需要剖析的。</p>
<p>代码@4：没执行一次选主，休息10ms。</p>
<p>DLedgerLeaderElector#maintainState</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">maintainState</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (memberState.isLeader()) &#123;  </span><br><span class="line">        maintainAsLeader();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (memberState.isFollower()) &#123;</span><br><span class="line">        maintainAsFollower();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        maintainAsCandidate();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>根据当前的状态机状态，执行对应的操作，从raft协议中可知，总共存在3种状态：</p>
<ul>
<li>leader<br>领导者，主节点，该状态下，需要定时向从节点发送心跳包，用来传播数据、确保其领导地位。</li>
<li>follower<br>从节点，该状态下，会开启定时器，尝试进入到candidate状态，以便发起投票选举，同时一旦收到主节点的心跳包，则重置定时器。</li>
<li>candidate<br>候选者，该状态下的节点会发起投票，尝试选择自己为主节点，选举成功后，不会存在该状态下的节点。</li>
</ul>
<p>我们在继续往下看之前，需要知道 memberState 的初始值是什么？我们追溯到创建 MemberState 的地方，发现其初始状态为 CANDIDATE。那我们接下从 maintainAsCandidate 方法开始跟进。</p>
<blockquote>
<p>温馨提示：在raft协议中，节点的状态默认为follower，DLedger的实现从candidate开始，一开始，集群内的所有节点都会尝试发起投票，这样第一轮要达成选举几乎不太可能。</p>
</blockquote>
<h3 id="2-3-选举状态机状态流转"><a href="#2-3-选举状态机状态流转" class="headerlink" title="2.3 选举状态机状态流转"></a>2.3 选举状态机状态流转</h3><p>整个状态机的驱动，由线程反复执行maintainState方法。下面重点来分析其状态的驱动。</p>
<h4 id="2-3-1-maintainAsCandidate-方法"><a href="#2-3-1-maintainAsCandidate-方法" class="headerlink" title="2.3.1  maintainAsCandidate 方法"></a>2.3.1  maintainAsCandidate 方法</h4><p>DLedgerLeaderElector#maintainAsCandidate</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (System.currentTimeMillis() &lt; nextTimeToRequestVote &amp;&amp; !needIncreaseTermImmediately) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">long</span> term;</span><br><span class="line"><span class="keyword">long</span> ledgerEndTerm;</span><br><span class="line"><span class="keyword">long</span> ledgerEndIndex;</span><br></pre></td></tr></table></figure>
<p>Step1：首先先介绍几个变量的含义：</p>
<ul>
<li>nextTimeToRequestVote<br>下一次发发起的投票的时间，如果当前时间小于该值，说明计时器未过期，此时无需发起投票。</li>
<li>needIncreaseTermImmediately<br>是否应该立即发起投票。如果为true，则忽略计时器，该值默认为false，当收到从主节点的心跳包并且当前状态机的轮次大于主节点的轮次，说明集群中Leader的投票轮次小于从几点的轮次，应该立即发起新的投票。</li>
<li>term<br>投票轮次。</li>
<li>ledgerEndTerm<br>Leader节点当前的投票轮次。</li>
<li>ledgerEndIndex<br>当前日志的最大序列，即下一条日志的开始index，在日志复制部分会详细介绍。</li>
</ul>
<p>DLedgerLeaderElector#maintainAsCandidate</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">synchronized</span> (memberState) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!memberState.isCandidate()) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (lastParseResult == VoteResponse.ParseResult.WAIT_TO_VOTE_NEXT || needIncreaseTermImmediately) &#123;</span><br><span class="line">        <span class="keyword">long</span> prevTerm = memberState.currTerm();</span><br><span class="line">        term = memberState.nextTerm();</span><br><span class="line">        logger.info(<span class="string">&quot;&#123;&#125;_[INCREASE_TERM] from &#123;&#125; to &#123;&#125;&quot;</span>, memberState.getSelfId(), prevTerm, term);</span><br><span class="line">        lastParseResult = VoteResponse.ParseResult.WAIT_TO_REVOTE;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        term = memberState.currTerm();</span><br><span class="line">    &#125;</span><br><span class="line">    ledgerEndIndex = memberState.getLedgerEndIndex();</span><br><span class="line">    ledgerEndTerm = memberState.getLedgerEndTerm();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：初始化team、ledgerEndIndex 、ledgerEndTerm 属性，其实现关键点如下：</p>
<ul>
<li>如果上一次的投票结果为待下一次投票或应该立即开启投票，并且根据当前状态机获取下一轮的投票轮次，稍后会着重讲解一下状态机轮次的维护机制。</li>
<li>如果上一次的投票结果不是WAIT_TO_VOTE_NEXT(等待下一轮投票)，则投票轮次依然为状态机内部维护的轮次。</li>
</ul>
<p>DLedgerLeaderElector#maintainAsCandidate</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (needIncreaseTermImmediately) &#123;</span><br><span class="line">    nextTimeToRequestVote = getNextTimeToRequestVote();</span><br><span class="line">    needIncreaseTermImmediately = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step3：如果needIncreaseTermImmediately为true，则重置该标记位为false，并重新设置下一次投票超时时间，其实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">getNextTimeToRequestVote</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> System.currentTimeMillis() + lastVoteCost + minVoteIntervalMs + random.nextInt(maxVoteIntervalMs - minVoteIntervalMs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下一次倒计时：当前时间戳 + 上次投票的开销 + 最小投票间隔(300ms) +  （1000- 300 ）之间的随机值。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> List&lt;CompletableFuture&lt;VoteResponse&gt;&gt; quorumVoteResponses = voteForQuorumResponses(term, ledgerEndTerm, ledgerEndIndex);</span><br></pre></td></tr></table></figure>
<p>Step4：向集群内的其他节点发起投票请，并返回投票结果列表，稍后会重点分析其投票过程。可以预见，接下来就是根据各投票结果进行仲裁。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> AtomicLong knownMaxTermInGroup = <span class="keyword">new</span> AtomicLong(-<span class="number">1</span>);</span><br><span class="line"><span class="keyword">final</span> AtomicInteger allNum = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">final</span> AtomicInteger validNum = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">final</span> AtomicInteger acceptedNum = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">final</span> AtomicInteger notReadyTermNum = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">final</span> AtomicInteger biggerLedgerNum = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">final</span> AtomicBoolean alreadyHasLeader = <span class="keyword">new</span> AtomicBoolean(<span class="keyword">false</span>);</span><br></pre></td></tr></table></figure>
<p>Step5：在进行投票结果仲裁之前，先来介绍几个局部变量的含义：</p>
<ul>
<li>knownMaxTermInGroup<br>已知的最大投票轮次。</li>
<li>allNum<br>所有投票票数。</li>
<li>validNum<br>有效投票数。 </li>
<li>acceptedNum<br>获得的投票数。 </li>
<li>notReadyTermNum<br>未准备投票的节点数量，如果对端节点的投票轮次小于发起投票的轮次，则认为对端未准备好，对端节点使用本次的轮次进入 - Candidate 状态。</li>
<li>biggerLedgerNum<br> 发起投票的节点的ledgerEndTerm小于对端节点的个数。</li>
<li>alreadyHasLeader<br>是否已经存在Leader。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (CompletableFuture&lt;VoteResponse&gt; future : quorumVoteResponses) &#123;</span><br><span class="line">   <span class="comment">// 省略部分代码</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
Step5：遍历投票结果，收集投票结果，接下来重点看其内部实现。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (x.getVoteResult() != VoteResponse.RESULT.UNKNOWN) &#123;</span><br><span class="line">    validNum.incrementAndGet();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
Step6：如果投票结果不是UNKNOW，则有效投票数量增1。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">synchronized</span> (knownMaxTermInGroup) &#123;</span><br><span class="line">    <span class="keyword">switch</span> (x.getVoteResult()) &#123;</span><br><span class="line">        <span class="keyword">case</span> ACCEPT:</span><br><span class="line">            acceptedNum.incrementAndGet();</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> REJECT_ALREADY_VOTED:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> REJECT_ALREADY_HAS_LEADER:</span><br><span class="line">            alreadyHasLeader.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> REJECT_TERM_SMALL_THAN_LEDGER:</span><br><span class="line">        <span class="keyword">case</span> REJECT_EXPIRED_VOTE_TERM:</span><br><span class="line">            <span class="keyword">if</span> (x.getTerm() &gt; knownMaxTermInGroup.get()) &#123;</span><br><span class="line">                knownMaxTermInGroup.set(x.getTerm());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> REJECT_EXPIRED_LEDGER_TERM:</span><br><span class="line">        <span class="keyword">case</span> REJECT_SMALL_LEDGER_END_INDEX:</span><br><span class="line">            biggerLedgerNum.incrementAndGet();</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> REJECT_TERM_NOT_READY:</span><br><span class="line">            notReadyTermNum.incrementAndGet();</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
Step7：统计投票结构，几个关键点如下：</li>
<li>ACCEPT<br>赞成票，acceptedNum加一，只有得到的赞成票超过集群节点数量的一半才能成为Leader。</li>
<li>REJECT_ALREADY_VOTED<br>拒绝票，原因是已经投了其他节点的票。</li>
<li>REJECT_ALREADY_HAS_LEADER<br>拒绝票，原因是因为集群中已经存在Leaer了。alreadyHasLeader设置为true，无需在判断其他投票结果了，结束本轮投票。</li>
<li>REJECT_TERM_SMALL_THAN_LEDGER<br>拒绝票，如果自己维护的term小于远端维护的ledgerEndTerm，则返回该结果，如果对端的team大于自己的team，需要记录对端最大的投票轮次，以便更新自己的投票轮次。</li>
<li>REJECT_EXPIRED_VOTE_TERM<br>拒绝票，如果自己维护的term小于远端维护的term，更新自己维护的投票轮次。</li>
<li>REJECT_EXPIRED_LEDGER_TERM<br>拒绝票，如果自己维护的 ledgerTerm小于对端维护的ledgerTerm，则返回该结果。如果是此种情况，增加计数器- biggerLedgerNum的值。</li>
<li>REJECT_SMALL_LEDGER_END_INDEX<br>拒绝票，如果对端的ledgerTeam与自己维护的ledgerTeam相等，但是自己维护的dedgerEndIndex小于对端维护的值，返回该值，增加biggerLedgerNum计数器的值。</li>
<li>REJECT_TERM_NOT_READY<br>拒绝票，对端的投票轮次小于自己的team，则认为对端还未准备好投票，对端使用自己的投票轮次，是自己进入到Candidate状态。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    voteLatch.await(<span class="number">3000</span> + random.nextInt(maxVoteIntervalMs), TimeUnit.MILLISECONDS);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Throwable ignore) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
Step8：等待收集投票结果，并设置超时时间。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">lastVoteCost = DLedgerUtils.elapsed(startVoteTimeMs);</span><br><span class="line">VoteResponse.ParseResult parseResult;</span><br><span class="line"><span class="keyword">if</span> (knownMaxTermInGroup.get() &gt; term) &#123;</span><br><span class="line">    parseResult = VoteResponse.ParseResult.WAIT_TO_VOTE_NEXT;</span><br><span class="line">    nextTimeToRequestVote = getNextTimeToRequestVote();</span><br><span class="line">    changeRoleToCandidate(knownMaxTermInGroup.get());</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (alreadyHasLeader.get()) &#123;</span><br><span class="line">    parseResult = VoteResponse.ParseResult.WAIT_TO_VOTE_NEXT;</span><br><span class="line">    nextTimeToRequestVote = getNextTimeToRequestVote() + heartBeatTimeIntervalMs * maxHeartBeatLeak;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (!memberState.isQuorum(validNum.get())) &#123;</span><br><span class="line">    parseResult = VoteResponse.ParseResult.WAIT_TO_REVOTE;</span><br><span class="line">    nextTimeToRequestVote = getNextTimeToRequestVote();</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (memberState.isQuorum(acceptedNum.get())) &#123;</span><br><span class="line">    parseResult = VoteResponse.ParseResult.PASSED;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (memberState.isQuorum(acceptedNum.get() + notReadyTermNum.get())) &#123;</span><br><span class="line">    parseResult = VoteResponse.ParseResult.REVOTE_IMMEDIATELY;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (memberState.isQuorum(acceptedNum.get() + biggerLedgerNum.get())) &#123;</span><br><span class="line">    parseResult = VoteResponse.ParseResult.WAIT_TO_REVOTE;</span><br><span class="line">    nextTimeToRequestVote = getNextTimeToRequestVote();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    parseResult = VoteResponse.ParseResult.WAIT_TO_VOTE_NEXT;</span><br><span class="line">    nextTimeToRequestVote = getNextTimeToRequestVote();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
Step9：根据收集的投票结果判断是否能成为Leader。<blockquote>
<p>温馨提示：在讲解关键点之前，我们先定义先将（当前时间戳 + 上次投票的开销 + 最小投票间隔(300ms) +  （1000- 300 ）之间的随机值）定义为“ 1个常规计时器”。</p>
</blockquote>
</li>
</ul>
<p>其关键点如下：</p>
<ul>
<li>如果对端的投票轮次大于发起投票的节点，则该节点使用对端的轮次，重新进入到Candidate状态，并且重置投票计时器，其值为“1个常规计时器”</li>
<li>如果已经存在Leader，该节点重新进入到Candidate,并重置定时器，该定时器的时间： “1个常规计时器” + heartBeatTimeIntervalMs * maxHeartBeatLeak ，其中 heartBeatTimeIntervalMs 为一次心跳间隔时间，<br>maxHeartBeatLeak 为  允许最大丢失的心跳包，即如果Flower节点在多少个心跳周期内未收到心跳包，则认为Leader已下线。</li>
<li>如果收到的有效票数未超过半数，则重置计时器为“ 1个常规计时器”，然后等待重新投票，注意状态为WAIT_TO_REVOTE，该状态下的特征是下次投票时不增加投票轮次。</li>
<li>如果得到的赞同票超过半数，则成为Leader。</li>
<li>如果得到的赞成票加上未准备投票的节点数超过半数，则应该立即发起投票，故其结果为REVOTE_IMMEDIATELY。</li>
<li>如果得到的赞成票加上对端维护的ledgerEndIndex超过半数，则重置计时器，继续本轮次的选举。</li>
<li>其他情况，开启下一轮投票。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (parseResult == VoteResponse.ParseResult.PASSED) &#123;</span><br><span class="line">    logger.info(<span class="string">&quot;[&#123;&#125;] [VOTE_RESULT] has been elected to be the leader in term &#123;&#125;&quot;</span>, memberState.getSelfId(), term);</span><br><span class="line">    changeRoleToLeader(term);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
Step10：如果投票成功，则状态机状态设置为Leader，然后状态管理在驱动状态时会调用DLedgerLeaderElector#maintainState时，将进入到maintainAsLeader方法。</li>
</ul>
<h4 id="2-3-2-maintainAsLeader-方法"><a href="#2-3-2-maintainAsLeader-方法" class="headerlink" title="2.3.2  maintainAsLeader 方法"></a>2.3.2  maintainAsLeader 方法</h4><p>经过maintainAsCandidate 投票选举后，被其他节点选举成为领导后，会执行该方法，其他节点的状态还是Candidate，并在计时器过期后，又尝试去发起选举。接下来重点分析成为Leader节点后，该节点会做些什么？</p>
<p>DLedgerLeaderElector#maintainAsLeader</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">maintainAsLeader</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (DLedgerUtils.elapsed(lastSendHeartBeatTime) &gt; heartBeatTimeIntervalMs) &#123;  <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">long</span> term;</span><br><span class="line">        String leaderId;</span><br><span class="line">        <span class="keyword">synchronized</span> (memberState) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!memberState.isLeader()) &#123;     <span class="comment">// @2</span></span><br><span class="line">                <span class="comment">//stop sending</span></span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            term = memberState.currTerm();</span><br><span class="line">            leaderId = memberState.getLeaderId();</span><br><span class="line">            lastSendHeartBeatTime = System.currentTimeMillis();    <span class="comment">// @3</span></span><br><span class="line">        &#125;</span><br><span class="line">        sendHeartbeats(term, leaderId);    <span class="comment">// @4</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先判断上一次发送心跳的时间与当前时间的差值是否大于心跳包发送间隔，如果超过，则说明需要发送心跳包。</p>
<p>代码@2：如果当前不是leader节点，则直接返回，主要是为了二次判断。</p>
<p>代码@3：重置心跳包发送计时器。</p>
<p>代码@4：向集群内的所有节点发送心跳包，稍后会详细介绍心跳包的发送。</p>
<h4 id="2-3-3-maintainAsFollower方法"><a href="#2-3-3-maintainAsFollower方法" class="headerlink" title="2.3.3  maintainAsFollower方法"></a>2.3.3  maintainAsFollower方法</h4><p>当 Candidate 状态的节点在收到主节点发送的心跳包后，会将状态变更为follower，那我们先来看一下在follower状态下，节点会做些什么事情？</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">maintainAsFollower</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (DLedgerUtils.elapsed(lastLeaderHeartBeatTime) &gt; <span class="number">2</span> * heartBeatTimeIntervalMs) &#123;   </span><br><span class="line">        <span class="keyword">synchronized</span> (memberState) &#123;</span><br><span class="line">            <span class="keyword">if</span> (memberState.isFollower() &amp;&amp; (DLedgerUtils.elapsed(lastLeaderHeartBeatTime) &gt; maxHeartBeatLeak * heartBeatTimeIntervalMs)) &#123;</span><br><span class="line">                logger.info(<span class="string">&quot;[&#123;&#125;][HeartBeatTimeOut] lastLeaderHeartBeatTime: &#123;&#125; heartBeatTimeIntervalMs: &#123;&#125; lastLeader=&#123;&#125;&quot;</span>, memberState.getSelfId(), <span class="keyword">new</span> Timestamp(lastLeaderHeartBeatTime), heartBeatTimeIntervalMs, memberState.getLeaderId());</span><br><span class="line">                changeRoleToCandidate(memberState.currTerm());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果maxHeartBeatLeak (默认为3)个心跳包周期内未收到心跳，则将状态变更为Candidate。</p>
<p>状态机的驱动就介绍到这里，在上面的流程中，其实我们忽略了两个重要的过程，一个是发起投票请求与投票请求响应、发送心跳包与心跳包响应，那我们接下来将重点介绍这两个过程。</p>
<h3 id="2-4-投票与投票请求"><a href="#2-4-投票与投票请求" class="headerlink" title="2.4 投票与投票请求"></a>2.4 投票与投票请求</h3><p>节点的状态为 Candidate 时会向集群内的其他节点发起投票请求(个人觉得理解为拉票更好)，向对方询问是否愿意选举我为Leader，对端节点会根据自己的情况对其投赞成票、拒绝票，如果是拒绝票，还会给出拒绝原因，具体由voteForQuorumResponses、handleVote 这两个方法来实现，接下来我们分别对这两个方法进行详细分析。</p>
<h4 id="2-4-1-voteForQuorumResponses"><a href="#2-4-1-voteForQuorumResponses" class="headerlink" title="2.4.1 voteForQuorumResponses"></a>2.4.1 voteForQuorumResponses</h4><p>发起投票请求。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> List&lt;CompletableFuture&lt;VoteResponse&gt;&gt; voteForQuorumResponses(<span class="keyword">long</span> term, <span class="keyword">long</span> ledgerEndTerm,</span><br><span class="line">    <span class="keyword">long</span> ledgerEndIndex) <span class="keyword">throws</span> Exception &#123;   <span class="comment">// @1</span></span><br><span class="line">    List&lt;CompletableFuture&lt;VoteResponse&gt;&gt; responses = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    <span class="keyword">for</span> (String id : memberState.getPeerMap().keySet()) &#123;               <span class="comment">// @2</span></span><br><span class="line">        VoteRequest voteRequest = <span class="keyword">new</span> VoteRequest();                  <span class="comment">// @3 start</span></span><br><span class="line">        voteRequest.setGroup(memberState.getGroup());</span><br><span class="line">        voteRequest.setLedgerEndIndex(ledgerEndIndex);</span><br><span class="line">        voteRequest.setLedgerEndTerm(ledgerEndTerm);</span><br><span class="line">        voteRequest.setLeaderId(memberState.getSelfId());</span><br><span class="line">        voteRequest.setTerm(term);</span><br><span class="line">        voteRequest.setRemoteId(id);</span><br><span class="line">        CompletableFuture&lt;VoteResponse&gt; voteResponse;          <span class="comment">// @3 end</span></span><br><span class="line">        <span class="keyword">if</span> (memberState.getSelfId().equals(id)) &#123;                             <span class="comment">// @4</span></span><br><span class="line">            voteResponse = handleVote(voteRequest, <span class="keyword">true</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//async</span></span><br><span class="line">            voteResponse = dLedgerRpcService.vote(voteRequest);  <span class="comment">// @5</span></span><br><span class="line">        &#125;</span><br><span class="line">        responses.add(voteResponse);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> responses;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先先解释一下参数的含义：</p>
<ul>
<li>long term<br>发起投票的节点当前的投票轮次。</li>
<li>long ledgerEndTerm<br>发起投票节点维护的已知的最大投票轮次。</li>
<li>long ledgerEndIndex<br>发起投票节点维护的已知的最大日志条目索引。</li>
</ul>
<p>代码@2：遍历集群内的节点集合，准备异步发起投票请求。这个集合在启动的时候指定，不能修改。</p>
<p>代码@3：构建投票请求。</p>
<p>代码@4：如果是发送给自己的，则直接调用handleVote进行投票请求响应，如果是发送给集群内的其他节点，则通过网络发送投票请求，对端节点调用各自的handleVote对集群进行响应。</p>
<p>接下来重点关注 handleVote 方法，重点探讨其投票处理逻辑。</p>
<h4 id="2-4-2-handleVote-方法"><a href="#2-4-2-handleVote-方法" class="headerlink" title="2.4.2 handleVote 方法"></a>2.4.2 handleVote 方法</h4><p>由于handleVote 方法会并发被调用，因为可能同时收到多个节点的投票请求，故本方法都被synchronized方法包含，锁定的对象为状态机 memberState 对象。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!memberState.isPeerMember(request.getLeaderId())) &#123;</span><br><span class="line">    logger.warn(<span class="string">&quot;[BUG] [HandleVote] remoteId=&#123;&#125; is an unknown member&quot;</span>, request.getLeaderId());</span><br><span class="line">    <span class="keyword">return</span> CompletableFuture.completedFuture(newVoteResponse(request).term(memberState.currTerm()).voteResult(VoteResponse.RESULT.REJECT_UNKNOWN_LEADER));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (!self &amp;&amp; memberState.getSelfId().equals(request.getLeaderId())) &#123;</span><br><span class="line">    logger.warn(<span class="string">&quot;[BUG] [HandleVote] selfId=&#123;&#125; but remoteId=&#123;&#125;&quot;</span>, memberState.getSelfId(), request.getLeaderId());</span><br><span class="line">    <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> VoteResponse(request).term(memberState.currTerm()).voteResult(VoteResponse.RESULT.REJECT_UNEXPECTED_LEADER));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step1：为了逻辑的完整性对其请求进行检验，除非有BUG存在，否则是不会出现上述问题的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (request.getTerm() &lt; memberState.currTerm()) &#123;    <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> VoteResponse(request).term(memberState.currTerm()).voteResult(VoteResponse.RESULT.REJECT_EXPIRED_VOTE_TERM));</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (request.getTerm() == memberState.currTerm()) &#123;   <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">if</span> (memberState.currVoteFor() == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">//let it go</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (memberState.currVoteFor().equals(request.getLeaderId())) &#123;</span><br><span class="line">         <span class="comment">//repeat just let it go</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (memberState.getLeaderId() != <span class="keyword">null</span>) &#123;</span><br><span class="line">             <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> VoteResponse(request).term(memberState.currTerm()).voteResult(VoteResponse.RESULT.REJECT_ALREADY__HAS_LEADER));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> VoteResponse(request).term(memberState.currTerm()).voteResult(VoteResponse.RESULT.REJECT_ALREADY_VOTED));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;            <span class="comment">// @3</span></span><br><span class="line">    <span class="comment">//stepped down by larger term</span></span><br><span class="line">    changeRoleToCandidate(request.getTerm());</span><br><span class="line">    needIncreaseTermImmediately = <span class="keyword">true</span>;</span><br><span class="line">    <span class="comment">//only can handleVote when the term is consistent</span></span><br><span class="line">    <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> VoteResponse(request).term(memberState.currTerm()).voteResult(VoteResponse.RESULT.REJECT_TERM_NOT_READY));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：判断发起节点、响应节点维护的team进行投票“仲裁”，分如下3种情况讨论：</p>
<ul>
<li>如果发起投票节点的 term 小于当前节点的 term<br>此种情况下投拒绝票，也就是说在 raft 协议的世界中，谁的 term 越大，越有话语权。 </li>
<li>如果发起投票节点的 term 等于当前节点的 term<br>如果两者的 term 相等，说明两者都处在同一个投票轮次中，地位平等，接下来看该节点是否已经投过票。<ul>
<li>如果未投票、或已投票给请求节点，则继续后面的逻辑（请看step3）。</li>
<li>如果该节点已存在的Leader节点，则拒绝并告知已存在Leader节点。</li>
<li>如果该节点还未有Leader节点，但已经投了其他节点的票，则拒绝请求节点，并告知已投票。</li>
</ul>
</li>
<li>如果发起投票节点的 term 大于当前节点的 term<br>拒绝请求节点的投票请求，并告知自身还未准备投票，自身会使用请求节点的投票轮次立即进入到Candidate状态。<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (request.getLedgerEndTerm() &lt; memberState.getLedgerEndTerm()) &#123;</span><br><span class="line">    <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> VoteResponse(request).term(memberState.currTerm()).voteResult(VoteResponse.RESULT.REJECT_EXPIRED_LEDGER_TERM));</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (request.getLedgerEndTerm() == memberState.getLedgerEndTerm() &amp;&amp; request.getLedgerEndIndex() &lt; memberState.getLedgerEndIndex()) &#123;</span><br><span class="line">    <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> VoteResponse(request).term(memberState.currTerm()).voteResult(VoteResponse.RESULT.REJECT_SMALL_LEDGER_END_INDEX));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (request.getTerm() &lt; memberState.getLedgerEndTerm()) &#123;</span><br><span class="line">    <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> VoteResponse(request).term(memberState.getLedgerEndTerm()).voteResult(VoteResponse.RESULT.REJECT_TERM_SMALL_THAN_LEDGER));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
Step3：判断请求节点的 ledgerEndTerm 与当前节点的 ledgerEndTerm，这里主要是判断日志的复制进度。</li>
<li>如果请求节点的 ledgerEndTerm  小于当前节点的 ledgerEndTerm 则拒绝，其原因是请求节点的日志复制进度比当前节点低，这种情况是不能成为主节点的。</li>
<li>如果 ledgerEndTerm  相等，但是 ledgerEndIndex 比当前节点小，则拒绝，原因与上一条相同。</li>
<li>如果请求的 term 小于 ledgerEndTerm 以同样的理由拒绝。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">memberState.setCurrVoteFor(request.getLeaderId());</span><br><span class="line"><span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> VoteResponse(request).term(memberState.currTerm()).voteResult(VoteResponse.RESULT.ACCEPT));</span><br></pre></td></tr></table></figure>
<p>Step4：经过层层条件帅选，将宝贵的赞成票投给请求节点。</p>
<p>经过几轮投票，最终一个节点能成功被推举出来，选为主节点。主节点为了维持其领导地位，需要定时向从节点发送心跳包，接下来我们重点看一下心跳包的发送与响应。</p>
<h3 id="2-5-心跳包与心跳包响应"><a href="#2-5-心跳包与心跳包响应" class="headerlink" title="2.5 心跳包与心跳包响应"></a>2.5 心跳包与心跳包响应</h3><h4 id="2-5-1-sendHeartbeats"><a href="#2-5-1-sendHeartbeats" class="headerlink" title="2.5.1 sendHeartbeats"></a>2.5.1 sendHeartbeats</h4><p>Step1：遍历集群中的节点，异步发送心跳包。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> CompletableFuture&lt;HeartBeatResponse&gt; future = dLedgerRpcService.heartBeat(heartBeatRequest);</span><br><span class="line">    future.whenComplete((HeartBeatResponse x, Throwable ex) -&gt; &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (ex != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">throw</span> ex;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">switch</span> (DLedgerResponseCode.valueOf(x.getCode())) &#123;</span><br><span class="line">                <span class="keyword">case</span> SUCCESS:</span><br><span class="line">                    succNum.incrementAndGet();</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> EXPIRED_TERM:</span><br><span class="line">                    maxTerm.set(x.getTerm());</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> INCONSISTENT_LEADER:</span><br><span class="line">                    inconsistLeader.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> TERM_NOT_READY:</span><br><span class="line">                    notReadyNum.incrementAndGet();</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">default</span>:</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (memberState.isQuorum(succNum.get())</span><br><span class="line">                || memberState.isQuorum(succNum.get() + notReadyNum.get())) &#123;</span><br><span class="line">                beatLatch.countDown();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">            logger.error(<span class="string">&quot;Parse heartbeat response failed&quot;</span>, t);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            allNum.incrementAndGet();</span><br><span class="line">            <span class="keyword">if</span> (allNum.get() == memberState.peerSize()) &#123;</span><br><span class="line">                beatLatch.countDown();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：统计心跳包发送响应结果，关键点如下：</p>
<ul>
<li>SUCCESS<br>心跳包成功响应。</li>
<li>EXPIRED_TERM<br>主节点的投票 term 小于从节点的投票轮次。</li>
<li>INCONSISTENT_LEADER<br>从节点已经有了新的主节点。</li>
<li>TERM_NOT_READY<br>从节点未准备好。</li>
</ul>
<p>这些响应值，我们在处理心跳包时重点探讨。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">beatLatch.await(heartBeatTimeIntervalMs, TimeUnit.MILLISECONDS);</span><br><span class="line"><span class="keyword">if</span> (memberState.isQuorum(succNum.get())) &#123;   <span class="comment">// @1</span></span><br><span class="line">    lastSuccHeartBeatTime = System.currentTimeMillis();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    logger.info(<span class="string">&quot;[&#123;&#125;] Parse heartbeat responses in cost=&#123;&#125; term=&#123;&#125; allNum=&#123;&#125; succNum=&#123;&#125; notReadyNum=&#123;&#125; inconsistLeader=&#123;&#125; maxTerm=&#123;&#125; peerSize=&#123;&#125; lastSuccHeartBeatTime=&#123;&#125;&quot;</span>,</span><br><span class="line">                memberState.getSelfId(), DLedgerUtils.elapsed(startHeartbeatTimeMs), term, allNum.get(), succNum.get(), notReadyNum.get(), inconsistLeader.get(), maxTerm.get(), memberState.peerSize(), <span class="keyword">new</span> Timestamp(lastSuccHeartBeatTime));</span><br><span class="line">    <span class="keyword">if</span> (memberState.isQuorum(succNum.get() + notReadyNum.get())) &#123;    <span class="comment">// @2</span></span><br><span class="line">        lastSendHeartBeatTime = -<span class="number">1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (maxTerm.get() &gt; term) &#123;                                                          <span class="comment">// @3</span></span><br><span class="line">        changeRoleToCandidate(maxTerm.get());</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (inconsistLeader.get()) &#123;                                                            <span class="comment">// @4</span></span><br><span class="line">        changeRoleToCandidate(term);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (DLedgerUtils.elapsed(lastSuccHeartBeatTime) &gt; maxHeartBeatLeak * heartBeatTimeIntervalMs) &#123;</span><br><span class="line">        changeRoleToCandidate(term);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对收集的响应结果做仲裁，其实现关键点：</p>
<ul>
<li>如果成功的票数大于进群内的半数，则表示集群状态正常，正常按照心跳包间隔发送心跳包(见代码@1)。</li>
<li>如果成功的票数加上未准备的投票的节点数量超过集群内的半数，则立即发送心跳包(见代码@2)。</li>
<li>如果从节点的投票轮次比主节点的大，则使用从节点的投票轮次，或从节点已经有了另外的主节点，节点状态从 Leader 转换为 Candidate。</li>
</ul>
<p>接下来我们重点看一下心跳包的处理逻辑。</p>
<h4 id="2-5-2-handleHeartBeat"><a href="#2-5-2-handleHeartBeat" class="headerlink" title="2.5.2 handleHeartBeat"></a>2.5.2 handleHeartBeat</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (request.getTerm() &lt; memberState.currTerm()) &#123;</span><br><span class="line">    <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> HeartBeatResponse().term(memberState.currTerm()).code(DLedgerResponseCode.EXPIRED_TERM.getCode()));</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (request.getTerm() == memberState.currTerm()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (request.getLeaderId().equals(memberState.getLeaderId())) &#123;</span><br><span class="line">        lastLeaderHeartBeatTime = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> HeartBeatResponse());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step1：如果主节点的 term 小于 从节点的term，发送反馈给主节点，告知主节点的 term 已过时；如果投票轮次相同，并且发送心跳包的节点是该节点的主节点，则返回成功。</p>
<p>下面重点讨论主节点的 term 大于从节点的情况。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">synchronized</span> (memberState) &#123;</span><br><span class="line">    <span class="keyword">if</span> (request.getTerm() &lt; memberState.currTerm()) &#123;   <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> HeartBeatResponse().term(memberState.currTerm()).code(DLedgerResponseCode.EXPIRED_TERM.getCode()));</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (request.getTerm() == memberState.currTerm()) &#123;  <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">if</span> (memberState.getLeaderId() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            changeRoleToFollower(request.getTerm(), request.getLeaderId());</span><br><span class="line">            <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> HeartBeatResponse());</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (request.getLeaderId().equals(memberState.getLeaderId())) &#123;</span><br><span class="line">            lastLeaderHeartBeatTime = System.currentTimeMillis();</span><br><span class="line">            <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> HeartBeatResponse());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//this should not happen, but if happened</span></span><br><span class="line">            logger.error(<span class="string">&quot;[&#123;&#125;][BUG] currTerm &#123;&#125; has leader &#123;&#125;, but received leader &#123;&#125;&quot;</span>, memberState.getSelfId(), memberState.currTerm(), memberState.getLeaderId(), request.getLeaderId());</span><br><span class="line">            <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> HeartBeatResponse().code(DLedgerResponseCode.INCONSISTENT_LEADER.getCode()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//To make it simple, for larger term, do not change to follower immediately</span></span><br><span class="line">        <span class="comment">//first change to candidate, and notify the state-maintainer thread</span></span><br><span class="line">        changeRoleToCandidate(request.getTerm());</span><br><span class="line">        needIncreaseTermImmediately = <span class="keyword">true</span>;</span><br><span class="line">        <span class="comment">//TOOD notify</span></span><br><span class="line">        <span class="keyword">return</span> CompletableFuture.completedFuture(<span class="keyword">new</span> HeartBeatResponse().code(DLedgerResponseCode.TERM_NOT_READY.getCode()));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：加锁来处理（这里更多的是从节点第一次收到主节点的心跳包）</p>
<p>代码@1：如果主节的投票轮次小于当前投票轮次，则返回主节点投票轮次过期。</p>
<p>代码@2：如果投票轮次相同。</p>
<ul>
<li>如果当前节点的主节点字段为空，则使用主节点的ID，并返回成功。</li>
<li>如果当前节点的主节点就是发送心跳包的节点，则更新上一次收到心跳包的时间戳，并返回成功。</li>
<li>如果从节点的主节点与发送心跳包的节点ID不同，说明有另外一个Leaer，按道理来说是不会发送的，如果发生，则返回已存在- 主节点，标记该心跳包处理结束。</li>
</ul>
<p>代码@3：如果主节点的投票轮次大于从节点的投票轮次，则认为从节点并为准备好，则从节点进入Candidate 状态，并立即发起一次投票。</p>
<p>心跳包的处理就介绍到这里。</p>
<p>RocketMQ 多副本之 Leader 选举的源码分析就介绍到这里了，为了加强对源码的理解，先梳理流程图如下：<br><img src="https://img-blog.csdnimg.cn/20190817204737273.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>多副本</tag>
        <tag>raft</tag>
        <tag>选主</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析 RocketMQ DLedger(多副本) 之日志复制(传播)</title>
    <url>/posts/91680207.html</url>
    <content><![CDATA[<div id="vip-container"><p>本文紧接着 源码分析 RocketMQ DLedger(多副本) 之日志追加流程  ，继续 Leader 处理客户端 append 的请求流程中最至关重要的一环：日志复制。</p>
<p>DLedger 多副本的日志转发由 DLedgerEntryPusher 实现，接下来将对其进行详细介绍。</p>
<blockquote>
<p>温馨提示：由于本篇幅较长，为了更好的理解其实现，大家可以带着如下疑问来通读本篇文章：<br>1、raft 协议中有一个非常重要的概念：已提交日志序号，该如何实现。<br>2、客户端向 DLedger 集群发送一条日志，必须得到集群中大多数节点的认可才能被认为写入成功。<br>3、raft 协议中追加、提交两个动作如何实现。</p>
</blockquote>
<p>@<a href="%E6%9C%AC%E8%8A%82%E7%9B%AE%E5%BD%95">TOC</a></p>
<p>日志复制(日志转发)由 DLedgerEntryPusher 实现，具体类图如下：<br><img src="https://img-blog.csdnimg.cn/2019091421331888.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>主要由如下4个类构成：</p>
<ul>
<li>DLedgerEntryPusher<br>DLedger 日志转发与处理核心类，该内会启动如下3个对象，其分别对应一个线程。</li>
<li>EntryHandler<br>日志接收处理线程，当节点为从节点时激活。</li>
<li>QuorumAckChecker<br>日志追加ACK投票处理线程，当前节点为主节点时激活。</li>
<li>EntryDispatcher<br>日志转发线程，当前节点为主节点时追加。</li>
</ul>
<p>接下来我们将详细介绍上述4个类，从而揭晓日志复制的核心实现原理。</p>
<h2 id="1、DLedgerEntryPusher"><a href="#1、DLedgerEntryPusher" class="headerlink" title="1、DLedgerEntryPusher"></a>1、DLedgerEntryPusher</h2><h3 id="1-1-核心类图"><a href="#1-1-核心类图" class="headerlink" title="1.1 核心类图"></a>1.1 核心类图</h3><p><img src="https://img-blog.csdnimg.cn/20190914213606209.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>DLedger 多副本日志推送的核心实现类，里面会创建 EntryDispatcher、QuorumAckChecker、EntryHandler 三个核心线程。其核心属性如下：</p>
<ul>
<li>DLedgerConfig dLedgerConfig<br>多副本相关配置。</li>
<li>DLedgerStore dLedgerStore<br>存储实现类。</li>
<li>MemberState memberState<br>节点状态机。</li>
<li>DLedgerRpcService dLedgerRpcService<br>RPC 服务实现类，用于集群内的其他节点进行网络通讯。</li>
<li>Map&lt;Long, ConcurrentMap&lt;String, Long&gt;&gt; peerWaterMarksByTerm<br>每个节点基于投票轮次的当前水位线标记。键值为投票轮次，值为 ConcurrentMap&lt;String/** 节点id*/, Long/** 节点对应的日志序号*/&gt;。</li>
<li>Map&lt;Long, ConcurrentMap&lt;Long, TimeoutFuture<AppendEntryResponse>&gt;&gt; pendingAppendResponsesByTerm<br>用于存放追加请求的响应结果(Future模式)。</li>
<li>EntryHandler entryHandler<br>从节点上开启的线程，用于接收主节点的 push 请求（append、commit、append）。</li>
<li>QuorumAckChecker quorumAckChecker<br>主节点上的追加请求投票器。</li>
<li>Map&lt;String, EntryDispatcher&gt; dispatcherMap<br>主节点日志请求转发器，向从节点复制消息等。</li>
</ul>
<p>接下来介绍一下其核心方法的实现。</p>
<h3 id="1-2-构造方法"><a href="#1-2-构造方法" class="headerlink" title="1.2 构造方法"></a>1.2 构造方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DLedgerEntryPusher</span><span class="params">(DLedgerConfig dLedgerConfig, MemberState memberState, DLedgerStore dLedgerStore,</span></span></span><br><span class="line"><span class="function"><span class="params">    DLedgerRpcService dLedgerRpcService)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.dLedgerConfig = dLedgerConfig;</span><br><span class="line">    <span class="keyword">this</span>.memberState = memberState;</span><br><span class="line">    <span class="keyword">this</span>.dLedgerStore = dLedgerStore;</span><br><span class="line">    <span class="keyword">this</span>.dLedgerRpcService = dLedgerRpcService;</span><br><span class="line">    <span class="keyword">for</span> (String peer : memberState.getPeerMap().keySet()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!peer.equals(memberState.getSelfId())) &#123;</span><br><span class="line">            dispatcherMap.put(peer, <span class="keyword">new</span> EntryDispatcher(peer, logger));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>构造方法的重点是会根据集群内的节点，依次构建对应的 EntryDispatcher 对象。</p>
<h3 id="1-3-startup"><a href="#1-3-startup" class="headerlink" title="1.3 startup"></a>1.3 startup</h3><p>DLedgerEntryPusher#startup</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">startup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    entryHandler.start();</span><br><span class="line">    quorumAckChecker.start();</span><br><span class="line">    <span class="keyword">for</span> (EntryDispatcher dispatcher : dispatcherMap.values()) &#123;</span><br><span class="line">        dispatcher.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>依次启动 EntryHandler、QuorumAckChecker 与 EntryDispatcher 线程。</p>
<blockquote>
<p>备注：DLedgerEntryPusher 的其他核心方法在详细分析其日志复制原理的过程中会一一介绍。</p>
</blockquote>
<p>接下来将从 EntryDispatcher、QuorumAckChecker、EntryHandler 来阐述 RocketMQ DLedger(多副本)的实现原理。</p>
<h2 id="2、EntryDispatcher-详解"><a href="#2、EntryDispatcher-详解" class="headerlink" title="2、EntryDispatcher 详解"></a>2、EntryDispatcher 详解</h2><h3 id="2-1-核心类图"><a href="#2-1-核心类图" class="headerlink" title="2.1 核心类图"></a>2.1 核心类图</h3><p><img src="https://img-blog.csdnimg.cn/20190914215700841.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其核心属性如下。</p>
<ul>
<li>AtomicReference&lt;PushEntryRequest.Type&gt; type = new AtomicReference&lt;&gt;(PushEntryRequest.Type.COMPARE)<br>向从节点发送命令的类型，可选值：PushEntryRequest.Type.COMPARE、TRUNCATE、APPEND、COMMIT，下面详细说明。</li>
<li>long lastPushCommitTimeMs = -1<br>上一次发送提交类型的时间戳。</li>
<li>String peerId<br>目标节点ID。</li>
<li>long compareIndex = -1<br>已完成比较的日志序号。</li>
<li>long writeIndex = -1<br>已写入的日志序号。</li>
<li>int maxPendingSize = 1000<br>允许的最大挂起日志数量。</li>
<li>long term = -1<pre><code> Leader 节点当前的投票轮次。</code></pre>
</li>
<li>String leaderId = null<br>Leader 节点ID。</li>
<li>long lastCheckLeakTimeMs = System.currentTimeMillis()<br>上次检测泄漏的时间，所谓的泄漏，就是看挂起的日志请求数量是否查过了 maxPendingSize 。</li>
<li>ConcurrentMap&lt;Long, Long&gt; pendingMap = new ConcurrentHashMap&lt;&gt;()<br>记录日志的挂起时间，key：日志的序列(entryIndex)，value：挂起时间戳。</li>
<li>Quota quota = new Quota(dLedgerConfig.getPeerPushQuota())<br>配额。</li>
</ul>
<h3 id="2-2-Push-请求类型"><a href="#2-2-Push-请求类型" class="headerlink" title="2.2 Push 请求类型"></a>2.2 Push 请求类型</h3><p>DLedger 主节点向从从节点复制日志总共定义了4类请求类型，其枚举类型为 PushEntryRequest.Type，其值分别为 COMPARE、TRUNCATE、APPEND、COMMIT。</p>
<ul>
<li>COMPARE<br>如果 Leader 发生变化，新的 Leader 需要与他的从节点的日志条目进行比较，以便截断从节点多余的数据。 </li>
<li>TRUNCATE<br>如果 Leader 通过索引完成日志对比，则 Leader 将发送  TRUNCATE 给它的从节点。</li>
<li>APPEND<br>将日志条目追加到从节点。</li>
<li>COMMIT<br>通常，leader 会将提交的索引附加到 append 请求，但是如果 append 请求很少且分散，leader 将发送一个单独的请求来通知从节点提交的索引。</li>
</ul>
<p>对主从节点的请求类型有了一个初步的认识后，我们将从 EntryDispatcher 的业务处理入口 doWork 方法开始讲解。</p>
<a id="more"></a>

<h3 id="2-3-doWork-方法详解"><a href="#2-3-doWork-方法详解" class="headerlink" title="2.3 doWork 方法详解"></a>2.3 doWork 方法详解</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWork</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (!checkAndFreshState()) &#123;                                            <span class="comment">// @1</span></span><br><span class="line">            waitForRunning(<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (type.get() == PushEntryRequest.Type.APPEND) &#123;   <span class="comment">// @2</span></span><br><span class="line">            doAppend();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            doCompare();                                                           <span class="comment">// @3</span></span><br><span class="line">        &#125;</span><br><span class="line">        waitForRunning(<span class="number">1</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        DLedgerEntryPusher.logger.error(<span class="string">&quot;[Push-&#123;&#125;]Error in &#123;&#125; writeIndex=&#123;&#125; compareIndex=&#123;&#125;&quot;</span>, peerId, getName(), writeIndex, compareIndex, t);</span><br><span class="line">        DLedgerUtils.sleep(<span class="number">500</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：检查状态，是否可以继续发送 append 或 compare。</p>
<p>代码@2：如果推送类型为APPEND，主节点向从节点传播消息请求。</p>
<p>代码@3：主节点向从节点发送对比数据差异请求（当一个新节点被选举成为主节点时，往往这是第一步）。</p>
<h4 id="2-3-1-checkAndFreshState-详解"><a href="#2-3-1-checkAndFreshState-详解" class="headerlink" title="2.3.1 checkAndFreshState 详解"></a>2.3.1 checkAndFreshState 详解</h4><p>EntryDispatcher#checkAndFreshState</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">checkAndFreshState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!memberState.isLeader()) &#123;     <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (term != memberState.currTerm() || leaderId == <span class="keyword">null</span> || !leaderId.equals(memberState.getLeaderId())) &#123;     <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">synchronized</span> (memberState) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!memberState.isLeader()) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            PreConditions.check(memberState.getSelfId().equals(memberState.getLeaderId()), DLedgerResponseCode.UNKNOWN);</span><br><span class="line">            term = memberState.currTerm();</span><br><span class="line">            leaderId = memberState.getSelfId();</span><br><span class="line">            changeState(-<span class="number">1</span>, PushEntryRequest.Type.COMPARE);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果节点的状态不是主节点，则直接返回 false。则结束 本次 doWork 方法。因为只有主节点才需要向从节点转发日志。</p>
<p>代码@2：如果当前节点状态是主节点，但当前的投票轮次与状态机轮次或 leaderId 还未设置，或 leaderId 与状态机的 leaderId 不相等，这种情况通常是集群触发了重新选举，设置其term、leaderId与状态机同步，即将发送COMPARE 请求。</p>
<p>接下来看一下 changeState (改变状态)。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">changeState</span><span class="params">(<span class="keyword">long</span> index, PushEntryRequest.Type target)</span> </span>&#123;</span><br><span class="line">    logger.info(<span class="string">&quot;[Push-&#123;&#125;]Change state from &#123;&#125; to &#123;&#125; at &#123;&#125;&quot;</span>, peerId, type.get(), target, index);</span><br><span class="line">    <span class="keyword">switch</span> (target) &#123;</span><br><span class="line">        <span class="keyword">case</span> APPEND:      <span class="comment">// @1</span></span><br><span class="line">            compareIndex = -<span class="number">1</span>;</span><br><span class="line">            updatePeerWaterMark(term, peerId, index);</span><br><span class="line">            quorumAckChecker.wakeup();</span><br><span class="line">            writeIndex = index + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> COMPARE:    <span class="comment">// @2</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>.type.compareAndSet(PushEntryRequest.Type.APPEND, PushEntryRequest.Type.COMPARE)) &#123;</span><br><span class="line">                compareIndex = -<span class="number">1</span>;</span><br><span class="line">                pendingMap.clear();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> TRUNCATE:     <span class="comment">// @3</span></span><br><span class="line">            compareIndex = -<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    type.set(target);</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<p>代码@1：如果将目标类型设置为 append，则重置 compareIndex ，并设置 writeIndex 为当前 index 加1。</p>
<p>代码@2：如果将目标类型设置为 COMPARE，则重置 compareIndex 为负一，接下将向各个从节点发送 COMPARE 请求类似，并清除已挂起的请求。</p>
<p>代码@3：如果将目标类型设置为 TRUNCATE，则重置 compareIndex 为负一。</p>
<p>接下来具体来看一下 APPEND、COMPARE、TRUNCATE 等请求。</p>
<h4 id="2-3-2-append-请求详解"><a href="#2-3-2-append-请求详解" class="headerlink" title="2.3.2 append 请求详解"></a>2.3.2 append 请求详解</h4><p>EntryDispatcher#doAppend</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doAppend</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!checkAndFreshState()) &#123;                                                 <span class="comment">// @1</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (type.get() != PushEntryRequest.Type.APPEND) &#123;        <span class="comment">// @2</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (writeIndex &gt; dLedgerStore.getLedgerEndIndex()) &#123;    <span class="comment">// @3</span></span><br><span class="line">            doCommit();</span><br><span class="line">            doCheckAppendResponse();</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (pendingMap.size() &gt;= maxPendingSize || (DLedgerUtils.elapsed(lastCheckLeakTimeMs) &gt; <span class="number">1000</span>)) &#123;     <span class="comment">// @4</span></span><br><span class="line">            <span class="keyword">long</span> peerWaterMark = getPeerWaterMark(term, peerId);</span><br><span class="line">            <span class="keyword">for</span> (Long index : pendingMap.keySet()) &#123;</span><br><span class="line">                <span class="keyword">if</span> (index &lt; peerWaterMark) &#123;</span><br><span class="line">                    pendingMap.remove(index);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            lastCheckLeakTimeMs = System.currentTimeMillis();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (pendingMap.size() &gt;= maxPendingSize) &#123;    <span class="comment">// @5</span></span><br><span class="line">            doCheckAppendResponse();</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        doAppendInner(writeIndex);                               <span class="comment">// @6</span></span><br><span class="line">        writeIndex++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：检查状态，已经在上面详细介绍。</p>
<p>代码@2：如果请求类型不为 APPEND，则退出，结束本轮 doWork 方法执行。</p>
<p>代码@3：writeIndex 表示当前追加到从该节点的序号，通常情况下主节点向从节点发送 append 请求时，会附带主节点的已提交指针，但如何 append 请求发不那么频繁，writeIndex 大于 leaderEndIndex 时（由于pending请求超过其 pending 请求的队列长度（默认为1w)，时，会阻止数据的追加，此时有可能出现 writeIndex 大于 leaderEndIndex 的情况，此时单独发送 COMMIT 请求。</p>
<p>代码@4：检测 pendingMap(挂起的请求数量)是否发送泄漏，即挂起队列中容量是否超过允许的最大挂起阀值。获取当前节点关于本轮次的当前水位线(已成功 append 请求的日志序号)，如果发现正在挂起请求的日志序号小于水位线，则丢弃。</p>
<p>代码@5：如果挂起的请求（等待从节点追加结果）大于 maxPendingSize 时，检查并追加一次 append 请求。</p>
<p>代码@6：具体的追加请求。</p>
<h5 id="2-3-2-1-doCommit-发送提交请求"><a href="#2-3-2-1-doCommit-发送提交请求" class="headerlink" title="2.3.2.1 doCommit 发送提交请求"></a>2.3.2.1 doCommit 发送提交请求</h5><p>EntryDispatcher#doCommit</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doCommit</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (DLedgerUtils.elapsed(lastPushCommitTimeMs) &gt; <span class="number">1000</span>) &#123;   <span class="comment">// @1</span></span><br><span class="line">        PushEntryRequest request = buildPushRequest(<span class="keyword">null</span>, PushEntryRequest.Type.COMMIT);   <span class="comment">// @2</span></span><br><span class="line">        <span class="comment">//Ignore the results</span></span><br><span class="line">        dLedgerRpcService.push(request);                                                                                        <span class="comment">// @3</span></span><br><span class="line">        lastPushCommitTimeMs = System.currentTimeMillis();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果上一次单独发送 commit 的请求时间与当前时间相隔低于 1s，放弃本次提交请求。</p>
<p>代码@2：构建提交请求。</p>
<p>代码@3：通过网络向从节点发送 commit 请求。</p>
<p>接下来先了解一下如何构建 commit 请求包。</p>
<p>EntryDispatcher#buildPushRequest</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> PushEntryRequest <span class="title">buildPushRequest</span><span class="params">(DLedgerEntry entry, PushEntryRequest.Type target)</span> </span>&#123;</span><br><span class="line">    PushEntryRequest request = <span class="keyword">new</span> PushEntryRequest();</span><br><span class="line">    request.setGroup(memberState.getGroup());  </span><br><span class="line">    request.setRemoteId(peerId);                          </span><br><span class="line">    request.setLeaderId(leaderId);</span><br><span class="line">    request.setTerm(term);</span><br><span class="line">    request.setEntry(entry);</span><br><span class="line">    request.setType(target);</span><br><span class="line">    request.setCommitIndex(dLedgerStore.getCommittedIndex());</span><br><span class="line">    <span class="keyword">return</span> request;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>提交包请求字段主要包含如下字段：DLedger 节点所属组、从节点 id、主节点 id，当前投票轮次、日志内容、请求类型与 committedIndex(主节点已提交日志序号)。</p>
<h5 id="2-3-2-2-doCheckAppendResponse-检查并追加请求"><a href="#2-3-2-2-doCheckAppendResponse-检查并追加请求" class="headerlink" title="2.3.2.2 doCheckAppendResponse 检查并追加请求"></a>2.3.2.2 doCheckAppendResponse 检查并追加请求</h5><p>EntryDispatcher#doCheckAppendResponse</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doCheckAppendResponse</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> peerWaterMark = getPeerWaterMark(term, peerId);   <span class="comment">// @1</span></span><br><span class="line">    Long sendTimeMs = pendingMap.get(peerWaterMark + <span class="number">1</span>); </span><br><span class="line">    <span class="keyword">if</span> (sendTimeMs != <span class="keyword">null</span> &amp;&amp; System.currentTimeMillis() - sendTimeMs &gt; dLedgerConfig.getMaxPushTimeOutMs()) &#123; <span class="comment">// @2</span></span><br><span class="line">        logger.warn(<span class="string">&quot;[Push-&#123;&#125;]Retry to push entry at &#123;&#125;&quot;</span>, peerId, peerWaterMark + <span class="number">1</span>);</span><br><span class="line">        doAppendInner(peerWaterMark + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法的作用是检查 append 请求是否超时，其关键实现如下：</p>
<ul>
<li>获取已成功 append 的序号。</li>
<li>从挂起的请求队列中获取下一条的发送时间，如果不为空并去超过了 append 的超时时间，则再重新发送 append 请求，最大超时时间默认为 1s，可以通过 maxPushTimeOutMs 来改变默认值。</li>
</ul>
<h5 id="2-3-2-3-doAppendInner-追加请求"><a href="#2-3-2-3-doAppendInner-追加请求" class="headerlink" title="2.3.2.3 doAppendInner 追加请求"></a>2.3.2.3 doAppendInner 追加请求</h5><p>向从节点发送 append 请求。</p>
<p>EntryDispatcher#doAppendInner</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doAppendInner</span><span class="params">(<span class="keyword">long</span> index)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    DLedgerEntry entry = dLedgerStore.get(index);   <span class="comment">// @1</span></span><br><span class="line">    PreConditions.check(entry != <span class="keyword">null</span>, DLedgerResponseCode.UNKNOWN, <span class="string">&quot;writeIndex=%d&quot;</span>, index);</span><br><span class="line">    checkQuotaAndWait(entry);                                   <span class="comment">// @2</span></span><br><span class="line">    PushEntryRequest request = buildPushRequest(entry, PushEntryRequest.Type.APPEND);   <span class="comment">// @3</span></span><br><span class="line">    CompletableFuture&lt;PushEntryResponse&gt; responseFuture = dLedgerRpcService.push(request);   <span class="comment">// @4</span></span><br><span class="line">    pendingMap.put(index, System.currentTimeMillis());                                                                          <span class="comment">// @5</span></span><br><span class="line">    responseFuture.whenComplete((x, ex) -&gt; &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            PreConditions.check(ex == <span class="keyword">null</span>, DLedgerResponseCode.UNKNOWN);</span><br><span class="line">            DLedgerResponseCode responseCode = DLedgerResponseCode.valueOf(x.getCode());</span><br><span class="line">            <span class="keyword">switch</span> (responseCode) &#123;</span><br><span class="line">                <span class="keyword">case</span> SUCCESS:                                                                                                                <span class="comment">// @6</span></span><br><span class="line">                    pendingMap.remove(x.getIndex());</span><br><span class="line">                    updatePeerWaterMark(x.getTerm(), peerId, x.getIndex());</span><br><span class="line">                    quorumAckChecker.wakeup();</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> INCONSISTENT_STATE:                                                                                         <span class="comment">// @7</span></span><br><span class="line">                    logger.info(<span class="string">&quot;[Push-&#123;&#125;]Get INCONSISTENT_STATE when push index=&#123;&#125; term=&#123;&#125;&quot;</span>, peerId, x.getIndex(), x.getTerm());</span><br><span class="line">                    changeState(-<span class="number">1</span>, PushEntryRequest.Type.COMPARE);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">default</span>:</span><br><span class="line">                    logger.warn(<span class="string">&quot;[Push-&#123;&#125;]Get error response code &#123;&#125; &#123;&#125;&quot;</span>, peerId, responseCode, x.baseInfo());</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">            logger.error(<span class="string">&quot;&quot;</span>, t);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    lastPushCommitTimeMs = System.currentTimeMillis();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先根据序号查询出日志。</p>
<p>代码@2：检测配额，如果超过配额，会进行一定的限流，其关键实现点：</p>
<ul>
<li>首先触发条件：append 挂起请求数已超过最大允许挂起数；基于文件存储并主从差异超过300m，可通过 peerPushThrottlePoint 配置。</li>
<li>每秒追加的日志超过 20m(可通过 peerPushQuota 配置)，则会 sleep 1s中后再追加。</li>
</ul>
<p>代码@3：构建 PUSH  请求日志。</p>
<p>代码@4：通过 Netty 发送网络请求到从节点，从节点收到请求会进行处理(本文并不会探讨与网络相关的实现细节)。</p>
<p>代码@5：用 pendingMap 记录待追加的日志的发送时间，用于发送端判断是否超时的一个依据。</p>
<p>代码@6：请求成功的处理逻辑，其关键实现点如下：</p>
<ul>
<li>移除 pendingMap 中的关于该日志的发送超时时间。</li>
<li>更新已成功追加的日志序号(按投票轮次组织，并且每个从服务器一个键值对)。</li>
<li>唤醒 quorumAckChecker 线程(主要用于仲裁 append 结果)，后续会详细介绍。</li>
</ul>
<p>代码@7：Push 请求出现状态不一致情况，将发送 COMPARE 请求，来对比主从节点的数据是否一致。</p>
<p>日志转发 append 追加请求类型就介绍到这里了，接下来我们继续探讨另一个请求类型 compare。</p>
<h4 id="2-3-3-compare-请求详解"><a href="#2-3-3-compare-请求详解" class="headerlink" title="2.3.3  compare 请求详解"></a>2.3.3  compare 请求详解</h4><p>COMPARE 类型的请求有 doCompare 方法发送，首先该方法运行在 while (true) 中，故在查阅下面代码时，要注意其退出循环的条件。<br>EntryDispatcher#doCompare</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!checkAndFreshState()) &#123;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (type.get() != PushEntryRequest.Type.COMPARE</span><br><span class="line">    &amp;&amp; type.get() != PushEntryRequest.Type.TRUNCATE) &#123;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (compareIndex == -<span class="number">1</span> &amp;&amp; dLedgerStore.getLedgerEndIndex() == -<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step1：验证是否执行，有几个关键点如下：</p>
<ul>
<li>判断是否是主节点，如果不是主节点，则直接跳出。</li>
<li>如果是请求类型不是 COMPARE 或 TRUNCATE 请求，则直接跳出。</li>
<li>如果已比较索引 和 ledgerEndIndex 都为 -1 ，表示一个新的 DLedger 集群，则直接跳出。</li>
</ul>
<p>EntryDispatcher#doCompare</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (compareIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">    compareIndex = dLedgerStore.getLedgerEndIndex();</span><br><span class="line">    logger.info(<span class="string">&quot;[Push-&#123;&#125;][DoCompare] compareIndex=-1 means start to compare&quot;</span>, peerId);</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (compareIndex &gt; dLedgerStore.getLedgerEndIndex() || compareIndex &lt; dLedgerStore.getLedgerBeginIndex()) &#123;</span><br><span class="line">    logger.info(<span class="string">&quot;[Push-&#123;&#125;][DoCompare] compareIndex=&#123;&#125; out of range &#123;&#125;-&#123;&#125;&quot;</span>, peerId, compareIndex, dLedgerStore.getLedgerBeginIndex(), dLedgerStore.getLedgerEndIndex());</span><br><span class="line">    compareIndex = dLedgerStore.getLedgerEndIndex();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：如果 compareIndex 为 -1 或compareIndex 不在有效范围内，则重置待比较序列号为当前已已存储的最大日志序号：ledgerEndIndex。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DLedgerEntry entry = dLedgerStore.get(compareIndex);</span><br><span class="line">PreConditions.check(entry != <span class="keyword">null</span>, DLedgerResponseCode.INTERNAL_ERROR, <span class="string">&quot;compareIndex=%d&quot;</span>, compareIndex);</span><br><span class="line">PushEntryRequest request = buildPushRequest(entry, PushEntryRequest.Type.COMPARE);</span><br><span class="line">CompletableFuture&lt;PushEntryResponse&gt; responseFuture = dLedgerRpcService.push(request);</span><br><span class="line">PushEntryResponse response = responseFuture.get(<span class="number">3</span>, TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure>
<p>Step3：根据序号查询到日志，并向从节点发起 COMPARE 请求，其超时时间为 3s。</p>
<p>EntryDispatcher#doCompare</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> truncateIndex = -<span class="number">1</span>;</span><br><span class="line"><span class="keyword">if</span> (response.getCode() == DLedgerResponseCode.SUCCESS.getCode()) &#123;   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (compareIndex == response.getEndIndex()) &#123;</span><br><span class="line">        changeState(compareIndex, PushEntryRequest.Type.APPEND);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        truncateIndex = compareIndex;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (response.getEndIndex() &lt; dLedgerStore.getLedgerBeginIndex() </span><br><span class="line">        || response.getBeginIndex() &gt; dLedgerStore.getLedgerEndIndex()) &#123;    <span class="comment">// @2</span></span><br><span class="line">    truncateIndex = dLedgerStore.getLedgerBeginIndex();</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (compareIndex &lt; response.getBeginIndex()) &#123;                                    <span class="comment">// @3</span></span><br><span class="line">    truncateIndex = dLedgerStore.getLedgerBeginIndex();</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (compareIndex &gt; response.getEndIndex()) &#123;                                      <span class="comment">// @4</span></span><br><span class="line">    compareIndex = response.getEndIndex();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;                                                                                                              <span class="comment">// @5</span></span><br><span class="line">	compareIndex--;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (compareIndex &lt; dLedgerStore.getLedgerBeginIndex()) &#123;                          <span class="comment">// @6</span></span><br><span class="line">    truncateIndex = dLedgerStore.getLedgerBeginIndex();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step4：根据响应结果计算需要截断的日志序号，其主要实现关键点如下：</p>
<ul>
<li>代码@1：如果两者的日志序号相同，则无需截断，下次将直接先从节点发送 append 请求；否则将 truncateIndex  设置为响应结果中的 endIndex。</li>
<li>代码@2：如果从节点存储的最大日志序号小于主节点的最小序号，或者从节点的最小日志序号大于主节点的最大日志序号，即两者不相交，这通常发生在从节点崩溃很长一段时间，而主节点删除了过期的条目时。truncateIndex 设置为主节点的 ledgerBeginIndex，即主节点目前最小的偏移量。</li>
<li>代码@3：如果已比较的日志序号小于从节点的开始日志序号，很可能是从节点磁盘发送损耗，从主节点最小日志序号开始同步。</li>
<li>代码@4：如果已比较的日志序号大于从节点的最大日志序号，则已比较索引设置为从节点最大的日志序号，触发数据的继续同步。</li>
<li>代码@5：如果已比较的日志序号大于从节点的开始日志序号，但小于从节点的最大日志序号，则待比较索引减一。</li>
<li>代码@6：如果比较出来的日志序号小于主节点的最小日志需要，则设置为主节点的最小序号。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (truncateIndex != -<span class="number">1</span>) &#123;</span><br><span class="line">    changeState(truncateIndex, PushEntryRequest.Type.TRUNCATE);</span><br><span class="line">    doTruncate(truncateIndex);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step5：如果比较出来的日志序号不等于 -1 ，则向从节点发送 TRUNCATE 请求。</p>
<h5 id="2-3-3-1-doTruncate-详解"><a href="#2-3-3-1-doTruncate-详解" class="headerlink" title="2.3.3.1 doTruncate 详解"></a>2.3.3.1 doTruncate 详解</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doTruncate</span><span class="params">(<span class="keyword">long</span> truncateIndex)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    PreConditions.check(type.get() == PushEntryRequest.Type.TRUNCATE, DLedgerResponseCode.UNKNOWN);</span><br><span class="line">    DLedgerEntry truncateEntry = dLedgerStore.get(truncateIndex);</span><br><span class="line">    PreConditions.check(truncateEntry != <span class="keyword">null</span>, DLedgerResponseCode.UNKNOWN);</span><br><span class="line">    logger.info(<span class="string">&quot;[Push-&#123;&#125;]Will push data to truncate truncateIndex=&#123;&#125; pos=&#123;&#125;&quot;</span>, peerId, truncateIndex, truncateEntry.getPos());</span><br><span class="line">    PushEntryRequest truncateRequest = buildPushRequest(truncateEntry, PushEntryRequest.Type.TRUNCATE);</span><br><span class="line">    PushEntryResponse truncateResponse = dLedgerRpcService.push(truncateRequest).get(<span class="number">3</span>, TimeUnit.SECONDS);</span><br><span class="line">    PreConditions.check(truncateResponse != <span class="keyword">null</span>, DLedgerResponseCode.UNKNOWN, <span class="string">&quot;truncateIndex=%d&quot;</span>, truncateIndex);</span><br><span class="line">    PreConditions.check(truncateResponse.getCode() == DLedgerResponseCode.SUCCESS.getCode(), DLedgerResponseCode.valueOf(truncateResponse.getCode()), <span class="string">&quot;truncateIndex=%d&quot;</span>, truncateIndex);</span><br><span class="line">    lastPushCommitTimeMs = System.currentTimeMillis();</span><br><span class="line">    changeState(truncateIndex, PushEntryRequest.Type.APPEND);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法主要就是构建 truncate 请求到从节点。</p>
<p>关于服务端的消息复制转发就介绍到这里了，主节点负责向从服务器PUSH请求，从节点自然而然的要处理这些请求，接下来我们就按照主节点发送的请求，来具体分析一下从节点是如何响应的。</p>
<h2 id="3、EntryHandler-详解"><a href="#3、EntryHandler-详解" class="headerlink" title="3、EntryHandler 详解"></a>3、EntryHandler 详解</h2><p>EntryHandler 同样是一个线程，当节点状态为从节点时激活。</p>
<h3 id="3-1-核心类图"><a href="#3-1-核心类图" class="headerlink" title="3.1 核心类图"></a>3.1 核心类图</h3><p><img src="https://img-blog.csdnimg.cn/20190914220450532.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其核心属性如下：</p>
<ul>
<li>long lastCheckFastForwardTimeMs<br>上一次检查主服务器是否有 push 消息的时间戳。</li>
<li>ConcurrentMap&lt;Long, Pair&lt;PushEntryRequest, CompletableFuture&lt; PushEntryResponse&gt;&gt;&gt; writeRequestMap<br>append 请求处理队列。</li>
<li>BlockingQueue&lt;Pair&lt;PushEntryRequest, CompletableFuture&lt; PushEntryResponse&gt;&gt;&gt; compareOrTruncateRequests<br>COMMIT、COMPARE、TRUNCATE 相关请求</li>
</ul>
<h3 id="3-2-handlePush"><a href="#3-2-handlePush" class="headerlink" title="3.2 handlePush"></a>3.2 handlePush</h3><p>从上文得知，主节点会主动向从节点传播日志，从节点会通过网络接受到请求数据进行处理，其调用链如图所示：<br><img src="https://img-blog.csdnimg.cn/20190914220604630.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>最终会调用 EntryHandler 的 handlePush 方法。</p>
<p>EntryHandler#handlePush</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> CompletableFuture&lt;PushEntryResponse&gt; <span class="title">handlePush</span><span class="params">(PushEntryRequest request)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="comment">//The timeout should smaller than the remoting layer&#x27;s request timeout</span></span><br><span class="line">    CompletableFuture&lt;PushEntryResponse&gt; future = <span class="keyword">new</span> TimeoutFuture&lt;&gt;(<span class="number">1000</span>);      <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">switch</span> (request.getType()) &#123;</span><br><span class="line">        <span class="keyword">case</span> APPEND:                                                                                                          <span class="comment">// @2</span></span><br><span class="line">            PreConditions.check(request.getEntry() != <span class="keyword">null</span>, DLedgerResponseCode.UNEXPECTED_ARGUMENT);</span><br><span class="line">            <span class="keyword">long</span> index = request.getEntry().getIndex();</span><br><span class="line">            Pair&lt;PushEntryRequest, CompletableFuture&lt;PushEntryResponse&gt;&gt; old = writeRequestMap.putIfAbsent(index, <span class="keyword">new</span> Pair&lt;&gt;(request, future));</span><br><span class="line">            <span class="keyword">if</span> (old != <span class="keyword">null</span>) &#123;</span><br><span class="line">                logger.warn(<span class="string">&quot;[MONITOR]The index &#123;&#125; has already existed with &#123;&#125; and curr is &#123;&#125;&quot;</span>, index, old.getKey().baseInfo(), request.baseInfo());</span><br><span class="line">                future.complete(buildResponse(request, DLedgerResponseCode.REPEATED_PUSH.getCode()));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> COMMIT:                                                                                                           <span class="comment">// @3</span></span><br><span class="line">            compareOrTruncateRequests.put(<span class="keyword">new</span> Pair&lt;&gt;(request, future));</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> COMPARE:</span><br><span class="line">        <span class="keyword">case</span> TRUNCATE:                                                                                                     <span class="comment">// @4</span></span><br><span class="line">            PreConditions.check(request.getEntry() != <span class="keyword">null</span>, DLedgerResponseCode.UNEXPECTED_ARGUMENT);</span><br><span class="line">            writeRequestMap.clear();</span><br><span class="line">            compareOrTruncateRequests.put(<span class="keyword">new</span> Pair&lt;&gt;(request, future));</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            logger.error(<span class="string">&quot;[BUG]Unknown type &#123;&#125; from &#123;&#125;&quot;</span>, request.getType(), request.baseInfo());</span><br><span class="line">            future.complete(buildResponse(request, DLedgerResponseCode.UNEXPECTED_ARGUMENT.getCode()));</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> future;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从几点处理主节点的 push 请求，其实现关键点如下。</p>
<p>代码@1：首先构建一个响应结果Future，默认超时时间 1s。</p>
<p>代码@2：如果是 APPEND 请求，放入到 writeRequestMap 集合中，如果已存在该数据结构，说明主节点重复推送，构建返回结果，其状态码为 REPEATED_PUSH。放入到 writeRequestMap 中，由 doWork 方法定时去处理待写入的请求。</p>
<p>代码@3：如果是提交请求， 将请求存入 compareOrTruncateRequests 请求处理中，由 doWork 方法异步处理。</p>
<p>代码@4：如果是 COMPARE 或 TRUNCATE 请求，将待写入队列 writeRequestMap  清空，并将请求放入 compareOrTruncateRequests 请求队列中，由 doWork 方法异步处理。</p>
<p>接下来，我们重点来分析 doWork 方法的实现。</p>
<h3 id="3-3-doWork-方法详解"><a href="#3-3-doWork-方法详解" class="headerlink" title="3.3 doWork 方法详解"></a>3.3 doWork 方法详解</h3><p>EntryHandler#doWork</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWork</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (!memberState.isFollower()) &#123;     <span class="comment">// @1</span></span><br><span class="line">            waitForRunning(<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (compareOrTruncateRequests.peek() != <span class="keyword">null</span>) &#123;    <span class="comment">// @2</span></span><br><span class="line">            Pair&lt;PushEntryRequest, CompletableFuture&lt;PushEntryResponse&gt;&gt; pair = compareOrTruncateRequests.poll();</span><br><span class="line">            PreConditions.check(pair != <span class="keyword">null</span>, DLedgerResponseCode.UNKNOWN);</span><br><span class="line">            <span class="keyword">switch</span> (pair.getKey().getType()) &#123;</span><br><span class="line">                <span class="keyword">case</span> TRUNCATE:</span><br><span class="line">                    handleDoTruncate(pair.getKey().getEntry().getIndex(), pair.getKey(), pair.getValue());</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> COMPARE:</span><br><span class="line">                    handleDoCompare(pair.getKey().getEntry().getIndex(), pair.getKey(), pair.getValue());</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">case</span> COMMIT:</span><br><span class="line">                    handleDoCommit(pair.getKey().getCommitIndex(), pair.getKey(), pair.getValue());</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">default</span>:</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">// @3</span></span><br><span class="line">            <span class="keyword">long</span> nextIndex = dLedgerStore.getLedgerEndIndex() + <span class="number">1</span>;</span><br><span class="line">            Pair&lt;PushEntryRequest, CompletableFuture&lt;PushEntryResponse&gt;&gt; pair = writeRequestMap.remove(nextIndex);</span><br><span class="line">            <span class="keyword">if</span> (pair == <span class="keyword">null</span>) &#123;</span><br><span class="line">                checkAbnormalFuture(dLedgerStore.getLedgerEndIndex());</span><br><span class="line">                waitForRunning(<span class="number">1</span>);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            PushEntryRequest request = pair.getKey();</span><br><span class="line">            handleDoAppend(nextIndex, request, pair.getValue());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        DLedgerEntryPusher.logger.error(<span class="string">&quot;Error in &#123;&#125;&quot;</span>, getName(), t);</span><br><span class="line">        DLedgerUtils.sleep(<span class="number">100</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果当前节点的状态不是从节点，则跳出。</p>
<p>代码@2：如果 compareOrTruncateRequests 队列不为空，说明有COMMIT、COMPARE、TRUNCATE 等请求，这类请求优先处理。值得注意的是这里使用是 peek、poll 等非阻塞方法，然后根据请求的类型，调用对应的方法。稍后详细介绍。</p>
<p>代码@3：如果只有 append 类请求，则根据当前节点最大的消息序号，尝试从 writeRequestMap 容器中，获取下一个消息复制请求(ledgerEndIndex + 1) 为 key 去查找。如果不为空，则执行 doAppend 请求，如果为空，则调用 checkAbnormalFuture 来处理异常情况。</p>
<p>接下来我们来重点分析各个处理细节。</p>
<h4 id="3-3-1-handleDoCommit"><a href="#3-3-1-handleDoCommit" class="headerlink" title="3.3.1 handleDoCommit"></a>3.3.1 handleDoCommit</h4><p>处理提交请求，其处理比较简单，就是调用 DLedgerStore 的 updateCommittedIndex 更新其已提交偏移量，故我们还是具体看一下DLedgerStore 的 updateCommittedIndex 方法。</p>
<p>DLedgerMmapFileStore#updateCommittedIndex</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateCommittedIndex</span><span class="params">(<span class="keyword">long</span> term, <span class="keyword">long</span> newCommittedIndex)</span> </span>&#123;   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (newCommittedIndex == -<span class="number">1</span></span><br><span class="line">            || ledgerEndIndex == -<span class="number">1</span></span><br><span class="line">            || term &lt; memberState.currTerm()</span><br><span class="line">            || newCommittedIndex == <span class="keyword">this</span>.committedIndex) &#123;                               <span class="comment">// @2</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (newCommittedIndex &lt; <span class="keyword">this</span>.committedIndex</span><br><span class="line">            || newCommittedIndex &lt; <span class="keyword">this</span>.ledgerBeginIndex) &#123;                             <span class="comment">// @3</span></span><br><span class="line">        logger.warn(<span class="string">&quot;[MONITOR]Skip update committed index for new=&#123;&#125; &lt; old=&#123;&#125; or new=&#123;&#125; &lt; beginIndex=&#123;&#125;&quot;</span>, newCommittedIndex, <span class="keyword">this</span>.committedIndex, newCommittedIndex, <span class="keyword">this</span>.ledgerBeginIndex);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">long</span> endIndex = ledgerEndIndex;</span><br><span class="line">    <span class="keyword">if</span> (newCommittedIndex &gt; endIndex) &#123;                                                       <span class="comment">// @4</span></span><br><span class="line">            <span class="comment">//If the node fall behind too much, the committedIndex will be larger than enIndex.</span></span><br><span class="line">        newCommittedIndex = endIndex;</span><br><span class="line">    &#125;</span><br><span class="line">    DLedgerEntry dLedgerEntry = get(newCommittedIndex);                        <span class="comment">// @5                </span></span><br><span class="line">    PreConditions.check(dLedgerEntry != <span class="keyword">null</span>, DLedgerResponseCode.DISK_ERROR);</span><br><span class="line">    <span class="keyword">this</span>.committedIndex = newCommittedIndex;</span><br><span class="line">    <span class="keyword">this</span>.committedPos = dLedgerEntry.getPos() + dLedgerEntry.getSize();     <span class="comment">// @6</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先介绍一下方法的参数：</p>
<ul>
<li>long term<br>主节点当前的投票轮次。</li>
<li>long newCommittedIndex:<br>主节点发送日志复制请求时的已提交日志序号。</li>
</ul>
<p>代码@2：如果待更新提交序号为 -1 或 投票轮次小于从节点的投票轮次或主节点投票轮次等于从节点的已提交序号，则直接忽略本次提交动作。</p>
<p>代码@3：如果主节点的已提交日志序号小于从节点的已提交日志序号或待提交序号小于当前节点的最小有效日志序号，则输出警告日志[MONITOR]，并忽略本次提交动作。</p>
<p>代码@4：如果从节点落后主节点太多，则重置 提交索引为从节点当前最大有效日志序号。</p>
<p>代码@5：尝试根据待提交序号从从节点查找数据，如果数据不存在，则抛出 DISK_ERROR 错误。</p>
<p>代码@6：更新 commitedIndex、committedPos 两个指针，DledgerStore会定时将已提交指针刷入 checkpoint 文件，达到持久化 commitedIndex 指针的目的。</p>
<h4 id="3-3-2-handleDoCompare"><a href="#3-3-2-handleDoCompare" class="headerlink" title="3.3.2 handleDoCompare"></a>3.3.2 handleDoCompare</h4><p>处理主节点发送过来的 COMPARE 请求，其实现也比较简单，最终调用 buildResponse 方法构造响应结果。</p>
<p>EntryHandler#buildResponse</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> PushEntryResponse <span class="title">buildResponse</span><span class="params">(PushEntryRequest request, <span class="keyword">int</span> code)</span> </span>&#123;</span><br><span class="line">    PushEntryResponse response = <span class="keyword">new</span> PushEntryResponse();</span><br><span class="line">    response.setGroup(request.getGroup());</span><br><span class="line">    response.setCode(code);</span><br><span class="line">    response.setTerm(request.getTerm());</span><br><span class="line">    <span class="keyword">if</span> (request.getType() != PushEntryRequest.Type.COMMIT) &#123;</span><br><span class="line">        response.setIndex(request.getEntry().getIndex());</span><br><span class="line">    &#125;</span><br><span class="line">    response.setBeginIndex(dLedgerStore.getLedgerBeginIndex());</span><br><span class="line">    response.setEndIndex(dLedgerStore.getLedgerEndIndex());</span><br><span class="line">    <span class="keyword">return</span> response;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>主要也是返回当前从几点的 ledgerBeginIndex、ledgerEndIndex 以及投票轮次，供主节点进行判断比较。</p>
<h4 id="3-3-3-handleDoTruncate"><a href="#3-3-3-handleDoTruncate" class="headerlink" title="3.3.3 handleDoTruncate"></a>3.3.3 handleDoTruncate</h4><p>handleDoTruncate 方法实现比较简单，删除从节点上 truncateIndex 日志序号之后的所有日志，具体调用dLedgerStore 的 truncate 方法，由于其存储与 RocketMQ 的存储设计基本类似故本文就不在详细介绍，简单介绍其实现要点：根据日志序号，去定位到日志文件，如果命中具体的文件，则修改相应的读写指针、刷盘指针等，并将所在在物理文件之后的所有文件删除。大家如有兴趣，可以查阅笔者的《RocketMQ技术内幕》第4章：RocketMQ 存储相关内容。</p>
<h4 id="3-3-4-handleDoAppend"><a href="#3-3-4-handleDoAppend" class="headerlink" title="3.3.4 handleDoAppend"></a>3.3.4 handleDoAppend</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleDoAppend</span><span class="params">(<span class="keyword">long</span> writeIndex, PushEntryRequest request,</span></span></span><br><span class="line"><span class="function"><span class="params">    CompletableFuture&lt;PushEntryResponse&gt; future)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        PreConditions.check(writeIndex == request.getEntry().getIndex(), DLedgerResponseCode.INCONSISTENT_STATE);</span><br><span class="line">        DLedgerEntry entry = dLedgerStore.appendAsFollower(request.getEntry(), request.getTerm(), request.getLeaderId());</span><br><span class="line">        PreConditions.check(entry.getIndex() == writeIndex, DLedgerResponseCode.INCONSISTENT_STATE);</span><br><span class="line">        future.complete(buildResponse(request, DLedgerResponseCode.SUCCESS.getCode()));</span><br><span class="line">        dLedgerStore.updateCommittedIndex(request.getTerm(), request.getCommitIndex());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        logger.error(<span class="string">&quot;[HandleDoWrite] writeIndex=&#123;&#125;&quot;</span>, writeIndex, t);</span><br><span class="line">        future.complete(buildResponse(request, DLedgerResponseCode.INCONSISTENT_STATE.getCode()));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其实现也比较简单，调用DLedgerStore 的 appendAsFollower 方法进行日志的追加，与appendAsLeader 在日志存储部分相同，只是从节点无需再转发日志。</p>
<h4 id="3-3-5-checkAbnormalFuture"><a href="#3-3-5-checkAbnormalFuture" class="headerlink" title="3.3.5 checkAbnormalFuture"></a>3.3.5 checkAbnormalFuture</h4><p>该方法是本节的重点，doWork 的从服务器存储的最大有效日志序号(ledgerEndIndex) + 1 序号，尝试从待写请求中获取不到对应的请求时调用，这种情况也很常见，例如主节点并么有将最新的数据 PUSH 给从节点。接下来我们详细来看看该方法的实现细节。<br>EntryHandler#checkAbnormalFuture</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (DLedgerUtils.elapsed(lastCheckFastForwardTimeMs) &lt; <span class="number">1000</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line">lastCheckFastForwardTimeMs  = System.currentTimeMillis();</span><br><span class="line"><span class="keyword">if</span> (writeRequestMap.isEmpty()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step1：如果上一次检查的时间距现在不到1s，则跳出；如果当前没有积压的append请求，同样跳出，因为可以同样明确的判断出主节点还未推送日志。</p>
<p>EntryHandler#checkAbnormalFuture</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (Pair&lt;PushEntryRequest, CompletableFuture&lt;PushEntryResponse&gt;&gt; pair : writeRequestMap.values()) &#123;</span><br><span class="line">    <span class="keyword">long</span> index = pair.getKey().getEntry().getIndex();             <span class="comment">// @1</span></span><br><span class="line">    <span class="comment">//Fall behind</span></span><br><span class="line">    <span class="keyword">if</span> (index &lt;= endIndex) &#123;                                                   <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            DLedgerEntry local = dLedgerStore.get(index);</span><br><span class="line">            PreConditions.check(pair.getKey().getEntry().equals(local), DLedgerResponseCode.INCONSISTENT_STATE);</span><br><span class="line">            pair.getValue().complete(buildResponse(pair.getKey(), DLedgerResponseCode.SUCCESS.getCode()));</span><br><span class="line">            logger.warn(<span class="string">&quot;[PushFallBehind]The leader pushed an entry index=&#123;&#125; smaller than current ledgerEndIndex=&#123;&#125;, maybe the last ack is missed&quot;</span>, index, endIndex);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">            logger.error(<span class="string">&quot;[PushFallBehind]The leader pushed an entry index=&#123;&#125; smaller than current ledgerEndIndex=&#123;&#125;, maybe the last ack is missed&quot;</span>, index, endIndex, t);</span><br><span class="line">            pair.getValue().complete(buildResponse(pair.getKey(), DLedgerResponseCode.INCONSISTENT_STATE.getCode()));</span><br><span class="line">        &#125;</span><br><span class="line">        writeRequestMap.remove(index);</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//Just OK</span></span><br><span class="line">    <span class="keyword">if</span> (index ==  endIndex + <span class="number">1</span>) &#123;    <span class="comment">// @3</span></span><br><span class="line">        <span class="comment">//The next entry is coming, just return</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//Fast forward</span></span><br><span class="line">    TimeoutFuture&lt;PushEntryResponse&gt; future  = (TimeoutFuture&lt;PushEntryResponse&gt;) pair.getValue();    <span class="comment">// @4</span></span><br><span class="line">    <span class="keyword">if</span> (!future.isTimeOut()) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (index &lt; minFastForwardIndex) &#123;                                                                                                                <span class="comment">// @5</span></span><br><span class="line">        minFastForwardIndex = index;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：遍历当前待写入的日志追加请求(主服务器推送过来的日志复制请求)，找到需要快速快进的的索引。其关键实现点如下：</p>
<ul>
<li>代码@1：首先获取待写入日志的序号。</li>
<li>代码@2：如果待写入的日志序号小于从节点已追加的日志(endIndex)，并且日志的确已存储在从节点，则返回成功，并输出警告日志【PushFallBehind】，继续监测下一条待写入日志。</li>
<li>代码@3：如果待写入 index 等于 endIndex + 1，则结束循环，因为下一条日志消息已经在待写入队列中，即将写入。</li>
<li>代码@4：如果待写入 index 大于 endIndex + 1，并且未超时，则直接检查下一条待写入日志。</li>
<li>代码@5：如果待写入 index 大于 endIndex + 1，并且已经超时，则记录该索引，使用 minFastForwardIndex 存储。</li>
</ul>
<p>EntryHandler#checkAbnormalFuture</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (minFastForwardIndex == Long.MAX_VALUE) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line">Pair&lt;PushEntryRequest, CompletableFuture&lt;PushEntryResponse&gt;&gt; pair = writeRequestMap.get(minFastForwardIndex);</span><br><span class="line"><span class="keyword">if</span> (pair == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step3：如果未找到需要快速失败的日志序号或 writeRequestMap 中未找到其请求，则直接结束检测。</p>
<p>EntryHandler#checkAbnormalFuture</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">logger.warn(<span class="string">&quot;[PushFastForward] ledgerEndIndex=&#123;&#125; entryIndex=&#123;&#125;&quot;</span>, endIndex, minFastForwardIndex);</span><br><span class="line">pair.getValue().complete(buildResponse(pair.getKey(), DLedgerResponseCode.INCONSISTENT_STATE.getCode()));</span><br></pre></td></tr></table></figure>
<p>Step4：则向主节点报告从节点已经与主节点发生了数据不一致，从节点并没有写入序号 minFastForwardIndex 的日志。如果主节点收到此种响应，将会停止日志转发，转而向各个从节点发送 COMPARE 请求，从而使数据恢复一致。</p>
<p>行为至此，已经详细介绍了主服务器向从服务器发送请求，从服务做出响应，那接下来就来看一下，服务端收到响应结果后的处理，我们要知道主节点会向它所有的从节点传播日志，主节点需要在指定时间内收到超过集群一半节点的确认，才能认为日志写入成功，那我们接下来看一下其实现过程。</p>
<h2 id="4、QuorumAckChecker"><a href="#4、QuorumAckChecker" class="headerlink" title="4、QuorumAckChecker"></a>4、QuorumAckChecker</h2><p>日志复制投票器，一个日志写请求只有得到集群内的的大多数节点的响应，日志才会被提交。</p>
<h3 id="4-1-类图"><a href="#4-1-类图" class="headerlink" title="4.1 类图"></a>4.1 类图</h3><p><img src="https://img-blog.csdnimg.cn/20190914221601709.png" alt="在这里插入图片描述"><br>其核心属性如下：</p>
<ul>
<li>long lastPrintWatermarkTimeMs<br>上次打印水位线的时间戳，单位为毫秒。</li>
<li>long lastCheckLeakTimeMs<br>上次检测泄漏的时间戳，单位为毫秒。</li>
<li>long lastQuorumIndex<br>已投票仲裁的日志序号。</li>
</ul>
<h3 id="4-2-doWork-详解"><a href="#4-2-doWork-详解" class="headerlink" title="4.2 doWork 详解"></a>4.2 doWork 详解</h3><p>QuorumAckChecker#doWork </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (DLedgerUtils.elapsed(lastPrintWatermarkTimeMs) &gt; <span class="number">3000</span>) &#123;    </span><br><span class="line">    logger.info(<span class="string">&quot;[&#123;&#125;][&#123;&#125;] term=&#123;&#125; ledgerBegin=&#123;&#125; ledgerEnd=&#123;&#125; committed=&#123;&#125; watermarks=&#123;&#125;&quot;</span>,</span><br><span class="line">            memberState.getSelfId(), memberState.getRole(), memberState.currTerm(), dLedgerStore.getLedgerBeginIndex(), dLedgerStore.getLedgerEndIndex(), dLedgerStore.getCommittedIndex(), JSON.toJSONString(peerWaterMarksByTerm));</span><br><span class="line">    lastPrintWatermarkTimeMs = System.currentTimeMillis();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step1：如果离上一次打印 watermak 的时间超过3s，则打印一下当前的 term、ledgerBegin、ledgerEnd、committed、peerWaterMarksByTerm 这些数据日志。</p>
<p>QuorumAckChecker#doWork</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!memberState.isLeader()) &#123;   <span class="comment">// @2</span></span><br><span class="line">    waitForRunning(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step2：如果当前节点不是主节点，直接返回，不作为。</p>
<p>QuorumAckChecker#doWork</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (pendingAppendResponsesByTerm.size() &gt; <span class="number">1</span>) &#123;   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">for</span> (Long term : pendingAppendResponsesByTerm.keySet()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (term == currTerm) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;Long, TimeoutFuture&lt;AppendEntryResponse&gt;&gt; futureEntry : pendingAppendResponsesByTerm.get(term).entrySet()) &#123;</span><br><span class="line">            AppendEntryResponse response = <span class="keyword">new</span> AppendEntryResponse();</span><br><span class="line">            response.setGroup(memberState.getGroup());</span><br><span class="line">            response.setIndex(futureEntry.getKey());</span><br><span class="line">            response.setCode(DLedgerResponseCode.TERM_CHANGED.getCode());</span><br><span class="line">            response.setLeaderId(memberState.getLeaderId());</span><br><span class="line">            logger.info(<span class="string">&quot;[TermChange] Will clear the pending response index=&#123;&#125; for term changed from &#123;&#125; to &#123;&#125;&quot;</span>, futureEntry.getKey(), term, currTerm);</span><br><span class="line">            futureEntry.getValue().complete(response);</span><br><span class="line">        &#125;</span><br><span class="line">        pendingAppendResponsesByTerm.remove(term);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (peerWaterMarksByTerm.size() &gt; <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> (Long term : peerWaterMarksByTerm.keySet()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (term == currTerm) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        logger.info(<span class="string">&quot;[TermChange] Will clear the watermarks for term changed from &#123;&#125; to &#123;&#125;&quot;</span>, term, currTerm);</span><br><span class="line">        peerWaterMarksByTerm.remove(term);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step3：清理pendingAppendResponsesByTerm、peerWaterMarksByTerm 中本次投票轮次的数据，避免一些不必要的内存使用。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Map&lt;String, Long&gt; peerWaterMarks = peerWaterMarksByTerm.get(currTerm);</span><br><span class="line"><span class="keyword">long</span> quorumIndex = -<span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span> (Long index : peerWaterMarks.values()) &#123;  <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">int</span> num = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (Long another : peerWaterMarks.values()) &#123;  <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">if</span> (another &gt;= index) &#123;</span><br><span class="line">            num++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (memberState.isQuorum(num) &amp;&amp; index &gt; quorumIndex) &#123;  <span class="comment">// @3</span></span><br><span class="line">        quorumIndex = index;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">dLedgerStore.updateCommittedIndex(currTerm, quorumIndex);  <span class="comment">// @4</span></span><br></pre></td></tr></table></figure>
<p>Step4：根据各个从节点反馈的进度，进行仲裁，确定已提交序号。为了加深对这段代码的理解，再来啰嗦一下 peerWaterMarks 的作用，存储的是各个从节点当前已成功追加的日志序号。例如一个三节点的 DLedger 集群，peerWaterMarks 数据存储大概如下：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">“dledger_group_01_0” : 100,</span><br><span class="line">&quot;dledger_group_01_1&quot; : 101,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中 dledger_group_01_0 为从节点1的ID，当前已复制的序号为 100，而 dledger_group_01_1 为节点2的ID，当前已复制的序号为 101。再加上主节点，如何确定可提交序号呢？</p>
<ul>
<li>代码@1：首先遍历 peerWaterMarks 的 value 集合，即上述示例中的 {100, 101}，用临时变量 index 来表示待投票的日志序号，需要集群内超过半数的节点的已复制序号超过该值，则该日志能被确认提交。</li>
<li>代码@2：遍历 peerWaterMarks 中的所有已提交序号，与当前值进行比较，如果节点的已提交序号大于等于待投票的日志序号(index)，num 加一，表示投赞成票。</li>
<li>代码@3：对 index 进行仲裁，如果超过半数 并且 index 大于 quorumIndex，更新 quorumIndex 的值为 index。quorumIndex 经过遍历的，得出当前最大的可提交日志序号。</li>
<li>代码@4：更新 committedIndex 索引，方便 DLedgerStore 定时将 committedIndex 写入 checkpoint 中。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ConcurrentMap&lt;Long, TimeoutFuture&lt;AppendEntryResponse&gt;&gt; responses = pendingAppendResponsesByTerm.get(currTerm);</span><br><span class="line"><span class="keyword">boolean</span> needCheck = <span class="keyword">false</span>;</span><br><span class="line"><span class="keyword">int</span> ackNum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">if</span> (quorumIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> (Long i = quorumIndex; i &gt;= <span class="number">0</span>; i--) &#123;  <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            CompletableFuture&lt;AppendEntryResponse&gt; future = responses.remove(i);   <span class="comment">// @2</span></span><br><span class="line">            <span class="keyword">if</span> (future == <span class="keyword">null</span>) &#123;                                                                                              <span class="comment">// @3</span></span><br><span class="line">                needCheck = lastQuorumIndex != -<span class="number">1</span> &amp;&amp; lastQuorumIndex != quorumIndex &amp;&amp; i != lastQuorumIndex;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!future.isDone()) &#123;                                                                                <span class="comment">// @4</span></span><br><span class="line">                AppendEntryResponse response = <span class="keyword">new</span> AppendEntryResponse();</span><br><span class="line">                response.setGroup(memberState.getGroup());</span><br><span class="line">                response.setTerm(currTerm);</span><br><span class="line">                response.setIndex(i);</span><br><span class="line">                response.setLeaderId(memberState.getSelfId());</span><br><span class="line">                response.setPos(((AppendFuture) future).getPos());</span><br><span class="line">                future.complete(response);</span><br><span class="line">            &#125;</span><br><span class="line">            ackNum++;                                                                                                      <span class="comment">// @5</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">            logger.error(<span class="string">&quot;Error in ack to index=&#123;&#125; term=&#123;&#125;&quot;</span>, i, currTerm, t);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step5：处理 quorumIndex 之前的挂起请求，需要发送响应到客户端,其实现步骤：</p>
<ul>
<li><p>代码@1：从 quorumIndex 开始处理，没处理一条，该序号减一，直到大于0或主动退出，请看后面的退出逻辑。</p>
</li>
<li><p>代码@2：responses 中移除该日志条目的挂起请求。</p>
</li>
<li><p>代码@3：如果未找到挂起请求，说明前面挂起的请求已经全部处理完毕，准备退出，退出之前再 设置 needCheck 的值，其依据如下(三个条件必须同时满足)：</p>
<ul>
<li>最后一次仲裁的日志序号不等于-1</li>
<li>并且最后一次不等于本次新仲裁的日志序号</li>
<li>最后一次仲裁的日志序号不等于最后一次仲裁的日志。正常情况一下，条件一、条件二通常为true，但这一条大概率会返回false。</li>
</ul>
</li>
<li><p>代码@4：向客户端返回结果。</p>
</li>
<li><p>代码@5：ackNum，表示本次确认的数量。</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (ackNum == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">long</span> i = quorumIndex + <span class="number">1</span>; i &lt; Integer.MAX_VALUE; i++) &#123;</span><br><span class="line">        TimeoutFuture&lt;AppendEntryResponse&gt; future = responses.get(i);</span><br><span class="line">        <span class="keyword">if</span> (future == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (future.isTimeOut()) &#123;</span><br><span class="line">            AppendEntryResponse response = <span class="keyword">new</span> AppendEntryResponse();</span><br><span class="line">            response.setGroup(memberState.getGroup());</span><br><span class="line">            response.setCode(DLedgerResponseCode.WAIT_QUORUM_ACK_TIMEOUT.getCode());</span><br><span class="line">            response.setTerm(currTerm);</span><br><span class="line">            response.setIndex(i);</span><br><span class="line">            response.setLeaderId(memberState.getSelfId());</span><br><span class="line">            future.complete(response);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    waitForRunning(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step6：如果本次确认的个数为0，则尝试去判断超过该仲裁序号的请求，是否已经超时，如果已超时，则返回超时响应结果。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (DLedgerUtils.elapsed(lastCheckLeakTimeMs) &gt; <span class="number">1000</span> || needCheck) &#123;</span><br><span class="line">    updatePeerWaterMark(currTerm, memberState.getSelfId(), dLedgerStore.getLedgerEndIndex());</span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;Long, TimeoutFuture&lt;AppendEntryResponse&gt;&gt; futureEntry : responses.entrySet()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (futureEntry.getKey() &lt; quorumIndex) &#123;</span><br><span class="line">            AppendEntryResponse response = <span class="keyword">new</span> AppendEntryResponse();</span><br><span class="line">            response.setGroup(memberState.getGroup());</span><br><span class="line">            response.setTerm(currTerm);</span><br><span class="line">            response.setIndex(futureEntry.getKey());</span><br><span class="line">            response.setLeaderId(memberState.getSelfId());</span><br><span class="line">            response.setPos(((AppendFuture) futureEntry.getValue()).getPos());</span><br><span class="line">            futureEntry.getValue().complete(response);</span><br><span class="line">            responses.remove(futureEntry.getKey());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    lastCheckLeakTimeMs = System.currentTimeMillis();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Step7：检查是否发送泄漏。其判断泄漏的依据是如果挂起的请求的日志序号小于已提交的序号，则移除。</p>
<p>Step8：一次日志仲裁就结束了，最后更新 lastQuorumIndex 为本次仲裁的的新的提交值。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>rocketmq</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
        <tag>多副本</tag>
        <tag>主从切换</tag>
        <tag>DLedger</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分析Kafka 消息拉取流程</title>
    <url>/posts/497923c7.html</url>
    <content><![CDATA[<div id="vip-container"><h2 id="１、KafkaConsumer-poll-详解"><a href="#１、KafkaConsumer-poll-详解" class="headerlink" title="１、KafkaConsumer poll 详解"></a>１、KafkaConsumer poll 详解</h2><p>消息拉起主要入口为：KafkaConsumer#poll方法，其声明如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ConsumerRecords&lt;K, V&gt; <span class="title">poll</span><span class="params">(<span class="keyword">final</span> Duration timeout)</span> </span>&#123;  <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">return</span> poll(time.timer(timeout), <span class="keyword">true</span>);                                     <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码＠１：参数为超时时间，使用 java 的 Duration 来定义。<br>代码＠２：调用内部的 poll 方法。</p>
<p>KafkaConsumer#poll</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> ConsumerRecords&lt;K, V&gt; <span class="title">poll</span><span class="params">(<span class="keyword">final</span> Timer timer, <span class="keyword">final</span> <span class="keyword">boolean</span> includeMetadataInTimeout)</span> </span>&#123;  <span class="comment">// @1</span></span><br><span class="line">    acquireAndEnsureOpen();                                                                                                               <span class="comment">// @2</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.subscriptions.hasNoSubscriptionOrUserAssignment()) &#123;                                                  <span class="comment">// @3</span></span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">&quot;Consumer is not subscribed to any topics or assigned any partitions&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// poll for new data until the timeout expires</span></span><br><span class="line">        <span class="keyword">do</span> &#123;　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　<span class="comment">// @4</span></span><br><span class="line">            client.maybeTriggerWakeup();                                                                                               <span class="comment">//@5</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (includeMetadataInTimeout) &#123;                       　　　　　　　　　　　　　　　　　　　 <span class="comment">// @6 　　　　　　　　　　　　　　　　　　　　                                                          </span></span><br><span class="line">                <span class="keyword">if</span> (!updateAssignmentMetadataIfNeeded(timer)) &#123;</span><br><span class="line">                    <span class="keyword">return</span> ConsumerRecords.empty();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">while</span> (!updateAssignmentMetadataIfNeeded(time.timer(Long.MAX_VALUE))) &#123;        </span><br><span class="line">                    log.warn(<span class="string">&quot;Still waiting for metadata&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">final</span> Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = pollForFetches(timer);   <span class="comment">// @7</span></span><br><span class="line">            <span class="keyword">if</span> (!records.isEmpty()) &#123;                                                                                                           </span><br><span class="line">                <span class="keyword">if</span> (fetcher.sendFetches() &gt; <span class="number">0</span> || client.hasPendingRequests()) &#123;                                           <span class="comment">// @8</span></span><br><span class="line">                    client.pollNoWakeup();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">this</span>.interceptors.onConsume(<span class="keyword">new</span> ConsumerRecords&lt;&gt;(records));                         <span class="comment">// @９</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">while</span> (timer.notExpired());                                                                                                         </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> ConsumerRecords.empty();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        release();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码＠１：首先先对其参数含义进行讲解。</p>
<ul>
<li>boolean includeMetadataInTimeout<br>拉取消息的超时时间是否包含更新元数据的时间，默认为true，即包含。</li>
</ul>
<p>代码＠２：检查是否可以拉取消息，其主要判断依据如下：</p>
<ul>
<li>KafkaConsumer 是否有其他线程再执行，如果有，则抛出异常，因为 - KafkaConsumer 是线程不安全的，同一时间只能一个线程执行。</li>
<li>KafkaConsumer 没有被关闭。</li>
</ul>
<p>代码＠３：如果当前消费者未订阅任何主题或者没有指定队列，则抛出错误，结束本次消息拉取。</p>
<p>代码＠４：使用 do while 结构循环拉取消息，直到超时或拉取到消息。</p>
<p>代码＠５：避免在禁止禁用wakeup时，有请求想唤醒时则抛出异常，例如在下面的@8时，会禁用wakeup。</p>
<p>代码＠６：更新相关元数据，为真正向 broker 发送消息拉取请求做好准备，该方法将在下面详细介绍，现在先简单介绍其核心实现点：</p>
<ul>
<li>如有必要，先向 broker 端拉取最新的订阅信息(包含消费组内的在线的消费客户端)。</li>
<li>执行已完成(异步提交)的 offset 提交请求的回调函数。</li>
<li>维护与 broker 端的心跳请求，确保不会被“踢出”消费组。</li>
<li>更新元信息。</li>
<li>如果是自动提交消费偏移量，则自动提交偏移量。</li>
<li>更新各个分区下次待拉取的偏移量。</li>
</ul>
<p>这里会有一个更新元数据是否占用消息拉取的超时时间，默认为 true。</p>
<p>代码＠７：调用 pollForFetches 向broker拉取消息，该方法将在下文详细介绍。</p>
<p>代码＠８：如果拉取到的消息集合不为空，再返回该批消息之前，如果还有挤压的拉取请求，可以继续发送拉取请求，但此时会禁用warkup，主要的目的是用户在处理消息时，KafkaConsumer 还可以继续向broker 拉取消息。</p>
<p>代码＠９：执行消费拦截器。</p>
<p>接下来对上文提到的代码＠６、＠７进行详细介绍。</p>
<a id="more"></a>

<h4 id="1-1-KafkaConsumer-updateAssignmentMetadataIfNeeded-详解"><a href="#1-1-KafkaConsumer-updateAssignmentMetadataIfNeeded-详解" class="headerlink" title="1.1 KafkaConsumer updateAssignmentMetadataIfNeeded 详解"></a>1.1 KafkaConsumer updateAssignmentMetadataIfNeeded 详解</h4><p>KafkaConsumer＃updateAssignmentMetadataIfNeeded</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">updateAssignmentMetadataIfNeeded</span><span class="params">(<span class="keyword">final</span> Timer timer)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (coordinator != <span class="keyword">null</span> &amp;&amp; !coordinator.poll(timer)) &#123;                            <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> updateFetchPositions(timer);                                                  <span class="comment">// @2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>要理解这个方法实现的用途，我们就必须依次对 coordinator.poll 方法与 updateFetchPositions 方法。</p>
<h5 id="1-1-1-ConsumerCoordinator-poll"><a href="#1-1-1-ConsumerCoordinator-poll" class="headerlink" title="1.1.1 ConsumerCoordinator#poll"></a>1.1.1 ConsumerCoordinator#poll</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">poll</span><span class="params">(Timer timer)</span> </span>&#123;</span><br><span class="line">    invokeCompletedOffsetCommitCallbacks();  <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">if</span> (subscriptions.partitionsAutoAssigned()) &#123;  <span class="comment">// @2</span></span><br><span class="line">        pollHeartbeat(timer.currentTimeMs());       <span class="comment">// @21</span></span><br><span class="line">        <span class="keyword">if</span> (coordinatorUnknown() &amp;&amp; !ensureCoordinatorReady(timer)) &#123;   <span class="comment">//@22</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (rejoinNeededOrPending()) &#123;                                                       <span class="comment">// @23</span></span><br><span class="line">            <span class="keyword">if</span> (subscriptions.hasPatternSubscription()) &#123;                              <span class="comment">// @231</span></span><br><span class="line">                <span class="keyword">if</span> (<span class="keyword">this</span>.metadata.timeToAllowUpdate(time.milliseconds()) == <span class="number">0</span>) &#123;  </span><br><span class="line">                    <span class="keyword">this</span>.metadata.requestUpdate();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (!client.ensureFreshMetadata(timer)) &#123;                                  </span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (!ensureActiveGroup(timer)) &#123;                                                <span class="comment">// @232</span></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;                                                            <span class="comment">// @3</span></span><br><span class="line">        <span class="keyword">if</span> (metadata.updateRequested() &amp;&amp; !client.hasReadyNodes(timer.currentTimeMs())) &#123;</span><br><span class="line">            client.awaitMetadataUpdate(timer);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    maybeAutoCommitOffsetsAsync(timer.currentTimeMs());   <span class="comment">// @4</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码＠1：执行已完成的 offset (消费进度)提交请求的回调函数。</p>
<p>代码@2：队列负载算法为自动分配（即 Kafka 根据消费者个数与分区书动态负载分区）的相关的处理逻辑。其实现关键点如下：</p>
<ul>
<li>代码@21：更新发送心跳相关的时间，例如heartbeatTimer、sessionTimer、pollTimer 分别代表发送最新发送心跳的时间、会话最新活跃时间、最新拉取消息。</li>
<li>代码@22：如果不存在协调器或协调器已断开连接，则返回 false，结束本次拉取。如果协调器就绪，则继续往下走。</li>
<li>代码@23：判断是否需要触发重平衡，即消费组内的所有消费者重新分配topic中的分区信息，例如元数据发送变化，判断是否需要重新重平衡的关键点如下：<ul>
<li>如果队列负载是通过用户指定的，则返回 false，表示无需重平衡。</li>
<li>如果队列是自动负载，topic 队列元数据发生了变化，则需要重平衡。</li>
<li>如果队列是自动负载，订阅关系发生了变化，则需要重平衡。<br>如果需要重重平衡，则同步更新元数据，此过程会阻塞。详细的重平衡将单独重点介绍，这里暂时不深入展开。</li>
</ul>
</li>
</ul>
<p>代码@3：用户手动为消费组指定负载的队列的相关处理逻辑，其实现关键如下：</p>
<ul>
<li>如果需要更新元数据，并且还没有分区准备好，则同步阻塞等待元数据更新完毕。</li>
</ul>
<p>代码@4：如果开启了自动提交消费进度，并且已到下一次提交时间，则提交。Kafka 消费者可以通过设置属性 enable.auto.commit 来开启自动提交，该参数默认为 true，则默认会每隔 5s 提交一次消费进度，提交间隔可以通过参数 auto.commit.interval.ms 设置。</p>
<p>接下来继续探讨 updateAssignmentMetadataIfNeeded (更新元数据)的第二个步骤，更新拉取位移。</p>
<h5 id="1-1-2-updateFetchPositions-详解"><a href="#1-1-2-updateFetchPositions-详解" class="headerlink" title="1.1.2 updateFetchPositions 详解"></a>1.1.2 updateFetchPositions 详解</h5><p>KafkaConsumer#updateFetchPositions</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">updateFetchPositions</span><span class="params">(<span class="keyword">final</span> Timer timer)</span> </span>&#123;</span><br><span class="line">    cachedSubscriptionHashAllFetchPositions = subscriptions.hasAllFetchPositions();  </span><br><span class="line">    <span class="keyword">if</span> (cachedSubscriptionHashAllFetchPositions) &#123;           <span class="comment">// @1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (coordinator != <span class="keyword">null</span> &amp;&amp; !coordinator.refreshCommittedOffsetsIfNeeded(timer))   <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    subscriptions.resetMissingPositions();                         <span class="comment">// @3</span></span><br><span class="line">    fetcher.resetOffsetsIfNeeded();                                    <span class="comment">// @4</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：如果订阅关系中的所有分区都有有效的位移，则返回 true。</p>
<p>代码@2：如果存在任意一个分区没有有效的位移信息，则需要向 broker 发送请求，从broker 获取该消费组，该分区的消费进度。相关的实现细节将在后续文章【Kafka 消费进度】专题文章中详细介绍。</p>
<p>代码@3：如果经过第二步，订阅关系中还某些分区还是没有获取到有效的偏移量，则使用偏移量重置策略进行重置，如果未配置，则抛出异常。</p>
<p>代码@4：发送一个异步请求去重置那些正等待重置位置的分区。有关 Kafka 消费消费进度、重平衡等知识将会在后续文章中深入探讨，本文只需了解 poll 消息的核心处理流程。</p>
<p>从 KafkaConsumer#poll 中流程可以看到，通过 updateAssignmentMetadataIfNeeded 对元数据、重平衡，更新拉取偏移量等工作处理完成后，下一步就是需要向 broker 拉取消息了，其实现入口为：KafkaConsumer 的 pollForFetches 方法。</p>
<h4 id="1-2-消息拉取"><a href="#1-2-消息拉取" class="headerlink" title="1.2 消息拉取"></a>1.2 消息拉取</h4><p>KafkaConsumer#pollForFetches</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; pollForFetches(Timer timer) &#123;</span><br><span class="line">        <span class="keyword">long</span> pollTimeout = coordinator == <span class="keyword">null</span> ? timer.remainingMs() :</span><br><span class="line">                Math.min(coordinator.timeToNextPoll(timer.currentTimeMs()), timer.remainingMs());   <span class="comment">// @1</span></span><br><span class="line">        <span class="comment">// if data is available already, return it immediately</span></span><br><span class="line">        <span class="keyword">final</span> Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = fetcher.fetchedRecords();    <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">if</span> (!records.isEmpty()) &#123;</span><br><span class="line">            <span class="keyword">return</span> records;</span><br><span class="line">        &#125;</span><br><span class="line">        fetcher.sendFetches();                               <span class="comment">// @3</span></span><br><span class="line">        <span class="comment">// We do not want to be stuck blocking in poll if we are missing some positions</span></span><br><span class="line">        <span class="comment">// since the offset lookup may be backing off after a failure</span></span><br><span class="line">        <span class="comment">// <span class="doctag">NOTE:</span> the use of cachedSubscriptionHashAllFetchPositions means we MUST call</span></span><br><span class="line">        <span class="comment">// updateAssignmentMetadataIfNeeded before this method.</span></span><br><span class="line">        <span class="keyword">if</span> (!cachedSubscriptionHashAllFetchPositions &amp;&amp; pollTimeout &gt; retryBackoffMs) &#123;   <span class="comment">// @4</span></span><br><span class="line">            pollTimeout = retryBackoffMs;</span><br><span class="line">        &#125;</span><br><span class="line">        Timer pollTimer = time.timer(pollTimeout);</span><br><span class="line">        client.poll(pollTimer, () -&gt; &#123;</span><br><span class="line">            <span class="keyword">return</span> !fetcher.hasCompletedFetches();</span><br><span class="line">        &#125;);         <span class="comment">// @5</span></span><br><span class="line">        timer.update(pollTimer.currentTimeMs());   <span class="comment">// @6</span></span><br><span class="line">        <span class="keyword">if</span> (coordinator != <span class="keyword">null</span> &amp;&amp; coordinator.rejoinNeededOrPending()) &#123;  <span class="comment">// @7</span></span><br><span class="line">            <span class="keyword">return</span> Collections.emptyMap();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> fetcher.fetchedRecords();   <span class="comment">// @8</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：计算本次拉取的超时时间，其计算逻辑如下：</p>
<ul>
<li>如果协调器为空，则返回当前定时器剩余时间即可。</li>
<li>如果协调器不为空，其逻辑较为复杂，为下面返回的超时间与当前定时器剩余时间相比取最小值。</li>
<li>如果不开启自动提交位移并且未加入消费组，则超时时间为Long.MAX_VALUE。</li>
<li>如果不开启自动提交位移并且已加入消费组，则返回距离下一次发送心跳包还剩多少时间。</li>
<li>如果开启自动提交位移，则返回 距离下一次自动提交位移所需时间 与 距离下一次发送心跳包所需时间 之间的最小值。</li>
</ul>
<p>代码@2：如果数据已经拉回到本地，直接返回数据。将在下文详细介绍 Fetcher 的 fetchedRecords 方法。</p>
<p>代码@3:组装发送请求，并将存储在待发送请求列表中。</p>
<p>代码@4：如果已缓存的分区信息中存在某些分区缺少偏移量，如果拉取的超时时间大于失败重试需要阻塞的时间，则更新此次拉取的超时时间为失败重试需要的间隔时间，主要的目的是不希望在 poll 过程中被阻塞【后续会详细介绍 Kafka 拉取消息的线程模型，再来回顾一下这里】。</p>
<p>代码@5：通过调用NetworkClient 的 poll 方法发起消息拉取操作（触发网络读写）。</p>
<p>代码@6：更新本次拉取的时间。</p>
<p>代码@7：检查是需要重平衡。</p>
<p>代码@8：将从 broker 读取到的数据返回（即封装成消息）。</p>
<p>从上面消息拉取流程来看，有几个比较重要的方法，例如 Fetcher 类相关的方法，NetworkClient 的 poll 方法，那我们接下来来重点探讨。</p>
<p>我们先用一张流程图总结一下消息拉取的全过程：<br><img src="https://img-blog.csdnimg.cn/20191208193241248.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>接下来我们将重点看一下 KafkaConsumer 的 pollForFetches 详细过程，也就是需要详细探究 Fetcher 类的实现细节。</p>
<h2 id="2、Fetcher-类详解"><a href="#2、Fetcher-类详解" class="headerlink" title="2、Fetcher 类详解"></a>2、Fetcher 类详解</h2><p>Fetcher 封装消息拉取的方法，可以看成是消息拉取的门面类。</p>
<h4 id="2-1-类图"><a href="#2-1-类图" class="headerlink" title="2.1 类图"></a>2.1 类图</h4><p><img src="https://img-blog.csdnimg.cn/20191208193319781.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们首先一一介绍一下 Fetcher 的核心属性与核心方法。</p>
<ul>
<li>ConsumerNetworkClient client<br>消费端网络客户端，Kafka 负责网络通讯实现类。</li>
<li>int minBytes<br>一次消息拉取需要拉取的最小字节数，如果不组，会阻塞，默认值为1字节，如果增大这个值会增大吞吐，但会增加延迟，可以通参数 fetch.min.bytes 改变其默认值。</li>
<li>int maxBytes<br>一次消息拉取允许拉取的最大字节数，但这不是绝对的，如果一个分区的第一批记录超过了该值，也会返回。默认为50M,可通过参数 fetch.max.bytes 改变其默认值。同时不能超过 broker的配置参数(message.max.bytes) 和 主题级别的配置(max.message.bytes)。</li>
<li>int maxWaitMs<br>在 broker 如果符合拉取条件的数据小于 minBytes 时阻塞的时间，默认为 500ms ，可通属性 fetch.max.wait.ms 进行定制。</li>
<li>int fetchSize<br>每一个分区返回的最大消息字节数，如果分区中的第一批消息大于 fetchSize 也会返回。</li>
<li>long retryBackoffMs<br>失败重试后需要阻塞的时间，默认为 100 ms，可通过参数 retry.backoff.ms 定制。</li>
<li>long requestTimeoutMs<br>客户端向 broker 发送请求最大的超时时间，默认为 30s，可以通过 request.timeout.ms 参数定制。</li>
<li>int maxPollRecords<br>单次拉取返回的最大记录数，默认值 500，可通过参数 max.poll.records 进行定制。</li>
<li>boolean checkCrcs<br>是否检查消息的 crcs 校验和，默认为 true，可通过参数 check.crcs 进行定制。</li>
<li>Metadata metadata<br>元数据。</li>
<li>FetchManagerMetrics sensors<br>消息拉取的统计服务类。</li>
<li>SubscriptionState subscriptions<br>订阅信息状态。</li>
<li>ConcurrentLinkedQueue&lt; CompletedFetch&gt; completedFetches<br>已完成的 Fetch 的请求结果，待消费端从中取出数据。</li>
<li>Deserializer&lt; K&gt; keyDeserializer<br>key 的反序列化器。</li>
<li>Deserializer&lt; V&gt; valueDeserializer<br>value 的饭序列化器。</li>
<li>IsolationLevel isolationLevel<br>Kafka的隔离级别（与事务消息相关），后续在研究其事务相关时再进行探讨。</li>
<li>Map&lt;Integer, FetchSessionHandler&gt; sessionHandlers<br>拉取会话监听器。</li>
</ul>
<p>接下来我们将按照消息流程，一起来看一下 Fetcher 的核心方法。</p>
<h4 id="2-2-Fetcher-核心方法"><a href="#2-2-Fetcher-核心方法" class="headerlink" title="2.2 Fetcher 核心方法"></a>2.2 Fetcher 核心方法</h4><h5 id="2-2-1-Fetcher-fetchedRecords"><a href="#2-2-1-Fetcher-fetchedRecords" class="headerlink" title="2.2.1 Fetcher#fetchedRecords"></a>2.2.1 Fetcher#fetchedRecords</h5><p>Fetcher#fetchedRecords</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; fetchedRecords() &#123;</span><br><span class="line">    Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; fetched = <span class="keyword">new</span> HashMap&lt;&gt;();   <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">int</span> recordsRemaining = maxPollRecords;                                                              </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">while</span> (recordsRemaining &gt; <span class="number">0</span>) &#123;                                                                                  <span class="comment">// @2</span></span><br><span class="line">            <span class="keyword">if</span> (nextInLineRecords == <span class="keyword">null</span> || nextInLineRecords.isFetched) &#123;                           <span class="comment">// @3</span></span><br><span class="line">                CompletedFetch completedFetch = completedFetches.peek();</span><br><span class="line">                <span class="keyword">if</span> (completedFetch == <span class="keyword">null</span>) <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    nextInLineRecords = parseCompletedFetch(completedFetch);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                    FetchResponse.PartitionData partition = completedFetch.partitionData;</span><br><span class="line">                    <span class="keyword">if</span> (fetched.isEmpty() &amp;&amp; (partition.records == <span class="keyword">null</span> || partition.records.sizeInBytes() == <span class="number">0</span>)) &#123;</span><br><span class="line">                        completedFetches.poll();</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">throw</span> e;</span><br><span class="line">                &#125;</span><br><span class="line">                completedFetches.poll();</span><br><span class="line">             &#125; <span class="keyword">else</span> &#123;                                                                                                                         <span class="comment">// @4</span></span><br><span class="line">                List&lt;ConsumerRecord&lt;K, V&gt;&gt; records = fetchRecords(nextInLineRecords, recordsRemaining);</span><br><span class="line">                TopicPartition partition = nextInLineRecords.partition;</span><br><span class="line">                <span class="keyword">if</span> (!records.isEmpty()) &#123;</span><br><span class="line">                    List&lt;ConsumerRecord&lt;K, V&gt;&gt; currentRecords = fetched.get(partition);</span><br><span class="line">                    <span class="keyword">if</span> (currentRecords == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        fetched.put(partition, records);</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        List&lt;ConsumerRecord&lt;K, V&gt;&gt; newRecords = <span class="keyword">new</span> ArrayList&lt;&gt;(records.size() + currentRecords.size());</span><br><span class="line">                        newRecords.addAll(currentRecords);</span><br><span class="line">                        newRecords.addAll(records);</span><br><span class="line">                        fetched.put(partition, newRecords);</span><br><span class="line">                    &#125;</span><br><span class="line">                    recordsRemaining -= records.size();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">        <span class="keyword">if</span> (fetched.isEmpty())</span><br><span class="line">            <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> fetched;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先先解释两个局部变量的含义：</p>
<ul>
<li>Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; fetched 按分区存放已拉取的消息，返回给客户端进行处理。</li>
<li>recordsRemaining：剩余可拉取的消息条数。</li>
</ul>
<p>代码@2：循环去取已经完成了 Fetch 请求的消息，该 while 循环有两个跳出条件：</p>
<ul>
<li>如果拉取的消息已经达到一次拉取的最大消息条数，则跳出循环。</li>
<li>缓存中所有拉取结果已处理。</li>
</ul>
<p>代码@3、@4 主要完成从缓存中解析数据的两个步骤，初次运行的时候，会进入分支@3，然后从 调用 parseCompletedFetch 解析成 PartitionRecords 对象，然后代码@4的职责就是从解析 PartitionRecords ，将消息封装成 ConsumerRecord，返回给消费端线程处理。</p>
<p>代码@3的实现要点如下：</p>
<ul>
<li>首先从 completedFetches (Fetch请求的返回结果) 列表中获取一个 Fetcher 请求，主要使用的 Queue 的 peek()方法，并不会从该队列中移除该元素。</li>
<li>然后调用 parseCompletedFetch 对处理结果进行解析返回 PartitionRecords。</li>
<li>处理成功后，调用 Queue 的方法将已处理过的 Fetcher结果移除。</li>
</ul>
<p>从上面可知，上述方法的核心方法是：parseCompletedFetch。</p>
<p>代码@4的实现要点无非就是调用 fetchRecords 方法，按分区组装成 Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt;，供消费者处理，例如供业务处理。</p>
<p>接下来将重点探讨上述两个方法的实现细节。</p>
<h6 id="2-2-1-1-Fetcher-parseCompletedFetch"><a href="#2-2-1-1-Fetcher-parseCompletedFetch" class="headerlink" title="2.2.1.1 Fetcher#parseCompletedFetch"></a>2.2.1.1 Fetcher#parseCompletedFetch</h6><p>在尝试探讨该方法之前，我们首先对其入参进行一个梳理，特别是先认识其主要数据结构。</p>
<p>1、CompletedFetch 相关类图<br><img src="https://img-blog.csdnimg.cn/2019120819365575.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>从上图可以看出，CompleteFetch 核心属性主要如下：</p>
<ul>
<li>TopicPartition partition<br>分区信息，返回结果都是以分区为纬度。</li>
<li>long fetchedOffset<br>本次拉取的开始偏移量。</li>
<li>FetchResponse.PartitionData partitionData<br>返回的分区数据。</li>
<li>FetchResponseMetricAgregator metricAggregator<br>统计指标相关。</li>
<li>short responseVersion<br>broker 端的版本号。</li>
</ul>
<p>分区的数据是使用 PartitionData 来进行封装的。我们也来简单的了解一下其内部数据结果。</p>
<ul>
<li>Errors error<br>分区拉取的相应结果，Errors.NONE 表示请求成功。</li>
<li>long highWatermark<br>broker 端关于该分区的高水位线，即小于该偏移量的消息对于消费端是可见的。</li>
<li>long lastStableOffset<br>分区中小于该偏移量的消息的事务状态已得到确认，要么是已提交，要么是已回滚，与事务相关，后面会专门探讨。</li>
<li>List&lt; AbortedTransaction&gt; abortedTransactions<br>已拒绝的事物。</li>
<li>T records<br>分区数据，是 BaseRecords 的子类。</li>
</ul>
<p>2、parseCompletedFetch 详解</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> PartitionRecords <span class="title">parseCompletedFetch</span><span class="params">(CompletedFetch completedFetch)</span> </span>&#123;</span><br><span class="line">    TopicPartition tp = completedFetch.partition;</span><br><span class="line">    FetchResponse.PartitionData&lt;Records&gt; partition = completedFetch.partitionData;</span><br><span class="line">    <span class="keyword">long</span> fetchOffset = completedFetch.fetchedOffset;</span><br><span class="line">    PartitionRecords partitionRecords = <span class="keyword">null</span>;</span><br><span class="line">    Errors error = partition.error;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (!subscriptions.isFetchable(tp)) &#123;       <span class="comment">// @1</span></span><br><span class="line">            log.debug(<span class="string">&quot;Ignoring fetched records for partition &#123;&#125; since it is no longer fetchable&quot;</span>, tp);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.NONE) &#123;         <span class="comment">// @2</span></span><br><span class="line">            Long position = subscriptions.position(tp);</span><br><span class="line">            <span class="keyword">if</span> (position == <span class="keyword">null</span> || position != fetchOffset) &#123;    <span class="comment">// @21</span></span><br><span class="line">                log.debug(<span class="string">&quot;Discarding stale fetch response for partition &#123;&#125; since its offset &#123;&#125; does not match &quot;</span> +</span><br><span class="line">                            <span class="string">&quot;the expected offset &#123;&#125;&quot;</span>, tp, fetchOffset, position);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            log.trace(<span class="string">&quot;Preparing to read &#123;&#125; bytes of data for partition &#123;&#125; with offset &#123;&#125;&quot;</span>,</span><br><span class="line">                        partition.records.sizeInBytes(), tp, position);</span><br><span class="line">            Iterator&lt;? extends RecordBatch&gt; batches = partition.records.batches().iterator();   <span class="comment">// @22</span></span><br><span class="line">            partitionRecords = <span class="keyword">new</span> PartitionRecords(tp, completedFetch, batches);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (!batches.hasNext() &amp;&amp; partition.records.sizeInBytes() &gt; <span class="number">0</span>) &#123;   <span class="comment">// @23</span></span><br><span class="line">                <span class="keyword">if</span> (completedFetch.responseVersion &lt; <span class="number">3</span>) &#123;</span><br><span class="line">                    Map&lt;TopicPartition, Long&gt; recordTooLargePartitions = Collections.singletonMap(tp, fetchOffset);</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> RecordTooLargeException(<span class="string">&quot;There are some messages at [Partition=Offset]: &quot;</span> +</span><br><span class="line">                                recordTooLargePartitions + <span class="string">&quot; whose size is larger than the fetch size &quot;</span> + <span class="keyword">this</span>.fetchSize +</span><br><span class="line">                                <span class="string">&quot; and hence cannot be returned. Please considering upgrading your broker to 0.10.1.0 or &quot;</span> +</span><br><span class="line">                                <span class="string">&quot;newer to avoid this issue. Alternately, increase the fetch size on the client (using &quot;</span> +</span><br><span class="line">                                ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG + <span class="string">&quot;)&quot;</span>,</span><br><span class="line">                                recordTooLargePartitions);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// This should not happen with brokers that support FetchRequest/Response V3 or higher (i.e. KIP-74)</span></span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> KafkaException(<span class="string">&quot;Failed to make progress reading messages at &quot;</span> + tp + <span class="string">&quot;=&quot;</span> +</span><br><span class="line">                            fetchOffset + <span class="string">&quot;. Received a non-empty fetch response from the server, but no &quot;</span> +</span><br><span class="line">                            <span class="string">&quot;complete records were found.&quot;</span>);</span><br><span class="line">               &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (partition.highWatermark &gt;= <span class="number">0</span>) &#123;   <span class="comment">// @24</span></span><br><span class="line">                log.trace(<span class="string">&quot;Updating high watermark for partition &#123;&#125; to &#123;&#125;&quot;</span>, tp, partition.highWatermark);</span><br><span class="line">                subscriptions.updateHighWatermark(tp, partition.highWatermark);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (partition.logStartOffset &gt;= <span class="number">0</span>) &#123;    <span class="comment">// @25</span></span><br><span class="line">                log.trace(<span class="string">&quot;Updating log start offset for partition &#123;&#125; to &#123;&#125;&quot;</span>, tp, partition.logStartOffset);</span><br><span class="line">                    subscriptions.updateLogStartOffset(tp, partition.logStartOffset);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (partition.lastStableOffset &gt;= <span class="number">0</span>) &#123; <span class="comment">// @26</span></span><br><span class="line">                log.trace(<span class="string">&quot;Updating last stable offset for partition &#123;&#125; to &#123;&#125;&quot;</span>, tp, partition.lastStableOffset);</span><br><span class="line">                    subscriptions.updateLastStableOffset(tp, partition.lastStableOffset);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.NOT_LEADER_FOR_PARTITION ||</span><br><span class="line">                       error == Errors.REPLICA_NOT_AVAILABLE ||</span><br><span class="line">                       error == Errors.KAFKA_STORAGE_ERROR) &#123;                       <span class="comment">// @3</span></span><br><span class="line">                log.debug(<span class="string">&quot;Error in fetch for partition &#123;&#125;: &#123;&#125;&quot;</span>, tp, error.exceptionName());</span><br><span class="line">            <span class="keyword">this</span>.metadata.requestUpdate();</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.UNKNOWN_TOPIC_OR_PARTITION) &#123;          <span class="comment">// @4</span></span><br><span class="line">            log.warn(<span class="string">&quot;Received unknown topic or partition error in fetch for partition &#123;&#125;&quot;</span>, tp);</span><br><span class="line">            <span class="keyword">this</span>.metadata.requestUpdate();</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.OFFSET_OUT_OF_RANGE) &#123;                        <span class="comment">// @5</span></span><br><span class="line">            <span class="keyword">if</span> (fetchOffset != subscriptions.position(tp)) &#123;</span><br><span class="line">                log.debug(<span class="string">&quot;Discarding stale fetch response for partition &#123;&#125; since the fetched offset &#123;&#125; &quot;</span> +</span><br><span class="line">                            <span class="string">&quot;does not match the current offset &#123;&#125;&quot;</span>, tp, fetchOffset, subscriptions.position(tp));</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (subscriptions.hasDefaultOffsetResetPolicy()) &#123;</span><br><span class="line">                log.info(<span class="string">&quot;Fetch offset &#123;&#125; is out of range for partition &#123;&#125;, resetting offset&quot;</span>, fetchOffset, tp);</span><br><span class="line">                    subscriptions.requestOffsetReset(tp);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> OffsetOutOfRangeException(Collections.singletonMap(tp, fetchOffset));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.TOPIC_AUTHORIZATION_FAILED) &#123;             <span class="comment">// @6</span></span><br><span class="line">            log.warn(<span class="string">&quot;Not authorized to read from topic &#123;&#125;.&quot;</span>, tp.topic());</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> TopicAuthorizationException(Collections.singleton(tp.topic()));</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (error == Errors.UNKNOWN_SERVER_ERROR) &#123;                </span><br><span class="line">            log.warn(<span class="string">&quot;Unknown error fetching data for topic-partition &#123;&#125;&quot;</span>, tp);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">&quot;Unexpected error code &quot;</span> + error.code() + <span class="string">&quot; while fetching data&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;   <span class="comment">// @7</span></span><br><span class="line">        <span class="keyword">if</span> (partitionRecords == <span class="keyword">null</span>)</span><br><span class="line">            completedFetch.metricAggregator.record(tp, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (error != Errors.NONE)</span><br><span class="line">           <span class="comment">// we move the partition to the end if there was an error. This way, it&#x27;s more likely that partitions for</span></span><br><span class="line">           <span class="comment">// the same topic can remain together (allowing for more efficient serialization).</span></span><br><span class="line">           subscriptions.movePartitionToEnd(tp);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> partitionRecords;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码虽然比较长，其实整体还是比较简单，只是需要针对各种异常处理，打印对应的日志，接下来详细介绍该方法的实现关键点。</p>
<p>代码@1：判断该分区是否可拉取，如果不可拉取，则忽略这批拉取的消息，判断是可拉取的要点如下：</p>
<ul>
<li>当前消费者负载的队列包含该分区。</li>
<li>当前消费者针对该队列并没有被用户设置为暂停（消费端限流）。</li>
<li>当前消费者针对该队列有有效的拉取偏移量。</li>
</ul>
<p>代码@2：该分支是处理正常返回的相关逻辑。其关键点如下：</p>
<ul>
<li>如果当前针对该队列的消费位移 与 发起 fetch 请求时的 偏移量不一致，则认为本次拉取非法，直接返回 null ，如代码@21。</li>
<li>从返回结构中获取本次拉取的数据，使用数据迭代器，其基本数据单位为 RecordBatch，即一个发送批次，如代码@22。</li>
<li>如果返回结果中没有包含至少一个批次的消息，但是 sizeInBytes 又大于0，则直接抛出错误，根据服务端的版本，其错误信息有所不同，但主要是建议我们如何处理，如果 broker 的版本低于 0.10.1.0，则建议升级 broker 版本，或增大客户端的 fetch size，这种错误是因为一个批次的消息已经超过了本次拉取允许的最大拉取消息大小，如代码@23。</li>
<li>依次更新消费者本地关于该队列的订阅缓存信息的 highWatermark、logStartOffset、lastStableOffset。</li>
</ul>
<p>从代码@3到@8 是多种异常信息的处理。<br>代码@3：如果出现如下3种错误码，则使用 debug 打印错误日志，并且向服务端请求元数据并更新本地缓存。</p>
<ul>
<li>NOT_LEADER_FOR_PARTITION<br>请求的节点上不是该分区的 Leader 分区。</li>
<li>REPLICA_NOT_AVAILABLE<br>该分区副本之间无法复制</li>
<li>KAFKA_STORAGE_ERROR<br>存储异常。</li>
</ul>
<p>Kafka 认为上述错误是可恢复的，而且对消费不会造成太大影响，故只是用 debug 打印日志，然后更新本地缓存即可。</p>
<p>代码@4：如果出现 UNKNOWN_TOPIC_OR_PARTITION 未知主题与分区时，则使用 warn 级别输出错误日志，并更新元数据。</p>
<p>代码@5：针对 OFFSET_OUT_OF_RANGE 偏移量超过范围异常的处理逻辑，其实现关键点如下：</p>
<ul>
<li>如果此次拉取的开始偏移量与消费者本地缓存的偏移量不一致，则丢弃，说明该消息已过期，打印错误日志。</li>
<li>如果此次拉取的开始偏移量与消费者本地缓存的偏移量一致，说明此时的偏移量非法，如果有配置重置偏移量策略，则使用重置偏移量，否则抛出        OffsetOutOfRangeException 错误。</li>
</ul>
<p>代码@6：如果是 TOPIC_AUTHORIZATION_FAILED 没有权限(ACL)则抛出异常。</p>
<p>代码@7：如果本次拉取的结果不是NONE(成功)，并且是可恢复的，将该队列的订阅关系移动到消费者缓存列表的末尾。如果成功，则返回拉取到的分区数据，其封装对象为 PartitionRecords。</p>
<p>接下来我们再来看看 2.1.1 fetchedRecords 中的另外一个核心方法。</p>
<h6 id="2-2-1-2-fetchRecords"><a href="#2-2-1-2-fetchRecords" class="headerlink" title="2.2.1.2 fetchRecords()"></a>2.2.1.2 fetchRecords()</h6><p>在介绍该方法之前同样先来看一下参数 PartitionRecords 的内部结构。</p>
<p>1、PartitionRecords 类图<br><img src="https://img-blog.csdnimg.cn/20191208194302768.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>主要的核心属性如下：</p>
<ul>
<li>TopicPartition partition<br>分区信息。</li>
<li>CompletedFetch completedFetch<br>Fetch请求完成结果</li>
<li>Iterator&lt;? extends RecordBatch&gt; batches<br>本次 Fetch 操作获取的结果集。</li>
<li>Set&lt; Long&gt; abortedProducerIds<br>与事物相关，后续会专门的章节详细介绍。</li>
<li>PriorityQueue&lt;FetchResponse.AbortedTransaction&gt; abortedTransactions<br>与事物相关，后续会专门的章节详细介绍。</li>
<li>int recordsRead<br>已读取的记录条数。</li>
<li>int bytesRead<br>已读取的记录字节数。</li>
<li>RecordBatch currentBatch<br>当前遍历的批次。</li>
<li>Record lastRecord<br>该迭代器最后一条消息。</li>
<li>long nextFetchOffset<br>下次待拉取的偏移量。</li>
</ul>
<p>2、fetchRecords 详解</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> List&lt;ConsumerRecord&lt;K, V&gt;&gt; fetchRecords(PartitionRecords partitionRecords, <span class="keyword">int</span> maxRecords) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!subscriptions.isAssigned(partitionRecords.partition)) &#123;   <span class="comment">// @1</span></span><br><span class="line">            <span class="comment">// this can happen when a rebalance happened before fetched records are returned to the consumer&#x27;s poll call</span></span><br><span class="line">        log.debug(<span class="string">&quot;Not returning fetched records for partition &#123;&#125; since it is no longer assigned&quot;</span>,</span><br><span class="line">                    partitionRecords.partition);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!subscriptions.isFetchable(partitionRecords.partition)) &#123; <span class="comment">// @2</span></span><br><span class="line">        <span class="comment">// this can happen when a partition is paused before fetched records are returned to the consumer&#x27;s</span></span><br><span class="line">        <span class="comment">// poll call or if the offset is being reset</span></span><br><span class="line">        log.debug(<span class="string">&quot;Not returning fetched records for assigned partition &#123;&#125; since it is no longer fetchable&quot;</span>,</span><br><span class="line">                    partitionRecords.partition);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">long</span> position = subscriptions.position(partitionRecords.partition);       <span class="comment">// @3</span></span><br><span class="line">        <span class="keyword">if</span> (partitionRecords.nextFetchOffset == position) &#123;      <span class="comment">// @4</span></span><br><span class="line">            List&lt;ConsumerRecord&lt;K, V&gt;&gt; partRecords = partitionRecords.fetchRecords(maxRecords);</span><br><span class="line">            <span class="keyword">long</span> nextOffset = partitionRecords.nextFetchOffset;</span><br><span class="line">            log.trace(<span class="string">&quot;Returning fetched records at offset &#123;&#125; for assigned partition &#123;&#125; and update &quot;</span> +</span><br><span class="line">                        <span class="string">&quot;position to &#123;&#125;&quot;</span>, position, partitionRecords.partition, nextOffset);</span><br><span class="line">            subscriptions.position(partitionRecords.partition, nextOffset);</span><br><span class="line"></span><br><span class="line">            Long partitionLag = subscriptions.partitionLag(partitionRecords.partition, isolationLevel);  </span><br><span class="line">            <span class="keyword">if</span> (partitionLag != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">this</span>.sensors.recordPartitionLag(partitionRecords.partition, partitionLag);</span><br><span class="line"></span><br><span class="line">            Long lead = subscriptions.partitionLead(partitionRecords.partition);</span><br><span class="line">            <span class="keyword">if</span> (lead != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">this</span>.sensors.recordPartitionLead(partitionRecords.partition, lead);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> partRecords;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;   <span class="comment">// @5</span></span><br><span class="line">            <span class="comment">// these records aren&#x27;t next in line based on the last consumed position, ignore them</span></span><br><span class="line">            <span class="comment">// they must be from an obsolete request</span></span><br><span class="line">            log.debug(<span class="string">&quot;Ignoring fetched records for &#123;&#125; at offset &#123;&#125; since the current position is &#123;&#125;&quot;</span>,</span><br><span class="line">                        partitionRecords.partition, partitionRecords.nextFetchOffset, position);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    partitionRecords.drain();</span><br><span class="line">    <span class="keyword">return</span> emptyList();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：从 PartitionRecords 中提取消息之前，再次判断订阅消息中是否包含当前分区，如果不包含，则使用 debug 打印日志，很有可能是发生了重平衡。</p>
<p>代码@2：是否允许拉取，如果用户主动暂停消费，则忽略本次拉取的消息。备注：Kafka 消费端如果消费太快，可以进行限流。</p>
<p>代码@3：从本地消费者缓存中获取该队列已消费的偏移量，在发送拉取消息时，就是从该偏移量开始拉取的。</p>
<p>代码@4：如果本地缓存已消费偏移量与从服务端拉回的起始偏移量相等的话，则认为是一个有效拉取，否则则认为是一个过期的拉取，该批消息已被消费，见代码@5。如果是一个有效请求，则使用 sensors 收集统计信息，并返回拉取到的消息， 返回结果被封装在 List&lt;ConsumerRecord&lt;K, V&gt;&gt; 。</p>
<h5 id="2-2-2-sendFetches"><a href="#2-2-2-sendFetches" class="headerlink" title="2.2.2 sendFetches"></a>2.2.2 sendFetches</h5><p>“发送” fetch 请求，注意这里并不会触发网络操作，而是组装拉取请求，将其放入网络缓存区。</p>
<p>Fetcher#sendFetches</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">int</span> <span class="title">sendFetches</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Map&lt;Node, FetchSessionHandler.FetchRequestData&gt; fetchRequestMap = prepareFetchRequests();  <span class="comment">// @1</span></span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;Node, FetchSessionHandler.FetchRequestData&gt; entry : fetchRequestMap.entrySet()) &#123;   <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">final</span> Node fetchTarget = entry.getKey();</span><br><span class="line">        <span class="keyword">final</span> FetchSessionHandler.FetchRequestData data = entry.getValue();</span><br><span class="line">        <span class="keyword">final</span> FetchRequest.Builder request = FetchRequest.Builder</span><br><span class="line">            .forConsumer(<span class="keyword">this</span>.maxWaitMs, <span class="keyword">this</span>.minBytes, data.toSend())</span><br><span class="line">            .isolationLevel(isolationLevel)</span><br><span class="line">            .setMaxBytes(<span class="keyword">this</span>.maxBytes)</span><br><span class="line">            .metadata(data.metadata())</span><br><span class="line">            .toForget(data.toForget());   <span class="comment">// @3</span></span><br><span class="line"> </span><br><span class="line">        client.send(fetchTarget, request)    <span class="comment">// @4</span></span><br><span class="line">            .addListener(<span class="keyword">new</span> RequestFutureListener&lt;ClientResponse&gt;() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onSuccess</span><span class="params">(ClientResponse resp)</span> </span>&#123;  <span class="comment">// @5</span></span><br><span class="line">                    <span class="keyword">synchronized</span> (Fetcher.<span class="keyword">this</span>) &#123;</span><br><span class="line">                        <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">                        FetchResponse&lt;Records&gt; response = (FetchResponse&lt;Records&gt;) resp.responseBody();</span><br><span class="line">                        FetchSessionHandler handler = sessionHandler(fetchTarget.id());</span><br><span class="line">                        <span class="keyword">if</span> (handler == <span class="keyword">null</span>) &#123;</span><br><span class="line">                            log.error(<span class="string">&quot;Unable to find FetchSessionHandler for node &#123;&#125;. Ignoring fetch response.&quot;</span>,</span><br><span class="line">                                fetchTarget.id());</span><br><span class="line">                            <span class="keyword">return</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">if</span> (!handler.handleResponse(response)) &#123;</span><br><span class="line">                            <span class="keyword">return</span>;</span><br><span class="line">                        &#125;</span><br><span class="line"></span><br><span class="line">                        Set&lt;TopicPartition&gt; partitions = <span class="keyword">new</span> HashSet&lt;&gt;(response.responseData().keySet());</span><br><span class="line">                        FetchResponseMetricAggregator metricAggregator = <span class="keyword">new</span> FetchResponseMetricAggregator(sensors, partitions);</span><br><span class="line">                        <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, FetchResponse.PartitionData&lt;Records&gt;&gt; entry : </span><br><span class="line">                                 response.responseData().entrySet()) &#123;</span><br><span class="line">                            TopicPartition partition = entry.getKey();</span><br><span class="line">                            <span class="keyword">long</span> fetchOffset = data.sessionPartitions().get(partition).fetchOffset;</span><br><span class="line">                            FetchResponse.PartitionData&lt;Records&gt; fetchData = entry.getValue();</span><br><span class="line">                            completedFetches.add(<span class="keyword">new</span> CompletedFetch(partition, fetchOffset, fetchData, metricAggregator,</span><br><span class="line">                                resp.requestHeader().apiVersion()));</span><br><span class="line">                            &#125;    <span class="comment">// @6</span></span><br><span class="line"></span><br><span class="line">                            sensors.fetchLatency.record(resp.requestLatencyMs());</span><br><span class="line">                        &#125;</span><br><span class="line">                  &#125;</span><br><span class="line">                  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(RuntimeException e)</span> </span>&#123;  <span class="comment">// @7</span></span><br><span class="line">                    <span class="keyword">synchronized</span> (Fetcher.<span class="keyword">this</span>) &#123;</span><br><span class="line">                        FetchSessionHandler handler = sessionHandler(fetchTarget.id());</span><br><span class="line">                        <span class="keyword">if</span> (handler != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            handler.handleError(e);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> fetchRequestMap.size();</span><br><span class="line">&#125;</span><br><span class="line">​~~~java</span><br><span class="line">上面的方法比较长，其实现的关键点如下：</span><br><span class="line">代码@<span class="number">1</span>：通过调用 Fetcher 的 prepareFetchRequests 方法按节点组装拉取请求，将在后面详细介绍。</span><br><span class="line"></span><br><span class="line">代码@<span class="number">2</span>：遍历上面的待发请求，进一步组装请求。下面就是分节点发送拉取请求。</span><br><span class="line"></span><br><span class="line">代码@<span class="number">3</span>：构建 FetchRequest 拉取请求对象。</span><br><span class="line"></span><br><span class="line">代码@<span class="number">4</span>：调用 NetworkClient 的 send 方法将其发送到发送缓存区，本文不会详细介绍网络方面的实现，但下文会截图说明拉取请求发送缓存区的一个关键点。</span><br><span class="line"></span><br><span class="line">代码@<span class="number">5</span>：这里会注册事件监听器，当消息从 broker 拉取到本地后触发回调，即消息拉取请求收到返回结果后会将返回结果放入到completedFetches 中（代码@<span class="number">6</span>），这就和上文消息拉取时 Fetcher 的 fetchedRecords 方法形成闭环。</span><br><span class="line">代码@<span class="number">7</span>：消息拉取一次处理。</span><br><span class="line"></span><br><span class="line">接下来详细介绍 prepareFetchRequests 方法。</span><br><span class="line"></span><br><span class="line">###### 2.2.2.1 Fetcher prepareFetchRequests 方法详解</span><br><span class="line">​~~~java</span><br><span class="line"><span class="keyword">private</span> Map&lt;Node, FetchSessionHandler.FetchRequestData&gt; prepareFetchRequests() &#123;</span><br><span class="line">    Map&lt;Node, FetchSessionHandler.Builder&gt; fetchable = <span class="keyword">new</span> LinkedHashMap&lt;&gt;();  </span><br><span class="line">    <span class="keyword">for</span> (TopicPartition partition : fetchablePartitions()) &#123;    <span class="comment">// @1</span></span><br><span class="line">        Node node = metadata.partitionInfoIfCurrent(partition).map(PartitionInfo::leader).orElse(<span class="keyword">null</span>);  <span class="comment">// @2</span></span><br><span class="line">        <span class="keyword">if</span> (node == <span class="keyword">null</span>) &#123;    <span class="comment">// @3</span></span><br><span class="line">            metadata.requestUpdate();</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (client.isUnavailable(node)) &#123;   <span class="comment">// @4</span></span><br><span class="line">           client.maybeThrowAuthFailure(node);</span><br><span class="line">           log.trace(<span class="string">&quot;Skipping fetch for partition &#123;&#125; because node &#123;&#125; is awaiting reconnect backoff&quot;</span>, partition, node);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (client.hasPendingRequests(node)) &#123;   <span class="comment">// @5</span></span><br><span class="line">            log.trace(<span class="string">&quot;Skipping fetch for partition &#123;&#125; because there is an in-flight request to &#123;&#125;&quot;</span>, partition, node);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// if there is a leader and no in-flight requests, issue a new fetch</span></span><br><span class="line">            FetchSessionHandler.Builder builder = fetchable.get(node);    <span class="comment">// @7</span></span><br><span class="line">            <span class="keyword">if</span> (builder == <span class="keyword">null</span>) &#123;</span><br><span class="line">                FetchSessionHandler handler = sessionHandler(node.id());</span><br><span class="line">                <span class="keyword">if</span> (handler == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    handler = <span class="keyword">new</span> FetchSessionHandler(logContext, node.id());</span><br><span class="line">                    sessionHandlers.put(node.id(), handler);</span><br><span class="line">                &#125;</span><br><span class="line">                builder = handler.newBuilder();</span><br><span class="line">                fetchable.put(node, builder);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">long</span> position = <span class="keyword">this</span>.subscriptions.position(partition);</span><br><span class="line">            builder.add(partition, <span class="keyword">new</span> FetchRequest.PartitionData(position, FetchRequest.INVALID_LOG_START_OFFSET,</span><br><span class="line">            <span class="keyword">this</span>.fetchSize, Optional.empty()));</span><br><span class="line">            log.debug(<span class="string">&quot;Added &#123;&#125; fetch request for partition &#123;&#125; at offset &#123;&#125; to node &#123;&#125;&quot;</span>, isolationLevel,</span><br><span class="line">                    partition, position, node);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    Map&lt;Node, FetchSessionHandler.FetchRequestData&gt; reqs = <span class="keyword">new</span> LinkedHashMap&lt;&gt;();  </span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;Node, FetchSessionHandler.Builder&gt; entry : fetchable.entrySet()) &#123;</span><br><span class="line">        reqs.put(entry.getKey(), entry.getValue().build());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> reqs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码@1：首先通过调用 fetchablePartitions() 获取可发起拉取任务的分区信息，下文简单介绍一下。</p>
<p>代码@2：如果该分区在客户端本地缓存中获取该分区的 Leader 节点信息。</p>
<p>代码@3：如果其 Leader 节点信息为空，则发起更新元数据请求，本次拉取任务将不会包含该分区。</p>
<p>代码@4：如果客户端与该分区的 Leader 连接为完成，如果是因为权限的原因则抛出ACL相关异常，否则打印日志，本次拉取请求不会包含该分区。</p>
<p>代码@5：判断该节点是否有挂起的拉取请求，即发送缓存区中是待发送的请求,如果有，本次将不会被拉取。</p>
<p>代码@6：构建拉取请求，分节点组织请求。</p>
<h6 id="2-2-2-2-NetworkClient-send-方法关键点"><a href="#2-2-2-2-NetworkClient-send-方法关键点" class="headerlink" title="2.2.2.2 NetworkClient send 方法关键点"></a>2.2.2.2 NetworkClient send 方法关键点</h6><p><img src="https://img-blog.csdnimg.cn/2019120819462738.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>NetworkClient 的 send 方法只是将其放入 unsent 中。<br><img src="https://img-blog.csdnimg.cn/20191208194637842.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>与上文的 client.hasPendingRequests(node) 方法遥相呼应。</p>
<p>3、总结<br>上面的源码分析有点长，也有点枯燥，我们还是画一张流程图来进行总结。<br><img src="https://img-blog.csdnimg.cn/20191208194720402.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191208194726675.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ByZXN0aWdlZGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>Kafka 的消息拉取流程还是比较复杂的，后面会基于上述流程，重点进行拆解，例如消费进度提交，负载队列重平衡等等。</p>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "18019-1573088808868-542",
			        "name": "中间件兴趣圈",
			        "qrcode": "https://img-blog.csdnimg.cn/20190314214003962.jpg",
			        "keyword": "more"
			    });
			}
			</script>
		]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>源码</tag>
        <tag>消息拉取</tag>
      </tags>
  </entry>
</search>
